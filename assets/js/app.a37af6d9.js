(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var r,s,i=e[0],l=e[1],c=e[2],d=0,u=[];d<i.length;d++)s=i[d],Object.prototype.hasOwnProperty.call(a,s)&&a[s]&&u.push(a[s][0]),a[s]=0;for(r in l)Object.prototype.hasOwnProperty.call(l,r)&&(n[r]=l[r]);for(p&&p(e);u.length;)u.shift()();return o.push.apply(o,c||[]),t()}function t(){for(var n,e=0;e<o.length;e++){for(var t=o[e],r=!0,i=1;i<t.length;i++){var l=t[i];0!==a[l]&&(r=!1)}r&&(o.splice(e--,1),n=s(s.s=t[0]))}return n}var r={},a={1:0},o=[];function s(e){if(r[e])return r[e].exports;var t=r[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,s),t.l=!0,t.exports}s.e=function(n){var e=[],t=a[n];if(0!==t)if(t)e.push(t[2]);else{var r=new Promise((function(e,r){t=a[n]=[e,r]}));e.push(t[2]=r);var o,i=document.createElement("script");i.charset="utf-8",i.timeout=120,s.nc&&i.setAttribute("nonce",s.nc),i.src=function(n){return s.p+"assets/js/"+({}[n]||n)+"."+{2:"ba2df60a",3:"7b7b7ad0",4:"ee8017dd",5:"522bd6ec",6:"24f2b434",7:"fa04b38a",8:"9ccba721",9:"616f3d23",10:"49a84f11",11:"dc1f7f59",12:"d5cafed8",13:"d35cdd82",14:"0552ffa3",15:"dd83f90d",16:"cd39b01c",17:"be2c5d1c",18:"30011395",19:"91079076",20:"b9d0dabe",21:"d9c47444",22:"acdf2bd8",23:"bcbd2fc3",24:"dd45921c",25:"fc4665a1",26:"604115fe",27:"fe372ae0",28:"269a2f2c",29:"cb38c79a",30:"2a72aaa6",31:"5e699f78",32:"7caefc7b",33:"2cba8fe7",34:"1633e2ed",35:"27c53d02",36:"525ea1a7",37:"f9997184",38:"2e481766",39:"9edefdc0",40:"d20c14a0",41:"4a8a99f7",42:"a3e6900d",43:"58146ace",44:"d54f7679",45:"9f3d0746",46:"67b6d541",47:"1bdc2f23",48:"ce48209b",49:"1124b5b8",50:"4836a5a2",51:"2e0285d8",52:"178fafe1",53:"76d6f991",54:"7bae518f",55:"8ad542dd",56:"eb3a5866",57:"66a548b5",58:"11c919a4",59:"56ee65ad",60:"3f3cc5b3",61:"6aafaf2b",62:"3e86764a",63:"eb854243",64:"047122c3",65:"ab3be43f",66:"0e819df1",67:"10046f7e",68:"dd3f9d4c",69:"61a878dc",70:"723f314f",71:"d885dd2c",72:"31685ecb",73:"b240ced0",74:"7463a336",75:"7a05004d",76:"ecb99c56",77:"c57bc56b",78:"00ee2dbd",79:"b145c896",80:"d71abb80",81:"1552378a",82:"5f88610a",83:"b80ddb74",84:"ae1cf267",85:"08950c74",86:"99955193",87:"7c290c78",88:"f7f4496c",89:"bf057c70",90:"886e171c",91:"9ee9ec0e",92:"1c227473",93:"4881a96e",94:"68ac79b2",95:"744db94e",96:"77331cfb",97:"a4e9229f",98:"60f98d83",99:"995587b3",100:"6713a918",101:"662a7fd4",102:"7caa9051",103:"d2e4b5ac",104:"1b4b2c8e",105:"fb4fd6d8",106:"a840626a",107:"87b06d77",108:"6b6c072f",109:"25e2c915",110:"2a66b5c5",111:"207f71bd",112:"8bd38d71",113:"6713bacc",114:"29464f99",115:"96eaf075",116:"4e5cb7b4",117:"d1a5de4c",118:"655c6520",119:"94830a2a",120:"01eb7047",121:"a68fd0f7",122:"93091491"}[n]+".js"}(n);var l=new Error;o=function(e){i.onerror=i.onload=null,clearTimeout(c);var t=a[n];if(0!==t){if(t){var r=e&&("load"===e.type?"missing":e.type),o=e&&e.target&&e.target.src;l.message="Loading chunk "+n+" failed.\n("+r+": "+o+")",l.name="ChunkLoadError",l.type=r,l.request=o,t[1](l)}a[n]=void 0}};var c=setTimeout((function(){o({type:"timeout",target:i})}),12e4);i.onerror=i.onload=o,document.head.appendChild(i)}return Promise.all(e)},s.m=n,s.c=r,s.d=function(n,e,t){s.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},s.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},s.t=function(n,e){if(1&e&&(n=s(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(s.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var r in n)s.d(t,r,function(e){return n[e]}.bind(null,r));return t},s.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return s.d(e,"a",e),e},s.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},s.p="/",s.oe=function(n){throw console.error(n),n};var i=window.webpackJsonp=window.webpackJsonp||[],l=i.push.bind(i);i.push=e,i=i.slice();for(var c=0;c<i.length;c++)e(i[c]);var p=l;o.push([99,0]),t()}([function(n,e,t){"use strict";function r(n,e,t,r,a,o,s,i){var l,c="function"==typeof n?n.options:n;if(e&&(c.render=e,c.staticRenderFns=t,c._compiled=!0),r&&(c.functional=!0),o&&(c._scopeId="data-v-"+o),s?(l=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),a&&a.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(s)},c._ssrRegister=l):a&&(l=i?function(){a.call(this,(c.functional?this.parent:this).$root.$options.shadowRoot)}:a),l)if(c.functional){c._injectStyles=l;var p=c.render;c.render=function(n,e){return l.call(e),p(n,e)}}else{var d=c.beforeCreate;c.beforeCreate=d?[].concat(d,l):[l]}return{exports:n,options:c}}t.d(e,"a",(function(){return r}))},function(n,e,t){"use strict";var r=function(n){return n&&n.Math===Math&&n};n.exports=r("object"==typeof globalThis&&globalThis)||r("object"==typeof window&&window)||r("object"==typeof self&&self)||r("object"==typeof global&&global)||r("object"==typeof this&&this)||function(){return this}()||Function("return this")()},function(n,e,t){"use strict";var r="object"==typeof document&&document.all;n.exports=void 0===r&&void 0!==r?function(n){return"function"==typeof n||n===r}:function(n){return"function"==typeof n}},function(n,e,t){"use strict";n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e,t){"use strict";var r=t(28),a=Function.prototype,o=a.call,s=r&&a.bind.bind(o,o);n.exports=r?s:function(n){return function(){return o.apply(n,arguments)}}},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){"use strict";var r=t(3);n.exports=!r((function(){return 7!==Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e,t){"use strict";var r=t(2);n.exports=function(n){return"object"==typeof n?null!==n:r(n)}},function(n,e,t){var r=t(69),a="object"==typeof self&&self&&self.Object===Object&&self,o=r||a||Function("return this")();n.exports=o},function(n,e,t){"use strict";var r=t(4),a=t(37),o=r({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return o(a(n),e)}},function(n,e,t){var r=t(166),a=t(169);n.exports=function(n,e){var t=a(n,e);return r(t)?t:void 0}},function(n,e,t){"use strict";t.d(e,"e",(function(){return r})),t.d(e,"b",(function(){return o})),t.d(e,"j",(function(){return s})),t.d(e,"g",(function(){return l})),t.d(e,"h",(function(){return c})),t.d(e,"i",(function(){return p})),t.d(e,"c",(function(){return d})),t.d(e,"f",(function(){return u})),t.d(e,"l",(function(){return m})),t.d(e,"m",(function(){return f})),t.d(e,"d",(function(){return h})),t.d(e,"k",(function(){return v})),t.d(e,"n",(function(){return b})),t.d(e,"a",(function(){return _}));t(16);const r=/#.*$/,a=/\.(md|html)$/,o=/\/$/,s=/^[a-z]+:/i;function i(n){return decodeURI(n).replace(r,"").replace(a,"")}function l(n){return s.test(n)}function c(n){return/^mailto:/.test(n)}function p(n){return/^tel:/.test(n)}function d(n){if(l(n))return n;if(!n)return"404";const e=n.match(r),t=e?e[0]:"",a=i(n);return o.test(a)?n:a+".html"+t}function u(n,e){const t=n.hash,a=function(n){const e=n&&n.match(r);if(e)return e[0]}(e);if(a&&t!==a)return!1;return i(n.path)===i(e)}function m(n,e,t){if(l(e))return{type:"external",path:e};t&&(e=function(n,e,t){const r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;const a=e.split("/");t&&a[a.length-1]||a.pop();const o=n.replace(/^\//,"").split("/");for(let n=0;n<o.length;n++){const e=o[n];".."===e?a.pop():"."!==e&&a.push(e)}""!==a[0]&&a.unshift("");return a.join("/")}(e,t));const r=i(e);for(let e=0;e<n.length;e++)if(i(n[e].regularPath)===r)return Object.assign({},n[e],{type:"page",path:d(n[e].path)});return console.error(`[vuepress] No matching page found for sidebar item "${e}"`),{}}function f(n,e,t,r){const{pages:a,themeConfig:o}=t,s=r&&o.locales&&o.locales[r]||o;if("auto"===(n.frontmatter.sidebar||s.sidebar||o.sidebar))return g(n);const i=s.sidebar||o.sidebar;if(i){const{base:t,config:r}=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(const r in e)if(0===(t=n,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(r)))return{base:r,config:e[r]};var t;return{}}(e,i);return"auto"===r?g(n):r?r.map(n=>function n(e,t,r,a=1){if("string"==typeof e)return m(t,e,r);if(Array.isArray(e))return Object.assign(m(t,e[0],r),{title:e[1]});{a>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const o=e.children||[];return 0===o.length&&e.path?Object.assign(m(t,e.path,r),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:o.map(e=>n(e,t,r,a+1)),collapsable:!1!==e.collapsable}}}(n,a,t)):[]}return[]}function g(n){const e=h(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map(e=>({type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}))}]}function h(n){let e;return(n=n.map(n=>Object.assign({},n))).forEach(n=>{2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)}),n.filter(n=>2===n.level)}function v(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function b(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function y(n){let e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function _(n,e){return y(e)-y(n)}},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){var r=t(15),a=t(151),o=t(152),s=r?r.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":s&&s in Object(n)?a(n):o(n)}},function(n,e,t){"use strict";var r=t(6),a=t(18),o=t(29);n.exports=r?function(n,e,t){return a.f(n,e,o(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){var r=t(8).Symbol;n.exports=r},function(n,e,t){"use strict";var r=t(26),a=t(37),o=t(38),s=t(145),i=t(147);r({target:"Array",proto:!0,arity:1,forced:t(3)((function(){return 4294967297!==[].push.call({length:4294967296},1)}))||!function(){try{Object.defineProperty([],"length",{writable:!1}).push()}catch(n){return n instanceof TypeError}}()},{push:function(n){var e=a(this),t=o(e),r=arguments.length;i(t+r);for(var l=0;l<r;l++)e[t]=arguments[l],t++;return s(e,t),t}})},function(n,e,t){"use strict";var r=t(4),a=r({}.toString),o=r("".slice);n.exports=function(n){return o(a(n),8,-1)}},function(n,e,t){"use strict";var r=t(6),a=t(62),o=t(108),s=t(63),i=t(53),l=TypeError,c=Object.defineProperty,p=Object.getOwnPropertyDescriptor;e.f=r?o?function(n,e,t){if(s(n),e=i(e),s(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var r=p(n,e);r&&r.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:r.configurable,enumerable:"enumerable"in t?t.enumerable:r.enumerable,writable:!1})}return c(n,e,t)}:c:function(n,e,t){if(s(n),e=i(e),s(t),a)try{return c(n,e,t)}catch(n){}if("get"in t||"set"in t)throw new l("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var r=t(156),a=t(157),o=t(158),s=t(159),i=t(160);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=a,l.prototype.get=o,l.prototype.has=s,l.prototype.set=i,n.exports=l},function(n,e,t){var r=t(71);n.exports=function(n,e){for(var t=n.length;t--;)if(r(n[t][0],e))return t;return-1}},function(n,e,t){var r=t(10)(Object,"create");n.exports=r},function(n,e,t){var r=t(178);n.exports=function(n,e){var t=n.__data__;return r(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var r=t(46);n.exports=function(n){if("string"==typeof n||r(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var r,a;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(a="function"==typeof(r=function(){var n,e,t={version:"0.2.0"},r=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function a(n,e,t){return n<e?e:n>t?t:n}function o(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(r[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=a(n,r.minimum,1),t.status=1===n?null:n;var l=t.render(!e),c=l.querySelector(r.barSelector),p=r.speed,d=r.easing;return l.offsetWidth,s((function(e){""===r.positionUsing&&(r.positionUsing=t.getPositioningCSS()),i(c,function(n,e,t){var a;return(a="translate3d"===r.positionUsing?{transform:"translate3d("+o(n)+"%,0,0)"}:"translate"===r.positionUsing?{transform:"translate("+o(n)+"%,0)"}:{"margin-left":o(n)+"%"}).transition="all "+e+"ms "+t,a}(n,p,d)),1===n?(i(l,{transition:"none",opacity:1}),l.offsetWidth,setTimeout((function(){i(l,{transition:"all "+p+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),p)}),p)):setTimeout(e,p)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),r.trickleSpeed)};return r.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*a(Math.random()*e,.1,.95)),e=a(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*r.trickleRate)},n=0,e=0,t.promise=function(r){return r&&"resolved"!==r.state()?(0===e&&t.start(),n++,e++,r.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");c(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=r.template;var a,s=e.querySelector(r.barSelector),l=n?"-100":o(t.status||0),p=document.querySelector(r.parent);return i(s,{transition:"all 0 linear",transform:"translate3d("+l+"%,0,0)"}),r.showSpinner||(a=e.querySelector(r.spinnerSelector))&&u(a),p!=document.body&&c(p,"nprogress-custom-parent"),p.appendChild(e),e},t.remove=function(){p(document.documentElement,"nprogress-busy"),p(document.querySelector(r.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&u(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var s=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),i=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var r,a=n.length,o=e.charAt(0).toUpperCase()+e.slice(1);a--;)if((r=n[a]+o)in t)return r;return e}(t))}function r(n,e,r){e=t(e),n.style[e]=r}return function(n,e){var t,a,o=arguments;if(2==o.length)for(t in e)void 0!==(a=e[t])&&e.hasOwnProperty(t)&&r(n,t,a);else r(n,o[1],o[2])}}();function l(n,e){return("string"==typeof n?n:d(n)).indexOf(" "+e+" ")>=0}function c(n,e){var t=d(n),r=t+e;l(t,e)||(n.className=r.substring(1))}function p(n,e){var t,r=d(n);l(n,e)&&(t=r.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function d(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function u(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?r.call(e,t,e,n):r)||(n.exports=a)},function(n){n.exports=JSON.parse('{"name":"vuepress-plugin-comment-plus","version":"1.1.0","description":"Comment plugin in vuepress, such as Gitalk, Valine...","main":"index.js","scripts":{"test":"echo \\"Error: no test specified\\" && exit 1"},"repository":{"type":"git","url":"git+ssh://git@github.com/SivanLaai/vuepress-plugin-comment-plus.git"},"keywords":["vuepress","comment","plugin","vue","gitalk","valine","waline"],"author":"dongyuanxin","license":"MIT","bugs":{"url":"https://github.com/SivanLaai/vuepress-plugin-comment-plus/issues"},"homepage":"https://github.com/SivanLaai/vuepress-plugin-comment-plus#readme","dependencies":{"ejs":"^2.6.1","gitalk":"^1.5.0","gitalk-fix":"^1.5.2","i":"^0.3.6","npm":"^6.9.0","valine":"^1.3.9","@waline/client":"^1.3.3"},"__npminstall_done":true,"_from":"vuepress-plugin-comment-plus@1.1.0","_resolved":"https://registry.npmmirror.com/vuepress-plugin-comment-plus/-/vuepress-plugin-comment-plus-1.1.0.tgz"}')},function(n,e,t){"use strict";var r=t(1),a=t(50).f,o=t(14),s=t(109),i=t(36),l=t(65),c=t(125);n.exports=function(n,e){var t,p,d,u,m,f=n.target,g=n.global,h=n.stat;if(t=g?r:h?r[f]||i(f,{}):r[f]&&r[f].prototype)for(p in e){if(u=e[p],d=n.dontCallGetSet?(m=a(t,p))&&m.value:t[p],!c(g?p:f+(h?".":"#")+p,n.forced)&&void 0!==d){if(typeof u==typeof d)continue;l(u,d)}(n.sham||d&&d.sham)&&o(u,"sham",!0),s(t,p,u,n)}}},function(n,e,t){"use strict";var r=t(28),a=Function.prototype.call;n.exports=r?a.bind(a):function(){return a.apply(a,arguments)}},function(n,e,t){"use strict";var r=t(3);n.exports=!r((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e,t){"use strict";n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){"use strict";var r=t(51),a=t(31);n.exports=function(n){return r(a(n))}},function(n,e,t){"use strict";var r=t(52),a=TypeError;n.exports=function(n){if(r(n))throw new a("Can't call method on "+n);return n}},function(n,e,t){"use strict";var r=t(1),a=t(2),o=function(n){return a(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?o(r[n]):r[n]&&r[n][e]}},function(n,e,t){"use strict";var r=t(2),a=t(105),o=TypeError;n.exports=function(n){if(r(n))return n;throw new o(a(n)+" is not a function")}},function(n,e,t){"use strict";var r=t(1),a=t(59),o=t(9),s=t(61),i=t(57),l=t(56),c=r.Symbol,p=a("wks"),d=l?c.for||c:c&&c.withoutSetter||s;n.exports=function(n){return o(p,n)||(p[n]=i&&o(c,n)?c[n]:d("Symbol."+n)),p[n]}},function(n,e,t){"use strict";var r=t(60),a=t(1),o=t(36),s=n.exports=a["__core-js_shared__"]||o("__core-js_shared__",{});(s.versions||(s.versions=[])).push({version:"3.37.1",mode:r?"pure":"global",copyright:"© 2014-2024 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.37.1/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e,t){"use strict";var r=t(1),a=Object.defineProperty;n.exports=function(n,e){try{a(r,n,{value:e,configurable:!0,writable:!0})}catch(t){r[n]=e}return e}},function(n,e,t){"use strict";var r=t(31),a=Object;n.exports=function(n){return a(r(n))}},function(n,e,t){"use strict";var r=t(122);n.exports=function(n){return r(n.length)}},function(n,e,t){var r=t(150),a=t(12),o=Object.prototype,s=o.hasOwnProperty,i=o.propertyIsEnumerable,l=r(function(){return arguments}())?r:function(n){return a(n)&&s.call(n,"callee")&&!i.call(n,"callee")};n.exports=l},function(n,e,t){var r=t(10)(t(8),"Map");n.exports=r},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var r=t(170),a=t(177),o=t(179),s=t(180),i=t(181);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=a,l.prototype.get=o,l.prototype.has=s,l.prototype.set=i,n.exports=l},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var r=t(5),a=t(46),o=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,s=/^\w*$/;n.exports=function(n,e){if(r(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!a(n))||(s.test(n)||!o.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var r=t(13),a=t(12);n.exports=function(n){return"symbol"==typeof n||a(n)&&"[object Symbol]"==r(n)}},function(n,e){n.exports=function(n){return n}},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e){var t=/^\s+|\s+$/g,r=/^[-+]0x[0-9a-f]+$/i,a=/^0b[01]+$/i,o=/^0o[0-7]+$/i,s=parseInt,i="object"==typeof global&&global&&global.Object===Object&&global,l="object"==typeof self&&self&&self.Object===Object&&self,c=i||l||Function("return this")(),p=Object.prototype.toString,d=Math.max,u=Math.min,m=function(){return c.Date.now()};function f(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function g(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==p.call(n)}(n))return NaN;if(f(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=f(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var i=a.test(n);return i||o.test(n)?s(n.slice(2),i?2:8):r.test(n)?NaN:+n}n.exports=function(n,e,t){var r,a,o,s,i,l,c=0,p=!1,h=!1,v=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function b(e){var t=r,o=a;return r=a=void 0,c=e,s=n.apply(o,t)}function y(n){return c=n,i=setTimeout(k,e),p?b(n):s}function _(n){var t=n-l;return void 0===l||t>=e||t<0||h&&n-c>=o}function k(){var n=m();if(_(n))return w(n);i=setTimeout(k,function(n){var t=e-(n-l);return h?u(t,o-(n-c)):t}(n))}function w(n){return i=void 0,v&&r?b(n):(r=a=void 0,s)}function x(){var n=m(),t=_(n);if(r=arguments,a=this,l=n,t){if(void 0===i)return y(l);if(h)return i=setTimeout(k,e),b(l)}return void 0===i&&(i=setTimeout(k,e)),s}return e=g(e)||0,f(t)&&(p=!!t.leading,o=(h="maxWait"in t)?d(g(t.maxWait)||0,e):o,v="trailing"in t?!!t.trailing:v),x.cancel=function(){void 0!==i&&clearTimeout(i),c=0,r=l=a=i=void 0},x.flush=function(){return void 0===i?s:w(m())},x}},function(n,e,t){"use strict";var r=t(6),a=t(27),o=t(101),s=t(29),i=t(30),l=t(53),c=t(9),p=t(62),d=Object.getOwnPropertyDescriptor;e.f=r?d:function(n,e){if(n=i(n),e=l(e),p)try{return d(n,e)}catch(n){}if(c(n,e))return s(!a(o.f,n,e),n[e])}},function(n,e,t){"use strict";var r=t(4),a=t(3),o=t(17),s=Object,i=r("".split);n.exports=a((function(){return!s("z").propertyIsEnumerable(0)}))?function(n){return"String"===o(n)?i(n,""):s(n)}:s},function(n,e,t){"use strict";n.exports=function(n){return null==n}},function(n,e,t){"use strict";var r=t(102),a=t(54);n.exports=function(n){var e=r(n,"string");return a(e)?e:e+""}},function(n,e,t){"use strict";var r=t(32),a=t(2),o=t(55),s=t(56),i=Object;n.exports=s?function(n){return"symbol"==typeof n}:function(n){var e=r("Symbol");return a(e)&&o(e.prototype,i(n))}},function(n,e,t){"use strict";var r=t(4);n.exports=r({}.isPrototypeOf)},function(n,e,t){"use strict";var r=t(57);n.exports=r&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){"use strict";var r=t(58),a=t(3),o=t(1).String;n.exports=!!Object.getOwnPropertySymbols&&!a((function(){var n=Symbol("symbol detection");return!o(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&r&&r<41}))},function(n,e,t){"use strict";var r,a,o=t(1),s=t(103),i=o.process,l=o.Deno,c=i&&i.versions||l&&l.version,p=c&&c.v8;p&&(a=(r=p.split("."))[0]>0&&r[0]<4?1:+(r[0]+r[1])),!a&&s&&(!(r=s.match(/Edge\/(\d+)/))||r[1]>=74)&&(r=s.match(/Chrome\/(\d+)/))&&(a=+r[1]),n.exports=a},function(n,e,t){"use strict";var r=t(35);n.exports=function(n,e){return r[n]||(r[n]=e||{})}},function(n,e,t){"use strict";n.exports=!1},function(n,e,t){"use strict";var r=t(4),a=0,o=Math.random(),s=r(1..toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+s(++a+o,36)}},function(n,e,t){"use strict";var r=t(6),a=t(3),o=t(107);n.exports=!r&&!a((function(){return 7!==Object.defineProperty(o("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){"use strict";var r=t(7),a=String,o=TypeError;n.exports=function(n){if(r(n))return n;throw new o(a(n)+" is not an object")}},function(n,e,t){"use strict";n.exports={}},function(n,e,t){"use strict";var r=t(9),a=t(116),o=t(50),s=t(18);n.exports=function(n,e,t){for(var i=a(e),l=s.f,c=o.f,p=0;p<i.length;p++){var d=i[p];r(n,d)||t&&r(t,d)||l(n,d,c(e,d))}}},function(n,e,t){"use strict";var r=t(121);n.exports=function(n){var e=+n;return e!=e||0===e?0:r(e)}},function(n,e,t){"use strict";var r=t(132),a=t(7),o=t(31),s=t(133);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=r(Object.prototype,"__proto__","set"))(t,[]),e=t instanceof Array}catch(n){}return function(t,r){return o(t),s(r),a(t)?(e?n(t,r):t.__proto__=r,t):t}}():void 0)},function(n,e){n.exports=function(n,e){for(var t=-1,r=e.length,a=n.length;++t<r;)n[a+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var r=t(19),a=t(161),o=t(162),s=t(163),i=t(164),l=t(165);function c(n){var e=this.__data__=new r(n);this.size=e.size}c.prototype.clear=a,c.prototype.delete=o,c.prototype.get=s,c.prototype.has=i,c.prototype.set=l,n.exports=c},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var r=t(13),a=t(41);n.exports=function(n){if(!a(n))return!1;var e=r(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var r=t(182),a=t(12);n.exports=function n(e,t,o,s,i){return e===t||(null==e||null==t||!a(e)&&!a(t)?e!=e&&t!=t:r(e,t,o,s,n,i))}},function(n,e,t){var r=t(76),a=t(185),o=t(77);n.exports=function(n,e,t,s,i,l){var c=1&t,p=n.length,d=e.length;if(p!=d&&!(c&&d>p))return!1;var u=l.get(n),m=l.get(e);if(u&&m)return u==e&&m==n;var f=-1,g=!0,h=2&t?new r:void 0;for(l.set(n,e),l.set(e,n);++f<p;){var v=n[f],b=e[f];if(s)var y=c?s(b,v,f,e,n,l):s(v,b,f,n,e,l);if(void 0!==y){if(y)continue;g=!1;break}if(h){if(!a(e,(function(n,e){if(!o(h,e)&&(v===n||i(v,n,t,s,l)))return h.push(e)}))){g=!1;break}}else if(v!==b&&!i(v,b,t,s,l)){g=!1;break}}return l.delete(n),l.delete(e),g}},function(n,e,t){var r=t(42),a=t(183),o=t(184);function s(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new r;++e<t;)this.add(n[e])}s.prototype.add=s.prototype.push=a,s.prototype.has=o,n.exports=s},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var r=t(195),a=t(201),o=t(82);n.exports=function(n){return o(n)?r(n):a(n)}},function(n,e,t){(function(n){var r=t(8),a=t(197),o=e&&!e.nodeType&&e,s=o&&"object"==typeof n&&n&&!n.nodeType&&n,i=s&&s.exports===o?r.Buffer:void 0,l=(i?i.isBuffer:void 0)||a;n.exports=l}).call(this,t(48)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var r=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==r||"symbol"!=r&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var r=t(198),a=t(199),o=t(200),s=o&&o.isTypedArray,i=s?a(s):r;n.exports=i},function(n,e,t){var r=t(72),a=t(44);n.exports=function(n){return null!=n&&a(n.length)&&!r(n)}},function(n,e,t){var r=t(10)(t(8),"Set");n.exports=r},function(n,e,t){var r=t(41);n.exports=function(n){return n==n&&!r(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var r=t(87),a=t(23);n.exports=function(n,e){for(var t=0,o=(e=r(e,n)).length;null!=n&&t<o;)n=n[a(e[t++])];return t&&t==o?n:void 0}},function(n,e,t){var r=t(5),a=t(45),o=t(212),s=t(215);n.exports=function(n,e){return r(n)?n:a(n,e)?[n]:o(s(n))}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(148),a=t(153),o=t(224),s=t(232),i=t(241),l=t(98),c=o((function(n){var e=l(n);return i(e)&&(e=void 0),s(r(n,1,i,!0),a(e,2))}));n.exports=c},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var r=/["'&<>]/;n.exports=function(n){var e,t=""+n,a=r.exec(t);if(!a)return t;var o="",s=0,i=0;for(s=a.index;s<t.length;s++){switch(t.charCodeAt(s)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}i!==s&&(o+=t.substring(i,s)),i=s+1,o+=e}return i!==s?o+t.substring(i,s):o}},function(n,e,t){"use strict";
/**
 * @file Embedded JavaScript templating engine. {@link http://ejs.co}
 * @author Matthew Eernisse <mde@fleegix.org>
 * @author Tiancheng "Timothy" Gu <timothygu99@gmail.com>
 * @project EJS
 * @license {@link http://www.apache.org/licenses/LICENSE-2.0 Apache License, Version 2.0}
 */var r=t(248),a=t(249),o=t(250),s=!1,i=t(251).version,l=["delimiter","scope","context","debug","compileDebug","client","_with","rmWhitespace","strict","filename","async"],c=l.concat("cache"),p=/^\uFEFF/,d=/^[a-zA-Z_$][0-9a-zA-Z_$]*$/;function u(n,t){var a;if(t.some((function(t){return a=e.resolveInclude(n,t,!0),r.existsSync(a)})))return a}function m(n,t){var r,a=n.filename,o=arguments.length>1;if(n.cache){if(!a)throw new Error("cache option requires a filename");if(r=e.cache.get(a))return r;o||(t=g(a).toString().replace(p,""))}else if(!o){if(!a)throw new Error("Internal EJS error: no file name or template provided");t=g(a).toString().replace(p,"")}return r=e.compile(t,n),n.cache&&e.cache.set(a,r),r}function f(n,t,r){var a;if(!r){if("function"==typeof e.promiseImpl)return new e.promiseImpl((function(e,r){try{e(a=m(n)(t))}catch(n){r(n)}}));throw new Error("Please provide a callback function")}try{a=m(n)(t)}catch(n){return r(n)}r(null,a)}function g(n){return e.fileLoader(n)}function h(n,t){var a=o.shallowCopy(o.createNullProtoObjWherePossible(),t);if(a.filename=function(n,t){var a,o,s=t.views,i=/^[A-Za-z]+:\\|^\//.exec(n);if(i&&i.length)n=n.replace(/^\/*/,""),a=Array.isArray(t.root)?u(n,t.root):e.resolveInclude(n,t.root||"/",!0);else if(t.filename&&(o=e.resolveInclude(n,t.filename),r.existsSync(o)&&(a=o)),!a&&Array.isArray(s)&&(a=u(n,s)),!a&&"function"!=typeof t.includer)throw new Error('Could not find the include file "'+t.escapeFunction(n)+'"');return a}(n,a),"function"==typeof t.includer){var s=t.includer(n,a.filename);if(s&&(s.filename&&(a.filename=s.filename),s.template))return m(a,s.template)}return m(a)}function v(n,e,t,r,a){var o=e.split("\n"),s=Math.max(r-3,0),i=Math.min(o.length,r+3),l=a(t),c=o.slice(s,i).map((function(n,e){var t=e+s+1;return(t==r?" >> ":"    ")+t+"| "+n})).join("\n");throw n.path=l,n.message=(l||"ejs")+":"+r+"\n"+c+"\n\n"+n.message,n}function b(n){return n.replace(/;(\s*$)/,"$1")}function y(n,t){var r=o.hasOwnOnlyObject(t),a=o.createNullProtoObjWherePossible();this.templateText=n,this.mode=null,this.truncate=!1,this.currentLine=1,this.source="",a.client=r.client||!1,a.escapeFunction=r.escape||r.escapeFunction||o.escapeXML,a.compileDebug=!1!==r.compileDebug,a.debug=!!r.debug,a.filename=r.filename,a.openDelimiter=r.openDelimiter||e.openDelimiter||"<",a.closeDelimiter=r.closeDelimiter||e.closeDelimiter||">",a.delimiter=r.delimiter||e.delimiter||"%",a.strict=r.strict||!1,a.context=r.context,a.cache=r.cache||!1,a.rmWhitespace=r.rmWhitespace,a.root=r.root,a.includer=r.includer,a.outputFunctionName=r.outputFunctionName,a.localsName=r.localsName||e.localsName||"locals",a.views=r.views,a.async=r.async,a.destructuredLocals=r.destructuredLocals,a.legacyInclude=void 0===r.legacyInclude||!!r.legacyInclude,a.strict?a._with=!1:a._with=void 0===r._with||r._with,this.opts=a,this.regex=this.createRegex()}e.cache=o.cache,e.fileLoader=r.readFileSync,e.localsName="locals",e.promiseImpl=new Function("return this;")().Promise,e.resolveInclude=function(n,e,t){var r=a.dirname,o=a.extname,s=(0,a.resolve)(t?e:r(e),n);return o(n)||(s+=".ejs"),s},e.compile=function(n,e){return e&&e.scope&&(s||(console.warn("`scope` option is deprecated and will be removed in EJS 3"),s=!0),e.context||(e.context=e.scope),delete e.scope),new y(n,e).compile()},e.render=function(n,e,t){var r=e||o.createNullProtoObjWherePossible(),a=t||o.createNullProtoObjWherePossible();return 2==arguments.length&&o.shallowCopyFromList(a,r,l),m(a,n)(r)},e.renderFile=function(){var n,e,t,r=Array.prototype.slice.call(arguments),a=r.shift(),s={filename:a};return"function"==typeof arguments[arguments.length-1]&&(n=r.pop()),r.length?(e=r.shift(),r.length?o.shallowCopy(s,r.pop()):(e.settings&&(e.settings.views&&(s.views=e.settings.views),e.settings["view cache"]&&(s.cache=!0),(t=e.settings["view options"])&&o.shallowCopy(s,t)),o.shallowCopyFromList(s,e,c)),s.filename=a):e=o.createNullProtoObjWherePossible(),f(s,e,n)},e.Template=y,e.clearCache=function(){e.cache.reset()},y.modes={EVAL:"eval",ESCAPED:"escaped",RAW:"raw",COMMENT:"comment",LITERAL:"literal"},y.prototype={createRegex:function(){var n="(<%%|%%>|<%=|<%-|<%_|<%#|<%|%>|-%>|_%>)",e=o.escapeRegExpChars(this.opts.delimiter),t=o.escapeRegExpChars(this.opts.openDelimiter),r=o.escapeRegExpChars(this.opts.closeDelimiter);return n=n.replace(/%/g,e).replace(/</g,t).replace(/>/g,r),new RegExp(n)},compile:function(){var n,e,t,r=this.opts,s="",i="",l=r.escapeFunction,c=r.filename?JSON.stringify(r.filename):"undefined";if(!this.source){if(this.generateSource(),s+='  var __output = "";\n  function __append(s) { if (s !== undefined && s !== null) __output += s }\n',r.outputFunctionName){if(!d.test(r.outputFunctionName))throw new Error("outputFunctionName is not a valid JS identifier.");s+="  var "+r.outputFunctionName+" = __append;\n"}if(r.localsName&&!d.test(r.localsName))throw new Error("localsName is not a valid JS identifier.");if(r.destructuredLocals&&r.destructuredLocals.length){for(var p="  var __locals = ("+r.localsName+" || {}),\n",u=0;u<r.destructuredLocals.length;u++){var m=r.destructuredLocals[u];if(!d.test(m))throw new Error("destructuredLocals["+u+"] is not a valid JS identifier.");u>0&&(p+=",\n  "),p+=m+" = __locals."+m}s+=p+";\n"}!1!==r._with&&(s+="  with ("+r.localsName+" || {}) {\n",i+="  }\n"),i+="  return __output;\n",this.source=s+this.source+i}n=r.compileDebug?"var __line = 1\n  , __lines = "+JSON.stringify(this.templateText)+"\n  , __filename = "+c+";\ntry {\n"+this.source+"} catch (e) {\n  rethrow(e, __lines, __filename, __line, escapeFn);\n}\n":this.source,r.client&&(n="escapeFn = escapeFn || "+l.toString()+";\n"+n,r.compileDebug&&(n="rethrow = rethrow || "+v.toString()+";\n"+n)),r.strict&&(n='"use strict";\n'+n),r.debug&&console.log(n),r.compileDebug&&r.filename&&(n=n+"\n//# sourceURL="+c+"\n");try{if(r.async)try{t=new Function("return (async function(){}).constructor;")()}catch(n){throw n instanceof SyntaxError?new Error("This environment does not support async/await"):n}else t=Function;e=new t(r.localsName+", escapeFn, include, rethrow",n)}catch(n){throw n instanceof SyntaxError&&(r.filename&&(n.message+=" in "+r.filename),n.message+=" while compiling ejs\n\n",n.message+="If the above error is not helpful, you may want to try EJS-Lint:\n",n.message+="https://github.com/RyanZim/EJS-Lint",r.async||(n.message+="\n",n.message+="Or, if you meant to create an async function, pass `async: true` as an option.")),n}var f=r.client?e:function(n){return e.apply(r.context,[n||o.createNullProtoObjWherePossible(),l,function(e,t){var a=o.shallowCopy(o.createNullProtoObjWherePossible(),n);return t&&(a=o.shallowCopy(a,t)),h(e,r)(a)},v])};if(r.filename&&"function"==typeof Object.defineProperty){var g=r.filename,b=a.basename(g,a.extname(g));try{Object.defineProperty(f,"name",{value:b,writable:!1,enumerable:!1,configurable:!0})}catch(n){}}return f},generateSource:function(){this.opts.rmWhitespace&&(this.templateText=this.templateText.replace(/[\r\n]+/g,"\n").replace(/^\s+|\s+$/gm,"")),this.templateText=this.templateText.replace(/[ \t]*<%_/gm,"<%_").replace(/_%>[ \t]*/gm,"_%>");var n=this,e=this.parseTemplateText(),t=this.opts.delimiter,r=this.opts.openDelimiter,a=this.opts.closeDelimiter;e&&e.length&&e.forEach((function(o,s){var i;if(0===o.indexOf(r+t)&&0!==o.indexOf(r+t+t)&&(i=e[s+2])!=t+a&&i!="-"+t+a&&i!="_"+t+a)throw new Error('Could not find matching close tag for "'+o+'".');n.scanLine(o)}))},parseTemplateText:function(){for(var n,e=this.templateText,t=this.regex,r=t.exec(e),a=[];r;)0!==(n=r.index)&&(a.push(e.substring(0,n)),e=e.slice(n)),a.push(r[0]),e=e.slice(r[0].length),r=t.exec(e);return e&&a.push(e),a},_addOutput:function(n){if(this.truncate&&(n=n.replace(/^(?:\r\n|\r|\n)/,""),this.truncate=!1),!n)return n;n=(n=(n=(n=n.replace(/\\/g,"\\\\")).replace(/\n/g,"\\n")).replace(/\r/g,"\\r")).replace(/"/g,'\\"'),this.source+='    ; __append("'+n+'")\n'},scanLine:function(n){var e,t=this.opts.delimiter,r=this.opts.openDelimiter,a=this.opts.closeDelimiter;switch(e=n.split("\n").length-1,n){case r+t:case r+t+"_":this.mode=y.modes.EVAL;break;case r+t+"=":this.mode=y.modes.ESCAPED;break;case r+t+"-":this.mode=y.modes.RAW;break;case r+t+"#":this.mode=y.modes.COMMENT;break;case r+t+t:this.mode=y.modes.LITERAL,this.source+='    ; __append("'+n.replace(r+t+t,r+t)+'")\n';break;case t+t+a:this.mode=y.modes.LITERAL,this.source+='    ; __append("'+n.replace(t+t+a,t+a)+'")\n';break;case t+a:case"-"+t+a:case"_"+t+a:this.mode==y.modes.LITERAL&&this._addOutput(n),this.mode=null,this.truncate=0===n.indexOf("-")||0===n.indexOf("_");break;default:if(this.mode){switch(this.mode){case y.modes.EVAL:case y.modes.ESCAPED:case y.modes.RAW:n.lastIndexOf("//")>n.lastIndexOf("\n")&&(n+="\n")}switch(this.mode){case y.modes.EVAL:this.source+="    ; "+n+"\n";break;case y.modes.ESCAPED:this.source+="    ; __append(escapeFn("+b(n)+"))\n";break;case y.modes.RAW:this.source+="    ; __append("+b(n)+")\n";break;case y.modes.COMMENT:break;case y.modes.LITERAL:this._addOutput(n)}}else this._addOutput(n)}this.opts.compileDebug&&e&&(this.currentLine+=e,this.source+="    ; __line = "+this.currentLine+"\n")}},e.escapeXML=o.escapeXML,e.__express=e.renderFile,e.VERSION=i,e.name="ejs","undefined"!=typeof window&&(window.ejs=e)},function(n,e,t){"use strict";t.r(e);var r={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},a=(t(244),t(0)),o=Object(a.a)(r,(function(){var n=this.$createElement;return(this._self._c||n)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"6c83c644",null);e.default=o.exports},function(n,e,t){"use strict";t.r(e);var r={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(n){this.codeTabs.forEach(n=>{n.elm.classList.remove("theme-code-block__active")}),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(n=>Boolean(n.componentOptions)).map((n,e)=>(""===n.componentOptions.propsData.active&&(this.activeCodeTabIndex=e),{title:n.componentOptions.propsData.title,elm:n.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(n){this.activeCodeTabIndex=n}}},a=(t(245),t(0)),o=Object(a.a)(r,(function(){var n=this,e=n.$createElement,t=n._self._c||e;return t("div",{staticClass:"theme-code-group"},[t("div",{staticClass:"theme-code-group__nav"},[t("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(e,r){return t("li",{key:e.title,staticClass:"theme-code-group__li"},[t("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":r===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(r)}}},[n._v("\n            "+n._s(e.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?t("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"24edfee2",null);e.default=o.exports},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){n.exports=t(255)},function(n,e,t){"use strict";var r=t(26),a=t(126).left,o=t(127),s=t(58);r({target:"Array",proto:!0,forced:!t(128)&&s>79&&s<83||!o("reduce")},{reduce:function(n){var e=arguments.length;return a(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r={}.propertyIsEnumerable,a=Object.getOwnPropertyDescriptor,o=a&&!r.call({1:2},1);e.f=o?function(n){var e=a(this,n);return!!e&&e.enumerable}:r},function(n,e,t){"use strict";var r=t(27),a=t(7),o=t(54),s=t(104),i=t(106),l=t(34),c=TypeError,p=l("toPrimitive");n.exports=function(n,e){if(!a(n)||o(n))return n;var t,l=s(n,p);if(l){if(void 0===e&&(e="default"),t=r(l,n,e),!a(t)||o(t))return t;throw new c("Can't convert object to primitive value")}return void 0===e&&(e="number"),i(n,e)}},function(n,e,t){"use strict";n.exports="undefined"!=typeof navigator&&String(navigator.userAgent)||""},function(n,e,t){"use strict";var r=t(33),a=t(52);n.exports=function(n,e){var t=n[e];return a(t)?void 0:r(t)}},function(n,e,t){"use strict";var r=String;n.exports=function(n){try{return r(n)}catch(n){return"Object"}}},function(n,e,t){"use strict";var r=t(27),a=t(2),o=t(7),s=TypeError;n.exports=function(n,e){var t,i;if("string"===e&&a(t=n.toString)&&!o(i=r(t,n)))return i;if(a(t=n.valueOf)&&!o(i=r(t,n)))return i;if("string"!==e&&a(t=n.toString)&&!o(i=r(t,n)))return i;throw new s("Can't convert object to primitive value")}},function(n,e,t){"use strict";var r=t(1),a=t(7),o=r.document,s=a(o)&&a(o.createElement);n.exports=function(n){return s?o.createElement(n):{}}},function(n,e,t){"use strict";var r=t(6),a=t(3);n.exports=r&&a((function(){return 42!==Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){"use strict";var r=t(2),a=t(18),o=t(110),s=t(36);n.exports=function(n,e,t,i){i||(i={});var l=i.enumerable,c=void 0!==i.name?i.name:e;if(r(t)&&o(t,c,i),i.global)l?n[e]=t:s(e,t);else{try{i.unsafe?n[e]&&(l=!0):delete n[e]}catch(n){}l?n[e]=t:a.f(n,e,{value:t,enumerable:!1,configurable:!i.nonConfigurable,writable:!i.nonWritable})}return n}},function(n,e,t){"use strict";var r=t(4),a=t(3),o=t(2),s=t(9),i=t(6),l=t(111).CONFIGURABLE,c=t(112),p=t(113),d=p.enforce,u=p.get,m=String,f=Object.defineProperty,g=r("".slice),h=r("".replace),v=r([].join),b=i&&!a((function(){return 8!==f((function(){}),"length",{value:8}).length})),y=String(String).split("String"),_=n.exports=function(n,e,t){"Symbol("===g(m(e),0,7)&&(e="["+h(m(e),/^Symbol\(([^)]*)\).*$/,"$1")+"]"),t&&t.getter&&(e="get "+e),t&&t.setter&&(e="set "+e),(!s(n,"name")||l&&n.name!==e)&&(i?f(n,"name",{value:e,configurable:!0}):n.name=e),b&&t&&s(t,"arity")&&n.length!==t.arity&&f(n,"length",{value:t.arity});try{t&&s(t,"constructor")&&t.constructor?i&&f(n,"prototype",{writable:!1}):n.prototype&&(n.prototype=void 0)}catch(n){}var r=d(n);return s(r,"source")||(r.source=v(y,"string"==typeof e?e:"")),n};Function.prototype.toString=_((function(){return o(this)&&u(this).source||c(this)}),"toString")},function(n,e,t){"use strict";var r=t(6),a=t(9),o=Function.prototype,s=r&&Object.getOwnPropertyDescriptor,i=a(o,"name"),l=i&&"something"===function(){}.name,c=i&&(!r||r&&s(o,"name").configurable);n.exports={EXISTS:i,PROPER:l,CONFIGURABLE:c}},function(n,e,t){"use strict";var r=t(4),a=t(2),o=t(35),s=r(Function.toString);a(o.inspectSource)||(o.inspectSource=function(n){return s(n)}),n.exports=o.inspectSource},function(n,e,t){"use strict";var r,a,o,s=t(114),i=t(1),l=t(7),c=t(14),p=t(9),d=t(35),u=t(115),m=t(64),f=i.TypeError,g=i.WeakMap;if(s||d.state){var h=d.state||(d.state=new g);h.get=h.get,h.has=h.has,h.set=h.set,r=function(n,e){if(h.has(n))throw new f("Object already initialized");return e.facade=n,h.set(n,e),e},a=function(n){return h.get(n)||{}},o=function(n){return h.has(n)}}else{var v=u("state");m[v]=!0,r=function(n,e){if(p(n,v))throw new f("Object already initialized");return e.facade=n,c(n,v,e),e},a=function(n){return p(n,v)?n[v]:{}},o=function(n){return p(n,v)}}n.exports={set:r,get:a,has:o,enforce:function(n){return o(n)?a(n):r(n,{})},getterFor:function(n){return function(e){var t;if(!l(e)||(t=a(e)).type!==n)throw new f("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){"use strict";var r=t(1),a=t(2),o=r.WeakMap;n.exports=a(o)&&/native code/.test(String(o))},function(n,e,t){"use strict";var r=t(59),a=t(61),o=r("keys");n.exports=function(n){return o[n]||(o[n]=a(n))}},function(n,e,t){"use strict";var r=t(32),a=t(4),o=t(117),s=t(124),i=t(63),l=a([].concat);n.exports=r("Reflect","ownKeys")||function(n){var e=o.f(i(n)),t=s.f;return t?l(e,t(n)):e}},function(n,e,t){"use strict";var r=t(118),a=t(123).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return r(n,a)}},function(n,e,t){"use strict";var r=t(4),a=t(9),o=t(30),s=t(119).indexOf,i=t(64),l=r([].push);n.exports=function(n,e){var t,r=o(n),c=0,p=[];for(t in r)!a(i,t)&&a(r,t)&&l(p,t);for(;e.length>c;)a(r,t=e[c++])&&(~s(p,t)||l(p,t));return p}},function(n,e,t){"use strict";var r=t(30),a=t(120),o=t(38),s=function(n){return function(e,t,s){var i=r(e),l=o(i);if(0===l)return!n&&-1;var c,p=a(s,l);if(n&&t!=t){for(;l>p;)if((c=i[p++])!=c)return!0}else for(;l>p;p++)if((n||p in i)&&i[p]===t)return n||p||0;return!n&&-1}};n.exports={includes:s(!0),indexOf:s(!1)}},function(n,e,t){"use strict";var r=t(66),a=Math.max,o=Math.min;n.exports=function(n,e){var t=r(n);return t<0?a(t+e,0):o(t,e)}},function(n,e,t){"use strict";var r=Math.ceil,a=Math.floor;n.exports=Math.trunc||function(n){var e=+n;return(e>0?a:r)(e)}},function(n,e,t){"use strict";var r=t(66),a=Math.min;n.exports=function(n){var e=r(n);return e>0?a(e,9007199254740991):0}},function(n,e,t){"use strict";n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){"use strict";e.f=Object.getOwnPropertySymbols},function(n,e,t){"use strict";var r=t(3),a=t(2),o=/#|\.prototype\./,s=function(n,e){var t=l[i(n)];return t===p||t!==c&&(a(e)?r(e):!!e)},i=s.normalize=function(n){return String(n).replace(o,".").toLowerCase()},l=s.data={},c=s.NATIVE="N",p=s.POLYFILL="P";n.exports=s},function(n,e,t){"use strict";var r=t(33),a=t(37),o=t(51),s=t(38),i=TypeError,l="Reduce of empty array with no initial value",c=function(n){return function(e,t,c,p){var d=a(e),u=o(d),m=s(d);if(r(t),0===m&&c<2)throw new i(l);var f=n?m-1:0,g=n?-1:1;if(c<2)for(;;){if(f in u){p=u[f],f+=g;break}if(f+=g,n?f<0:m<=f)throw new i(l)}for(;n?f>=0:m>f;f+=g)f in u&&(p=t(p,u[f],f,d));return p}};n.exports={left:c(!1),right:c(!0)}},function(n,e,t){"use strict";var r=t(3);n.exports=function(n,e){var t=[][n];return!!t&&r((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){"use strict";var r=t(1),a=t(17);n.exports="process"===a(r.process)},function(n,e,t){"use strict";var r=t(26),a=t(1),o=t(130),s=t(131),i=a.WebAssembly,l=7!==new Error("e",{cause:7}).cause,c=function(n,e){var t={};t[n]=s(n,e,l),r({global:!0,constructor:!0,arity:1,forced:l},t)},p=function(n,e){if(i&&i[n]){var t={};t[n]=s("WebAssembly."+n,e,l),r({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:l},t)}};c("Error",(function(n){return function(e){return o(n,this,arguments)}})),c("EvalError",(function(n){return function(e){return o(n,this,arguments)}})),c("RangeError",(function(n){return function(e){return o(n,this,arguments)}})),c("ReferenceError",(function(n){return function(e){return o(n,this,arguments)}})),c("SyntaxError",(function(n){return function(e){return o(n,this,arguments)}})),c("TypeError",(function(n){return function(e){return o(n,this,arguments)}})),c("URIError",(function(n){return function(e){return o(n,this,arguments)}})),p("CompileError",(function(n){return function(e){return o(n,this,arguments)}})),p("LinkError",(function(n){return function(e){return o(n,this,arguments)}})),p("RuntimeError",(function(n){return function(e){return o(n,this,arguments)}}))},function(n,e,t){"use strict";var r=t(28),a=Function.prototype,o=a.apply,s=a.call;n.exports="object"==typeof Reflect&&Reflect.apply||(r?s.bind(o):function(){return s.apply(o,arguments)})},function(n,e,t){"use strict";var r=t(32),a=t(9),o=t(14),s=t(55),i=t(67),l=t(65),c=t(135),p=t(136),d=t(137),u=t(141),m=t(142),f=t(6),g=t(60);n.exports=function(n,e,t,h){var v=h?2:1,b=n.split("."),y=b[b.length-1],_=r.apply(null,b);if(_){var k=_.prototype;if(!g&&a(k,"cause")&&delete k.cause,!t)return _;var w=r("Error"),x=e((function(n,e){var t=d(h?e:n,void 0),r=h?new _(n):new _;return void 0!==t&&o(r,"message",t),m(r,x,r.stack,2),this&&s(k,this)&&p(r,this,x),arguments.length>v&&u(r,arguments[v]),r}));if(x.prototype=k,"Error"!==y?i?i(x,w):l(x,w,{name:!0}):f&&"stackTraceLimit"in _&&(c(x,_,"stackTraceLimit"),c(x,_,"prepareStackTrace")),l(x,_),!g)try{k.name!==y&&o(k,"name",y),k.constructor=x}catch(n){}return x}}},function(n,e,t){"use strict";var r=t(4),a=t(33);n.exports=function(n,e,t){try{return r(a(Object.getOwnPropertyDescriptor(n,e)[t]))}catch(n){}}},function(n,e,t){"use strict";var r=t(134),a=String,o=TypeError;n.exports=function(n){if(r(n))return n;throw new o("Can't set "+a(n)+" as a prototype")}},function(n,e,t){"use strict";var r=t(7);n.exports=function(n){return r(n)||null===n}},function(n,e,t){"use strict";var r=t(18).f;n.exports=function(n,e,t){t in n||r(n,t,{configurable:!0,get:function(){return e[t]},set:function(n){e[t]=n}})}},function(n,e,t){"use strict";var r=t(2),a=t(7),o=t(67);n.exports=function(n,e,t){var s,i;return o&&r(s=e.constructor)&&s!==t&&a(i=s.prototype)&&i!==t.prototype&&o(n,i),n}},function(n,e,t){"use strict";var r=t(138);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:r(n)}},function(n,e,t){"use strict";var r=t(139),a=String;n.exports=function(n){if("Symbol"===r(n))throw new TypeError("Cannot convert a Symbol value to a string");return a(n)}},function(n,e,t){"use strict";var r=t(140),a=t(2),o=t(17),s=t(34)("toStringTag"),i=Object,l="Arguments"===o(function(){return arguments}());n.exports=r?o:function(n){var e,t,r;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=i(n),s))?t:l?o(e):"Object"===(r=o(e))&&a(e.callee)?"Arguments":r}},function(n,e,t){"use strict";var r={};r[t(34)("toStringTag")]="z",n.exports="[object z]"===String(r)},function(n,e,t){"use strict";var r=t(7),a=t(14);n.exports=function(n,e){r(e)&&"cause"in e&&a(n,"cause",e.cause)}},function(n,e,t){"use strict";var r=t(14),a=t(143),o=t(144),s=Error.captureStackTrace;n.exports=function(n,e,t,i){o&&(s?s(n,e):r(n,"stack",a(t,i)))}},function(n,e,t){"use strict";var r=t(4),a=Error,o=r("".replace),s=String(new a("zxcasd").stack),i=/\n\s*at [^:]*:[^\n]*/,l=i.test(s);n.exports=function(n,e){if(l&&"string"==typeof n&&!a.prepareStackTrace)for(;e--;)n=o(n,i,"");return n}},function(n,e,t){"use strict";var r=t(3),a=t(29);n.exports=!r((function(){var n=new Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",a(1,7)),7!==n.stack)}))},function(n,e,t){"use strict";var r=t(6),a=t(146),o=TypeError,s=Object.getOwnPropertyDescriptor,i=r&&!function(){if(void 0!==this)return!0;try{Object.defineProperty([],"length",{writable:!1}).length=1}catch(n){return n instanceof TypeError}}();n.exports=i?function(n,e){if(a(n)&&!s(n,"length").writable)throw new o("Cannot set read only .length");return n.length=e}:function(n,e){return n.length=e}},function(n,e,t){"use strict";var r=t(17);n.exports=Array.isArray||function(n){return"Array"===r(n)}},function(n,e,t){"use strict";var r=TypeError;n.exports=function(n){if(n>9007199254740991)throw r("Maximum allowed index exceeded");return n}},function(n,e,t){var r=t(68),a=t(149);n.exports=function n(e,t,o,s,i){var l=-1,c=e.length;for(o||(o=a),i||(i=[]);++l<c;){var p=e[l];t>0&&o(p)?t>1?n(p,t-1,o,s,i):r(i,p):s||(i[i.length]=p)}return i}},function(n,e,t){var r=t(15),a=t(39),o=t(5),s=r?r.isConcatSpreadable:void 0;n.exports=function(n){return o(n)||a(n)||!!(s&&n&&n[s])}},function(n,e,t){var r=t(13),a=t(12);n.exports=function(n){return a(n)&&"[object Arguments]"==r(n)}},function(n,e,t){var r=t(15),a=Object.prototype,o=a.hasOwnProperty,s=a.toString,i=r?r.toStringTag:void 0;n.exports=function(n){var e=o.call(n,i),t=n[i];try{n[i]=void 0;var r=!0}catch(n){}var a=s.call(n);return r&&(e?n[i]=t:delete n[i]),a}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var r=t(154),a=t(210),o=t(47),s=t(5),i=t(221);n.exports=function(n){return"function"==typeof n?n:null==n?o:"object"==typeof n?s(n)?a(n[0],n[1]):r(n):i(n)}},function(n,e,t){var r=t(155),a=t(209),o=t(85);n.exports=function(n){var e=a(n);return 1==e.length&&e[0][2]?o(e[0][0],e[0][1]):function(t){return t===n||r(t,n,e)}}},function(n,e,t){var r=t(70),a=t(74);n.exports=function(n,e,t,o){var s=t.length,i=s,l=!o;if(null==n)return!i;for(n=Object(n);s--;){var c=t[s];if(l&&c[2]?c[1]!==n[c[0]]:!(c[0]in n))return!1}for(;++s<i;){var p=(c=t[s])[0],d=n[p],u=c[1];if(l&&c[2]){if(void 0===d&&!(p in n))return!1}else{var m=new r;if(o)var f=o(d,u,p,n,e,m);if(!(void 0===f?a(u,d,3,o,m):f))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var r=t(20),a=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=r(e,n);return!(t<0)&&(t==e.length-1?e.pop():a.call(e,t,1),--this.size,!0)}},function(n,e,t){var r=t(20);n.exports=function(n){var e=this.__data__,t=r(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var r=t(20);n.exports=function(n){return r(this.__data__,n)>-1}},function(n,e,t){var r=t(20);n.exports=function(n,e){var t=this.__data__,a=r(t,n);return a<0?(++this.size,t.push([n,e])):t[a][1]=e,this}},function(n,e,t){var r=t(19);n.exports=function(){this.__data__=new r,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var r=t(19),a=t(40),o=t(42);n.exports=function(n,e){var t=this.__data__;if(t instanceof r){var s=t.__data__;if(!a||s.length<199)return s.push([n,e]),this.size=++t.size,this;t=this.__data__=new o(s)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var r=t(72),a=t(167),o=t(41),s=t(73),i=/^\[object .+?Constructor\]$/,l=Function.prototype,c=Object.prototype,p=l.toString,d=c.hasOwnProperty,u=RegExp("^"+p.call(d).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!o(n)||a(n))&&(r(n)?u:i).test(s(n))}},function(n,e,t){var r,a=t(168),o=(r=/[^.]+$/.exec(a&&a.keys&&a.keys.IE_PROTO||""))?"Symbol(src)_1."+r:"";n.exports=function(n){return!!o&&o in n}},function(n,e,t){var r=t(8)["__core-js_shared__"];n.exports=r},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var r=t(171),a=t(19),o=t(40);n.exports=function(){this.size=0,this.__data__={hash:new r,map:new(o||a),string:new r}}},function(n,e,t){var r=t(172),a=t(173),o=t(174),s=t(175),i=t(176);function l(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}l.prototype.clear=r,l.prototype.delete=a,l.prototype.get=o,l.prototype.has=s,l.prototype.set=i,n.exports=l},function(n,e,t){var r=t(21);n.exports=function(){this.__data__=r?r(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var r=t(21),a=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(r){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return a.call(e,n)?e[n]:void 0}},function(n,e,t){var r=t(21),a=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return r?void 0!==e[n]:a.call(e,n)}},function(n,e,t){var r=t(21);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=r&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var r=t(22);n.exports=function(n){var e=r(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var r=t(22);n.exports=function(n){return r(this,n).get(n)}},function(n,e,t){var r=t(22);n.exports=function(n){return r(this,n).has(n)}},function(n,e,t){var r=t(22);n.exports=function(n,e){var t=r(this,n),a=t.size;return t.set(n,e),this.size+=t.size==a?0:1,this}},function(n,e,t){var r=t(70),a=t(75),o=t(186),s=t(189),i=t(205),l=t(5),c=t(79),p=t(81),d="[object Object]",u=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,m,f,g){var h=l(n),v=l(e),b=h?"[object Array]":i(n),y=v?"[object Array]":i(e),_=(b="[object Arguments]"==b?d:b)==d,k=(y="[object Arguments]"==y?d:y)==d,w=b==y;if(w&&c(n)){if(!c(e))return!1;h=!0,_=!1}if(w&&!_)return g||(g=new r),h||p(n)?a(n,e,t,m,f,g):o(n,e,b,t,m,f,g);if(!(1&t)){var x=_&&u.call(n,"__wrapped__"),E=k&&u.call(e,"__wrapped__");if(x||E){var j=x?n.value():n,A=E?e.value():e;return g||(g=new r),f(j,A,t,m,g)}}return!!w&&(g||(g=new r),s(n,e,t,m,f,g))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length;++t<r;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var r=t(15),a=t(187),o=t(71),s=t(75),i=t(188),l=t(43),c=r?r.prototype:void 0,p=c?c.valueOf:void 0;n.exports=function(n,e,t,r,c,d,u){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!d(new a(n),new a(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return o(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var m=i;case"[object Set]":var f=1&r;if(m||(m=l),n.size!=e.size&&!f)return!1;var g=u.get(n);if(g)return g==e;r|=2,u.set(n,e);var h=s(m(n),m(e),r,c,d,u);return u.delete(n),h;case"[object Symbol]":if(p)return p.call(n)==p.call(e)}return!1}},function(n,e,t){var r=t(8).Uint8Array;n.exports=r},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,r){t[++e]=[r,n]})),t}},function(n,e,t){var r=t(190),a=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,o,s,i){var l=1&t,c=r(n),p=c.length;if(p!=r(e).length&&!l)return!1;for(var d=p;d--;){var u=c[d];if(!(l?u in e:a.call(e,u)))return!1}var m=i.get(n),f=i.get(e);if(m&&f)return m==e&&f==n;var g=!0;i.set(n,e),i.set(e,n);for(var h=l;++d<p;){var v=n[u=c[d]],b=e[u];if(o)var y=l?o(b,v,u,e,n,i):o(v,b,u,n,e,i);if(!(void 0===y?v===b||s(v,b,t,o,i):y)){g=!1;break}h||(h="constructor"==u)}if(g&&!h){var _=n.constructor,k=e.constructor;_==k||!("constructor"in n)||!("constructor"in e)||"function"==typeof _&&_ instanceof _&&"function"==typeof k&&k instanceof k||(g=!1)}return i.delete(n),i.delete(e),g}},function(n,e,t){var r=t(191),a=t(192),o=t(78);n.exports=function(n){return r(n,o,a)}},function(n,e,t){var r=t(68),a=t(5);n.exports=function(n,e,t){var o=e(n);return a(n)?o:r(o,t(n))}},function(n,e,t){var r=t(193),a=t(194),o=Object.prototype.propertyIsEnumerable,s=Object.getOwnPropertySymbols,i=s?function(n){return null==n?[]:(n=Object(n),r(s(n),(function(e){return o.call(n,e)})))}:a;n.exports=i},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,a=0,o=[];++t<r;){var s=n[t];e(s,t,n)&&(o[a++]=s)}return o}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var r=t(196),a=t(39),o=t(5),s=t(79),i=t(80),l=t(81),c=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=o(n),p=!t&&a(n),d=!t&&!p&&s(n),u=!t&&!p&&!d&&l(n),m=t||p||d||u,f=m?r(n.length,String):[],g=f.length;for(var h in n)!e&&!c.call(n,h)||m&&("length"==h||d&&("offset"==h||"parent"==h)||u&&("buffer"==h||"byteLength"==h||"byteOffset"==h)||i(h,g))||f.push(h);return f}},function(n,e){n.exports=function(n,e){for(var t=-1,r=Array(n);++t<n;)r[t]=e(t);return r}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var r=t(13),a=t(44),o=t(12),s={};s["[object Float32Array]"]=s["[object Float64Array]"]=s["[object Int8Array]"]=s["[object Int16Array]"]=s["[object Int32Array]"]=s["[object Uint8Array]"]=s["[object Uint8ClampedArray]"]=s["[object Uint16Array]"]=s["[object Uint32Array]"]=!0,s["[object Arguments]"]=s["[object Array]"]=s["[object ArrayBuffer]"]=s["[object Boolean]"]=s["[object DataView]"]=s["[object Date]"]=s["[object Error]"]=s["[object Function]"]=s["[object Map]"]=s["[object Number]"]=s["[object Object]"]=s["[object RegExp]"]=s["[object Set]"]=s["[object String]"]=s["[object WeakMap]"]=!1,n.exports=function(n){return o(n)&&a(n.length)&&!!s[r(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var r=t(69),a=e&&!e.nodeType&&e,o=a&&"object"==typeof n&&n&&!n.nodeType&&n,s=o&&o.exports===a&&r.process,i=function(){try{var n=o&&o.require&&o.require("util").types;return n||s&&s.binding&&s.binding("util")}catch(n){}}();n.exports=i}).call(this,t(48)(n))},function(n,e,t){var r=t(202),a=t(203),o=Object.prototype.hasOwnProperty;n.exports=function(n){if(!r(n))return a(n);var e=[];for(var t in Object(n))o.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var r=t(204)(Object.keys,Object);n.exports=r},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var r=t(206),a=t(40),o=t(207),s=t(83),i=t(208),l=t(13),c=t(73),p=c(r),d=c(a),u=c(o),m=c(s),f=c(i),g=l;(r&&"[object DataView]"!=g(new r(new ArrayBuffer(1)))||a&&"[object Map]"!=g(new a)||o&&"[object Promise]"!=g(o.resolve())||s&&"[object Set]"!=g(new s)||i&&"[object WeakMap]"!=g(new i))&&(g=function(n){var e=l(n),t="[object Object]"==e?n.constructor:void 0,r=t?c(t):"";if(r)switch(r){case p:return"[object DataView]";case d:return"[object Map]";case u:return"[object Promise]";case m:return"[object Set]";case f:return"[object WeakMap]"}return e}),n.exports=g},function(n,e,t){var r=t(10)(t(8),"DataView");n.exports=r},function(n,e,t){var r=t(10)(t(8),"Promise");n.exports=r},function(n,e,t){var r=t(10)(t(8),"WeakMap");n.exports=r},function(n,e,t){var r=t(84),a=t(78);n.exports=function(n){for(var e=a(n),t=e.length;t--;){var o=e[t],s=n[o];e[t]=[o,s,r(s)]}return e}},function(n,e,t){var r=t(74),a=t(211),o=t(218),s=t(45),i=t(84),l=t(85),c=t(23);n.exports=function(n,e){return s(n)&&i(e)?l(c(n),e):function(t){var s=a(t,n);return void 0===s&&s===e?o(t,n):r(e,s,3)}}},function(n,e,t){var r=t(86);n.exports=function(n,e,t){var a=null==n?void 0:r(n,e);return void 0===a?t:a}},function(n,e,t){var r=t(213),a=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,o=/\\(\\)?/g,s=r((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(a,(function(n,t,r,a){e.push(r?a.replace(o,"$1"):t||n)})),e}));n.exports=s},function(n,e,t){var r=t(214);n.exports=function(n){var e=r(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var r=t(42);function a(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var r=arguments,a=e?e.apply(this,r):r[0],o=t.cache;if(o.has(a))return o.get(a);var s=n.apply(this,r);return t.cache=o.set(a,s)||o,s};return t.cache=new(a.Cache||r),t}a.Cache=r,n.exports=a},function(n,e,t){var r=t(216);n.exports=function(n){return null==n?"":r(n)}},function(n,e,t){var r=t(15),a=t(217),o=t(5),s=t(46),i=r?r.prototype:void 0,l=i?i.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(o(e))return a(e,n)+"";if(s(e))return l?l.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,a=Array(r);++t<r;)a[t]=e(n[t],t,n);return a}},function(n,e,t){var r=t(219),a=t(220);n.exports=function(n,e){return null!=n&&a(n,e,r)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var r=t(87),a=t(39),o=t(5),s=t(80),i=t(44),l=t(23);n.exports=function(n,e,t){for(var c=-1,p=(e=r(e,n)).length,d=!1;++c<p;){var u=l(e[c]);if(!(d=null!=n&&t(n,u)))break;n=n[u]}return d||++c!=p?d:!!(p=null==n?0:n.length)&&i(p)&&s(u,p)&&(o(n)||a(n))}},function(n,e,t){var r=t(222),a=t(223),o=t(45),s=t(23);n.exports=function(n){return o(n)?r(s(n)):a(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var r=t(86);n.exports=function(n){return function(e){return r(e,n)}}},function(n,e,t){var r=t(47),a=t(225),o=t(227);n.exports=function(n,e){return o(a(n,e,r),n+"")}},function(n,e,t){var r=t(226),a=Math.max;n.exports=function(n,e,t){return e=a(void 0===e?n.length-1:e,0),function(){for(var o=arguments,s=-1,i=a(o.length-e,0),l=Array(i);++s<i;)l[s]=o[e+s];s=-1;for(var c=Array(e+1);++s<e;)c[s]=o[s];return c[e]=t(l),r(n,this,c)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var r=t(228),a=t(231)(r);n.exports=a},function(n,e,t){var r=t(229),a=t(230),o=t(47),s=a?function(n,e){return a(n,"toString",{configurable:!0,enumerable:!1,value:r(e),writable:!0})}:o;n.exports=s},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var r=t(10),a=function(){try{var n=r(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=a},function(n,e){var t=Date.now;n.exports=function(n){var e=0,r=0;return function(){var a=t(),o=16-(a-r);if(r=a,o>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var r=t(76),a=t(233),o=t(238),s=t(77),i=t(239),l=t(43);n.exports=function(n,e,t){var c=-1,p=a,d=n.length,u=!0,m=[],f=m;if(t)u=!1,p=o;else if(d>=200){var g=e?null:i(n);if(g)return l(g);u=!1,p=s,f=new r}else f=e?[]:m;n:for(;++c<d;){var h=n[c],v=e?e(h):h;if(h=t||0!==h?h:0,u&&v==v){for(var b=f.length;b--;)if(f[b]===v)continue n;e&&f.push(v),m.push(h)}else p(f,v,t)||(f!==m&&f.push(v),m.push(h))}return m}},function(n,e,t){var r=t(234);n.exports=function(n,e){return!!(null==n?0:n.length)&&r(n,e,0)>-1}},function(n,e,t){var r=t(235),a=t(236),o=t(237);n.exports=function(n,e,t){return e==e?o(n,e,t):r(n,a,t)}},function(n,e){n.exports=function(n,e,t,r){for(var a=n.length,o=t+(r?1:-1);r?o--:++o<a;)if(e(n[o],o,n))return o;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var r=t-1,a=n.length;++r<a;)if(n[r]===e)return r;return-1}},function(n,e){n.exports=function(n,e,t){for(var r=-1,a=null==n?0:n.length;++r<a;)if(t(e,n[r]))return!0;return!1}},function(n,e,t){var r=t(83),a=t(240),o=t(43),s=r&&1/o(new r([,-0]))[1]==1/0?function(n){return new r(n)}:a;n.exports=s},function(n,e){n.exports=function(){}},function(n,e,t){var r=t(82),a=t(12);n.exports=function(n){return a(n)&&r(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(88)},function(n,e,t){"use strict";t(89)},function(n,e,t){},function(n,e,t){},function(n,e){},function(n,e){function t(n,e){for(var t=0,r=n.length-1;r>=0;r--){var a=n[r];"."===a?n.splice(r,1):".."===a?(n.splice(r,1),t++):t&&(n.splice(r,1),t--)}if(e)for(;t--;t)n.unshift("..");return n}function r(n,e){if(n.filter)return n.filter(e);for(var t=[],r=0;r<n.length;r++)e(n[r],r,n)&&t.push(n[r]);return t}e.resolve=function(){for(var n="",e=!1,a=arguments.length-1;a>=-1&&!e;a--){var o=a>=0?arguments[a]:process.cwd();if("string"!=typeof o)throw new TypeError("Arguments to path.resolve must be strings");o&&(n=o+"/"+n,e="/"===o.charAt(0))}return(e?"/":"")+(n=t(r(n.split("/"),(function(n){return!!n})),!e).join("/"))||"."},e.normalize=function(n){var o=e.isAbsolute(n),s="/"===a(n,-1);return(n=t(r(n.split("/"),(function(n){return!!n})),!o).join("/"))||o||(n="."),n&&s&&(n+="/"),(o?"/":"")+n},e.isAbsolute=function(n){return"/"===n.charAt(0)},e.join=function(){var n=Array.prototype.slice.call(arguments,0);return e.normalize(r(n,(function(n,e){if("string"!=typeof n)throw new TypeError("Arguments to path.join must be strings");return n})).join("/"))},e.relative=function(n,t){function r(n){for(var e=0;e<n.length&&""===n[e];e++);for(var t=n.length-1;t>=0&&""===n[t];t--);return e>t?[]:n.slice(e,t-e+1)}n=e.resolve(n).substr(1),t=e.resolve(t).substr(1);for(var a=r(n.split("/")),o=r(t.split("/")),s=Math.min(a.length,o.length),i=s,l=0;l<s;l++)if(a[l]!==o[l]){i=l;break}var c=[];for(l=i;l<a.length;l++)c.push("..");return(c=c.concat(o.slice(i))).join("/")},e.sep="/",e.delimiter=":",e.dirname=function(n){if("string"!=typeof n&&(n+=""),0===n.length)return".";for(var e=n.charCodeAt(0),t=47===e,r=-1,a=!0,o=n.length-1;o>=1;--o)if(47===(e=n.charCodeAt(o))){if(!a){r=o;break}}else a=!1;return-1===r?t?"/":".":t&&1===r?"/":n.slice(0,r)},e.basename=function(n,e){var t=function(n){"string"!=typeof n&&(n+="");var e,t=0,r=-1,a=!0;for(e=n.length-1;e>=0;--e)if(47===n.charCodeAt(e)){if(!a){t=e+1;break}}else-1===r&&(a=!1,r=e+1);return-1===r?"":n.slice(t,r)}(n);return e&&t.substr(-1*e.length)===e&&(t=t.substr(0,t.length-e.length)),t},e.extname=function(n){"string"!=typeof n&&(n+="");for(var e=-1,t=0,r=-1,a=!0,o=0,s=n.length-1;s>=0;--s){var i=n.charCodeAt(s);if(47!==i)-1===r&&(a=!1,r=s+1),46===i?-1===e?e=s:1!==o&&(o=1):-1!==e&&(o=-1);else if(!a){t=s+1;break}}return-1===e||-1===r||0===o||1===o&&e===r-1&&e===t+1?"":n.slice(e,r)};var a="b"==="ab".substr(-1)?function(n,e,t){return n.substr(e,t)}:function(n,e,t){return e<0&&(e=n.length+e),n.substr(e,t)}},function(n,e,t){"use strict";var r=/[|\\{}()[\]^$+*?.]/g,a=Object.prototype.hasOwnProperty,o=function(n,e){return a.apply(n,[e])};e.escapeRegExpChars=function(n){return n?String(n).replace(r,"\\$&"):""};var s={"&":"&amp;","<":"&lt;",">":"&gt;",'"':"&#34;","'":"&#39;"},i=/[&<>'"]/g;function l(n){return s[n]||n}function c(){return Function.prototype.toString.call(this)+';\nvar _ENCODE_HTML_RULES = {\n      "&": "&amp;"\n    , "<": "&lt;"\n    , ">": "&gt;"\n    , \'"\': "&#34;"\n    , "\'": "&#39;"\n    }\n  , _MATCH_HTML = /[&<>\'"]/g;\nfunction encode_char(c) {\n  return _ENCODE_HTML_RULES[c] || c;\n};\n'}e.escapeXML=function(n){return null==n?"":String(n).replace(i,l)};try{"function"==typeof Object.defineProperty?Object.defineProperty(e.escapeXML,"toString",{value:c}):e.escapeXML.toString=c}catch(n){console.warn("Unable to set escapeXML.toString (is the Function prototype frozen?)")}e.shallowCopy=function(n,e){if(e=e||{},null!=n)for(var t in e)o(e,t)&&"__proto__"!==t&&"constructor"!==t&&(n[t]=e[t]);return n},e.shallowCopyFromList=function(n,e,t){if(t=t||[],e=e||{},null!=n)for(var r=0;r<t.length;r++){var a=t[r];if(void 0!==e[a]){if(!o(e,a))continue;if("__proto__"===a||"constructor"===a)continue;n[a]=e[a]}}return n},e.cache={_data:{},set:function(n,e){this._data[n]=e},get:function(n){return this._data[n]},remove:function(n){delete this._data[n]},reset:function(){this._data={}}},e.hyphenToCamel=function(n){return n.replace(/-[a-z]/g,(function(n){return n[1].toUpperCase()}))},e.createNullProtoObjWherePossible="function"==typeof Object.create?function(){return Object.create(null)}:{__proto__:null}instanceof Object?function(){return{}}:function(){return{__proto__:null}},e.hasOwnOnlyObject=function(n){var t=e.createNullProtoObjWherePossible();for(var r in n)o(n,r)&&(t[r]=n[r]);return t}},function(n){n.exports=JSON.parse('{"name":"ejs","description":"Embedded JavaScript templates","keywords":["template","engine","ejs"],"version":"3.1.10","author":"Matthew Eernisse <mde@fleegix.org> (http://fleegix.org)","license":"Apache-2.0","bin":{"ejs":"./bin/cli.js"},"main":"./lib/ejs.js","jsdelivr":"ejs.min.js","unpkg":"ejs.min.js","repository":{"type":"git","url":"git://github.com/mde/ejs.git"},"bugs":"https://github.com/mde/ejs/issues","homepage":"https://github.com/mde/ejs","dependencies":{"jake":"^10.8.5"},"devDependencies":{"browserify":"^16.5.1","eslint":"^6.8.0","git-directory-deploy":"^1.5.1","jsdoc":"^4.0.2","lru-cache":"^4.0.1","mocha":"^10.2.0","uglify-js":"^3.3.16"},"engines":{"node":">=0.10.0"},"scripts":{"test":"npx jake test"},"__npminstall_done":true,"_from":"ejs@3.1.10","_resolved":"https://registry.npmmirror.com/ejs/-/ejs-3.1.10.tgz"}')},function(n,e,t){"use strict";t(90)},function(n,e,t){"use strict";t(91)},function(n,e,t){"use strict";t(92)},function(n,e,t){"use strict";t.r(e);
/*!
 * Vue.js v2.7.16
 * (c) 2014-2023 Evan You
 * Released under the MIT License.
 */
var r=Object.freeze({}),a=Array.isArray;function o(n){return null==n}function s(n){return null!=n}function i(n){return!0===n}function l(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function c(n){return"function"==typeof n}function p(n){return null!==n&&"object"==typeof n}var d=Object.prototype.toString;function u(n){return"[object Object]"===d.call(n)}function m(n){return"[object RegExp]"===d.call(n)}function f(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function g(n){return s(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function h(n){return null==n?"":Array.isArray(n)||u(n)&&n.toString===d?JSON.stringify(n,v,2):String(n)}function v(n,e){return e&&e.__v_isRef?e.value:e}function b(n){var e=parseFloat(n);return isNaN(e)?n:e}function y(n,e){for(var t=Object.create(null),r=n.split(","),a=0;a<r.length;a++)t[r[a]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}y("slot,component",!0);var _=y("key,ref,slot,slot-scope,is");function k(n,e){var t=n.length;if(t){if(e===n[t-1])return void(n.length=t-1);var r=n.indexOf(e);if(r>-1)return n.splice(r,1)}}var w=Object.prototype.hasOwnProperty;function x(n,e){return w.call(n,e)}function E(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var j=/-(\w)/g,A=E((function(n){return n.replace(j,(function(n,e){return e?e.toUpperCase():""}))})),T=E((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),S=/\B([A-Z])/g,C=E((function(n){return n.replace(S,"-$1").toLowerCase()}));var B=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var r=arguments.length;return r?r>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function z(n,e){e=e||0;for(var t=n.length-e,r=new Array(t);t--;)r[t]=n[t+e];return r}function P(n,e){for(var t in e)n[t]=e[t];return n}function I(n){for(var e={},t=0;t<n.length;t++)n[t]&&P(e,n[t]);return e}function q(n,e,t){}var N=function(n,e,t){return!1},D=function(n){return n};function F(n,e){if(n===e)return!0;var t=p(n),r=p(e);if(!t||!r)return!t&&!r&&String(n)===String(e);try{var a=Array.isArray(n),o=Array.isArray(e);if(a&&o)return n.length===e.length&&n.every((function(n,t){return F(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(a||o)return!1;var s=Object.keys(n),i=Object.keys(e);return s.length===i.length&&s.every((function(t){return F(n[t],e[t])}))}catch(n){return!1}}function O(n,e){for(var t=0;t<n.length;t++)if(F(n[t],e))return t;return-1}function L(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}function R(n,e){return n===e?0===n&&1/n!=1/e:n==n||e==e}var M=["component","directive","filter"],U=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],V={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:N,isReservedAttr:N,isUnknownElement:N,getTagNamespace:q,parsePlatformTagName:D,mustUseProp:N,async:!0,_lifecycleHooks:U},J=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function H(n){var e=(n+"").charCodeAt(0);return 36===e||95===e}function G(n,e,t,r){Object.defineProperty(n,e,{value:t,enumerable:!!r,writable:!0,configurable:!0})}var $=new RegExp("[^".concat(J.source,".$_\\d]"));var K="__proto__"in{},Z="undefined"!=typeof window,W=Z&&window.navigator.userAgent.toLowerCase(),X=W&&/msie|trident/.test(W),Q=W&&W.indexOf("msie 9.0")>0,Y=W&&W.indexOf("edge/")>0;W&&W.indexOf("android");var nn=W&&/iphone|ipad|ipod|ios/.test(W);W&&/chrome\/\d+/.test(W),W&&/phantomjs/.test(W);var en,tn=W&&W.match(/firefox\/(\d+)/),rn={}.watch,an=!1;if(Z)try{var on={};Object.defineProperty(on,"passive",{get:function(){an=!0}}),window.addEventListener("test-passive",null,on)}catch(n){}var sn=function(){return void 0===en&&(en=!Z&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),en},ln=Z&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function cn(n){return"function"==typeof n&&/native code/.test(n.toString())}var pn,dn="undefined"!=typeof Symbol&&cn(Symbol)&&"undefined"!=typeof Reflect&&cn(Reflect.ownKeys);pn="undefined"!=typeof Set&&cn(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var un=null;function mn(n){void 0===n&&(n=null),n||un&&un._scope.off(),un=n,n&&n._scope.on()}var fn=function(){function n(n,e,t,r,a,o,s,i){this.tag=n,this.data=e,this.children=t,this.text=r,this.elm=a,this.ns=void 0,this.context=o,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=s,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=i,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(n.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),n}(),gn=function(n){void 0===n&&(n="");var e=new fn;return e.text=n,e.isComment=!0,e};function hn(n){return new fn(void 0,void 0,void 0,String(n))}function vn(n){var e=new fn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}"function"==typeof SuppressedError&&SuppressedError;var bn=0,yn=[],_n=function(){function n(){this._pending=!1,this.id=bn++,this.subs=[]}return n.prototype.addSub=function(n){this.subs.push(n)},n.prototype.removeSub=function(n){this.subs[this.subs.indexOf(n)]=null,this._pending||(this._pending=!0,yn.push(this))},n.prototype.depend=function(e){n.target&&n.target.addDep(this)},n.prototype.notify=function(n){var e=this.subs.filter((function(n){return n}));for(var t=0,r=e.length;t<r;t++){0,e[t].update()}},n}();_n.target=null;var kn=[];function wn(n){kn.push(n),_n.target=n}function xn(){kn.pop(),_n.target=kn[kn.length-1]}var En=Array.prototype,jn=Object.create(En);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=En[n];G(jn,n,(function(){for(var t=[],r=0;r<arguments.length;r++)t[r]=arguments[r];var a,o=e.apply(this,t),s=this.__ob__;switch(n){case"push":case"unshift":a=t;break;case"splice":a=t.slice(2)}return a&&s.observeArray(a),s.dep.notify(),o}))}));var An=Object.getOwnPropertyNames(jn),Tn={},Sn=!0;function Cn(n){Sn=n}var Bn={notify:q,depend:q,addSub:q,removeSub:q},zn=function(){function n(n,e,t){if(void 0===e&&(e=!1),void 0===t&&(t=!1),this.value=n,this.shallow=e,this.mock=t,this.dep=t?Bn:new _n,this.vmCount=0,G(n,"__ob__",this),a(n)){if(!t)if(K)n.__proto__=jn;else for(var r=0,o=An.length;r<o;r++){G(n,i=An[r],jn[i])}e||this.observeArray(n)}else{var s=Object.keys(n);for(r=0;r<s.length;r++){var i;In(n,i=s[r],Tn,void 0,e,t)}}}return n.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)Pn(n[e],!1,this.mock)},n}();function Pn(n,e,t){return n&&x(n,"__ob__")&&n.__ob__ instanceof zn?n.__ob__:!Sn||!t&&sn()||!a(n)&&!u(n)||!Object.isExtensible(n)||n.__v_skip||Rn(n)||n instanceof fn?void 0:new zn(n,e,t)}function In(n,e,t,r,o,s,i){void 0===i&&(i=!1);var l=new _n,c=Object.getOwnPropertyDescriptor(n,e);if(!c||!1!==c.configurable){var p=c&&c.get,d=c&&c.set;p&&!d||t!==Tn&&2!==arguments.length||(t=n[e]);var u=o?t&&t.__ob__:Pn(t,!1,s);return Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=p?p.call(n):t;return _n.target&&(l.depend(),u&&(u.dep.depend(),a(e)&&Dn(e))),Rn(e)&&!o?e.value:e},set:function(e){var r=p?p.call(n):t;if(R(r,e)){if(d)d.call(n,e);else{if(p)return;if(!o&&Rn(r)&&!Rn(e))return void(r.value=e);t=e}u=o?e&&e.__ob__:Pn(e,!1,s),l.notify()}}}),l}}function qn(n,e,t){if(!Ln(n)){var r=n.__ob__;return a(n)&&f(e)?(n.length=Math.max(n.length,e),n.splice(e,1,t),r&&!r.shallow&&r.mock&&Pn(t,!1,!0),t):e in n&&!(e in Object.prototype)?(n[e]=t,t):n._isVue||r&&r.vmCount?t:r?(In(r.value,e,t,void 0,r.shallow,r.mock),r.dep.notify(),t):(n[e]=t,t)}}function Nn(n,e){if(a(n)&&f(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||Ln(n)||x(n,e)&&(delete n[e],t&&t.dep.notify())}}function Dn(n){for(var e=void 0,t=0,r=n.length;t<r;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),a(e)&&Dn(e)}function Fn(n){return On(n,!0),G(n,"__v_isShallow",!0),n}function On(n,e){if(!Ln(n)){Pn(n,e,sn());0}}function Ln(n){return!(!n||!n.__v_isReadonly)}function Rn(n){return!(!n||!0!==n.__v_isRef)}function Mn(n,e,t){Object.defineProperty(n,t,{enumerable:!0,configurable:!0,get:function(){var n=e[t];if(Rn(n))return n.value;var r=n&&n.__ob__;return r&&r.dep.depend(),n},set:function(n){var r=e[t];Rn(r)&&!Rn(n)?r.value=n:e[t]=n}})}"".concat("watcher"," callback"),"".concat("watcher"," getter"),"".concat("watcher"," cleanup");var Un;var Vn=function(){function n(n){void 0===n&&(n=!1),this.detached=n,this.active=!0,this.effects=[],this.cleanups=[],this.parent=Un,!n&&Un&&(this.index=(Un.scopes||(Un.scopes=[])).push(this)-1)}return n.prototype.run=function(n){if(this.active){var e=Un;try{return Un=this,n()}finally{Un=e}}else 0},n.prototype.on=function(){Un=this},n.prototype.off=function(){Un=this.parent},n.prototype.stop=function(n){if(this.active){var e=void 0,t=void 0;for(e=0,t=this.effects.length;e<t;e++)this.effects[e].teardown();for(e=0,t=this.cleanups.length;e<t;e++)this.cleanups[e]();if(this.scopes)for(e=0,t=this.scopes.length;e<t;e++)this.scopes[e].stop(!0);if(!this.detached&&this.parent&&!n){var r=this.parent.scopes.pop();r&&r!==this&&(this.parent.scopes[this.index]=r,r.index=this.index)}this.parent=void 0,this.active=!1}},n}();function Jn(n){var e=n._provided,t=n.$parent&&n.$parent._provided;return t===e?n._provided=Object.create(t):e}var Hn=E((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),r="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=r?n.slice(1):n,once:t,capture:r,passive:e}}));function Gn(n,e){function t(){var n=t.fns;if(!a(n))return Se(n,null,arguments,e,"v-on handler");for(var r=n.slice(),o=0;o<r.length;o++)Se(r[o],null,arguments,e,"v-on handler")}return t.fns=n,t}function $n(n,e,t,r,a,s){var l,c,p,d;for(l in n)c=n[l],p=e[l],d=Hn(l),o(c)||(o(p)?(o(c.fns)&&(c=n[l]=Gn(c,s)),i(d.once)&&(c=n[l]=a(d.name,c,d.capture)),t(d.name,c,d.capture,d.passive,d.params)):c!==p&&(p.fns=c,n[l]=p));for(l in e)o(n[l])&&r((d=Hn(l)).name,e[l],d.capture)}function Kn(n,e,t){var r;n instanceof fn&&(n=n.data.hook||(n.data.hook={}));var a=n[e];function l(){t.apply(this,arguments),k(r.fns,l)}o(a)?r=Gn([l]):s(a.fns)&&i(a.merged)?(r=a).fns.push(l):r=Gn([a,l]),r.merged=!0,n[e]=r}function Zn(n,e,t,r,a){if(s(e)){if(x(e,t))return n[t]=e[t],a||delete e[t],!0;if(x(e,r))return n[t]=e[r],a||delete e[r],!0}return!1}function Wn(n){return l(n)?[hn(n)]:a(n)?function n(e,t){var r,c,p,d,u=[];for(r=0;r<e.length;r++)o(c=e[r])||"boolean"==typeof c||(p=u.length-1,d=u[p],a(c)?c.length>0&&(Xn((c=n(c,"".concat(t||"","_").concat(r)))[0])&&Xn(d)&&(u[p]=hn(d.text+c[0].text),c.shift()),u.push.apply(u,c)):l(c)?Xn(d)?u[p]=hn(d.text+c):""!==c&&u.push(hn(c)):Xn(c)&&Xn(d)?u[p]=hn(d.text+c.text):(i(e._isVList)&&s(c.tag)&&o(c.key)&&s(t)&&(c.key="__vlist".concat(t,"_").concat(r,"__")),u.push(c)));return u}(n):void 0}function Xn(n){return s(n)&&s(n.text)&&!1===n.isComment}function Qn(n,e){var t,r,o,i,l=null;if(a(n)||"string"==typeof n)for(l=new Array(n.length),t=0,r=n.length;t<r;t++)l[t]=e(n[t],t);else if("number"==typeof n)for(l=new Array(n),t=0;t<n;t++)l[t]=e(t+1,t);else if(p(n))if(dn&&n[Symbol.iterator]){l=[];for(var c=n[Symbol.iterator](),d=c.next();!d.done;)l.push(e(d.value,l.length)),d=c.next()}else for(o=Object.keys(n),l=new Array(o.length),t=0,r=o.length;t<r;t++)i=o[t],l[t]=e(n[i],i,t);return s(l)||(l=[]),l._isVList=!0,l}function Yn(n,e,t,r){var a,o=this.$scopedSlots[n];o?(t=t||{},r&&(t=P(P({},r),t)),a=o(t)||(c(e)?e():e)):a=this.$slots[n]||(c(e)?e():e);var s=t&&t.slot;return s?this.$createElement("template",{slot:s},a):a}function ne(n){return zt(this.$options,"filters",n,!0)||D}function ee(n,e){return a(n)?-1===n.indexOf(e):n!==e}function te(n,e,t,r,a){var o=V.keyCodes[e]||t;return a&&r&&!V.keyCodes[e]?ee(a,r):o?ee(o,n):r?C(r)!==e:void 0===n}function re(n,e,t,r,o){if(t)if(p(t)){a(t)&&(t=I(t));var s=void 0,i=function(a){if("class"===a||"style"===a||_(a))s=n;else{var i=n.attrs&&n.attrs.type;s=r||V.mustUseProp(e,i,a)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var l=A(a),c=C(a);l in s||c in s||(s[a]=t[a],o&&((n.on||(n.on={}))["update:".concat(a)]=function(n){t[a]=n}))};for(var l in t)i(l)}else;return n}function ae(n,e){var t=this._staticTrees||(this._staticTrees=[]),r=t[n];return r&&!e||se(r=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,this._c,this),"__static__".concat(n),!1),r}function oe(n,e,t){return se(n,"__once__".concat(e).concat(t?"_".concat(t):""),!0),n}function se(n,e,t){if(a(n))for(var r=0;r<n.length;r++)n[r]&&"string"!=typeof n[r]&&ie(n[r],"".concat(e,"_").concat(r),t);else ie(n,e,t)}function ie(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function le(n,e){if(e)if(u(e)){var t=n.on=n.on?P({},n.on):{};for(var r in e){var a=t[r],o=e[r];t[r]=a?[].concat(a,o):o}}else;return n}function ce(n,e,t,r){e=e||{$stable:!t};for(var o=0;o<n.length;o++){var s=n[o];a(s)?ce(s,e,t):s&&(s.proxy&&(s.fn.proxy=!0),e[s.key]=s.fn)}return r&&(e.$key=r),e}function pe(n,e){for(var t=0;t<e.length;t+=2){var r=e[t];"string"==typeof r&&r&&(n[e[t]]=e[t+1])}return n}function de(n,e){return"string"==typeof n?e+n:n}function ue(n){n._o=oe,n._n=b,n._s=h,n._l=Qn,n._t=Yn,n._q=F,n._i=O,n._m=ae,n._f=ne,n._k=te,n._b=re,n._v=hn,n._e=gn,n._u=ce,n._g=le,n._d=pe,n._p=de}function me(n,e){if(!n||!n.length)return{};for(var t={},r=0,a=n.length;r<a;r++){var o=n[r],s=o.data;if(s&&s.attrs&&s.attrs.slot&&delete s.attrs.slot,o.context!==e&&o.fnContext!==e||!s||null==s.slot)(t.default||(t.default=[])).push(o);else{var i=s.slot,l=t[i]||(t[i]=[]);"template"===o.tag?l.push.apply(l,o.children||[]):l.push(o)}}for(var c in t)t[c].every(fe)&&delete t[c];return t}function fe(n){return n.isComment&&!n.asyncFactory||" "===n.text}function ge(n){return n.isComment&&n.asyncFactory}function he(n,e,t,a){var o,s=Object.keys(t).length>0,i=e?!!e.$stable:!s,l=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(i&&a&&a!==r&&l===a.$key&&!s&&!a.$hasNormal)return a;for(var c in o={},e)e[c]&&"$"!==c[0]&&(o[c]=ve(n,t,c,e[c]))}else o={};for(var p in t)p in o||(o[p]=be(t,p));return e&&Object.isExtensible(e)&&(e._normalized=o),G(o,"$stable",i),G(o,"$key",l),G(o,"$hasNormal",s),o}function ve(n,e,t,r){var o=function(){var e=un;mn(n);var t=arguments.length?r.apply(null,arguments):r({}),o=(t=t&&"object"==typeof t&&!a(t)?[t]:Wn(t))&&t[0];return mn(e),t&&(!o||1===t.length&&o.isComment&&!ge(o))?void 0:t};return r.proxy&&Object.defineProperty(e,t,{get:o,enumerable:!0,configurable:!0}),o}function be(n,e){return function(){return n[e]}}function ye(n){return{get attrs(){if(!n._attrsProxy){var e=n._attrsProxy={};G(e,"_v_attr_proxy",!0),_e(e,n.$attrs,r,n,"$attrs")}return n._attrsProxy},get listeners(){n._listenersProxy||_e(n._listenersProxy={},n.$listeners,r,n,"$listeners");return n._listenersProxy},get slots(){return function(n){n._slotsProxy||we(n._slotsProxy={},n.$scopedSlots);return n._slotsProxy}(n)},emit:B(n.$emit,n),expose:function(e){e&&Object.keys(e).forEach((function(t){return Mn(n,e,t)}))}}}function _e(n,e,t,r,a){var o=!1;for(var s in e)s in n?e[s]!==t[s]&&(o=!0):(o=!0,ke(n,s,r,a));for(var s in n)s in e||(o=!0,delete n[s]);return o}function ke(n,e,t,r){Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){return t[r][e]}})}function we(n,e){for(var t in e)n[t]=e[t];for(var t in n)t in e||delete n[t]}var xe=null;function Ee(n,e){return(n.__esModule||dn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),p(n)?e.extend(n):n}function je(n){if(a(n))for(var e=0;e<n.length;e++){var t=n[e];if(s(t)&&(s(t.componentOptions)||ge(t)))return t}}function Ae(n,e,t,r,d,u){return(a(t)||l(t))&&(d=r,r=t,t=void 0),i(u)&&(d=2),function(n,e,t,r,l){if(s(t)&&s(t.__ob__))return gn();s(t)&&s(t.is)&&(e=t.is);if(!e)return gn();0;a(r)&&c(r[0])&&((t=t||{}).scopedSlots={default:r[0]},r.length=0);2===l?r=Wn(r):1===l&&(r=function(n){for(var e=0;e<n.length;e++)if(a(n[e]))return Array.prototype.concat.apply([],n);return n}(r));var d,u;if("string"==typeof e){var m=void 0;u=n.$vnode&&n.$vnode.ns||V.getTagNamespace(e),d=V.isReservedTag(e)?new fn(V.parsePlatformTagName(e),t,r,void 0,void 0,n):t&&t.pre||!s(m=zt(n.$options,"components",e))?new fn(e,t,r,void 0,void 0,n):kt(m,t,n,r,e)}else d=kt(e,t,n,r);return a(d)?d:s(d)?(s(u)&&function n(e,t,r){e.ns=t,"foreignObject"===e.tag&&(t=void 0,r=!0);if(s(e.children))for(var a=0,l=e.children.length;a<l;a++){var c=e.children[a];s(c.tag)&&(o(c.ns)||i(r)&&"svg"!==c.tag)&&n(c,t,r)}}(d,u),s(t)&&function(n){p(n.style)&&Ve(n.style);p(n.class)&&Ve(n.class)}(t),d):gn()}(n,e,t,r,d)}function Te(n,e,t){wn();try{if(e)for(var r=e;r=r.$parent;){var a=r.$options.errorCaptured;if(a)for(var o=0;o<a.length;o++)try{if(!1===a[o].call(r,n,e,t))return}catch(n){Ce(n,r,"errorCaptured hook")}}Ce(n,e,t)}finally{xn()}}function Se(n,e,t,r,a){var o;try{(o=t?n.apply(e,t):n.call(e))&&!o._isVue&&g(o)&&!o._handled&&(o.catch((function(n){return Te(n,r,a+" (Promise/async)")})),o._handled=!0)}catch(n){Te(n,r,a)}return o}function Ce(n,e,t){if(V.errorHandler)try{return V.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Be(e,null,"config.errorHandler")}Be(n,e,t)}function Be(n,e,t){if(!Z||"undefined"==typeof console)throw n;console.error(n)}var ze,Pe=!1,Ie=[],qe=!1;function Ne(){qe=!1;var n=Ie.slice(0);Ie.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&cn(Promise)){var De=Promise.resolve();ze=function(){De.then(Ne),nn&&setTimeout(q)},Pe=!0}else if(X||"undefined"==typeof MutationObserver||!cn(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())ze="undefined"!=typeof setImmediate&&cn(setImmediate)?function(){setImmediate(Ne)}:function(){setTimeout(Ne,0)};else{var Fe=1,Oe=new MutationObserver(Ne),Le=document.createTextNode(String(Fe));Oe.observe(Le,{characterData:!0}),ze=function(){Fe=(Fe+1)%2,Le.data=String(Fe)},Pe=!0}function Re(n,e){var t;if(Ie.push((function(){if(n)try{n.call(e)}catch(n){Te(n,e,"nextTick")}else t&&t(e)})),qe||(qe=!0,ze()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}function Me(n){return function(e,t){if(void 0===t&&(t=un),t)return function(n,e,t){var r=n.$options;r[e]=Tt(r[e],t)}(t,n,e)}}Me("beforeMount"),Me("mounted"),Me("beforeUpdate"),Me("updated"),Me("beforeDestroy"),Me("destroyed"),Me("activated"),Me("deactivated"),Me("serverPrefetch"),Me("renderTracked"),Me("renderTriggered"),Me("errorCaptured");var Ue=new pn;function Ve(n){return function n(e,t){var r,o,s=a(e);if(!s&&!p(e)||e.__v_skip||Object.isFrozen(e)||e instanceof fn)return;if(e.__ob__){var i=e.__ob__.dep.id;if(t.has(i))return;t.add(i)}if(s)for(r=e.length;r--;)n(e[r],t);else if(Rn(e))n(e.value,t);else for(o=Object.keys(e),r=o.length;r--;)n(e[o[r]],t)}(n,Ue),Ue.clear(),n}var Je,He=0,Ge=function(){function n(n,e,t,r,a){var o,s;o=this,void 0===(s=Un&&!Un._vm?Un:n?n._scope:void 0)&&(s=Un),s&&s.active&&s.effects.push(o),(this.vm=n)&&a&&(n._watcher=this),r?(this.deep=!!r.deep,this.user=!!r.user,this.lazy=!!r.lazy,this.sync=!!r.sync,this.before=r.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++He,this.active=!0,this.post=!1,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new pn,this.newDepIds=new pn,this.expression="",c(e)?this.getter=e:(this.getter=function(n){if(!$.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=q)),this.value=this.lazy?void 0:this.get()}return n.prototype.get=function(){var n;wn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;Te(n,e,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&Ve(n),xn(),this.cleanupDeps()}return n},n.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},n.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},n.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():mt(this)},n.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||p(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'.concat(this.expression,'"');Se(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},n.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},n.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},n.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&k(this.vm._scope.effects,this),this.active){for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},n}();function $e(n,e){Je.$on(n,e)}function Ke(n,e){Je.$off(n,e)}function Ze(n,e){var t=Je;return function r(){var a=e.apply(null,arguments);null!==a&&t.$off(n,r)}}function We(n,e,t){Je=n,$n(e,t||{},$e,Ke,Ze,n),Je=void 0}var Xe=null;function Qe(n){var e=Xe;return Xe=n,function(){Xe=e}}function Ye(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function nt(n,e){if(e){if(n._directInactive=!1,Ye(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)nt(n.$children[t]);et(n,"activated")}}function et(n,e,t,r){void 0===r&&(r=!0),wn();var a=un,o=Un;r&&mn(n);var s=n.$options[e],i="".concat(e," hook");if(s)for(var l=0,c=s.length;l<c;l++)Se(s[l],n,t||null,n,i);n._hasHookEvent&&n.$emit("hook:"+e),r&&(mn(a),o&&o.on()),xn()}var tt=[],rt=[],at={},ot=!1,st=!1,it=0;var lt=0,ct=Date.now;if(Z&&!X){var pt=window.performance;pt&&"function"==typeof pt.now&&ct()>document.createEvent("Event").timeStamp&&(ct=function(){return pt.now()})}var dt=function(n,e){if(n.post){if(!e.post)return 1}else if(e.post)return-1;return n.id-e.id};function ut(){var n,e;for(lt=ct(),st=!0,tt.sort(dt),it=0;it<tt.length;it++)(n=tt[it]).before&&n.before(),e=n.id,at[e]=null,n.run();var t=rt.slice(),r=tt.slice();it=tt.length=rt.length=0,at={},ot=st=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,nt(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],r=t.vm;r&&r._watcher===t&&r._isMounted&&!r._isDestroyed&&et(r,"updated")}}(r),function(){for(var n=0;n<yn.length;n++){var e=yn[n];e.subs=e.subs.filter((function(n){return n})),e._pending=!1}yn.length=0}(),ln&&V.devtools&&ln.emit("flush")}function mt(n){var e=n.id;if(null==at[e]&&(n!==_n.target||!n.noRecurse)){if(at[e]=!0,st){for(var t=tt.length-1;t>it&&tt[t].id>n.id;)t--;tt.splice(t+1,0,n)}else tt.push(n);ot||(ot=!0,Re(ut))}}function ft(n,e){if(n){for(var t=Object.create(null),r=dn?Reflect.ownKeys(n):Object.keys(n),a=0;a<r.length;a++){var o=r[a];if("__ob__"!==o){var s=n[o].from;if(s in e._provided)t[o]=e._provided[s];else if("default"in n[o]){var i=n[o].default;t[o]=c(i)?i.call(e):i}else 0}}return t}}function gt(n,e,t,o,s){var l,c=this,p=s.options;x(o,"_uid")?(l=Object.create(o))._original=o:(l=o,o=o._original);var d=i(p._compiled),u=!d;this.data=n,this.props=e,this.children=t,this.parent=o,this.listeners=n.on||r,this.injections=ft(p.inject,o),this.slots=function(){return c.$slots||he(o,n.scopedSlots,c.$slots=me(t,o)),c.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return he(o,n.scopedSlots,this.slots())}}),d&&(this.$options=p,this.$slots=this.slots(),this.$scopedSlots=he(o,n.scopedSlots,this.$slots)),p._scopeId?this._c=function(n,e,t,r){var s=Ae(l,n,e,t,r,u);return s&&!a(s)&&(s.fnScopeId=p._scopeId,s.fnContext=o),s}:this._c=function(n,e,t,r){return Ae(l,n,e,t,r,u)}}function ht(n,e,t,r,a){var o=vn(n);return o.fnContext=t,o.fnOptions=r,e.slot&&((o.data||(o.data={})).slot=e.slot),o}function vt(n,e){for(var t in e)n[A(t)]=e[t]}function bt(n){return n.name||n.__name||n._componentTag}ue(gt.prototype);var yt={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;yt.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},r=n.data.inlineTemplate;s(r)&&(t.render=r.render,t.staticRenderFns=r.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,Xe)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,a,o){var s=a.data.scopedSlots,i=n.$scopedSlots,l=!!(s&&!s.$stable||i!==r&&!i.$stable||s&&n.$scopedSlots.$key!==s.$key||!s&&n.$scopedSlots.$key),c=!!(o||n.$options._renderChildren||l),p=n.$vnode;n.$options._parentVnode=a,n.$vnode=a,n._vnode&&(n._vnode.parent=a),n.$options._renderChildren=o;var d=a.data.attrs||r;n._attrsProxy&&_e(n._attrsProxy,d,p.data&&p.data.attrs||r,n,"$attrs")&&(c=!0),n.$attrs=d,t=t||r;var u=n.$options._parentListeners;if(n._listenersProxy&&_e(n._listenersProxy,t,u||r,n,"$listeners"),n.$listeners=n.$options._parentListeners=t,We(n,t,u),e&&n.$options.props){Cn(!1);for(var m=n._props,f=n.$options._propKeys||[],g=0;g<f.length;g++){var h=f[g],v=n.$options.props;m[h]=Pt(h,v,e,n)}Cn(!0),n.$options.propsData=e}c&&(n.$slots=me(o,a.context),n.$forceUpdate())}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,r=n.componentInstance;r._isMounted||(r._isMounted=!0,et(r,"mounted")),n.data.keepAlive&&(t._isMounted?((e=r)._inactive=!1,rt.push(e)):nt(r,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(!(t&&(e._directInactive=!0,Ye(e))||e._inactive)){e._inactive=!0;for(var r=0;r<e.$children.length;r++)n(e.$children[r]);et(e,"deactivated")}}(e,!0):e.$destroy())}},_t=Object.keys(yt);function kt(n,e,t,l,c){if(!o(n)){var d=t.$options._base;if(p(n)&&(n=d.extend(n)),"function"==typeof n){var u;if(o(n.cid)&&void 0===(n=function(n,e){if(i(n.error)&&s(n.errorComp))return n.errorComp;if(s(n.resolved))return n.resolved;var t=xe;if(t&&s(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t),i(n.loading)&&s(n.loadingComp))return n.loadingComp;if(t&&!s(n.owners)){var r=n.owners=[t],a=!0,l=null,c=null;t.$on("hook:destroyed",(function(){return k(r,t)}));var d=function(n){for(var e=0,t=r.length;e<t;e++)r[e].$forceUpdate();n&&(r.length=0,null!==l&&(clearTimeout(l),l=null),null!==c&&(clearTimeout(c),c=null))},u=L((function(t){n.resolved=Ee(t,e),a?r.length=0:d(!0)})),m=L((function(e){s(n.errorComp)&&(n.error=!0,d(!0))})),f=n(u,m);return p(f)&&(g(f)?o(n.resolved)&&f.then(u,m):g(f.component)&&(f.component.then(u,m),s(f.error)&&(n.errorComp=Ee(f.error,e)),s(f.loading)&&(n.loadingComp=Ee(f.loading,e),0===f.delay?n.loading=!0:l=setTimeout((function(){l=null,o(n.resolved)&&o(n.error)&&(n.loading=!0,d(!1))}),f.delay||200)),s(f.timeout)&&(c=setTimeout((function(){c=null,o(n.resolved)&&m(null)}),f.timeout)))),a=!1,n.loading?n.loadingComp:n.resolved}}(u=n,d)))return function(n,e,t,r,a){var o=gn();return o.asyncFactory=n,o.asyncMeta={data:e,context:t,children:r,tag:a},o}(u,e,t,l,c);e=e||{},Gt(n),s(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",r=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var o=e.on||(e.on={}),i=o[r],l=e.model.callback;s(i)?(a(i)?-1===i.indexOf(l):i!==l)&&(o[r]=[l].concat(i)):o[r]=l}(n.options,e);var m=function(n,e,t){var r=e.options.props;if(!o(r)){var a={},i=n.attrs,l=n.props;if(s(i)||s(l))for(var c in r){var p=C(c);Zn(a,l,c,p,!0)||Zn(a,i,c,p,!1)}return a}}(e,n);if(i(n.options.functional))return function(n,e,t,o,i){var l=n.options,c={},p=l.props;if(s(p))for(var d in p)c[d]=Pt(d,p,e||r);else s(t.attrs)&&vt(c,t.attrs),s(t.props)&&vt(c,t.props);var u=new gt(t,c,i,o,n),m=l.render.call(null,u._c,u);if(m instanceof fn)return ht(m,t,u.parent,l,u);if(a(m)){for(var f=Wn(m)||[],g=new Array(f.length),h=0;h<f.length;h++)g[h]=ht(f[h],t,u.parent,l,u);return g}}(n,m,e,t,l);var f=e.on;if(e.on=e.nativeOn,i(n.options.abstract)){var h=e.slot;e={},h&&(e.slot=h)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<_t.length;t++){var r=_t[t],a=e[r],o=yt[r];a===o||a&&a._merged||(e[r]=a?wt(o,a):o)}}(e);var v=bt(n.options)||c;return new fn("vue-component-".concat(n.cid).concat(v?"-".concat(v):""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:m,listeners:f,tag:c,children:l},u)}}}function wt(n,e){var t=function(t,r){n(t,r),e(t,r)};return t._merged=!0,t}var xt=q,Et=V.optionMergeStrategies;function jt(n,e,t){if(void 0===t&&(t=!0),!e)return n;for(var r,a,o,s=dn?Reflect.ownKeys(e):Object.keys(e),i=0;i<s.length;i++)"__ob__"!==(r=s[i])&&(a=n[r],o=e[r],t&&x(n,r)?a!==o&&u(a)&&u(o)&&jt(a,o):qn(n,r,o));return n}function At(n,e,t){return t?function(){var r=c(e)?e.call(t,t):e,a=c(n)?n.call(t,t):n;return r?jt(r,a):a}:e?n?function(){return jt(c(e)?e.call(this,this):e,c(n)?n.call(this,this):n)}:e:n}function Tt(n,e){var t=e?n?n.concat(e):a(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function St(n,e,t,r){var a=Object.create(n||null);return e?P(a,e):a}Et.data=function(n,e,t){return t?At(n,e,t):e&&"function"!=typeof e?n:At(n,e)},U.forEach((function(n){Et[n]=Tt})),M.forEach((function(n){Et[n+"s"]=St})),Et.watch=function(n,e,t,r){if(n===rn&&(n=void 0),e===rn&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var o={};for(var s in P(o,n),e){var i=o[s],l=e[s];i&&!a(i)&&(i=[i]),o[s]=i?i.concat(l):a(l)?l:[l]}return o},Et.props=Et.methods=Et.inject=Et.computed=function(n,e,t,r){if(!n)return e;var a=Object.create(null);return P(a,n),e&&P(a,e),a},Et.provide=function(n,e){return n?function(){var t=Object.create(null);return jt(t,c(n)?n.call(this):n),e&&jt(t,c(e)?e.call(this):e,!1),t}:e};var Ct=function(n,e){return void 0===e?n:e};function Bt(n,e,t){if(c(e)&&(e=e.options),function(n,e){var t=n.props;if(t){var r,o,s={};if(a(t))for(r=t.length;r--;)"string"==typeof(o=t[r])&&(s[A(o)]={type:null});else if(u(t))for(var i in t)o=t[i],s[A(i)]=u(o)?o:{type:o};else 0;n.props=s}}(e),function(n,e){var t=n.inject;if(t){var r=n.inject={};if(a(t))for(var o=0;o<t.length;o++)r[t[o]]={from:t[o]};else if(u(t))for(var s in t){var i=t[s];r[s]=u(i)?P({from:s},i):{from:i}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var r=e[t];c(r)&&(e[t]={bind:r,update:r})}}(e),!e._base&&(e.extends&&(n=Bt(n,e.extends,t)),e.mixins))for(var r=0,o=e.mixins.length;r<o;r++)n=Bt(n,e.mixins[r],t);var s,i={};for(s in n)l(s);for(s in e)x(n,s)||l(s);function l(r){var a=Et[r]||Ct;i[r]=a(n[r],e[r],t,r)}return i}function zt(n,e,t,r){if("string"==typeof t){var a=n[e];if(x(a,t))return a[t];var o=A(t);if(x(a,o))return a[o];var s=T(o);return x(a,s)?a[s]:a[t]||a[o]||a[s]}}function Pt(n,e,t,r){var a=e[n],o=!x(t,n),s=t[n],i=Dt(Boolean,a.type);if(i>-1)if(o&&!x(a,"default"))s=!1;else if(""===s||s===C(n)){var l=Dt(String,a.type);(l<0||i<l)&&(s=!0)}if(void 0===s){s=function(n,e,t){if(!x(e,"default"))return;var r=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return c(r)&&"Function"!==qt(e.type)?r.call(n):r}(r,a,n);var p=Sn;Cn(!0),Pn(s),Cn(p)}return s}var It=/^\s*function (\w+)/;function qt(n){var e=n&&n.toString().match(It);return e?e[1]:""}function Nt(n,e){return qt(n)===qt(e)}function Dt(n,e){if(!a(e))return Nt(e,n)?0:-1;for(var t=0,r=e.length;t<r;t++)if(Nt(e[t],n))return t;return-1}var Ft={enumerable:!0,configurable:!0,get:q,set:q};function Ot(n,e,t){Ft.get=function(){return this[e][t]},Ft.set=function(n){this[e][t]=n},Object.defineProperty(n,t,Ft)}function Lt(n){var e=n.$options;if(e.props&&function(n,e){var t=n.$options.propsData||{},r=n._props=Fn({}),a=n.$options._propKeys=[];n.$parent&&Cn(!1);var o=function(o){a.push(o);var s=Pt(o,e,t,n);In(r,o,s,void 0,!0),o in n||Ot(n,"_props",o)};for(var s in e)o(s);Cn(!0)}(n,e.props),function(n){var e=n.$options,t=e.setup;if(t){var r=n._setupContext=ye(n);mn(n),wn();var a=Se(t,null,[n._props||Fn({}),r],n,"setup");if(xn(),mn(),c(a))e.render=a;else if(p(a))if(n._setupState=a,a.__sfc){var o=n._setupProxy={};for(var s in a)"__sfc"!==s&&Mn(o,a,s)}else for(var s in a)H(s)||Mn(n,a,s);else 0}}(n),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?q:B(e[t],n)}(n,e.methods),e.data)!function(n){var e=n.$options.data;u(e=n._data=c(e)?function(n,e){wn();try{return n.call(e,e)}catch(n){return Te(n,e,"data()"),{}}finally{xn()}}(e,n):e||{})||(e={});var t=Object.keys(e),r=n.$options.props,a=(n.$options.methods,t.length);for(;a--;){var o=t[a];0,r&&x(r,o)||H(o)||Ot(n,"_data",o)}var s=Pn(e);s&&s.vmCount++}(n);else{var t=Pn(n._data={});t&&t.vmCount++}e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),r=sn();for(var a in e){var o=e[a],s=c(o)?o:o.get;0,r||(t[a]=new Ge(n,s||q,q,Rt)),a in n||Mt(n,a,o)}}(n,e.computed),e.watch&&e.watch!==rn&&function(n,e){for(var t in e){var r=e[t];if(a(r))for(var o=0;o<r.length;o++)Jt(n,t,r[o]);else Jt(n,t,r)}}(n,e.watch)}var Rt={lazy:!0};function Mt(n,e,t){var r=!sn();c(t)?(Ft.get=r?Ut(e):Vt(t),Ft.set=q):(Ft.get=t.get?r&&!1!==t.cache?Ut(e):Vt(t.get):q,Ft.set=t.set||q),Object.defineProperty(n,e,Ft)}function Ut(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),_n.target&&e.depend(),e.value}}function Vt(n){return function(){return n.call(this,this)}}function Jt(n,e,t,r){return u(t)&&(r=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,r)}var Ht=0;function Gt(n){var e=n.options;if(n.super){var t=Gt(n.super);if(t!==n.superOptions){n.superOptions=t;var r=function(n){var e,t=n.options,r=n.sealedOptions;for(var a in t)t[a]!==r[a]&&(e||(e={}),e[a]=t[a]);return e}(n);r&&P(n.extendOptions,r),(e=n.options=Bt(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function $t(n){this._init(n)}function Kt(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,r=t.cid,a=n._Ctor||(n._Ctor={});if(a[r])return a[r];var o=bt(n)||bt(t.options);var s=function(n){this._init(n)};return(s.prototype=Object.create(t.prototype)).constructor=s,s.cid=e++,s.options=Bt(t.options,n),s.super=t,s.options.props&&function(n){var e=n.options.props;for(var t in e)Ot(n.prototype,"_props",t)}(s),s.options.computed&&function(n){var e=n.options.computed;for(var t in e)Mt(n.prototype,t,e[t])}(s),s.extend=t.extend,s.mixin=t.mixin,s.use=t.use,M.forEach((function(n){s[n]=t[n]})),o&&(s.options.components[o]=s),s.superOptions=t.options,s.extendOptions=n,s.sealedOptions=P({},s.options),a[r]=s,s}}function Zt(n){return n&&(bt(n.Ctor.options)||n.tag)}function Wt(n,e){return a(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!m(n)&&n.test(e)}function Xt(n,e){var t=n.cache,r=n.keys,a=n._vnode,o=n.$vnode;for(var s in t){var i=t[s];if(i){var l=i.name;l&&!e(l)&&Qt(t,s,r,a)}}o.componentOptions.children=void 0}function Qt(n,e,t,r){var a=n[e];!a||r&&a.tag===r.tag||a.componentInstance.$destroy(),n[e]=null,k(t,e)}!function(n){n.prototype._init=function(n){var e=this;e._uid=Ht++,e._isVue=!0,e.__v_skip=!0,e._scope=new Vn(!0),e._scope.parent=void 0,e._scope._vm=!0,n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),r=e._parentVnode;t.parent=e.parent,t._parentVnode=r;var a=r.componentOptions;t.propsData=a.propsData,t._parentListeners=a.listeners,t._renderChildren=a.children,t._componentTag=a.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=Bt(Gt(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._provided=t?t._provided:Object.create(null),n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&We(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,a=t&&t.context;n.$slots=me(e._renderChildren,a),n.$scopedSlots=t?he(n.$parent,t.data.scopedSlots,n.$slots):r,n._c=function(e,t,r,a){return Ae(n,e,t,r,a,!1)},n.$createElement=function(e,t,r,a){return Ae(n,e,t,r,a,!0)};var o=t&&t.data;In(n,"$attrs",o&&o.attrs||r,null,!0),In(n,"$listeners",e._parentListeners||r,null,!0)}(e),et(e,"beforeCreate",void 0,!1),function(n){var e=ft(n.$options.inject,n);e&&(Cn(!1),Object.keys(e).forEach((function(t){In(n,t,e[t])})),Cn(!0))}(e),Lt(e),function(n){var e=n.$options.provide;if(e){var t=c(e)?e.call(n):e;if(!p(t))return;for(var r=Jn(n),a=dn?Reflect.ownKeys(t):Object.keys(t),o=0;o<a.length;o++){var s=a[o];Object.defineProperty(r,s,Object.getOwnPropertyDescriptor(t,s))}}}(e),et(e,"created"),e.$options.el&&e.$mount(e.$options.el)}}($t),function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=qn,n.prototype.$delete=Nn,n.prototype.$watch=function(n,e,t){if(u(e))return Jt(this,n,e,t);(t=t||{}).user=!0;var r=new Ge(this,n,e,t);if(t.immediate){var a='callback for immediate watcher "'.concat(r.expression,'"');wn(),Se(e,this,[r.value],this,a),xn()}return function(){r.teardown()}}}($t),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var r=this;if(a(n))for(var o=0,s=n.length;o<s;o++)r.$on(n[o],t);else(r._events[n]||(r._events[n]=[])).push(t),e.test(n)&&(r._hasHookEvent=!0);return r},n.prototype.$once=function(n,e){var t=this;function r(){t.$off(n,r),e.apply(t,arguments)}return r.fn=e,t.$on(n,r),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(a(n)){for(var r=0,o=n.length;r<o;r++)t.$off(n[r],e);return t}var s,i=t._events[n];if(!i)return t;if(!e)return t._events[n]=null,t;for(var l=i.length;l--;)if((s=i[l])===e||s.fn===e){i.splice(l,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?z(t):t;for(var r=z(arguments,1),a='event handler for "'.concat(n,'"'),o=0,s=t.length;o<s;o++)Se(t[o],e,r,e,a)}return e}}($t),function(n){n.prototype._update=function(n,e){var t=this,r=t.$el,a=t._vnode,o=Qe(t);t._vnode=n,t.$el=a?t.__patch__(a,n):t.__patch__(t.$el,n,e,!1),o(),r&&(r.__vue__=null),t.$el&&(t.$el.__vue__=t);for(var s=t;s&&s.$vnode&&s.$parent&&s.$vnode===s.$parent._vnode;)s.$parent.$el=s.$el,s=s.$parent},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){et(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||k(e.$children,n),n._scope.stop(),n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),et(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}($t),function(n){ue(n.prototype),n.prototype.$nextTick=function(n){return Re(n,this)},n.prototype._render=function(){var n=this,e=n.$options,t=e.render,r=e._parentVnode;r&&n._isMounted&&(n.$scopedSlots=he(n.$parent,r.data.scopedSlots,n.$slots,n.$scopedSlots),n._slotsProxy&&we(n._slotsProxy,n.$scopedSlots)),n.$vnode=r;var o,s=un,i=xe;try{mn(n),xe=n,o=t.call(n._renderProxy,n.$createElement)}catch(e){Te(e,n,"render"),o=n._vnode}finally{xe=i,mn(s)}return a(o)&&1===o.length&&(o=o[0]),o instanceof fn||(o=gn()),o.parent=r,o}}($t);var Yt=[String,RegExp,Array],nr={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Yt,exclude:Yt,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,r=this.keyToCache;if(t){var a=t.tag,o=t.componentInstance,s=t.componentOptions;n[r]={name:Zt(s),tag:a,componentInstance:o},e.push(r),this.max&&e.length>parseInt(this.max)&&Qt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Qt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Xt(n,(function(n){return Wt(e,n)}))})),this.$watch("exclude",(function(e){Xt(n,(function(n){return!Wt(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=je(n),t=e&&e.componentOptions;if(t){var r=Zt(t),a=this.include,o=this.exclude;if(a&&(!r||!Wt(a,r))||o&&r&&Wt(o,r))return e;var s=this.cache,i=this.keys,l=null==e.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):e.key;s[l]?(e.componentInstance=s[l].componentInstance,k(i,l),i.push(l)):(this.vnodeToCache=e,this.keyToCache=l),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return V}};Object.defineProperty(n,"config",e),n.util={warn:xt,extend:P,mergeOptions:Bt,defineReactive:In},n.set=qn,n.delete=Nn,n.nextTick=Re,n.observable=function(n){return Pn(n),n},n.options=Object.create(null),M.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,P(n.options.components,nr),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=z(arguments,1);return t.unshift(this),c(n.install)?n.install.apply(n,t):c(n)&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=Bt(this.options,n),this}}(n),Kt(n),function(n){M.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&u(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&c(t)&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}($t),Object.defineProperty($t.prototype,"$isServer",{get:sn}),Object.defineProperty($t.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty($t,"FunctionalRenderContext",{value:gt}),$t.version="2.7.16";var er=y("style,class"),tr=y("input,textarea,option,select,progress"),rr=y("contenteditable,draggable,spellcheck"),ar=y("events,caret,typing,plaintext-only"),or=y("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),sr="http://www.w3.org/1999/xlink",ir=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},lr=function(n){return ir(n)?n.slice(6,n.length):""},cr=function(n){return null==n||!1===n};function pr(n){for(var e=n.data,t=n,r=n;s(r.componentInstance);)(r=r.componentInstance._vnode)&&r.data&&(e=dr(r.data,e));for(;s(t=t.parent);)t&&t.data&&(e=dr(e,t.data));return function(n,e){if(s(n)||s(e))return ur(n,mr(e));return""}(e.staticClass,e.class)}function dr(n,e){return{staticClass:ur(n.staticClass,e.staticClass),class:s(n.class)?[n.class,e.class]:e.class}}function ur(n,e){return n?e?n+" "+e:n:e||""}function mr(n){return Array.isArray(n)?function(n){for(var e,t="",r=0,a=n.length;r<a;r++)s(e=mr(n[r]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):p(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var fr={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},gr=y("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),hr=y("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),vr=function(n){return gr(n)||hr(n)};var br=Object.create(null);var yr=y("text,number,password,search,email,tel,url");var _r=Object.freeze({__proto__:null,createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(fr[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),kr={create:function(n,e){wr(e)},update:function(n,e){n.data.ref!==e.data.ref&&(wr(n,!0),wr(e))},destroy:function(n){wr(n,!0)}};function wr(n,e){var t=n.data.ref;if(s(t)){var r=n.context,o=n.componentInstance||n.elm,i=e?null:o,l=e?void 0:o;if(c(t))Se(t,r,[i],r,"template ref function");else{var p=n.data.refInFor,d="string"==typeof t||"number"==typeof t,u=Rn(t),m=r.$refs;if(d||u)if(p){var f=d?m[t]:t.value;e?a(f)&&k(f,o):a(f)?f.includes(o)||f.push(o):d?(m[t]=[o],xr(r,t,m[t])):t.value=[o]}else if(d){if(e&&m[t]!==o)return;m[t]=l,xr(r,t,i)}else if(u){if(e&&t.value!==o)return;t.value=i}else 0}}}function xr(n,e,t){var r=n._setupState;r&&x(r,e)&&(Rn(r[e])?r[e].value=t:r[e]=t)}var Er=new fn("",{},[]),jr=["create","activate","update","remove","destroy"];function Ar(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&s(n.data)===s(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,r=s(t=n.data)&&s(t=t.attrs)&&t.type,a=s(t=e.data)&&s(t=t.attrs)&&t.type;return r===a||yr(r)&&yr(a)}(n,e)||i(n.isAsyncPlaceholder)&&o(e.asyncFactory.error))}function Tr(n,e,t){var r,a,o={};for(r=e;r<=t;++r)s(a=n[r].key)&&(o[a]=r);return o}var Sr={create:Cr,update:Cr,destroy:function(n){Cr(n,Er)}};function Cr(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,r,a,o=n===Er,s=e===Er,i=zr(n.data.directives,n.context),l=zr(e.data.directives,e.context),c=[],p=[];for(t in l)r=i[t],a=l[t],r?(a.oldValue=r.value,a.oldArg=r.arg,Ir(a,"update",e,n),a.def&&a.def.componentUpdated&&p.push(a)):(Ir(a,"bind",e,n),a.def&&a.def.inserted&&c.push(a));if(c.length){var d=function(){for(var t=0;t<c.length;t++)Ir(c[t],"inserted",e,n)};o?Kn(e,"insert",d):d()}p.length&&Kn(e,"postpatch",(function(){for(var t=0;t<p.length;t++)Ir(p[t],"componentUpdated",e,n)}));if(!o)for(t in i)l[t]||Ir(i[t],"unbind",n,n,s)}(n,e)}var Br=Object.create(null);function zr(n,e){var t,r,a=Object.create(null);if(!n)return a;for(t=0;t<n.length;t++){if((r=n[t]).modifiers||(r.modifiers=Br),a[Pr(r)]=r,e._setupState&&e._setupState.__sfc){var o=r.def||zt(e,"_setupState","v-"+r.name);r.def="function"==typeof o?{bind:o,update:o}:o}r.def=r.def||zt(e.$options,"directives",r.name)}return a}function Pr(n){return n.rawName||"".concat(n.name,".").concat(Object.keys(n.modifiers||{}).join("."))}function Ir(n,e,t,r,a){var o=n.def&&n.def[e];if(o)try{o(t.elm,n,t,r,a)}catch(r){Te(r,t.context,"directive ".concat(n.name," ").concat(e," hook"))}}var qr=[kr,Sr];function Nr(n,e){var t=e.componentOptions;if(!(s(t)&&!1===t.Ctor.options.inheritAttrs||o(n.data.attrs)&&o(e.data.attrs))){var r,a,l=e.elm,c=n.data.attrs||{},p=e.data.attrs||{};for(r in(s(p.__ob__)||i(p._v_attr_proxy))&&(p=e.data.attrs=P({},p)),p)a=p[r],c[r]!==a&&Dr(l,r,a,e.data.pre);for(r in(X||Y)&&p.value!==c.value&&Dr(l,"value",p.value),c)o(p[r])&&(ir(r)?l.removeAttributeNS(sr,lr(r)):rr(r)||l.removeAttribute(r))}}function Dr(n,e,t,r){r||n.tagName.indexOf("-")>-1?Fr(n,e,t):or(e)?cr(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):rr(e)?n.setAttribute(e,function(n,e){return cr(e)||"false"===e?"false":"contenteditable"===n&&ar(e)?e:"true"}(e,t)):ir(e)?cr(t)?n.removeAttributeNS(sr,lr(e)):n.setAttributeNS(sr,e,t):Fr(n,e,t)}function Fr(n,e,t){if(cr(t))n.removeAttribute(e);else{if(X&&!Q&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var r=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",r)};n.addEventListener("input",r),n.__ieph=!0}n.setAttribute(e,t)}}var Or={create:Nr,update:Nr};function Lr(n,e){var t=e.elm,r=e.data,a=n.data;if(!(o(r.staticClass)&&o(r.class)&&(o(a)||o(a.staticClass)&&o(a.class)))){var i=pr(e),l=t._transitionClasses;s(l)&&(i=ur(i,mr(l))),i!==t._prevClass&&(t.setAttribute("class",i),t._prevClass=i)}}var Rr,Mr={create:Lr,update:Lr};function Ur(n,e,t){var r=Rr;return function a(){var o=e.apply(null,arguments);null!==o&&Hr(n,a,t,r)}}var Vr=Pe&&!(tn&&Number(tn[1])<=53);function Jr(n,e,t,r){if(Vr){var a=lt,o=e;e=o._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=a||n.timeStamp<=0||n.target.ownerDocument!==document)return o.apply(this,arguments)}}Rr.addEventListener(n,e,an?{capture:t,passive:r}:t)}function Hr(n,e,t,r){(r||Rr).removeEventListener(n,e._wrapper||e,t)}function Gr(n,e){if(!o(n.data.on)||!o(e.data.on)){var t=e.data.on||{},r=n.data.on||{};Rr=e.elm||n.elm,function(n){if(s(n.__r)){var e=X?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}s(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),$n(t,r,Jr,Hr,Ur,e.context),Rr=void 0}}var $r,Kr={create:Gr,update:Gr,destroy:function(n){return Gr(n,Er)}};function Zr(n,e){if(!o(n.data.domProps)||!o(e.data.domProps)){var t,r,a=e.elm,l=n.data.domProps||{},c=e.data.domProps||{};for(t in(s(c.__ob__)||i(c._v_attr_proxy))&&(c=e.data.domProps=P({},c)),l)t in c||(a[t]="");for(t in c){if(r=c[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),r===l[t])continue;1===a.childNodes.length&&a.removeChild(a.childNodes[0])}if("value"===t&&"PROGRESS"!==a.tagName){a._value=r;var p=o(r)?"":String(r);Wr(a,p)&&(a.value=p)}else if("innerHTML"===t&&hr(a.tagName)&&o(a.innerHTML)){($r=$r||document.createElement("div")).innerHTML="<svg>".concat(r,"</svg>");for(var d=$r.firstChild;a.firstChild;)a.removeChild(a.firstChild);for(;d.firstChild;)a.appendChild(d.firstChild)}else if(r!==l[t])try{a[t]=r}catch(n){}}}}function Wr(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,r=n._vModifiers;if(s(r)){if(r.number)return b(t)!==b(e);if(r.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Xr={create:Zr,update:Zr},Qr=E((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var r=n.split(t);r.length>1&&(e[r[0].trim()]=r[1].trim())}})),e}));function Yr(n){var e=na(n.style);return n.staticStyle?P(n.staticStyle,e):e}function na(n){return Array.isArray(n)?I(n):"string"==typeof n?Qr(n):n}var ea,ta=/^--/,ra=/\s*!important$/,aa=function(n,e,t){if(ta.test(e))n.style.setProperty(e,t);else if(ra.test(t))n.style.setProperty(C(e),t.replace(ra,""),"important");else{var r=sa(e);if(Array.isArray(t))for(var a=0,o=t.length;a<o;a++)n.style[r]=t[a];else n.style[r]=t}},oa=["Webkit","Moz","ms"],sa=E((function(n){if(ea=ea||document.createElement("div").style,"filter"!==(n=A(n))&&n in ea)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<oa.length;t++){var r=oa[t]+e;if(r in ea)return r}}));function ia(n,e){var t=e.data,r=n.data;if(!(o(t.staticStyle)&&o(t.style)&&o(r.staticStyle)&&o(r.style))){var a,i,l=e.elm,c=r.staticStyle,p=r.normalizedStyle||r.style||{},d=c||p,u=na(e.data.style)||{};e.data.normalizedStyle=s(u.__ob__)?P({},u):u;var m=function(n,e){var t,r={};if(e)for(var a=n;a.componentInstance;)(a=a.componentInstance._vnode)&&a.data&&(t=Yr(a.data))&&P(r,t);(t=Yr(n.data))&&P(r,t);for(var o=n;o=o.parent;)o.data&&(t=Yr(o.data))&&P(r,t);return r}(e,!0);for(i in d)o(m[i])&&aa(l,i,"");for(i in m)a=m[i],aa(l,i,null==a?"":a)}}var la={create:ia,update:ia},ca=/\s+/;function pa(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(ca).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" ".concat(n.getAttribute("class")||""," ");t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function da(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(ca).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" ".concat(n.getAttribute("class")||""," "),r=" "+e+" ";t.indexOf(r)>=0;)t=t.replace(r," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function ua(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&P(e,ma(n.name||"v")),P(e,n),e}return"string"==typeof n?ma(n):void 0}}var ma=E((function(n){return{enterClass:"".concat(n,"-enter"),enterToClass:"".concat(n,"-enter-to"),enterActiveClass:"".concat(n,"-enter-active"),leaveClass:"".concat(n,"-leave"),leaveToClass:"".concat(n,"-leave-to"),leaveActiveClass:"".concat(n,"-leave-active")}})),fa=Z&&!Q,ga="transition",ha="transitionend",va="animation",ba="animationend";fa&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(ga="WebkitTransition",ha="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(va="WebkitAnimation",ba="webkitAnimationEnd"));var ya=Z?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function _a(n){ya((function(){ya(n)}))}function ka(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),pa(n,e))}function wa(n,e){n._transitionClasses&&k(n._transitionClasses,e),da(n,e)}function xa(n,e,t){var r=ja(n,e),a=r.type,o=r.timeout,s=r.propCount;if(!a)return t();var i="transition"===a?ha:ba,l=0,c=function(){n.removeEventListener(i,p),t()},p=function(e){e.target===n&&++l>=s&&c()};setTimeout((function(){l<s&&c()}),o+1),n.addEventListener(i,p)}var Ea=/\b(transform|all)(,|$)/;function ja(n,e){var t,r=window.getComputedStyle(n),a=(r[ga+"Delay"]||"").split(", "),o=(r[ga+"Duration"]||"").split(", "),s=Aa(a,o),i=(r[va+"Delay"]||"").split(", "),l=(r[va+"Duration"]||"").split(", "),c=Aa(i,l),p=0,d=0;return"transition"===e?s>0&&(t="transition",p=s,d=o.length):"animation"===e?c>0&&(t="animation",p=c,d=l.length):d=(t=(p=Math.max(s,c))>0?s>c?"transition":"animation":null)?"transition"===t?o.length:l.length:0,{type:t,timeout:p,propCount:d,hasTransform:"transition"===t&&Ea.test(r[ga+"Property"])}}function Aa(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return Ta(e)+Ta(n[t])})))}function Ta(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function Sa(n,e){var t=n.elm;s(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var r=ua(n.data.transition);if(!o(r)&&!s(t._enterCb)&&1===t.nodeType){for(var a=r.css,i=r.type,l=r.enterClass,d=r.enterToClass,u=r.enterActiveClass,m=r.appearClass,f=r.appearToClass,g=r.appearActiveClass,h=r.beforeEnter,v=r.enter,y=r.afterEnter,_=r.enterCancelled,k=r.beforeAppear,w=r.appear,x=r.afterAppear,E=r.appearCancelled,j=r.duration,A=Xe,T=Xe.$vnode;T&&T.parent;)A=T.context,T=T.parent;var S=!A._isMounted||!n.isRootInsert;if(!S||w||""===w){var C=S&&m?m:l,B=S&&g?g:u,z=S&&f?f:d,P=S&&k||h,I=S&&c(w)?w:v,q=S&&x||y,N=S&&E||_,D=b(p(j)?j.enter:j);0;var F=!1!==a&&!Q,O=za(I),R=t._enterCb=L((function(){F&&(wa(t,z),wa(t,B)),R.cancelled?(F&&wa(t,C),N&&N(t)):q&&q(t),t._enterCb=null}));n.data.show||Kn(n,"insert",(function(){var e=t.parentNode,r=e&&e._pending&&e._pending[n.key];r&&r.tag===n.tag&&r.elm._leaveCb&&r.elm._leaveCb(),I&&I(t,R)})),P&&P(t),F&&(ka(t,C),ka(t,B),_a((function(){wa(t,C),R.cancelled||(ka(t,z),O||(Ba(D)?setTimeout(R,D):xa(t,i,R)))}))),n.data.show&&(e&&e(),I&&I(t,R)),F||O||R()}}}function Ca(n,e){var t=n.elm;s(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var r=ua(n.data.transition);if(o(r)||1!==t.nodeType)return e();if(!s(t._leaveCb)){var a=r.css,i=r.type,l=r.leaveClass,c=r.leaveToClass,d=r.leaveActiveClass,u=r.beforeLeave,m=r.leave,f=r.afterLeave,g=r.leaveCancelled,h=r.delayLeave,v=r.duration,y=!1!==a&&!Q,_=za(m),k=b(p(v)?v.leave:v);0;var w=t._leaveCb=L((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),y&&(wa(t,c),wa(t,d)),w.cancelled?(y&&wa(t,l),g&&g(t)):(e(),f&&f(t)),t._leaveCb=null}));h?h(x):x()}function x(){w.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),u&&u(t),y&&(ka(t,l),ka(t,d),_a((function(){wa(t,l),w.cancelled||(ka(t,c),_||(Ba(k)?setTimeout(w,k):xa(t,i,w)))}))),m&&m(t,w),y||_||w())}}function Ba(n){return"number"==typeof n&&!isNaN(n)}function za(n){if(o(n))return!1;var e=n.fns;return s(e)?za(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function Pa(n,e){!0!==e.data.show&&Sa(e)}var Ia=function(n){var e,t,r={},c=n.modules,p=n.nodeOps;for(e=0;e<jr.length;++e)for(r[jr[e]]=[],t=0;t<c.length;++t)s(c[t][jr[e]])&&r[jr[e]].push(c[t][jr[e]]);function d(n){var e=p.parentNode(n);s(e)&&p.removeChild(e,n)}function u(n,e,t,a,o,l,c){if(s(n.elm)&&s(l)&&(n=l[c]=vn(n)),n.isRootInsert=!o,!function(n,e,t,a){var o=n.data;if(s(o)){var l=s(n.componentInstance)&&o.keepAlive;if(s(o=o.hook)&&s(o=o.init)&&o(n,!1),s(n.componentInstance))return m(n,e),f(t,n.elm,a),i(l)&&function(n,e,t,a){var o,i=n;for(;i.componentInstance;)if(i=i.componentInstance._vnode,s(o=i.data)&&s(o=o.transition)){for(o=0;o<r.activate.length;++o)r.activate[o](Er,i);e.push(i);break}f(t,n.elm,a)}(n,e,t,a),!0}}(n,e,t,a)){var d=n.data,u=n.children,h=n.tag;s(h)?(n.elm=n.ns?p.createElementNS(n.ns,h):p.createElement(h,n),b(n),g(n,u,e),s(d)&&v(n,e),f(t,n.elm,a)):i(n.isComment)?(n.elm=p.createComment(n.text),f(t,n.elm,a)):(n.elm=p.createTextNode(n.text),f(t,n.elm,a))}}function m(n,e){s(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,h(n)?(v(n,e),b(n)):(wr(n),e.push(n))}function f(n,e,t){s(n)&&(s(t)?p.parentNode(t)===n&&p.insertBefore(n,e,t):p.appendChild(n,e))}function g(n,e,t){if(a(e)){0;for(var r=0;r<e.length;++r)u(e[r],t,n.elm,null,!0,e,r)}else l(n.text)&&p.appendChild(n.elm,p.createTextNode(String(n.text)))}function h(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return s(n.tag)}function v(n,t){for(var a=0;a<r.create.length;++a)r.create[a](Er,n);s(e=n.data.hook)&&(s(e.create)&&e.create(Er,n),s(e.insert)&&t.push(n))}function b(n){var e;if(s(e=n.fnScopeId))p.setStyleScope(n.elm,e);else for(var t=n;t;)s(e=t.context)&&s(e=e.$options._scopeId)&&p.setStyleScope(n.elm,e),t=t.parent;s(e=Xe)&&e!==n.context&&e!==n.fnContext&&s(e=e.$options._scopeId)&&p.setStyleScope(n.elm,e)}function _(n,e,t,r,a,o){for(;r<=a;++r)u(t[r],o,n,e,!1,t,r)}function k(n){var e,t,a=n.data;if(s(a))for(s(e=a.hook)&&s(e=e.destroy)&&e(n),e=0;e<r.destroy.length;++e)r.destroy[e](n);if(s(e=n.children))for(t=0;t<n.children.length;++t)k(n.children[t])}function w(n,e,t){for(;e<=t;++e){var r=n[e];s(r)&&(s(r.tag)?(x(r),k(r)):d(r.elm))}}function x(n,e){if(s(e)||s(n.data)){var t,a=r.remove.length+1;for(s(e)?e.listeners+=a:e=function(n,e){function t(){0==--t.listeners&&d(n)}return t.listeners=e,t}(n.elm,a),s(t=n.componentInstance)&&s(t=t._vnode)&&s(t.data)&&x(t,e),t=0;t<r.remove.length;++t)r.remove[t](n,e);s(t=n.data.hook)&&s(t=t.remove)?t(n,e):e()}else d(n.elm)}function E(n,e,t,r){for(var a=t;a<r;a++){var o=e[a];if(s(o)&&Ar(n,o))return a}}function j(n,e,t,a,l,c){if(n!==e){s(e.elm)&&s(a)&&(e=a[l]=vn(e));var d=e.elm=n.elm;if(i(n.isAsyncPlaceholder))s(e.asyncFactory.resolved)?S(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(i(e.isStatic)&&i(n.isStatic)&&e.key===n.key&&(i(e.isCloned)||i(e.isOnce)))e.componentInstance=n.componentInstance;else{var m,f=e.data;s(f)&&s(m=f.hook)&&s(m=m.prepatch)&&m(n,e);var g=n.children,v=e.children;if(s(f)&&h(e)){for(m=0;m<r.update.length;++m)r.update[m](n,e);s(m=f.hook)&&s(m=m.update)&&m(n,e)}o(e.text)?s(g)&&s(v)?g!==v&&function(n,e,t,r,a){var i,l,c,d=0,m=0,f=e.length-1,g=e[0],h=e[f],v=t.length-1,b=t[0],y=t[v],k=!a;for(0;d<=f&&m<=v;)o(g)?g=e[++d]:o(h)?h=e[--f]:Ar(g,b)?(j(g,b,r,t,m),g=e[++d],b=t[++m]):Ar(h,y)?(j(h,y,r,t,v),h=e[--f],y=t[--v]):Ar(g,y)?(j(g,y,r,t,v),k&&p.insertBefore(n,g.elm,p.nextSibling(h.elm)),g=e[++d],y=t[--v]):Ar(h,b)?(j(h,b,r,t,m),k&&p.insertBefore(n,h.elm,g.elm),h=e[--f],b=t[++m]):(o(i)&&(i=Tr(e,d,f)),o(l=s(b.key)?i[b.key]:E(b,e,d,f))?u(b,r,n,g.elm,!1,t,m):Ar(c=e[l],b)?(j(c,b,r,t,m),e[l]=void 0,k&&p.insertBefore(n,c.elm,g.elm)):u(b,r,n,g.elm,!1,t,m),b=t[++m]);d>f?_(n,o(t[v+1])?null:t[v+1].elm,t,m,v,r):m>v&&w(e,d,f)}(d,g,v,t,c):s(v)?(s(n.text)&&p.setTextContent(d,""),_(d,null,v,0,v.length-1,t)):s(g)?w(g,0,g.length-1):s(n.text)&&p.setTextContent(d,""):n.text!==e.text&&p.setTextContent(d,e.text),s(f)&&s(m=f.hook)&&s(m=m.postpatch)&&m(n,e)}}}function A(n,e,t){if(i(t)&&s(n.parent))n.parent.data.pendingInsert=e;else for(var r=0;r<e.length;++r)e[r].data.hook.insert(e[r])}var T=y("attrs,class,staticClass,staticStyle,key");function S(n,e,t,r){var a,o=e.tag,l=e.data,c=e.children;if(r=r||l&&l.pre,e.elm=n,i(e.isComment)&&s(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(s(l)&&(s(a=l.hook)&&s(a=a.init)&&a(e,!0),s(a=e.componentInstance)))return m(e,t),!0;if(s(o)){if(s(c))if(n.hasChildNodes())if(s(a=l)&&s(a=a.domProps)&&s(a=a.innerHTML)){if(a!==n.innerHTML)return!1}else{for(var p=!0,d=n.firstChild,u=0;u<c.length;u++){if(!d||!S(d,c[u],t,r)){p=!1;break}d=d.nextSibling}if(!p||d)return!1}else g(e,c,t);if(s(l)){var f=!1;for(var h in l)if(!T(h)){f=!0,v(e,t);break}!f&&l.class&&Ve(l.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,a){if(!o(e)){var l,c=!1,d=[];if(o(n))c=!0,u(e,d);else{var m=s(n.nodeType);if(!m&&Ar(n,e))j(n,e,d,null,null,a);else{if(m){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),i(t)&&S(n,e,d))return A(e,d,!0),n;l=n,n=new fn(p.tagName(l).toLowerCase(),{},[],void 0,l)}var f=n.elm,g=p.parentNode(f);if(u(e,d,f._leaveCb?null:g,p.nextSibling(f)),s(e.parent))for(var v=e.parent,b=h(e);v;){for(var y=0;y<r.destroy.length;++y)r.destroy[y](v);if(v.elm=e.elm,b){for(var _=0;_<r.create.length;++_)r.create[_](Er,v);var x=v.data.hook.insert;if(x.merged)for(var E=x.fns.slice(1),T=0;T<E.length;T++)E[T]()}else wr(v);v=v.parent}s(g)?w([n],0,0):s(n.tag)&&k(n)}}return A(e,d,c),e.elm}s(n)&&k(n)}}({nodeOps:_r,modules:[Or,Mr,Kr,Xr,la,Z?{create:Pa,activate:Pa,remove:function(n,e){!0!==n.data.show?Ca(n,e):e()}}:{}].concat(qr)});Q&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&Ma(n,"input")}));var qa={inserted:function(n,e,t,r){"select"===t.tag?(r.elm&&!r.elm._vOptions?Kn(t,"postpatch",(function(){qa.componentUpdated(n,e,t)})):Na(n,e,t.context),n._vOptions=[].map.call(n.options,Oa)):("textarea"===t.tag||yr(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",La),n.addEventListener("compositionend",Ra),n.addEventListener("change",Ra),Q&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){Na(n,e,t.context);var r=n._vOptions,a=n._vOptions=[].map.call(n.options,Oa);if(a.some((function(n,e){return!F(n,r[e])})))(n.multiple?e.value.some((function(n){return Fa(n,a)})):e.value!==e.oldValue&&Fa(e.value,a))&&Ma(n,"change")}}};function Na(n,e,t){Da(n,e,t),(X||Y)&&setTimeout((function(){Da(n,e,t)}),0)}function Da(n,e,t){var r=e.value,a=n.multiple;if(!a||Array.isArray(r)){for(var o,s,i=0,l=n.options.length;i<l;i++)if(s=n.options[i],a)o=O(r,Oa(s))>-1,s.selected!==o&&(s.selected=o);else if(F(Oa(s),r))return void(n.selectedIndex!==i&&(n.selectedIndex=i));a||(n.selectedIndex=-1)}}function Fa(n,e){return e.every((function(e){return!F(e,n)}))}function Oa(n){return"_value"in n?n._value:n.value}function La(n){n.target.composing=!0}function Ra(n){n.target.composing&&(n.target.composing=!1,Ma(n.target,"input"))}function Ma(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function Ua(n){return!n.componentInstance||n.data&&n.data.transition?n:Ua(n.componentInstance._vnode)}var Va={model:qa,show:{bind:function(n,e,t){var r=e.value,a=(t=Ua(t)).data&&t.data.transition,o=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;r&&a?(t.data.show=!0,Sa(t,(function(){n.style.display=o}))):n.style.display=r?o:"none"},update:function(n,e,t){var r=e.value;!r!=!e.oldValue&&((t=Ua(t)).data&&t.data.transition?(t.data.show=!0,r?Sa(t,(function(){n.style.display=n.__vOriginalDisplay})):Ca(t,(function(){n.style.display="none"}))):n.style.display=r?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,r,a){a||(n.style.display=n.__vOriginalDisplay)}}},Ja={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Ha(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?Ha(je(e.children)):n}function Ga(n){var e={},t=n.$options;for(var r in t.propsData)e[r]=n[r];var a=t._parentListeners;for(var r in a)e[A(r)]=a[r];return e}function $a(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Ka=function(n){return n.tag||ge(n)},Za=function(n){return"show"===n.name},Wa={name:"transition",props:Ja,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Ka)).length){0;var r=this.mode;0;var a=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return a;var o=Ha(a);if(!o)return a;if(this._leaving)return $a(n,a);var s="__transition-".concat(this._uid,"-");o.key=null==o.key?o.isComment?s+"comment":s+o.tag:l(o.key)?0===String(o.key).indexOf(s)?o.key:s+o.key:o.key;var i=(o.data||(o.data={})).transition=Ga(this),c=this._vnode,p=Ha(c);if(o.data.directives&&o.data.directives.some(Za)&&(o.data.show=!0),p&&p.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(o,p)&&!ge(p)&&(!p.componentInstance||!p.componentInstance._vnode.isComment)){var d=p.data.transition=P({},i);if("out-in"===r)return this._leaving=!0,Kn(d,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),$a(n,a);if("in-out"===r){if(ge(o))return c;var u,m=function(){u()};Kn(i,"afterEnter",m),Kn(i,"enterCancelled",m),Kn(d,"delayLeave",(function(n){u=n}))}}return a}}},Xa=P({tag:String,moveClass:String},Ja);function Qa(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function Ya(n){n.data.newPos=n.elm.getBoundingClientRect()}function no(n){var e=n.data.pos,t=n.data.newPos,r=e.left-t.left,a=e.top-t.top;if(r||a){n.data.moved=!0;var o=n.elm.style;o.transform=o.WebkitTransform="translate(".concat(r,"px,").concat(a,"px)"),o.transitionDuration="0s"}}delete Xa.mode;var eo={Transition:Wa,TransitionGroup:{props:Xa,beforeMount:function(){var n=this,e=this._update;this._update=function(t,r){var a=Qe(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,a(),e.call(n,t,r)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),r=this.prevChildren=this.children,a=this.$slots.default||[],o=this.children=[],s=Ga(this),i=0;i<a.length;i++){if((p=a[i]).tag)if(null!=p.key&&0!==String(p.key).indexOf("__vlist"))o.push(p),t[p.key]=p,(p.data||(p.data={})).transition=s;else;}if(r){var l=[],c=[];for(i=0;i<r.length;i++){var p;(p=r[i]).data.transition=s,p.data.pos=p.elm.getBoundingClientRect(),t[p.key]?l.push(p):c.push(p)}this.kept=n(e,null,l),this.removed=c}return n(e,null,o)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Qa),n.forEach(Ya),n.forEach(no),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,r=t.style;ka(t,e),r.transform=r.WebkitTransform=r.transitionDuration="",t.addEventListener(ha,t._moveCb=function n(r){r&&r.target!==t||r&&!/transform$/.test(r.propertyName)||(t.removeEventListener(ha,n),t._moveCb=null,wa(t,e))})}})))},methods:{hasMove:function(n,e){if(!fa)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){da(t,n)})),pa(t,e),t.style.display="none",this.$el.appendChild(t);var r=ja(t);return this.$el.removeChild(t),this._hasMove=r.hasTransform}}}};function to(n,e){for(var t in e)n[t]=e[t];return n}$t.config.mustUseProp=function(n,e,t){return"value"===t&&tr(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},$t.config.isReservedTag=vr,$t.config.isReservedAttr=er,$t.config.getTagNamespace=function(n){return hr(n)?"svg":"math"===n?"math":void 0},$t.config.isUnknownElement=function(n){if(!Z)return!0;if(vr(n))return!1;if(n=n.toLowerCase(),null!=br[n])return br[n];var e=document.createElement(n);return n.indexOf("-")>-1?br[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:br[n]=/HTMLUnknownElement/.test(e.toString())},P($t.options.directives,Va),P($t.options.components,eo),$t.prototype.__patch__=Z?Ia:q,$t.prototype.$mount=function(n,e){return function(n,e,t){var r;n.$el=e,n.$options.render||(n.$options.render=gn),et(n,"beforeMount"),r=function(){n._update(n._render(),t)},new Ge(n,r,q,{before:function(){n._isMounted&&!n._isDestroyed&&et(n,"beforeUpdate")}},!0),t=!1;var a=n._preWatchers;if(a)for(var o=0;o<a.length;o++)a[o].run();return null==n.$vnode&&(n._isMounted=!0,et(n,"mounted")),n}(this,n=n&&Z?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},Z&&setTimeout((function(){V.devtools&&ln&&ln.emit("init",$t)}),0);var ro=/[!'()*]/g,ao=function(n){return"%"+n.charCodeAt(0).toString(16)},oo=/%2C/g,so=function(n){return encodeURIComponent(n).replace(ro,ao).replace(oo,",")};function io(n){try{return decodeURIComponent(n)}catch(n){0}return n}var lo=function(n){return null==n||"object"==typeof n?n:String(n)};function co(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),r=io(t.shift()),a=t.length>0?io(t.join("=")):null;void 0===e[r]?e[r]=a:Array.isArray(e[r])?e[r].push(a):e[r]=[e[r],a]})),e):e}function po(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return so(e);if(Array.isArray(t)){var r=[];return t.forEach((function(n){void 0!==n&&(null===n?r.push(so(e)):r.push(so(e)+"="+so(n)))})),r.join("&")}return so(e)+"="+so(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var uo=/\/?$/;function mo(n,e,t,r){var a=r&&r.options.stringifyQuery,o=e.query||{};try{o=fo(o)}catch(n){}var s={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:o,params:e.params||{},fullPath:vo(e,a),matched:n?ho(n):[]};return t&&(s.redirectedFrom=vo(t,a)),Object.freeze(s)}function fo(n){if(Array.isArray(n))return n.map(fo);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=fo(n[t]);return e}return n}var go=mo(null,{path:"/"});function ho(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function vo(n,e){var t=n.path,r=n.query;void 0===r&&(r={});var a=n.hash;return void 0===a&&(a=""),(t||"/")+(e||po)(r)+a}function bo(n,e,t){return e===go?n===e:!!e&&(n.path&&e.path?n.path.replace(uo,"")===e.path.replace(uo,"")&&(t||n.hash===e.hash&&yo(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&yo(n.query,e.query)&&yo(n.params,e.params))))}function yo(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),r=Object.keys(e).sort();return t.length===r.length&&t.every((function(t,a){var o=n[t];if(r[a]!==t)return!1;var s=e[t];return null==o||null==s?o===s:"object"==typeof o&&"object"==typeof s?yo(o,s):String(o)===String(s)}))}function _o(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var r in t.instances){var a=t.instances[r],o=t.enteredCbs[r];if(a&&o){delete t.enteredCbs[r];for(var s=0;s<o.length;s++)a._isBeingDestroyed||o[s](a)}}}}var ko={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,r=e.children,a=e.parent,o=e.data;o.routerView=!0;for(var s=a.$createElement,i=t.name,l=a.$route,c=a._routerViewCache||(a._routerViewCache={}),p=0,d=!1;a&&a._routerRoot!==a;){var u=a.$vnode?a.$vnode.data:{};u.routerView&&p++,u.keepAlive&&a._directInactive&&a._inactive&&(d=!0),a=a.$parent}if(o.routerViewDepth=p,d){var m=c[i],f=m&&m.component;return f?(m.configProps&&wo(f,o,m.route,m.configProps),s(f,o,r)):s()}var g=l.matched[p],h=g&&g.components[i];if(!g||!h)return c[i]=null,s();c[i]={component:h},o.registerRouteInstance=function(n,e){var t=g.instances[i];(e&&t!==n||!e&&t===n)&&(g.instances[i]=e)},(o.hook||(o.hook={})).prepatch=function(n,e){g.instances[i]=e.componentInstance},o.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==g.instances[i]&&(g.instances[i]=n.componentInstance),_o(l)};var v=g.props&&g.props[i];return v&&(to(c[i],{route:l,configProps:v}),wo(h,o,l,v)),s(h,o,r)}};function wo(n,e,t,r){var a=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,r);if(a){a=e.props=to({},a);var o=e.attrs=e.attrs||{};for(var s in a)n.props&&s in n.props||(o[s]=a[s],delete a[s])}}function xo(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var a=e.split("/");t&&a[a.length-1]||a.pop();for(var o=n.replace(/^\//,"").split("/"),s=0;s<o.length;s++){var i=o[s];".."===i?a.pop():"."!==i&&a.push(i)}return""!==a[0]&&a.unshift(""),a.join("/")}function Eo(n){return n.replace(/\/(?:\s*\/)+/g,"/")}var jo=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},Ao=Ro,To=Po,So=function(n,e){return qo(Po(n,e),e)},Co=qo,Bo=Lo,zo=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function Po(n,e){for(var t,r=[],a=0,o=0,s="",i=e&&e.delimiter||"/";null!=(t=zo.exec(n));){var l=t[0],c=t[1],p=t.index;if(s+=n.slice(o,p),o=p+l.length,c)s+=c[1];else{var d=n[o],u=t[2],m=t[3],f=t[4],g=t[5],h=t[6],v=t[7];s&&(r.push(s),s="");var b=null!=u&&null!=d&&d!==u,y="+"===h||"*"===h,_="?"===h||"*"===h,k=t[2]||i,w=f||g;r.push({name:m||a++,prefix:u||"",delimiter:k,optional:_,repeat:y,partial:b,asterisk:!!v,pattern:w?Do(w):v?".*":"[^"+No(k)+"]+?"})}}return o<n.length&&(s+=n.substr(o)),s&&r.push(s),r}function Io(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function qo(n,e){for(var t=new Array(n.length),r=0;r<n.length;r++)"object"==typeof n[r]&&(t[r]=new RegExp("^(?:"+n[r].pattern+")$",Oo(e)));return function(e,r){for(var a="",o=e||{},s=(r||{}).pretty?Io:encodeURIComponent,i=0;i<n.length;i++){var l=n[i];if("string"!=typeof l){var c,p=o[l.name];if(null==p){if(l.optional){l.partial&&(a+=l.prefix);continue}throw new TypeError('Expected "'+l.name+'" to be defined')}if(jo(p)){if(!l.repeat)throw new TypeError('Expected "'+l.name+'" to not repeat, but received `'+JSON.stringify(p)+"`");if(0===p.length){if(l.optional)continue;throw new TypeError('Expected "'+l.name+'" to not be empty')}for(var d=0;d<p.length;d++){if(c=s(p[d]),!t[i].test(c))throw new TypeError('Expected all "'+l.name+'" to match "'+l.pattern+'", but received `'+JSON.stringify(c)+"`");a+=(0===d?l.prefix:l.delimiter)+c}}else{if(c=l.asterisk?encodeURI(p).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):s(p),!t[i].test(c))throw new TypeError('Expected "'+l.name+'" to match "'+l.pattern+'", but received "'+c+'"');a+=l.prefix+c}}else a+=l}return a}}function No(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function Do(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function Fo(n,e){return n.keys=e,n}function Oo(n){return n&&n.sensitive?"":"i"}function Lo(n,e,t){jo(e)||(t=e||t,e=[]);for(var r=(t=t||{}).strict,a=!1!==t.end,o="",s=0;s<n.length;s++){var i=n[s];if("string"==typeof i)o+=No(i);else{var l=No(i.prefix),c="(?:"+i.pattern+")";e.push(i),i.repeat&&(c+="(?:"+l+c+")*"),o+=c=i.optional?i.partial?l+"("+c+")?":"(?:"+l+"("+c+"))?":l+"("+c+")"}}var p=No(t.delimiter||"/"),d=o.slice(-p.length)===p;return r||(o=(d?o.slice(0,-p.length):o)+"(?:"+p+"(?=$))?"),o+=a?"$":r&&d?"":"(?="+p+"|$)",Fo(new RegExp("^"+o,Oo(t)),e)}function Ro(n,e,t){return jo(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var r=0;r<t.length;r++)e.push({name:r,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return Fo(n,e)}(n,e):jo(n)?function(n,e,t){for(var r=[],a=0;a<n.length;a++)r.push(Ro(n[a],e,t).source);return Fo(new RegExp("(?:"+r.join("|")+")",Oo(t)),e)}(n,e,t):function(n,e,t){return Lo(Po(n,t),e,t)}(n,e,t)}Ao.parse=To,Ao.compile=So,Ao.tokensToFunction=Co,Ao.tokensToRegExp=Bo;var Mo=Object.create(null);function Uo(n,e,t){e=e||{};try{var r=Mo[n]||(Mo[n]=Ao.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),r(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function Vo(n,e,t,r){var a="string"==typeof n?{path:n}:n;if(a._normalized)return a;if(a.name){var o=(a=to({},n)).params;return o&&"object"==typeof o&&(a.params=to({},o)),a}if(!a.path&&a.params&&e){(a=to({},a))._normalized=!0;var s=to(to({},e.params),a.params);if(e.name)a.name=e.name,a.params=s;else if(e.matched.length){var i=e.matched[e.matched.length-1].path;a.path=Uo(i,s,e.path)}else 0;return a}var l=function(n){var e="",t="",r=n.indexOf("#");r>=0&&(e=n.slice(r),n=n.slice(0,r));var a=n.indexOf("?");return a>=0&&(t=n.slice(a+1),n=n.slice(0,a)),{path:n,query:t,hash:e}}(a.path||""),c=e&&e.path||"/",p=l.path?xo(l.path,c,t||a.append):c,d=function(n,e,t){void 0===e&&(e={});var r,a=t||co;try{r=a(n||"")}catch(n){r={}}for(var o in e){var s=e[o];r[o]=Array.isArray(s)?s.map(lo):lo(s)}return r}(l.query,a.query,r&&r.options.parseQuery),u=a.hash||l.hash;return u&&"#"!==u.charAt(0)&&(u="#"+u),{_normalized:!0,path:p,query:d,hash:u}}var Jo,Ho=function(){},Go={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,r=this.$route,a=t.resolve(this.to,r,this.append),o=a.location,s=a.route,i=a.href,l={},c=t.options.linkActiveClass,p=t.options.linkExactActiveClass,d=null==c?"router-link-active":c,u=null==p?"router-link-exact-active":p,m=null==this.activeClass?d:this.activeClass,f=null==this.exactActiveClass?u:this.exactActiveClass,g=s.redirectedFrom?mo(null,Vo(s.redirectedFrom),null,t):s;l[f]=bo(r,g,this.exactPath),l[m]=this.exact||this.exactPath?l[f]:function(n,e){return 0===n.path.replace(uo,"/").indexOf(e.path.replace(uo,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(r,g);var h=l[f]?this.ariaCurrentValue:null,v=function(n){$o(n)&&(e.replace?t.replace(o,Ho):t.push(o,Ho))},b={click:$o};Array.isArray(this.event)?this.event.forEach((function(n){b[n]=v})):b[this.event]=v;var y={class:l},_=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:i,route:s,navigate:v,isActive:l[m],isExactActive:l[f]});if(_){if(1===_.length)return _[0];if(_.length>1||!_.length)return 0===_.length?n():n("span",{},_)}if("a"===this.tag)y.on=b,y.attrs={href:i,"aria-current":h};else{var k=function n(e){var t;if(e)for(var r=0;r<e.length;r++){if("a"===(t=e[r]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(k){k.isStatic=!1;var w=k.data=to({},k.data);for(var x in w.on=w.on||{},w.on){var E=w.on[x];x in b&&(w.on[x]=Array.isArray(E)?E:[E])}for(var j in b)j in w.on?w.on[j].push(b[j]):w.on[j]=v;var A=k.data.attrs=to({},k.data.attrs);A.href=i,A["aria-current"]=h}else y.on=b}return n(this.tag,y,this.$slots.default)}};function $o(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Ko="undefined"!=typeof window;function Zo(n,e,t,r,a){var o=e||[],s=t||Object.create(null),i=r||Object.create(null);n.forEach((function(n){!function n(e,t,r,a,o,s){var i=a.path,l=a.name;0;var c=a.pathToRegexpOptions||{},p=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return Eo(e.path+"/"+n)}(i,o,c.strict);"boolean"==typeof a.caseSensitive&&(c.sensitive=a.caseSensitive);var d={path:p,regex:Wo(p,c),components:a.components||{default:a.component},alias:a.alias?"string"==typeof a.alias?[a.alias]:a.alias:[],instances:{},enteredCbs:{},name:l,parent:o,matchAs:s,redirect:a.redirect,beforeEnter:a.beforeEnter,meta:a.meta||{},props:null==a.props?{}:a.components?a.props:{default:a.props}};a.children&&a.children.forEach((function(a){var o=s?Eo(s+"/"+a.path):void 0;n(e,t,r,a,d,o)}));t[d.path]||(e.push(d.path),t[d.path]=d);if(void 0!==a.alias)for(var u=Array.isArray(a.alias)?a.alias:[a.alias],m=0;m<u.length;++m){0;var f={path:u[m],children:a.children};n(e,t,r,f,o,d.path||"/")}l&&(r[l]||(r[l]=d))}(o,s,i,n,a)}));for(var l=0,c=o.length;l<c;l++)"*"===o[l]&&(o.push(o.splice(l,1)[0]),c--,l--);return{pathList:o,pathMap:s,nameMap:i}}function Wo(n,e){return Ao(n,[],e)}function Xo(n,e){var t=Zo(n),r=t.pathList,a=t.pathMap,o=t.nameMap;function s(n,t,s){var i=Vo(n,t,!1,e),c=i.name;if(c){var p=o[c];if(!p)return l(null,i);var d=p.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof i.params&&(i.params={}),t&&"object"==typeof t.params)for(var u in t.params)!(u in i.params)&&d.indexOf(u)>-1&&(i.params[u]=t.params[u]);return i.path=Uo(p.path,i.params),l(p,i,s)}if(i.path){i.params={};for(var m=0;m<r.length;m++){var f=r[m],g=a[f];if(Qo(g.regex,i.path,i.params))return l(g,i,s)}}return l(null,i)}function i(n,t){var r=n.redirect,a="function"==typeof r?r(mo(n,t,null,e)):r;if("string"==typeof a&&(a={path:a}),!a||"object"!=typeof a)return l(null,t);var i=a,c=i.name,p=i.path,d=t.query,u=t.hash,m=t.params;if(d=i.hasOwnProperty("query")?i.query:d,u=i.hasOwnProperty("hash")?i.hash:u,m=i.hasOwnProperty("params")?i.params:m,c){o[c];return s({_normalized:!0,name:c,query:d,hash:u,params:m},void 0,t)}if(p){var f=function(n,e){return xo(n,e.parent?e.parent.path:"/",!0)}(p,n);return s({_normalized:!0,path:Uo(f,m),query:d,hash:u},void 0,t)}return l(null,t)}function l(n,t,r){return n&&n.redirect?i(n,r||t):n&&n.matchAs?function(n,e,t){var r=s({_normalized:!0,path:Uo(t,e.params)});if(r){var a=r.matched,o=a[a.length-1];return e.params=r.params,l(o,e)}return l(null,e)}(0,t,n.matchAs):mo(n,t,r,e)}return{match:s,addRoute:function(n,e){var t="object"!=typeof n?o[n]:void 0;Zo([e||n],r,a,o,t),t&&t.alias.length&&Zo(t.alias.map((function(n){return{path:n,children:[e]}})),r,a,o,t)},getRoutes:function(){return r.map((function(n){return a[n]}))},addRoutes:function(n){Zo(n,r,a,o)}}}function Qo(n,e,t){var r=e.match(n);if(!r)return!1;if(!t)return!0;for(var a=1,o=r.length;a<o;++a){var s=n.keys[a-1];s&&(t[s.name||"pathMatch"]="string"==typeof r[a]?io(r[a]):r[a])}return!0}var Yo=Ko&&window.performance&&window.performance.now?window.performance:Date;function ns(){return Yo.now().toFixed(3)}var es=ns();function ts(){return es}function rs(n){return es=n}var as=Object.create(null);function os(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=to({},window.history.state);return t.key=ts(),window.history.replaceState(t,"",e),window.addEventListener("popstate",ls),function(){window.removeEventListener("popstate",ls)}}function ss(n,e,t,r){if(n.app){var a=n.options.scrollBehavior;a&&n.app.$nextTick((function(){var o=function(){var n=ts();if(n)return as[n]}(),s=a.call(n,e,t,r?o:null);s&&("function"==typeof s.then?s.then((function(n){ms(n,o)})).catch((function(n){0})):ms(s,o))}))}}function is(){var n=ts();n&&(as[n]={x:window.pageXOffset,y:window.pageYOffset})}function ls(n){is(),n.state&&n.state.key&&rs(n.state.key)}function cs(n){return ds(n.x)||ds(n.y)}function ps(n){return{x:ds(n.x)?n.x:window.pageXOffset,y:ds(n.y)?n.y:window.pageYOffset}}function ds(n){return"number"==typeof n}var us=/^#\d/;function ms(n,e){var t,r="object"==typeof n;if(r&&"string"==typeof n.selector){var a=us.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(a){var o=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),r=n.getBoundingClientRect();return{x:r.left-t.left-e.x,y:r.top-t.top-e.y}}(a,o={x:ds((t=o).x)?t.x:0,y:ds(t.y)?t.y:0})}else cs(n)&&(e=ps(n))}else r&&cs(n)&&(e=ps(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var fs,gs=Ko&&((-1===(fs=window.navigator.userAgent).indexOf("Android 2.")&&-1===fs.indexOf("Android 4.0")||-1===fs.indexOf("Mobile Safari")||-1!==fs.indexOf("Chrome")||-1!==fs.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function hs(n,e){is();var t=window.history;try{if(e){var r=to({},t.state);r.key=ts(),t.replaceState(r,"",n)}else t.pushState({key:rs(ns())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function vs(n){hs(n,!0)}var bs={redirected:2,aborted:4,cancelled:8,duplicated:16};function ys(n,e){return ks(n,e,bs.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return ws.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function _s(n,e){return ks(n,e,bs.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function ks(n,e,t,r){var a=new Error(r);return a._isRouter=!0,a.from=n,a.to=e,a.type=t,a}var ws=["params","query","hash"];function xs(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function Es(n,e){return xs(n)&&n._isRouter&&(null==e||n.type===e)}function js(n,e,t){var r=function(a){a>=n.length?t():n[a]?e(n[a],(function(){r(a+1)})):r(a+1)};r(0)}function As(n){return function(e,t,r){var a=!1,o=0,s=null;Ts(n,(function(n,e,t,i){if("function"==typeof n&&void 0===n.cid){a=!0,o++;var l,c=Bs((function(e){var a;((a=e).__esModule||Cs&&"Module"===a[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:Jo.extend(e),t.components[i]=e,--o<=0&&r()})),p=Bs((function(n){var e="Failed to resolve async component "+i+": "+n;s||(s=xs(n)?n:new Error(e),r(s))}));try{l=n(c,p)}catch(n){p(n)}if(l)if("function"==typeof l.then)l.then(c,p);else{var d=l.component;d&&"function"==typeof d.then&&d.then(c,p)}}})),a||r()}}function Ts(n,e){return Ss(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function Ss(n){return Array.prototype.concat.apply([],n)}var Cs="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Bs(n){var e=!1;return function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];if(!e)return e=!0,n.apply(this,t)}}var zs=function(n,e){this.router=n,this.base=function(n){if(!n)if(Ko){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=go,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Ps(n,e,t,r){var a=Ts(n,(function(n,r,a,o){var s=function(n,e){"function"!=typeof n&&(n=Jo.extend(n));return n.options[e]}(n,e);if(s)return Array.isArray(s)?s.map((function(n){return t(n,r,a,o)})):t(s,r,a,o)}));return Ss(r?a.reverse():a)}function Is(n,e){if(e)return function(){return n.apply(e,arguments)}}zs.prototype.listen=function(n){this.cb=n},zs.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},zs.prototype.onError=function(n){this.errorCbs.push(n)},zs.prototype.transitionTo=function(n,e,t){var r,a=this;try{r=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var o=this.current;this.confirmTransition(r,(function(){a.updateRoute(r),e&&e(r),a.ensureURL(),a.router.afterHooks.forEach((function(n){n&&n(r,o)})),a.ready||(a.ready=!0,a.readyCbs.forEach((function(n){n(r)})))}),(function(n){t&&t(n),n&&!a.ready&&(Es(n,bs.redirected)&&o===go||(a.ready=!0,a.readyErrorCbs.forEach((function(e){e(n)}))))}))},zs.prototype.confirmTransition=function(n,e,t){var r=this,a=this.current;this.pending=n;var o,s,i=function(n){!Es(n)&&xs(n)&&(r.errorCbs.length?r.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},l=n.matched.length-1,c=a.matched.length-1;if(bo(n,a)&&l===c&&n.matched[l]===a.matched[c])return this.ensureURL(),n.hash&&ss(this.router,a,n,!1),i(((s=ks(o=a,n,bs.duplicated,'Avoided redundant navigation to current location: "'+o.fullPath+'".')).name="NavigationDuplicated",s));var p=function(n,e){var t,r=Math.max(n.length,e.length);for(t=0;t<r&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),d=p.updated,u=p.deactivated,m=p.activated,f=[].concat(function(n){return Ps(n,"beforeRouteLeave",Is,!0)}(u),this.router.beforeHooks,function(n){return Ps(n,"beforeRouteUpdate",Is)}(d),m.map((function(n){return n.beforeEnter})),As(m)),g=function(e,t){if(r.pending!==n)return i(_s(a,n));try{e(n,a,(function(e){!1===e?(r.ensureURL(!0),i(function(n,e){return ks(n,e,bs.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(a,n))):xs(e)?(r.ensureURL(!0),i(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(i(ys(a,n)),"object"==typeof e&&e.replace?r.replace(e):r.push(e)):t(e)}))}catch(n){i(n)}};js(f,g,(function(){js(function(n){return Ps(n,"beforeRouteEnter",(function(n,e,t,r){return function(n,e,t){return function(r,a,o){return n(r,a,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),o(n)}))}}(n,t,r)}))}(m).concat(r.router.resolveHooks),g,(function(){if(r.pending!==n)return i(_s(a,n));r.pending=null,e(n),r.router.app&&r.router.app.$nextTick((function(){_o(n)}))}))}))},zs.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},zs.prototype.setupListeners=function(){},zs.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=go,this.pending=null};var qs=function(n){function e(e,t){n.call(this,e,t),this._startLocation=Ns(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,r=gs&&t;r&&this.listeners.push(os());var a=function(){var t=n.current,a=Ns(n.base);n.current===go&&a===n._startLocation||n.transitionTo(a,(function(n){r&&ss(e,n,t,!0)}))};window.addEventListener("popstate",a),this.listeners.push((function(){window.removeEventListener("popstate",a)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){hs(Eo(r.base+n.fullPath)),ss(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){vs(Eo(r.base+n.fullPath)),ss(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(Ns(this.base)!==this.current.fullPath){var e=Eo(this.base+this.current.fullPath);n?hs(e):vs(e)}},e.prototype.getCurrentLocation=function(){return Ns(this.base)},e}(zs);function Ns(n){var e=window.location.pathname,t=e.toLowerCase(),r=n.toLowerCase();return!n||t!==r&&0!==t.indexOf(Eo(r+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var Ds=function(n){function e(e,t,r){n.call(this,e,t),r&&function(n){var e=Ns(n);if(!/^\/#/.test(e))return window.location.replace(Eo(n+"/#"+e)),!0}(this.base)||Fs()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=gs&&e;t&&this.listeners.push(os());var r=function(){var e=n.current;Fs()&&n.transitionTo(Os(),(function(r){t&&ss(n.router,r,e,!0),gs||Ms(r.fullPath)}))},a=gs?"popstate":"hashchange";window.addEventListener(a,r),this.listeners.push((function(){window.removeEventListener(a,r)}))}},e.prototype.push=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){Rs(n.fullPath),ss(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){Ms(n.fullPath),ss(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;Os()!==e&&(n?Rs(e):Ms(e))},e.prototype.getCurrentLocation=function(){return Os()},e}(zs);function Fs(){var n=Os();return"/"===n.charAt(0)||(Ms("/"+n),!1)}function Os(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function Ls(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function Rs(n){gs?hs(Ls(n)):window.location.hash=n}function Ms(n){gs?vs(Ls(n)):window.location.replace(Ls(n))}var Us=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index+1).concat(n),r.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var r=this.stack[t];this.confirmTransition(r,(function(){var n=e.current;e.index=t,e.updateRoute(r),e.router.afterHooks.forEach((function(e){e&&e(r,n)}))}),(function(n){Es(n,bs.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(zs),Vs=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Xo(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!gs&&!1!==n.fallback,this.fallback&&(e="hash"),Ko||(e="abstract"),this.mode=e,e){case"history":this.history=new qs(this,n.base);break;case"hash":this.history=new Ds(this,n.base,this.fallback);break;case"abstract":this.history=new Us(this,n.base);break;default:0}},Js={currentRoute:{configurable:!0}};Vs.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},Js.currentRoute.get=function(){return this.history&&this.history.current},Vs.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof qs||t instanceof Ds){var r=function(n){t.setupListeners(),function(n){var r=t.current,a=e.options.scrollBehavior;gs&&a&&"fullPath"in n&&ss(e,n,r,!1)}(n)};t.transitionTo(t.getCurrentLocation(),r,r)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},Vs.prototype.beforeEach=function(n){return Gs(this.beforeHooks,n)},Vs.prototype.beforeResolve=function(n){return Gs(this.resolveHooks,n)},Vs.prototype.afterEach=function(n){return Gs(this.afterHooks,n)},Vs.prototype.onReady=function(n,e){this.history.onReady(n,e)},Vs.prototype.onError=function(n){this.history.onError(n)},Vs.prototype.push=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.push(n,e,t)}));this.history.push(n,e,t)},Vs.prototype.replace=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.replace(n,e,t)}));this.history.replace(n,e,t)},Vs.prototype.go=function(n){this.history.go(n)},Vs.prototype.back=function(){this.go(-1)},Vs.prototype.forward=function(){this.go(1)},Vs.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},Vs.prototype.resolve=function(n,e,t){var r=Vo(n,e=e||this.history.current,t,this),a=this.match(r,e),o=a.redirectedFrom||a.fullPath;return{location:r,route:a,href:function(n,e,t){var r="hash"===t?"#"+e:e;return n?Eo(n+"/"+r):r}(this.history.base,o,this.mode),normalizedTo:r,resolved:a}},Vs.prototype.getRoutes=function(){return this.matcher.getRoutes()},Vs.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==go&&this.history.transitionTo(this.history.getCurrentLocation())},Vs.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==go&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(Vs.prototype,Js);var Hs=Vs;function Gs(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}Vs.install=function n(e){if(!n.installed||Jo!==e){n.installed=!0,Jo=e;var t=function(n){return void 0!==n},r=function(n,e){var r=n.$options._parentVnode;t(r)&&t(r=r.data)&&t(r=r.registerRouteInstance)&&r(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,r(this,this)},destroyed:function(){r(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",ko),e.component("RouterLink",Go);var a=e.config.optionMergeStrategies;a.beforeRouteEnter=a.beforeRouteLeave=a.beforeRouteUpdate=a.created}},Vs.version="3.6.5",Vs.isNavigationFailure=Es,Vs.NavigationFailureType=bs,Vs.START_LOCATION=go,Ko&&window.Vue&&window.Vue.use(Vs);t(100);t(129),t(16);var $s={NotFound:()=>Promise.all([t.e(0),t.e(4)]).then(t.bind(null,330)),Layout:()=>Promise.all([t.e(0),t.e(2)]).then(t.bind(null,329))},Ks={"v-22282852":()=>t.e(119).then(t.bind(null,332)),"v-1ede408b":()=>t.e(6).then(t.bind(null,333)),"v-302e23f4":()=>t.e(8).then(t.bind(null,334)),"v-d1a6c318":()=>t.e(9).then(t.bind(null,335)),"v-7a11f4c8":()=>t.e(10).then(t.bind(null,336)),"v-4932a3f8":()=>t.e(11).then(t.bind(null,337)),"v-033d1db6":()=>t.e(12).then(t.bind(null,338)),"v-b983bcaa":()=>t.e(7).then(t.bind(null,339)),"v-a4110f34":()=>t.e(13).then(t.bind(null,340)),"v-718cb9b0":()=>t.e(14).then(t.bind(null,341)),"v-7e40cffe":()=>t.e(15).then(t.bind(null,342)),"v-566b048c":()=>t.e(16).then(t.bind(null,343)),"v-34e42639":()=>t.e(17).then(t.bind(null,344)),"v-423655cc":()=>t.e(18).then(t.bind(null,345)),"v-1b5f1ee8":()=>t.e(19).then(t.bind(null,346)),"v-b8532098":()=>t.e(20).then(t.bind(null,347)),"v-d5c1a816":()=>t.e(21).then(t.bind(null,348)),"v-0b03f7cc":()=>t.e(22).then(t.bind(null,349)),"v-7b03b51c":()=>t.e(23).then(t.bind(null,350)),"v-f9a862c8":()=>t.e(25).then(t.bind(null,351)),"v-6bd8e8aa":()=>t.e(26).then(t.bind(null,352)),"v-5a7b351e":()=>t.e(27).then(t.bind(null,353)),"v-0379b906":()=>t.e(28).then(t.bind(null,354)),"v-3223b15c":()=>t.e(24).then(t.bind(null,355)),"v-8cb0bf1a":()=>t.e(29).then(t.bind(null,356)),"v-4d95c10a":()=>t.e(33).then(t.bind(null,357)),"v-47b0b8a9":()=>t.e(32).then(t.bind(null,358)),"v-437ba2ee":()=>t.e(34).then(t.bind(null,359)),"v-7413a666":()=>t.e(37).then(t.bind(null,360)),"v-fdfd34bc":()=>t.e(38).then(t.bind(null,361)),"v-d51b20aa":()=>t.e(30).then(t.bind(null,362)),"v-74234f32":()=>t.e(39).then(t.bind(null,363)),"v-0fd7c93e":()=>t.e(40).then(t.bind(null,364)),"v-064e6b52":()=>t.e(41).then(t.bind(null,365)),"v-86796282":()=>t.e(42).then(t.bind(null,366)),"v-1a0f65c8":()=>t.e(36).then(t.bind(null,367)),"v-642acf34":()=>t.e(43).then(t.bind(null,368)),"v-86799138":()=>t.e(44).then(t.bind(null,369)),"v-1eacf608":()=>t.e(45).then(t.bind(null,370)),"v-77369d13":()=>t.e(35).then(t.bind(null,371)),"v-8f1b0f62":()=>t.e(46).then(t.bind(null,372)),"v-f08b0a92":()=>t.e(47).then(t.bind(null,373)),"v-0fd01db7":()=>t.e(48).then(t.bind(null,374)),"v-11e81284":()=>t.e(50).then(t.bind(null,375)),"v-be038f46":()=>t.e(49).then(t.bind(null,376)),"v-6cbb1851":()=>t.e(51).then(t.bind(null,377)),"v-67c4fe98":()=>t.e(53).then(t.bind(null,378)),"v-cc91cd44":()=>t.e(54).then(t.bind(null,379)),"v-16efd28d":()=>t.e(55).then(t.bind(null,380)),"v-079101b0":()=>t.e(52).then(t.bind(null,381)),"v-27753cf3":()=>t.e(56).then(t.bind(null,382)),"v-d04209ac":()=>t.e(57).then(t.bind(null,383)),"v-7a226c10":()=>t.e(58).then(t.bind(null,384)),"v-97fa14a4":()=>t.e(59).then(t.bind(null,385)),"v-8855b59c":()=>t.e(60).then(t.bind(null,386)),"v-3dc84304":()=>t.e(61).then(t.bind(null,387)),"v-cee6b5d2":()=>t.e(62).then(t.bind(null,388)),"v-5be0bc4c":()=>t.e(64).then(t.bind(null,389)),"v-54ae2f6d":()=>t.e(65).then(t.bind(null,390)),"v-6b5349e8":()=>t.e(63).then(t.bind(null,391)),"v-788e5ef9":()=>t.e(67).then(t.bind(null,392)),"v-597fc7ce":()=>t.e(66).then(t.bind(null,393)),"v-0e418e98":()=>t.e(68).then(t.bind(null,394)),"v-208228f3":()=>t.e(69).then(t.bind(null,395)),"v-4534d8ad":()=>t.e(70).then(t.bind(null,396)),"v-98683fbe":()=>t.e(71).then(t.bind(null,397)),"v-7dfe11b0":()=>t.e(72).then(t.bind(null,398)),"v-502d161c":()=>t.e(74).then(t.bind(null,399)),"v-abb9096c":()=>t.e(75).then(t.bind(null,400)),"v-2c646377":()=>t.e(76).then(t.bind(null,401)),"v-bb440a42":()=>t.e(77).then(t.bind(null,402)),"v-50cf7a82":()=>t.e(78).then(t.bind(null,403)),"v-6e6e165e":()=>t.e(79).then(t.bind(null,404)),"v-72f4b6b0":()=>t.e(80).then(t.bind(null,405)),"v-3e16c4d8":()=>t.e(81).then(t.bind(null,406)),"v-242c57bc":()=>t.e(82).then(t.bind(null,407)),"v-580c8dac":()=>t.e(83).then(t.bind(null,408)),"v-669ddbd6":()=>t.e(84).then(t.bind(null,409)),"v-5f11081e":()=>t.e(85).then(t.bind(null,410)),"v-e8f812b8":()=>t.e(86).then(t.bind(null,411)),"v-35d0167d":()=>t.e(87).then(t.bind(null,412)),"v-788c4982":()=>t.e(88).then(t.bind(null,413)),"v-f7e64afe":()=>t.e(89).then(t.bind(null,414)),"v-3c157da4":()=>t.e(90).then(t.bind(null,415)),"v-069fea3d":()=>t.e(91).then(t.bind(null,416)),"v-2e6d253f":()=>t.e(92).then(t.bind(null,417)),"v-573b59b6":()=>t.e(94).then(t.bind(null,418)),"v-0056c406":()=>t.e(95).then(t.bind(null,419)),"v-fc3c6860":()=>t.e(93).then(t.bind(null,420)),"v-3b941cbe":()=>t.e(97).then(t.bind(null,421)),"v-05407dda":()=>t.e(96).then(t.bind(null,422)),"v-a1f03dba":()=>t.e(98).then(t.bind(null,423)),"v-ec68963a":()=>t.e(99).then(t.bind(null,424)),"v-37dbc27d":()=>t.e(100).then(t.bind(null,425)),"v-118bdc85":()=>t.e(101).then(t.bind(null,426)),"v-fdcf4762":()=>t.e(102).then(t.bind(null,427)),"v-21216af8":()=>t.e(104).then(t.bind(null,428)),"v-325b46da":()=>t.e(105).then(t.bind(null,429)),"v-3e69314c":()=>t.e(106).then(t.bind(null,430)),"v-31a5e395":()=>t.e(103).then(t.bind(null,431)),"v-e9cb914e":()=>t.e(110).then(t.bind(null,432)),"v-087ac98a":()=>t.e(108).then(t.bind(null,433)),"v-05a28fa4":()=>t.e(111).then(t.bind(null,434)),"v-8c516c3e":()=>t.e(109).then(t.bind(null,435)),"v-54f1c73c":()=>t.e(113).then(t.bind(null,331)),"v-567cb3a8":()=>t.e(112).then(t.bind(null,436)),"v-0485a99b":()=>t.e(115).then(t.bind(null,437)),"v-e5fb5ede":()=>t.e(31).then(t.bind(null,438)),"v-e627318a":()=>t.e(107).then(t.bind(null,439)),"v-7ffecc44":()=>t.e(117).then(t.bind(null,440)),"v-25855433":()=>t.e(73).then(t.bind(null,441)),"v-8d4bc20e":()=>t.e(114).then(t.bind(null,442)),"v-6cd702fe":()=>t.e(116).then(t.bind(null,443)),"v-16e3f17e":()=>t.e(118).then(t.bind(null,444))};function Zs(n){const e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}const Ws=/-(\w)/g,Xs=Zs(n=>n.replace(Ws,(n,e)=>e?e.toUpperCase():"")),Qs=/\B([A-Z])/g,Ys=Zs(n=>n.replace(Qs,"-$1").toLowerCase()),ni=Zs(n=>n.charAt(0).toUpperCase()+n.slice(1));function ei(n,e){if(!e)return;if(n(e))return n(e);return e.includes("-")?n(ni(Xs(e))):n(ni(e))||n(Ys(e))}const ti=Object.assign({},$s,Ks),ri=n=>ti[n],ai=n=>Ks[n],oi=n=>$s[n],si=n=>$t.component(n);function ii(n){return ei(ai,n)}function li(n){return ei(oi,n)}function ci(n){return ei(ri,n)}function pi(n){return ei(si,n)}function di(...n){return Promise.all(n.filter(n=>n).map(async n=>{if(!pi(n)&&ci(n)){const e=await ci(n)();$t.component(n,e.default)}}))}function ui(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var mi=t(93),fi=t.n(mi),gi=t(94),hi=t.n(gi),vi={created(){if(this.siteMeta=this.$site.headTags.filter(([n])=>"meta"===n).map(([n,e])=>e),this.$ssrContext){const e=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(n=e)?n.map(n=>{let e="<meta";return Object.keys(n).forEach(t=>{e+=` ${t}="${hi()(n[t])}"`}),e+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=yi(this.$canonicalUrl)}var n},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const n=this.getMergedMetaTags();this.currentMetaTags=_i(n,this.currentMetaTags)},getMergedMetaTags(){const n=this.$page.frontmatter.meta||[];return fi()([{name:"description",content:this.$description}],n,this.siteMeta,ki)},updateCanonicalLink(){bi(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",yi(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){_i(null,this.currentMetaTags),bi()}};function bi(){const n=document.querySelector("link[rel='canonical']");n&&n.remove()}function yi(n=""){return n?`<link href="${n}" rel="canonical" />`:""}function _i(n,e){if(e&&[...e].filter(n=>n.parentNode===document.head).forEach(n=>document.head.removeChild(n)),n)return n.map(n=>{const e=document.createElement("meta");return Object.keys(n).forEach(t=>{e.setAttribute(t,n[t])}),document.head.appendChild(e),e})}function ki(n){for(const e of["name","property","itemprop"])if(n.hasOwnProperty(e))return n[e]+e;return JSON.stringify(n)}var wi=t(49),xi={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(wi)()((function(){this.setActiveHash()}),300),setActiveHash(){const n=[].slice.call(document.querySelectorAll(".sidebar-link")),e=[].slice.call(document.querySelectorAll(".header-anchor")).filter(e=>n.some(n=>n.hash===e.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),r=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),a=window.innerHeight+t;for(let n=0;n<e.length;n++){const o=e[n],s=e[n+1],i=0===n&&0===t||t>=o.parentElement.offsetTop+10&&(!s||t<s.parentElement.offsetTop-10),l=decodeURIComponent(this.$route.hash);if(i&&l!==decodeURIComponent(o.hash)){const t=o;if(a===r)for(let t=n+1;t<e.length;t++)if(l===decodeURIComponent(e[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},Ei=t(24),ji=t.n(Ei),Ai={mounted(){ji.a.configure({showSpinner:!1}),this.$router.beforeEach((n,e,t)=>{n.path===e.path||$t.component(n.name)||ji.a.start(),t()}),this.$router.afterEach(()=>{ji.a.done(),this.isSidebarOpen=!1})}};t(242),t(243);class Ti{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:n="",duration:e=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${n}</div>\n    `,this.containerEl.appendChild(t),e>0&&setTimeout(()=>{this.close(t)},e)}close(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",()=>{n.remove()})}}var Si={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(n=>{document.querySelectorAll(n).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(n){if(n.classList.contains("codecopy-enabled"))return;const e=document.createElement("i");e.className="code-copy",e.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',e.title="Copy to clipboard",e.addEventListener("click",()=>{this.copyToClipboard(n.innerText)}),n.appendChild(e),n.classList.add("codecopy-enabled")},copyToClipboard(n){const e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy");(new Ti).show({text:"复制成功",duration:1e3}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};!function(n,e){void 0===e&&(e={});var t=e.insertAt;if(n&&"undefined"!=typeof document){var r=document.head||document.getElementsByTagName("head")[0],a=document.createElement("style");a.type="text/css","top"===t&&r.firstChild?r.insertBefore(a,r.firstChild):r.appendChild(a),a.styleSheet?a.styleSheet.cssText=n:a.appendChild(document.createTextNode(n))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var Ci={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},Bi={},zi=function(n){return'<div id="app">\n'.concat(n,"\n</div>")},Pi=function(n){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[n]?window.$VUEPRESS_DEMO_BLOCK[n]:Ci[n]},Ii=function n(e,t,r){var a=document.createElement(e);return t&&Object.keys(t).forEach((function(n){if(n.indexOf("data"))a[n]=t[n];else{var e=n.replace("data","");a.dataset[e]=t[n]}})),r&&r.forEach((function(e){var t=e.tag,r=e.attrs,o=e.children;a.appendChild(n(t,r,o))})),a},qi=function(n,e,t){var r,a=(r=n.querySelectorAll(".".concat(e)),Array.prototype.slice.call(r));return 1!==a.length||t?a:a[0]},Ni=function(n,e){var t,r,a=n.match(/<style>([\s\S]+)<\/style>/),o=n.match(/<template>([\s\S]+)<\/template>/),s=n.match(/<script>([\s\S]+)<\/script>/),i={css:a&&a[1].replace(/^\n|\n$/g,""),html:o&&o[1].replace(/^\n|\n$/g,""),js:s&&s[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};i.htmlTpl=zi(i.html),i.jsTpl=(t=i.js,r=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(r,"\n})")),i.script=function(n,e){var t=n.split(/export\s+default/),r="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),a=window.Babel?window.Babel.transform(r,{presets:["es2015"]}).code:r,o=[eval][0](a);return o.template=e,o}(i.js,i.html);var l=Pi("vue");return i.jsLib.unshift(l),i},Di=function(n,e){var t,r=n.match(/<style>([\s\S]+)<\/style>/),a=n.match(/<html>([\s\S]+)<\/html>/),o=n.match(/<script>([\s\S]+)<\/script>/),s={css:r&&r[1].replace(/^\n|\n$/g,""),html:a&&a[1].replace(/^\n|\n$/g,""),js:o&&o[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};return s.htmlTpl=s.html,s.jsTpl=s.js,s.script=(t=s.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),s},Fi=function(n){return n=n.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),n+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function Oi(){var n=qi(document,"vuepress-plugin-demo-block__wrapper",!0);n.length?n.forEach((function(n){if("true"!==n.dataset.created){n.style.display="block";var e=qi(n,"vuepress-plugin-demo-block__code"),t=qi(n,"vuepress-plugin-demo-block__display"),r=qi(n,"vuepress-plugin-demo-block__footer"),a=qi(t,"vuepress-plugin-demo-block__app"),o=decodeURIComponent(n.dataset.code),s=decodeURIComponent(n.dataset.config),i=decodeURIComponent(n.dataset.type);s=s?JSON.parse(s):{};var l=e.querySelector("div").clientHeight,c="react"===i?function(n,e){var t=(0,window.Babel.transform)(n,{presets:["es2015","react"]}).code,r="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),a=new Function("return ".concat(r))(),o={js:a,css:a.__style__||"",jsLib:e.jsLib||[],cssLib:e.cssLib||[],jsTpl:Fi(n),htmlTpl:zi("")},s=Pi("react"),i=Pi("reactDOM");return o.jsLib.unshift(s,i),o}(o,s):"vanilla"===i?Di(o,s):Ni(o,s),p=Ii("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(r.appendChild(p),p.addEventListener("click",Li.bind(null,p,l,e,r)),Pi("jsfiddle")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,a=n.jsLib,o=n.cssLib,s=a.concat(o).concat(Pi("cssLib")).concat(Pi("jsLib")).join(",");return Ii("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:e}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:r}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:s}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(c)),Pi("codepen")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,a=n.jsLib,o=n.cssLib,s=JSON.stringify({css:e,html:t,js:r,js_external:a.concat(Pi("jsLib")).join(";"),css_external:o.concat(Pi("cssLib")).join(";"),layout:Pi("codepenLayout"),js_pre_processor:Pi("codepenJsProcessor"),editors:Pi("codepenEditors")});return Ii("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:s}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(c)),void 0!==s.horizontal?s.horizontal:Pi("horizontal")){n.classList.add("vuepress-plugin-demo-block__horizontal");var d=e.firstChild.cloneNode(!0);d.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(d)}if(c.css&&function(n){if(!Bi[n]){var e=Ii("style",{innerHTML:n});document.body.appendChild(e),Bi[n]=!0}}(c.css),"react"===i)ReactDOM.render(React.createElement(c.js),a);else if("vue"===i){var u=(new(Vue.extend(c.script))).$mount();a.appendChild(u.$el)}else"vanilla"===i&&(a.innerHTML=c.html,new Function("return (function(){".concat(c.script,"})()"))());n.dataset.created="true"}})):setTimeout((function(n){Oi()}),300)}function Li(n,e,t,r){var a="1"!==n.dataset.isExpand;t.style.height=a?"".concat(e,"px"):0,a?r.classList.add("vuepress-plugin-demo-block__show-link"):r.classList.remove("vuepress-plugin-demo-block__show-link"),n.dataset.isExpand=a?"1":"0"}var Ri={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},Oi()},updated:function(){Oi()}},Mi="auto",Ui="zoom-in",Vi="zoom-out",Ji="grab",Hi="move";function Gi(n,e,t){var r=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],a={passive:!1};r?n.addEventListener(e,t,a):n.removeEventListener(e,t,a)}function $i(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function Ki(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function Zi(n,e,t){!function(n){var e=Wi,t=Xi;if(n.transition){var r=n.transition;delete n.transition,n[e]=r}if(n.transform){var a=n.transform;delete n.transform,n[t]=a}}(e);var r=n.style,a={};for(var o in e)t&&(a[o]=r[o]||""),r[o]=e[o];return a}var Wi="transition",Xi="transform",Qi="transform",Yi="transitionend";var nl=function(){},el={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:nl,onClose:nl,onGrab:nl,onMove:nl,onRelease:nl,onBeforeOpen:nl,onBeforeClose:nl,onBeforeGrab:nl,onBeforeRelease:nl,onImageLoading:nl,onImageLoaded:nl},tl={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),al(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var r=this.lastScrollPosition.x-e,a=this.lastScrollPosition.y-t,o=this.options.scrollThreshold;(Math.abs(a)>=o||Math.abs(r)>=o)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(rl(n)&&!al(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){rl(n)&&!al(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,r=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,r)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,r=e.clientY;this.move(t,r)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function rl(n){return 0===n.button}function al(n){return n.metaKey||n.ctrlKey}var ol={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,Zi(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),Gi(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){Zi(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},sl="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},il=function(){function n(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}return function(e,t,r){return t&&n(e.prototype,t),r&&n(e,r),e}}(),ll=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(n[r]=t[r])}return n},cl={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=Ki(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,r=n.transitionDuration,a=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?Ji:Vi,transition:Qi+"\n        "+r+"s\n        "+a,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Zi(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Zi(this.el,{transform:"none"})},grab:function(n,e,t){var r=pl(),a=r.x-n,o=r.y-e;Zi(this.el,{cursor:Hi,transform:"translate3d(\n        "+(this.translate.x+a)+"px, "+(this.translate.y+o)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var r=pl(),a=r.x-n,o=r.y-e;Zi(this.el,{transition:Qi,transform:"translate3d(\n        "+(this.translate.x+a)+"px, "+(this.translate.y+o)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Zi(this.el,this.styleClose)},restoreOpenStyle:function(){Zi(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=pl(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,r=this.instance.options,a=r.customSize,o=r.scaleBase;if(!a&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(a&&"object"===(void 0===a?"undefined":sl(a)))return{x:a.width/this.rect.width,y:a.height/this.rect.height};var s=this.rect.width/2,i=this.rect.height/2,l=pl(),c={x:l.x-s,y:l.y-i},p=c.x/s,d=c.y/i,u=o+Math.min(p,d);if(a&&"string"==typeof a){var m=t||this.el.naturalWidth,f=e||this.el.naturalHeight,g=parseFloat(a)*m/(100*this.rect.width),h=parseFloat(a)*f/(100*this.rect.height);if(u>g||u>h)return{x:g,y:h}}return{x:u,y:u}}};function pl(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function dl(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(r){Gi(n,r,e[r],t)}))}var ul=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(cl),this.overlay=Object.create(ol),this.handler=Object.create(tl),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=ll({},el,e),this.overlay.init(this),this.handler.init(this)}return il(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=Ui,Gi(n,"click",this.handler.click),this.options.preloadImage&&$i(Ki(n)));return this}},{key:"config",value:function(n){return n?(ll(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var r="string"==typeof n?document.querySelector(n):n;if("IMG"===r.tagName){if(this.options.onBeforeOpen(r),this.target.init(r,this),!this.options.preloadImage){var a=this.target.srcOriginal;null!=a&&(this.options.onImageLoading(r),$i(a,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Gi(document,"scroll",this.handler.scroll),Gi(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Gi(window,"resize",this.handler.resizeWindow);var o=function n(){Gi(r,Yi,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&dl(document,e.handler,!0),t(r)};return Gi(r,Yi,o),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=Mi,this.overlay.fadeOut(),this.target.zoomOut(),Gi(document,"scroll",this.handler.scroll,!1),Gi(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Gi(window,"resize",this.handler.resizeWindow,!1);var r=function r(){Gi(t,Yi,r,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&dl(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return Gi(t,Yi,r),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var a=this.target.el;this.options.onBeforeGrab(a),this.released=!1,this.target.grab(n,e,t);var o=function n(){Gi(a,Yi,n,!1),r(a)};return Gi(a,Yi,o),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=Hi,this.target.move(n,e,t);var a=this.target.el,o=function n(){Gi(a,Yi,n,!1),r(a)};return Gi(a,Yi,o),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=Mi,this.target.restoreOpenStyle();var r=function r(){Gi(t,Yi,r,!1),n.lock=!1,n.released=!0,e(t)};return Gi(t,Yi,r),this}}}]),n}();const ml=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),fl=Number("500");class gl{constructor(){this.instance=new ul(ml)}update(n=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(n)}updateDelay(n=".theme-vdoing-content img:not(.no-zoom)",e=fl){setTimeout(()=>this.update(n),e)}}var hl=[vi,xi,Ai,Si,Ri,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new gl,this.$vuepress.zooming.updateDelay()}}],vl={name:"GlobalLayout",computed:{layout(){const n=this.getLayout();return ui("layout",n),$t.component(n)}},methods:{getLayout(){if(this.$page.path){const n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},bl=t(0),yl=Object(bl.a)(vl,(function(){var n=this.$createElement;return(this._self._c||n)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),n[e].push(...t);break;default:throw new Error("Unknown option name.")}}(yl,"mixins",hl);const _l=[{name:"v-22282852",path:"/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-22282852").then(t)}},{path:"/index.html",redirect:"/"},{name:"v-1ede408b",path:"/python/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-1ede408b").then(t)}},{path:"/python/index.html",redirect:"/python/"},{path:"/00.目录/01.python之路.html",redirect:"/python/"},{name:"v-302e23f4",path:"/code/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-302e23f4").then(t)}},{path:"/code/index.html",redirect:"/code/"},{path:"/00.目录/03.编程.html",redirect:"/code/"},{name:"v-d1a6c318",path:"/k8s/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-d1a6c318").then(t)}},{path:"/k8s/index.html",redirect:"/k8s/"},{path:"/00.目录/04.k8s.html",redirect:"/k8s/"},{name:"v-7a11f4c8",path:"/redis/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-7a11f4c8").then(t)}},{path:"/redis/index.html",redirect:"/redis/"},{path:"/00.目录/05.redis.html",redirect:"/redis/"},{name:"v-4932a3f8",path:"/mysql/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-4932a3f8").then(t)}},{path:"/mysql/index.html",redirect:"/mysql/"},{path:"/00.目录/06.mysql.html",redirect:"/mysql/"},{name:"v-033d1db6",path:"/readbook/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-033d1db6").then(t)}},{path:"/readbook/index.html",redirect:"/readbook/"},{path:"/00.目录/07.读书破万卷.html",redirect:"/readbook/"},{name:"v-b983bcaa",path:"/go/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-b983bcaa").then(t)}},{path:"/go/index.html",redirect:"/go/"},{path:"/00.目录/02.go之路.html",redirect:"/go/"},{name:"v-a4110f34",path:"/CloudNative/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-a4110f34").then(t)}},{path:"/CloudNative/index.html",redirect:"/CloudNative/"},{path:"/00.目录/08.云原生.html",redirect:"/CloudNative/"},{name:"v-718cb9b0",path:"/docker/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-718cb9b0").then(t)}},{path:"/docker/index.html",redirect:"/docker/"},{path:"/00.目录/10.docker.html",redirect:"/docker/"},{name:"v-7e40cffe",path:"/more/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-7e40cffe").then(t)}},{path:"/more/index.html",redirect:"/more/"},{path:"/00.目录/100.更多.html",redirect:"/more/"},{name:"v-566b048c",path:"/kafka/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-566b048c").then(t)}},{path:"/kafka/index.html",redirect:"/kafka/"},{path:"/00.目录/12.kafka.html",redirect:"/kafka/"},{name:"v-34e42639",path:"/middleware/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-34e42639").then(t)}},{path:"/middleware/index.html",redirect:"/middleware/"},{path:"/00.目录/13.中间件.html",redirect:"/middleware/"},{name:"v-423655cc",path:"/linux/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-423655cc").then(t)}},{path:"/linux/index.html",redirect:"/linux/"},{path:"/00.目录/14.linux.html",redirect:"/linux/"},{name:"v-1b5f1ee8",path:"/pages/11aacc/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-1b5f1ee8").then(t)}},{path:"/pages/11aacc/index.html",redirect:"/pages/11aacc/"},{path:"/01.java/01.基础篇/01.Java基础小结.html",redirect:"/pages/11aacc/"},{name:"v-b8532098",path:"/pages/b3eb48/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-b8532098").then(t)}},{path:"/pages/b3eb48/index.html",redirect:"/pages/b3eb48/"},{path:"/01.java/01.基础篇/02.Java基本数据类型.html",redirect:"/pages/b3eb48/"},{name:"v-d5c1a816",path:"/pages/2e780e/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-d5c1a816").then(t)}},{path:"/pages/2e780e/index.html",redirect:"/pages/2e780e/"},{path:"/01.java/02.集合篇/01.Java集合概述.html",redirect:"/pages/2e780e/"},{name:"v-0b03f7cc",path:"/pages/dcfa33/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-0b03f7cc").then(t)}},{path:"/pages/dcfa33/index.html",redirect:"/pages/dcfa33/"},{path:"/01.java/02.集合篇/02.List接口.html",redirect:"/pages/dcfa33/"},{name:"v-7b03b51c",path:"/pages/4d8b8b/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-7b03b51c").then(t)}},{path:"/pages/4d8b8b/index.html",redirect:"/pages/4d8b8b/"},{path:"/01.java/02.集合篇/03.Set接口.html",redirect:"/pages/4d8b8b/"},{name:"v-f9a862c8",path:"/pages/4c1680/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-f9a862c8").then(t)}},{path:"/pages/4c1680/index.html",redirect:"/pages/4c1680/"},{path:"/01.java/02.集合篇/05.Map接口.html",redirect:"/pages/4c1680/"},{name:"v-6bd8e8aa",path:"/pages/846d88/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-6bd8e8aa").then(t)}},{path:"/pages/846d88/index.html",redirect:"/pages/846d88/"},{path:"/01.java/03.并发篇/01.Java并发基础小结.html",redirect:"/pages/846d88/"},{name:"v-5a7b351e",path:"/pages/5a6aca/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-5a7b351e").then(t)}},{path:"/pages/5a6aca/index.html",redirect:"/pages/5a6aca/"},{path:"/01.java/03.并发篇/02.锁详解.html",redirect:"/pages/5a6aca/"},{name:"v-0379b906",path:"/pages/e19c5d/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-0379b906").then(t)}},{path:"/pages/e19c5d/index.html",redirect:"/pages/e19c5d/"},{path:"/01.java/03.并发篇/03.Synchronized和Volatile的使用与区别.html",redirect:"/pages/e19c5d/"},{name:"v-3223b15c",path:"/pages/887881/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-3223b15c").then(t)}},{path:"/pages/887881/index.html",redirect:"/pages/887881/"},{path:"/01.java/02.集合篇/04.Queue接口.html",redirect:"/pages/887881/"},{name:"v-8cb0bf1a",path:"/pages/040070/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-8cb0bf1a").then(t)}},{path:"/pages/040070/index.html",redirect:"/pages/040070/"},{path:"/01.java/03.并发篇/04.线程池详解.html",redirect:"/pages/040070/"},{name:"v-4d95c10a",path:"/pages/ff3623/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-4d95c10a").then(t)}},{path:"/pages/ff3623/index.html",redirect:"/pages/ff3623/"},{path:"/01.java/04.JVM/02.JVM常问.html",redirect:"/pages/ff3623/"},{name:"v-47b0b8a9",path:"/pages/562a37/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-47b0b8a9").then(t)}},{path:"/pages/562a37/index.html",redirect:"/pages/562a37/"},{path:"/01.java/04.JVM/01.JVM基础入门.html",redirect:"/pages/562a37/"},{name:"v-437ba2ee",path:"/pages/f3cf17/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-437ba2ee").then(t)}},{path:"/pages/f3cf17/index.html",redirect:"/pages/f3cf17/"},{path:"/01.云原生/06.docker/01.容器的本质.html",redirect:"/pages/f3cf17/"},{name:"v-7413a666",path:"/pages/0ddeb7/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-7413a666").then(t)}},{path:"/pages/0ddeb7/index.html",redirect:"/pages/0ddeb7/"},{path:"/01.云原生/06.docker/04.docker容器单机网络.html",redirect:"/pages/0ddeb7/"},{name:"v-fdfd34bc",path:"/pages/2b547f/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-fdfd34bc").then(t)}},{path:"/pages/2b547f/index.html",redirect:"/pages/2b547f/"},{path:"/01.云原生/07.k8s/03.k8s之pod.html",redirect:"/pages/2b547f/"},{name:"v-d51b20aa",path:"/pages/f6a447/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-d51b20aa").then(t)}},{path:"/pages/f6a447/index.html",redirect:"/pages/f6a447/"},{path:"/01.java/03.并发篇/05.CompletableFuture学习.html",redirect:"/pages/f6a447/"},{name:"v-74234f32",path:"/pages/d73c88/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-74234f32").then(t)}},{path:"/pages/d73c88/index.html",redirect:"/pages/d73c88/"},{path:"/01.云原生/07.k8s/04.k8s之deployment.html",redirect:"/pages/d73c88/"},{name:"v-0fd7c93e",path:"/pages/1f860b/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-0fd7c93e").then(t)}},{path:"/pages/1f860b/index.html",redirect:"/pages/1f860b/"},{path:"/01.云原生/07.k8s/05.k8s之service.html",redirect:"/pages/1f860b/"},{name:"v-064e6b52",path:"/pages/ff8188/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-064e6b52").then(t)}},{path:"/pages/ff8188/index.html",redirect:"/pages/ff8188/"},{path:"/01.云原生/07.k8s/06.k8s之ConfigMap和Secret.html",redirect:"/pages/ff8188/"},{name:"v-86796282",path:"/pages/c96905/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-86796282").then(t)}},{path:"/pages/c96905/index.html",redirect:"/pages/c96905/"},{path:"/01.云原生/07.k8s/07.k8s之Job和CronJob.html",redirect:"/pages/c96905/"},{name:"v-1a0f65c8",path:"/pages/d3768c/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-1a0f65c8").then(t)}},{path:"/pages/d3768c/index.html",redirect:"/pages/d3768c/"},{path:"/01.云原生/06.docker/03.手动实现docker容器bridge网络模型.html",redirect:"/pages/d3768c/"},{name:"v-642acf34",path:"/pages/92bee4/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-642acf34").then(t)}},{path:"/pages/92bee4/index.html",redirect:"/pages/92bee4/"},{path:"/01.云原生/07.k8s/08.k8s之DaemonSet.html",redirect:"/pages/92bee4/"},{name:"v-86799138",path:"/pages/095c75/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-86799138").then(t)}},{path:"/pages/095c75/index.html",redirect:"/pages/095c75/"},{path:"/01.云原生/07.k8s/09.k8s之PV、PVC和StorageClass.html",redirect:"/pages/095c75/"},{name:"v-1eacf608",path:"/pages/d178a2/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-1eacf608").then(t)}},{path:"/pages/d178a2/index.html",redirect:"/pages/d178a2/"},{path:"/01.云原生/07.k8s/10.k8s之StatefulSet.html",redirect:"/pages/d178a2/"},{name:"v-77369d13",path:"/pages/39f36e/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-77369d13").then(t)}},{path:"/pages/39f36e/index.html",redirect:"/pages/39f36e/"},{path:"/01.云原生/06.docker/02.docker容器.html",redirect:"/pages/39f36e/"},{name:"v-8f1b0f62",path:"/pages/9e17c8/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-8f1b0f62").then(t)}},{path:"/pages/9e17c8/index.html",redirect:"/pages/9e17c8/"},{path:"/01.云原生/07.k8s/11.使用kubeadm安装k8s.html",redirect:"/pages/9e17c8/"},{name:"v-f08b0a92",path:"/pages/27987d/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-f08b0a92").then(t)}},{path:"/pages/27987d/index.html",redirect:"/pages/27987d/"},{path:"/01.云原生/07.k8s/12.pod中将代码与运行环境分离.html",redirect:"/pages/27987d/"},{name:"v-0fd01db7",path:"/pages/b1b4a3/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-0fd01db7").then(t)}},{path:"/pages/b1b4a3/index.html",redirect:"/pages/b1b4a3/"},{path:"/01.云原生/07.k8s/13.django后端服务、logstash和flink接入VictoriaMetrics指标监控.html",redirect:"/pages/b1b4a3/"},{name:"v-11e81284",path:"/pages/f0f725/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-11e81284").then(t)}},{path:"/pages/f0f725/index.html",redirect:"/pages/f0f725/"},{path:"/01.云原生/07.k8s/15.理解calico容器网络通信方案原理.html",redirect:"/pages/f0f725/"},{name:"v-be038f46",path:"/pages/d9d0ce/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-be038f46").then(t)}},{path:"/pages/d9d0ce/index.html",redirect:"/pages/d9d0ce/"},{path:"/01.云原生/07.k8s/14.理解flannel的三种容器网络方案原理.html",redirect:"/pages/d9d0ce/"},{name:"v-6cbb1851",path:"/pages/b3955c/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-6cbb1851").then(t)}},{path:"/pages/b3955c/index.html",redirect:"/pages/b3955c/"},{path:"/01.云原生/07.k8s/16.kubernetes service如何通过iptables转发.html",redirect:"/pages/b3955c/"},{name:"v-67c4fe98",path:"/pages/fa114f/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-67c4fe98").then(t)}},{path:"/pages/fa114f/index.html",redirect:"/pages/fa114f/"},{path:"/03.中间件/01.kafka/01.listener和advertised.listeners的作用.html",redirect:"/pages/fa114f/"},{name:"v-cc91cd44",path:"/pages/2d69c7/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-cc91cd44").then(t)}},{path:"/pages/2d69c7/index.html",redirect:"/pages/2d69c7/"},{path:"/03.中间件/03.mysql/01.mysql之日志.html",redirect:"/pages/2d69c7/"},{name:"v-16efd28d",path:"/pages/0d8f4a/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-16efd28d").then(t)}},{path:"/pages/0d8f4a/index.html",redirect:"/pages/0d8f4a/"},{path:"/03.中间件/03.mysql/02.mysql之MVCC原理.html",redirect:"/pages/0d8f4a/"},{name:"v-079101b0",path:"/pages/6e0045/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-079101b0").then(t)}},{path:"/pages/6e0045/index.html",redirect:"/pages/6e0045/"},{path:"/01.云原生/07.k8s/17.kube-proxy源码分析.html",redirect:"/pages/6e0045/"},{name:"v-27753cf3",path:"/pages/2bbeb3/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-27753cf3").then(t)}},{path:"/pages/2bbeb3/index.html",redirect:"/pages/2bbeb3/"},{path:"/03.中间件/05.redis/01.redis之五种基本数据类型.html",redirect:"/pages/2bbeb3/"},{name:"v-d04209ac",path:"/pages/4c6b13/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-d04209ac").then(t)}},{path:"/pages/4c6b13/index.html",redirect:"/pages/4c6b13/"},{path:"/03.中间件/05.redis/02.redis之持久化.html",redirect:"/pages/4c6b13/"},{name:"v-7a226c10",path:"/pages/8072eb/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-7a226c10").then(t)}},{path:"/pages/8072eb/index.html",redirect:"/pages/8072eb/"},{path:"/03.中间件/05.redis/03. redis之主从库同步.html",redirect:"/pages/8072eb/"},{name:"v-97fa14a4",path:"/pages/ffee9e/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-97fa14a4").then(t)}},{path:"/pages/ffee9e/index.html",redirect:"/pages/ffee9e/"},{path:"/03.中间件/05.redis/04. redis之哨兵机制.html",redirect:"/pages/ffee9e/"},{name:"v-8855b59c",path:"/pages/1c2914/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-8855b59c").then(t)}},{path:"/pages/1c2914/index.html",redirect:"/pages/1c2914/"},{path:"/03.中间件/05.redis/05. redis之分片集群.html",redirect:"/pages/1c2914/"},{name:"v-3dc84304",path:"/pages/0d7b25/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-3dc84304").then(t)}},{path:"/pages/0d7b25/index.html",redirect:"/pages/0d7b25/"},{path:"/03.中间件/05.redis/06. redis之缓存.html",redirect:"/pages/0d7b25/"},{name:"v-cee6b5d2",path:"/pages/e31b06/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-cee6b5d2").then(t)}},{path:"/pages/e31b06/index.html",redirect:"/pages/e31b06/"},{path:"/04.编程/01.python/01.基础/01.python迭代器与生成器.html",redirect:"/pages/e31b06/"},{name:"v-5be0bc4c",path:"/pages/78c648/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-5be0bc4c").then(t)}},{path:"/pages/78c648/index.html",redirect:"/pages/78c648/"},{path:"/04.编程/01.python/01.基础/03.python垃圾回收机制.html",redirect:"/pages/78c648/"},{name:"v-54ae2f6d",path:"/pages/a6b804/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-54ae2f6d").then(t)}},{path:"/pages/a6b804/index.html",redirect:"/pages/a6b804/"},{path:"/04.编程/01.python/01.基础/04.python上下文管理器.html",redirect:"/pages/a6b804/"},{name:"v-6b5349e8",path:"/pages/5fa368/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-6b5349e8").then(t)}},{path:"/pages/5fa368/index.html",redirect:"/pages/5fa368/"},{path:"/04.编程/01.python/01.基础/02.python元编程.html",redirect:"/pages/5fa368/"},{name:"v-788e5ef9",path:"/pages/33b8d0/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-788e5ef9").then(t)}},{path:"/pages/33b8d0/index.html",redirect:"/pages/33b8d0/"},{path:"/04.编程/01.python/01.基础/06.使用python实现单例模式的三种方式.html",redirect:"/pages/33b8d0/"},{name:"v-597fc7ce",path:"/pages/7434f1/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-597fc7ce").then(t)}},{path:"/pages/7434f1/index.html",redirect:"/pages/7434f1/"},{path:"/04.编程/01.python/01.基础/05.python装饰器的使用方法.html",redirect:"/pages/7434f1/"},{name:"v-0e418e98",path:"/pages/d8fd49/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-0e418e98").then(t)}},{path:"/pages/d8fd49/index.html",redirect:"/pages/d8fd49/"},{path:"/04.编程/01.python/01.基础/07.python中import原理.html",redirect:"/pages/d8fd49/"},{name:"v-208228f3",path:"/pages/8d9ab9/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-208228f3").then(t)}},{path:"/pages/8d9ab9/index.html",redirect:"/pages/8d9ab9/"},{path:"/04.编程/01.python/02.第三方库/01.使用ddt实现unittest的参数化测试.html",redirect:"/pages/8d9ab9/"},{name:"v-4534d8ad",path:"/pages/069c65/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-4534d8ad").then(t)}},{path:"/pages/069c65/index.html",redirect:"/pages/069c65/"},{path:"/04.编程/01.python/02.第三方库/02.ddt源码分析.html",redirect:"/pages/069c65/"},{name:"v-98683fbe",path:"/pages/ec5110/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-98683fbe").then(t)}},{path:"/pages/ec5110/index.html",redirect:"/pages/ec5110/"},{path:"/04.编程/01.python/02.第三方库/03.django-apschedule定时任务异常停止.html",redirect:"/pages/ec5110/"},{name:"v-7dfe11b0",path:"/pages/853501/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-7dfe11b0").then(t)}},{path:"/pages/853501/index.html",redirect:"/pages/853501/"},{path:"/04.编程/01.python/06.django/01.django celery 结合使用.html",redirect:"/pages/853501/"},{name:"v-502d161c",path:"/pages/626675/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-502d161c").then(t)}},{path:"/pages/626675/index.html",redirect:"/pages/626675/"},{path:"/04.编程/01.python/06.django/03.django rest_framework Authentication.html",redirect:"/pages/626675/"},{name:"v-abb9096c",path:"/pages/070fec/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-abb9096c").then(t)}},{path:"/pages/070fec/index.html",redirect:"/pages/070fec/"},{path:"/04.编程/01.python/06.django/04.django rest_framework异常处理.html",redirect:"/pages/070fec/"},{name:"v-2c646377",path:"/pages/c3af6a/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-2c646377").then(t)}},{path:"/pages/c3af6a/index.html",redirect:"/pages/c3af6a/"},{path:"/04.编程/01.python/06.django/05.django rest_framework 自定义文档.html",redirect:"/pages/c3af6a/"},{name:"v-bb440a42",path:"/pages/f2738b/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-bb440a42").then(t)}},{path:"/pages/f2738b/index.html",redirect:"/pages/f2738b/"},{path:"/04.编程/01.python/06.django/06.django压缩文件下载.html",redirect:"/pages/f2738b/"},{name:"v-50cf7a82",path:"/pages/c28126/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-50cf7a82").then(t)}},{path:"/pages/c28126/index.html",redirect:"/pages/c28126/"},{path:"/04.编程/01.python/06.django/07.django rest_framework使用pytest单元测试.html",redirect:"/pages/c28126/"},{name:"v-6e6e165e",path:"/pages/b90015/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-6e6e165e").then(t)}},{path:"/pages/b90015/index.html",redirect:"/pages/b90015/"},{path:"/04.编程/01.python/06.django/08.django restframework choice 自定义输出数据.html",redirect:"/pages/b90015/"},{name:"v-72f4b6b0",path:"/pages/cfdb5f/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-72f4b6b0").then(t)}},{path:"/pages/cfdb5f/index.html",redirect:"/pages/cfdb5f/"},{path:"/04.编程/01.python/06.django/09.django Filtering 使用.html",redirect:"/pages/cfdb5f/"},{name:"v-3e16c4d8",path:"/pages/e75ceb/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-3e16c4d8").then(t)}},{path:"/pages/e75ceb/index.html",redirect:"/pages/e75ceb/"},{path:"/04.编程/01.python/06.django/10.django viewset 和 Router 配合使用时报的错.html",redirect:"/pages/e75ceb/"},{name:"v-242c57bc",path:"/pages/acdd50/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-242c57bc").then(t)}},{path:"/pages/acdd50/index.html",redirect:"/pages/acdd50/"},{path:"/04.编程/01.python/06.django/11.django model的序列化.html",redirect:"/pages/acdd50/"},{name:"v-580c8dac",path:"/pages/382755/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-580c8dac").then(t)}},{path:"/pages/382755/index.html",redirect:"/pages/382755/"},{path:"/04.编程/01.python/06.django/12.django中使用AbStractUser.html",redirect:"/pages/382755/"},{name:"v-669ddbd6",path:"/pages/060c51/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-669ddbd6").then(t)}},{path:"/pages/060c51/index.html",redirect:"/pages/060c51/"},{path:"/04.编程/01.python/06.django/13.django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users.html",redirect:"/pages/060c51/"},{name:"v-5f11081e",path:"/pages/de01e2/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-5f11081e").then(t)}},{path:"/pages/de01e2/index.html",redirect:"/pages/de01e2/"},{path:"/04.编程/01.python/06.django/14.django 中 media配置.html",redirect:"/pages/de01e2/"},{name:"v-e8f812b8",path:"/pages/b422bd/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-e8f812b8").then(t)}},{path:"/pages/b422bd/index.html",redirect:"/pages/b422bd/"},{path:"/04.编程/01.python/06.django/15.django 外键引用自身和on_delete参数.html",redirect:"/pages/b422bd/"},{name:"v-35d0167d",path:"/pages/f0d816/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-35d0167d").then(t)}},{path:"/pages/f0d816/index.html",redirect:"/pages/f0d816/"},{path:"/04.编程/01.python/06.django/16.django 警告 while time zone support is active.html",redirect:"/pages/f0d816/"},{name:"v-788c4982",path:"/pages/cb262f/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-788c4982").then(t)}},{path:"/pages/cb262f/index.html",redirect:"/pages/cb262f/"},{path:"/04.编程/01.python/06.django/17.django rest_framework 分页.html",redirect:"/pages/cb262f/"},{name:"v-f7e64afe",path:"/pages/b71dc2/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-f7e64afe").then(t)}},{path:"/pages/b71dc2/index.html",redirect:"/pages/b71dc2/"},{path:"/04.编程/01.python/07.flask/01.Flask使用flask_socketio实现websocket.html",redirect:"/pages/b71dc2/"},{name:"v-3c157da4",path:"/pages/c59edf/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-3c157da4").then(t)}},{path:"/pages/c59edf/index.html",redirect:"/pages/c59edf/"},{path:"/04.编程/01.python/07.flask/02.flask结合mongo.html",redirect:"/pages/c59edf/"},{name:"v-069fea3d",path:"/pages/4c38f5/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-069fea3d").then(t)}},{path:"/pages/4c38f5/index.html",redirect:"/pages/4c38f5/"},{path:"/04.编程/01.python/08.tornado/01.tornado 文件上传.html",redirect:"/pages/4c38f5/"},{name:"v-2e6d253f",path:"/pages/c24905/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-2e6d253f").then(t)}},{path:"/pages/c24905/index.html",redirect:"/pages/c24905/"},{path:"/04.编程/01.python/08.tornado/02.tornado 使用jwt完成用户异步认证.html",redirect:"/pages/c24905/"},{name:"v-573b59b6",path:"/pages/7ac01f/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-573b59b6").then(t)}},{path:"/pages/7ac01f/index.html",redirect:"/pages/7ac01f/"},{path:"/04.编程/01.python/08.tornado/04.tornado 结合wtforms使用表单操作.html",redirect:"/pages/7ac01f/"},{name:"v-0056c406",path:"/pages/d18657/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-0056c406").then(t)}},{path:"/pages/d18657/index.html",redirect:"/pages/d18657/"},{path:"/04.编程/01.python/08.tornado/05.tornado finish和write区别.html",redirect:"/pages/d18657/"},{name:"v-fc3c6860",path:"/pages/22f35b/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-fc3c6860").then(t)}},{path:"/pages/22f35b/index.html",redirect:"/pages/22f35b/"},{path:"/04.编程/01.python/08.tornado/03.tornado 用户密码 bcrypt加密.html",redirect:"/pages/22f35b/"},{name:"v-3b941cbe",path:"/pages/f9d78c/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-3b941cbe").then(t)}},{path:"/pages/f9d78c/index.html",redirect:"/pages/f9d78c/"},{path:"/04.编程/01.python/09.其他/01.python简单使用grpc.html",redirect:"/pages/f9d78c/"},{name:"v-05407dda",path:"/pages/113ab1/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-05407dda").then(t)}},{path:"/pages/113ab1/index.html",redirect:"/pages/113ab1/"},{path:"/04.编程/01.python/08.tornado/06.tornado 使用peewee-async 完成异步orm数据库操作.html",redirect:"/pages/113ab1/"},{name:"v-a1f03dba",path:"/pages/72664a/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-a1f03dba").then(t)}},{path:"/pages/72664a/index.html",redirect:"/pages/72664a/"},{path:"/04.编程/01.python/09.其他/02.pyspark streaming简介 和 消费 kafka示例.html",redirect:"/pages/72664a/"},{name:"v-ec68963a",path:"/pages/87014e/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-ec68963a").then(t)}},{path:"/pages/87014e/index.html",redirect:"/pages/87014e/"},{path:"/04.编程/02.go/01.go简单使用grpc.html",redirect:"/pages/87014e/"},{name:"v-37dbc27d",path:"/pages/c41003/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-37dbc27d").then(t)}},{path:"/pages/c41003/index.html",redirect:"/pages/c41003/"},{path:"/04.编程/02.go/02. gin中validator模块的源码分析.html",redirect:"/pages/c41003/"},{name:"v-118bdc85",path:"/pages/cf9a4d/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-118bdc85").then(t)}},{path:"/pages/cf9a4d/index.html",redirect:"/pages/cf9a4d/"},{path:"/04.编程/02.go/03.优化gin表单的错误提示信息.html",redirect:"/pages/cf9a4d/"},{name:"v-fdcf4762",path:"/pages/d93df5/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-fdcf4762").then(t)}},{path:"/pages/d93df5/index.html",redirect:"/pages/d93df5/"},{path:"/04.编程/02.go/04.go中如何处理error.html",redirect:"/pages/d93df5/"},{name:"v-21216af8",path:"/pages/72ba9a/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-21216af8").then(t)}},{path:"/pages/72ba9a/index.html",redirect:"/pages/72ba9a/"},{path:"/04.编程/03.linux/01.快速了解iptables.html",redirect:"/pages/72ba9a/"},{name:"v-325b46da",path:"/pages/143447/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-325b46da").then(t)}},{path:"/pages/143447/index.html",redirect:"/pages/143447/"},{path:"/04.编程/03.linux/02.理解Linux TunTap设备.html",redirect:"/pages/143447/"},{name:"v-3e69314c",path:"/pages/8a4b28/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-3e69314c").then(t)}},{path:"/pages/8a4b28/index.html",redirect:"/pages/8a4b28/"},{path:"/04.编程/03.linux/03.理解VXLAN网络.html",redirect:"/pages/8a4b28/"},{name:"v-31a5e395",path:"/pages/36b0b2/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-31a5e395").then(t)}},{path:"/pages/36b0b2/index.html",redirect:"/pages/36b0b2/"},{path:"/04.编程/02.go/05.tcp缓存引起的日志丢失.html",redirect:"/pages/36b0b2/"},{name:"v-e9cb914e",path:"/pages/7f16f6/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-e9cb914e").then(t)}},{path:"/pages/7f16f6/index.html",redirect:"/pages/7f16f6/"},{path:"/04.编程/09.其他/03.使用java开发logstash的filter插件.html",redirect:"/pages/7f16f6/"},{name:"v-087ac98a",path:"/pages/d91dfb/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-087ac98a").then(t)}},{path:"/pages/d91dfb/index.html",redirect:"/pages/d91dfb/"},{path:"/04.编程/09.其他/01.分布式锁.html",redirect:"/pages/d91dfb/"},{name:"v-05a28fa4",path:"/pages/19cfb6/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-05a28fa4").then(t)}},{path:"/pages/19cfb6/index.html",redirect:"/pages/19cfb6/"},{path:"/04.编程/09.其他/20.count的性能优化.html",redirect:"/pages/19cfb6/"},{name:"v-8c516c3e",path:"/pages/aba491/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-8c516c3e").then(t)}},{path:"/pages/aba491/index.html",redirect:"/pages/aba491/"},{path:"/04.编程/09.其他/02.使用hue创建ozzie的pyspark action workflow.html",redirect:"/pages/aba491/"},{name:"v-54f1c73c",path:"/about/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-54f1c73c").then(t)}},{path:"/about/index.html",redirect:"/about/"},{path:"/08.关于/01.关于.html",redirect:"/about/"},{name:"v-567cb3a8",path:"/pages/8bdb8d/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-567cb3a8").then(t)}},{path:"/pages/8bdb8d/index.html",redirect:"/pages/8bdb8d/"},{path:"/05.读书破万卷/01.如何阅读一本书.html",redirect:"/pages/8bdb8d/"},{name:"v-0485a99b",path:"/friends/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-0485a99b").then(t)}},{path:"/friends/index.html",redirect:"/friends/"},{path:"/09.更多/02.友链.html",redirect:"/friends/"},{name:"v-e5fb5ede",path:"/pages/277c5b/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-e5fb5ede").then(t)}},{path:"/pages/277c5b/index.html",redirect:"/pages/277c5b/"},{path:"/01.java/03.并发篇/10.Java内存管理总结.html",redirect:"/pages/277c5b/"},{name:"v-e627318a",path:"/pages/c128e7/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-e627318a").then(t)}},{path:"/pages/c128e7/index.html",redirect:"/pages/c128e7/"},{path:"/04.编程/03.linux/04.理解Linux IPIP隧道.html",redirect:"/pages/c128e7/"},{name:"v-7ffecc44",path:"/categories/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-7ffecc44").then(t)}},{path:"/categories/index.html",redirect:"/categories/"},{path:"/@pages/categoriesPage.html",redirect:"/categories/"},{name:"v-25855433",path:"/pages/25eafd/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-25855433").then(t)}},{path:"/pages/25eafd/index.html",redirect:"/pages/25eafd/"},{path:"/04.编程/01.python/06.django/02.django rest_framework使用jwt.html",redirect:"/pages/25eafd/"},{name:"v-8d4bc20e",path:"/pages/beb6c0bd8a66cea6/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-8d4bc20e").then(t)}},{path:"/pages/beb6c0bd8a66cea6/index.html",redirect:"/pages/beb6c0bd8a66cea6/"},{path:"/09.更多/01.收藏.html",redirect:"/pages/beb6c0bd8a66cea6/"},{name:"v-6cd702fe",path:"/archives/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-6cd702fe").then(t)}},{path:"/archives/index.html",redirect:"/archives/"},{path:"/@pages/archivesPage.html",redirect:"/archives/"},{name:"v-16e3f17e",path:"/tags/",component:yl,beforeEnter:(n,e,t)=>{di("Layout","v-16e3f17e").then(t)}},{path:"/tags/index.html",redirect:"/tags/"},{path:"/@pages/tagsPage.html",redirect:"/tags/"},{path:"*",component:yl}],kl={title:"陌上清风的博客",description:"技术博客，专注于后端学习与总结，python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown等技术类文章",base:"/",headTags:[["link",{rel:"icon",href:"/img/favicon.ico"}],["meta",{name:"keywords",content:"后端博客,个人技术博客,后端,后端开发,后端框架,后端面试题,技术文档,学习,面试,python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown"}],["meta",{name:"baidu-site-verification",content:"7F55weZDDc"}],["meta",{name:"theme-color",content:"#11a8cd"}],["meta",{name:"viewport",content:"width=device-width, initial-scale=1"}],["script",{},'var _hmt = _hmt || [];\n      (function() {\n        var hm = document.createElement("script");\n        hm.src = "https://hm.baidu.com/hm.js?7c28cc47ffa100de44e976f816b0b294";\n        var s = document.getElementsByTagName("script")[0]; \n        s.parentNode.insertBefore(hm, s);\n      })();'],["link",{rel:"alternate",type:"application/rss+xml",href:"https://www.zhengwenfeng.com/rss.xml",title:"陌上清风的博客 RSS Feed"}],["link",{rel:"alternate",type:"application/atom+xml",href:"https://www.zhengwenfeng.com/feed.atom",title:"陌上清风的博客 Atom Feed"}],["link",{rel:"alternate",type:"application/json",href:"https://www.zhengwenfeng.com/feed.json",title:"陌上清风的博客 JSON Feed"}]],pages:[{title:"Home",frontmatter:{home:!0,heroText:"陌上清风的博客",tagline:"朝闻道,夕死可矣。",hideRightBar:!1,description:"技术博客，专注于后端学习与总结，python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown等技术类文章",meta:[{name:"image",content:"https://www.msqfx.cc/img/panda-waving.png"},{name:"twitter:title",content:"陌上清风的博客"},{name:"twitter:description",content:"技术博客，专注于后端学习与总结，python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown等技术类文章"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://www.msqfx.cc/img/panda-waving.png"},{name:"twitter:url",content:"https://www.msqfx.cc/"},{property:"og:type",content:"website"},{property:"og:title",content:"陌上清风的博客"},{property:"og:description",content:"技术博客，专注于后端学习与总结，python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown等技术类文章"},{property:"og:image",content:"https://www.msqfx.cc/img/panda-waving.png"},{property:"og:url",content:"https://www.msqfx.cc/"},{property:"og:site_name",content:"msqfx"},{itemprop:"name",content:"陌上清风的博客"},{itemprop:"description",content:"技术博客，专注于后端学习与总结，python,go,redis,k8s,mysql,kafka,flask,django,tornado,git,github,markdown等技术类文章"},{itemprop:"image",content:"https://www.msqfx.cc/img/panda-waving.png"}],readingShow:"top"},regularPath:"/",relativePath:"index.md",key:"v-22282852",path:"/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/10/31, 21:57:05",lastUpdatedTimestamp:1667224625e3},{title:"python之路",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"04.编程/01.python",description:"人生苦短，我用python"}},title:"python之路",date:"2022-09-07T22:23:24.000Z",permalink:"/python/",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},meta:[{name:"twitter:title",content:"python之路"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/01.python%E4%B9%8B%E8%B7%AF.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python之路"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/01.python%E4%B9%8B%E8%B7%AF.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-09-07T22:23:24.000Z"},{itemprop:"name",content:"python之路"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/01.python%E4%B9%8B%E8%B7%AF.html",relativePath:"00.目录/01.python之路.md",key:"v-1ede408b",path:"/python/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"编程",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"04.编程",description:"编程"}},title:"编程",date:"2022-09-07T22:23:26.000Z",permalink:"/code/",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},meta:[{name:"twitter:title",content:"编程"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/03.%E7%BC%96%E7%A8%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"编程"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/03.%E7%BC%96%E7%A8%8B.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-09-07T22:23:26.000Z"},{itemprop:"name",content:"编程"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/03.%E7%BC%96%E7%A8%8B.html",relativePath:"00.目录/03.编程.md",key:"v-302e23f4",path:"/code/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"k8s",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"01.云原生/07.k8s",description:"k8s"}},title:"k8s",date:"2023-01-07T18:33:01.000Z",permalink:"/k8s/",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},meta:[{name:"twitter:title",content:"k8s"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/04.k8s.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/04.k8s.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-01-07T18:33:01.000Z"},{itemprop:"name",content:"k8s"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/04.k8s.html",relativePath:"00.目录/04.k8s.md",key:"v-d1a6c318",path:"/k8s/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/01/08, 21:19:56",lastUpdatedTimestamp:1673183996e3},{title:"redis",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"03.中间件/05.redis",description:"redis"}},title:"redis",date:"2023-01-07T18:33:02.000Z",permalink:"/redis/",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},meta:[{name:"twitter:title",content:"redis"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/05.redis.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/05.redis.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-01-07T18:33:02.000Z"},{itemprop:"name",content:"redis"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/05.redis.html",relativePath:"00.目录/05.redis.md",key:"v-7a11f4c8",path:"/redis/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"mysql",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"03.中间件/03.mysql",description:"mysql"}},title:"mysql",date:"2023-01-07T18:33:03.000Z",permalink:"/mysql/",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},meta:[{name:"twitter:title",content:"mysql"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/06.mysql.html"},{property:"og:type",content:"article"},{property:"og:title",content:"mysql"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/06.mysql.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-01-07T18:33:03.000Z"},{itemprop:"name",content:"mysql"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/06.mysql.html",relativePath:"00.目录/06.mysql.md",key:"v-4932a3f8",path:"/mysql/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"读书破万卷",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"05.读书破万卷",description:"读书破万卷"}},title:"读书破万卷",date:"2023-01-07T18:33:04.000Z",permalink:"/readbook/",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},meta:[{name:"twitter:title",content:"读书破万卷"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/07.%E8%AF%BB%E4%B9%A6%E7%A0%B4%E4%B8%87%E5%8D%B7.html"},{property:"og:type",content:"article"},{property:"og:title",content:"读书破万卷"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/07.%E8%AF%BB%E4%B9%A6%E7%A0%B4%E4%B8%87%E5%8D%B7.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-01-07T18:33:04.000Z"},{itemprop:"name",content:"读书破万卷"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/07.%E8%AF%BB%E4%B9%A6%E7%A0%B4%E4%B8%87%E5%8D%B7.html",relativePath:"00.目录/07.读书破万卷.md",key:"v-033d1db6",path:"/readbook/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"go之路",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"04.编程/02.go",description:"就是干"}},title:"go之路",permalink:"/go/",sidebar:!1,article:!1,comment:!1,editLink:!1,author:{name:"msqfx",link:"https://github.com/msqfx"},date:"2022-09-07T22:23:25.000Z",description:"",feed:{enable:!0},meta:[{name:"twitter:title",content:"go之路"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/02.go%E4%B9%8B%E8%B7%AF.html"},{property:"og:type",content:"article"},{property:"og:title",content:"go之路"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/02.go%E4%B9%8B%E8%B7%AF.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-09-07T22:23:25.000Z"},{itemprop:"name",content:"go之路"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/02.go%E4%B9%8B%E8%B7%AF.html",relativePath:"00.目录/02.go之路.md",key:"v-b983bcaa",path:"/go/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"云原生",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"01.云原生",description:"云原生"}},title:"云原生",date:"2023-01-07T18:33:04.000Z",permalink:"/CloudNative/",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},meta:[{name:"twitter:title",content:"云原生"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/08.%E4%BA%91%E5%8E%9F%E7%94%9F.html"},{property:"og:type",content:"article"},{property:"og:title",content:"云原生"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/08.%E4%BA%91%E5%8E%9F%E7%94%9F.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-01-07T18:33:04.000Z"},{itemprop:"name",content:"云原生"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/08.%E4%BA%91%E5%8E%9F%E7%94%9F.html",relativePath:"00.目录/08.云原生.md",key:"v-a4110f34",path:"/CloudNative/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/01/08, 21:19:56",lastUpdatedTimestamp:1673183996e3},{title:"docker",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"01.云原生/06.docker",description:"docker"}},title:"docker",date:"2023-01-07T18:33:01.000Z",permalink:"/docker/",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},meta:[{name:"twitter:title",content:"docker"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/10.docker.html"},{property:"og:type",content:"article"},{property:"og:title",content:"docker"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/10.docker.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-01-07T18:33:01.000Z"},{itemprop:"name",content:"docker"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/10.docker.html",relativePath:"00.目录/10.docker.md",key:"v-718cb9b0",path:"/docker/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/01/08, 21:19:56",lastUpdatedTimestamp:1673183996e3},{title:"更多",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"06.更多",description:"更多内容"}},title:"更多",date:"2020-03-11T21:50:53.000Z",permalink:"/more",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},meta:[{name:"twitter:title",content:"更多"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/100.%E6%9B%B4%E5%A4%9A.html"},{property:"og:type",content:"article"},{property:"og:title",content:"更多"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/100.%E6%9B%B4%E5%A4%9A.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2020-03-11T21:50:53.000Z"},{itemprop:"name",content:"更多"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/100.%E6%9B%B4%E5%A4%9A.html",relativePath:"00.目录/100.更多.md",key:"v-7e40cffe",path:"/more/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/01/07, 18:38:30",lastUpdatedTimestamp:167308791e4},{title:"kafka",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"03.中间件/01.kafka",description:"kafka"}},title:"kafka",permalink:"/kafka/",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},date:"2023-05-01T17:41:25.000Z",meta:[{name:"twitter:title",content:"kafka"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/12.kafka.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kafka"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/12.kafka.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-05-01T17:41:25.000Z"},{itemprop:"name",content:"kafka"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/12.kafka.html",relativePath:"00.目录/12.kafka.md",key:"v-566b048c",path:"/kafka/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"中间件",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"03.中间件",description:"中间件"}},title:"中间件",permalink:"/middleware/",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},date:"2023-05-01T17:46:08.000Z",meta:[{name:"twitter:title",content:"中间件"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/13.%E4%B8%AD%E9%97%B4%E4%BB%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"中间件"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/13.%E4%B8%AD%E9%97%B4%E4%BB%B6.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-05-01T17:46:08.000Z"},{itemprop:"name",content:"中间件"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/13.%E4%B8%AD%E9%97%B4%E4%BB%B6.html",relativePath:"00.目录/13.中间件.md",key:"v-34e42639",path:"/middleware/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"linux",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"04.编程/03.linux",description:"linux"}},title:"linux",permalink:"/linux/",sidebar:!1,article:!1,comment:!1,editLink:!1,description:"",author:{name:"msqfx",link:"https://github.com/msqfx"},date:"2023-05-01T17:46:08.000Z",meta:[{name:"twitter:title",content:"linux"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/14.linux.html"},{property:"og:type",content:"article"},{property:"og:title",content:"linux"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/00.%E7%9B%AE%E5%BD%95/14.linux.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-05-01T17:46:08.000Z"},{itemprop:"name",content:"linux"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/00.%E7%9B%AE%E5%BD%95/14.linux.html",relativePath:"00.目录/14.linux.md",key:"v-423655cc",path:"/linux/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2023/05/15, 19:34:26",lastUpdatedTimestamp:1684150466e3},{title:"Java基础小结",frontmatter:{title:"Java基础小结",date:"2023-06-15T11:11:15.000Z",permalink:"/pages/11aacc/",author:{name:"陌上清风",link:"https://github.com/msqfx"},categories:["java","基础篇"],tags:[null],description:"Java 是 1995 年由 sun 公司推出的一门高级语言。",comment:!0,meta:[{name:"image",content:"https://cmty256.github.io/imgs-blog/Java/image.u47c2l50zow.webp"},{name:"twitter:title",content:"Java基础小结"},{name:"twitter:description",content:"Java 是 1995 年由 sun 公司推出的一门高级语言。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://cmty256.github.io/imgs-blog/Java/image.u47c2l50zow.webp"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/01.%E5%9F%BA%E7%A1%80%E7%AF%87/01.Java%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Java基础小结"},{property:"og:description",content:"Java 是 1995 年由 sun 公司推出的一门高级语言。"},{property:"og:image",content:"https://cmty256.github.io/imgs-blog/Java/image.u47c2l50zow.webp"},{property:"og:url",content:"https://www.msqfx.cc/01.java/01.%E5%9F%BA%E7%A1%80%E7%AF%87/01.Java%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-06-15T11:11:15.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"Java基础小结"},{itemprop:"description",content:"Java 是 1995 年由 sun 公司推出的一门高级语言。"},{itemprop:"image",content:"https://cmty256.github.io/imgs-blog/Java/image.u47c2l50zow.webp"}],readingShow:"top"},regularPath:"/01.java/01.%E5%9F%BA%E7%A1%80%E7%AF%87/01.Java%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93.html",relativePath:"01.java/01.基础篇/01.Java基础小结.md",key:"v-1b5f1ee8",path:"/pages/11aacc/",headers:[{level:2,title:"Java 基础概念与常识",slug:"java-基础概念与常识",normalizedTitle:"java 基础概念与常识",charIndex:16},{level:3,title:"什么是 Java ?",slug:"什么是-java",normalizedTitle:"什么是 java ?",charIndex:33},{level:3,title:"Java 的三种技术架构",slug:"java-的三种技术架构",normalizedTitle:"java 的三种技术架构",charIndex:849},{level:3,title:"什么是 JVM ?",slug:"什么是-jvm",normalizedTitle:"什么是 jvm ?",charIndex:948},{level:3,title:"什么是 JDK ?",slug:"什么是-jdk",normalizedTitle:"什么是 jdk ?",charIndex:1184},{level:3,title:"什么是 JRE ?",slug:"什么是-jre",normalizedTitle:"什么是 jre ?",charIndex:1275},{level:3,title:"Java 与 C++ 的区别",slug:"java-与-c-的区别",normalizedTitle:"java 与 c++ 的区别",charIndex:1468},{level:2,title:"基本语法",slug:"基本语法",normalizedTitle:"基本语法",charIndex:1653},{level:3,title:"注释有哪几种形式？",slug:"注释有哪几种形式",normalizedTitle:"注释有哪几种形式？",charIndex:1662},{level:3,title:"标识符和关键字的区别是什么？",slug:"标识符和关键字的区别是什么",normalizedTitle:"标识符和关键字的区别是什么？",charIndex:1785},{level:3,title:"Java 有哪些关键字？",slug:"java-有哪些关键字",normalizedTitle:"java 有哪些关键字？",charIndex:1889},{level:3,title:"访问控制关键字解析",slug:"访问控制关键字解析",normalizedTitle:"访问控制关键字解析",charIndex:1908},{level:3,title:"final 关键字解析",slug:"final-关键字解析",normalizedTitle:"final 关键字解析",charIndex:2442},{level:3,title:"if 和 else if",slug:"if-和-else-if",normalizedTitle:"if 和 else if",charIndex:2814},{level:2,title:"变量",slug:"变量",normalizedTitle:"变量",charIndex:1932},{level:3,title:"成员变量与局部变量的区别？",slug:"成员变量与局部变量的区别",normalizedTitle:"成员变量与局部变量的区别？",charIndex:3561},{level:3,title:"静态变量有什么用？",slug:"静态变量有什么用",normalizedTitle:"静态变量有什么用？",charIndex:4265},{level:3,title:"字符型常量和字符串常量的区别？",slug:"字符型常量和字符串常量的区别",normalizedTitle:"字符型常量和字符串常量的区别？",charIndex:4713},{level:2,title:"方法",slug:"方法",normalizedTitle:"方法",charIndex:1570},{level:3,title:"什么是方法的返回值?方法有哪几种类型？",slug:"什么是方法的返回值-方法有哪几种类型",normalizedTitle:"什么是方法的返回值?方法有哪几种类型？",charIndex:4974},{level:3,title:"静态方法为什么不能调用非静态成员?",slug:"静态方法为什么不能调用非静态成员",normalizedTitle:"静态方法为什么不能调用非静态成员?",charIndex:5102},{level:3,title:"静态方法和实例方法有何不同？",slug:"静态方法和实例方法有何不同",normalizedTitle:"静态方法和实例方法有何不同？",charIndex:5266},{level:3,title:"重载和重写有什么区别？",slug:"重载和重写有什么区别",normalizedTitle:"重载和重写有什么区别？",charIndex:5482},{level:3,title:"什么是可变长参数？",slug:"什么是可变长参数",normalizedTitle:"什么是可变长参数？",charIndex:5766},{level:2,title:"注解",slug:"注解",normalizedTitle:"注解",charIndex:6343},{level:3,title:"谈谈对 Java 注解的理解，解决了什么问题？",slug:"谈谈对-java-注解的理解-解决了什么问题",normalizedTitle:"谈谈对 java 注解的理解，解决了什么问题？",charIndex:6350},{level:3,title:"注解的解析方法有哪几种？",slug:"注解的解析方法有哪几种",normalizedTitle:"注解的解析方法有哪几种？",charIndex:6600},{level:2,title:"SPI",slug:"spi",normalizedTitle:"spi",charIndex:8524},{level:3,title:"什么是 Java 的 SPI 机制？",slug:"什么是-java-的-spi-机制",normalizedTitle:"什么是 java 的 spi 机制？",charIndex:8532},{level:3,title:"SPI 机制的优缺点是什么？",slug:"spi-机制的优缺点是什么",normalizedTitle:"spi 机制的优缺点是什么？",charIndex:8665},{level:3,title:"如何在 Java 中使用 SPI 机制？",slug:"如何在-java-中使用-spi-机制",normalizedTitle:"如何在 java 中使用 spi 机制？",charIndex:8771},{level:3,title:"如何避免 SPI 机制中的冲突问题？",slug:"如何避免-spi-机制中的冲突问题",normalizedTitle:"如何避免 spi 机制中的冲突问题？",charIndex:8981},{level:3,title:"SPI 机制和 Spring 的 BeanFactory 有什么区别？",slug:"spi-机制和-spring-的-beanfactory-有什么区别",normalizedTitle:"spi 机制和 spring 的 beanfactory 有什么区别？",charIndex:9123},{level:2,title:"序列化和反序列化",slug:"序列化和反序列化",normalizedTitle:"序列化和反序列化",charIndex:9354},{level:3,title:"什么是序列化？什么是反序列化？",slug:"什么是序列化-什么是反序列化",normalizedTitle:"什么是序列化？什么是反序列化？",charIndex:9367},{level:3,title:"序列化协议对应于 TCP/IP 4 层模型的哪一层？",slug:"序列化协议对应于-tcp-ip-4-层模型的哪一层",normalizedTitle:"序列化协议对应于 tcp/ip 4 层模型的哪一层？",charIndex:9576},{level:3,title:"项目中，JSON 数据的传输体现在哪？",slug:"项目中-json-数据的传输体现在哪",normalizedTitle:"项目中，json 数据的传输体现在哪？",charIndex:9644},{level:2,title:"语法糖",slug:"语法糖",normalizedTitle:"语法糖",charIndex:10267},{level:3,title:"什么是语法糖？",slug:"什么是语法糖",normalizedTitle:"什么是语法糖？",charIndex:10275},{level:3,title:"Java 中有哪些常见的语法糖？",slug:"java-中有哪些常见的语法糖",normalizedTitle:"java 中有哪些常见的语法糖？",charIndex:10611},{level:3,title:"内部类了解吗？",slug:"内部类了解吗",normalizedTitle:"内部类了解吗？",charIndex:10715},{level:3,title:"匿名内部类了解吗？",slug:"匿名内部类了解吗",normalizedTitle:"匿名内部类了解吗？",charIndex:10929}],headersStr:"Java 基础概念与常识 什么是 Java ? Java 的三种技术架构 什么是 JVM ? 什么是 JDK ? 什么是 JRE ? Java 与 C++ 的区别 基本语法 注释有哪几种形式？ 标识符和关键字的区别是什么？ Java 有哪些关键字？ 访问控制关键字解析 final 关键字解析 if 和 else if 变量 成员变量与局部变量的区别？ 静态变量有什么用？ 字符型常量和字符串常量的区别？ 方法 什么是方法的返回值?方法有哪几种类型？ 静态方法为什么不能调用非静态成员? 静态方法和实例方法有何不同？ 重载和重写有什么区别？ 什么是可变长参数？ 注解 谈谈对 Java 注解的理解，解决了什么问题？ 注解的解析方法有哪几种？ SPI 什么是 Java 的 SPI 机制？ SPI 机制的优缺点是什么？ 如何在 Java 中使用 SPI 机制？ 如何避免 SPI 机制中的冲突问题？ SPI 机制和 Spring 的 BeanFactory 有什么区别？ 序列化和反序列化 什么是序列化？什么是反序列化？ 序列化协议对应于 TCP/IP 4 层模型的哪一层？ 项目中，JSON 数据的传输体现在哪？ 语法糖 什么是语法糖？ Java 中有哪些常见的语法糖？ 内部类了解吗？ 匿名内部类了解吗？",content:'# Java 基础小结\n\n\n# Java 基础概念与常识\n\n\n# 什么是 Java ?\n\nJava 是 1995 年由 sun 公司推出的一门高级语言。\n\nJava 的四个基本特性是面向对象、平台无关性、安全性和简单性。\n\n具体特点如下:\n\n 1. 简单易学。\n\n 2. 平台无关性。\n\n 3. 面向对象\n    \n    * 面向对象是一种程序设计技术，以木匠工作为例，使用面向对象方式实现的木匠的工作关注重点永远是制作椅子，其次才是工具。\n    \n    * 而面向过程则优先关注制作工具。\n    \n    * 与 C++ 不同的是，Java 不支持多继承，取而代之的是更加简单的接口的概念。\n    \n    * 面向对象三大特性: 封装、多态、继承。\n\n 4. 编译与解释并存\n\n 5. 可靠性\n    \n    * Java 通过早期检测以及运行时检测消除了容易出错的情况。\n    * 与 C++ 不同的是，C++ 在操作数组、字符串方式上利用指针模型避免了重写内存或者损坏数据的问题。\n\n 6. 安全性: Java 适用于网络/分布式环境，为了达到这个目标，Java 在防病毒，防篡改做出很大的努力。\n\n 7. 支持网络编程并且非常方便。\n\n 8. 支持多线程。\n\n> 什么是【编译型】语言和【解释型】语言？\n> \n> 编译型：编译型语言 会通过编译器将源代码一次性翻译成可被该平台执行的机器码。一般情况下，编译语言的执行速度比较快，开发效率比较低。常见的编译性语言有 C、C++、Go、Rust 等等。\n> \n> 解释型：解释型语言会通过解释器一句一句的将代码解释（interpret）为机器代码后再执行。解释型语言开发效率比较快，执行速度比较慢。常见的解释性语言有 Python、JavaScript、PHP 等等。\n> \n> 而 Java 是编译与解释并存，因为 java 源代码运行时需要先编译成为字节码文件 (.class)，然后再通过解释器翻译成机器码运行。\n\n\n# Java 的三种技术架构\n\n 1. JavaSE：标准版，即学生时期学习时使用的版本。\n 2. JavaEE：web 开发采用的技术架构。\n 3. JavaME：为嵌入式设备提供的解决方案\n\n\n# 什么是 JVM ?\n\nJava 虚拟机（JVM）是运行 Java 字节码的虚拟机。\n\nJVM 有针对不同系统的特定实现（Windows，Linux，macOS），目的是使用相同的字节码，它们都会给出相同的结果。\n\n字节码和不同系统的 JVM 实现是 Java 语言 “一次编译，随处可以运行” 的关键所在。\n\nJVM 并不是只有一种！只要遵守 JVM 设计规范就能开发出自己所需要的 Java 虚拟机，我们日常所用的 HotSpot VM 只是其中一种实现而已。\n\n\n# 什么是 JDK ?\n\nJDK(Java Development Kit) 是 Java 开发工具包，包含了 JRE 所有的东西，所以作为开发人员，只需要安装 JDK 即可。\n\n\n# 什么是 JRE ?\n\nJRE(Java Runtime Environment) 是 Java 运行环境，包含运行所需要的类库以及 JVM。\n\n你可能认为如果仅仅要运行 Java 程序，安装 JRE 即可，但是某些 web 程序例如：需要将 JSP 转换为 Java servlet 就需要 jdk 编译了，所以保守起见，无论运行还是开发，我们都建议在操作系统上安装 JDK。\n\n\n# Java 与 C++ 的区别\n\n 1. Java 没有指针的概念，不能像 C++ 一样直接操作内存，所以更加安全。\n 2. Java 不支持多继承，但是可以通过多接口实现多继承。\n 3. Java 只支持方法重载，不像 C++ 一样可以运算符重载。\n 4. Java 有自动内存管理垃圾回收机制 (GC)，无需像 C++ 一样手动释放。\n\n> 什么是 GC ?\n\n\n# 基本语法\n\n\n# 注释有哪几种形式？\n\n有三种：\n\n 1. 单行注释：通常用于解释方法内某单行代码的作用。(//)\n 2. 多行注释：通常用于解释一段代码的作用。（/* */)\n 3. 文档注释：通常用于生成 Java 开发文档。（即 java doc）\n\n\n# 标识符和关键字的区别是什么？\n\n标识符：简单来说就是一个名字，比如 某个店铺名。\n\n关键字：被赋予特殊含义的标识符，比如 警察局，医院。\n\n注意：所有关键字都是小写，在 IDE 中会以特殊颜色展示。\n\n\n# Java 有哪些关键字？\n\n\n\n\n# 访问控制关键字解析\n\n它们的作用是控制类、方法和变量的访问权限。\n\nJava 中的访问控制关键字主要有以下四个：\n\n 1. public: 表示公共的，任何地方都可以访问。在同一项目中或其他项目中，都可以通过引入类或模块进行访问。\n 2. protected: 表示受保护的，只有本类和其子类以及同一包中的其他类可以访问。在其他包中的子类不可以访问。\n 3. default（即不写访问控制符）: 表示默认的，只有本类和同一包中的其他类可以访问，其他包中的类都不可以访问。\n 4. private: 表示私有的，只有本类中可以访问，其他类都不可以访问。\n\n可见性\n\n同一个类 -> 同一个包 -> 子类 -> 全局范围\n\n可见性     PRIVATE   DEFAULT   PROTECTED   PUBLIC\n同一个类中   ✔️        ✔️        ✔️          ✔️\n同一个包中   ❌         ❌         ✔️          ✔️\n子类中     ❌         ❌         ✔️          ✔️\n全局范围    ❌         ❌         ❌           ✔️\n\n\n# final 关键字解析\n\nfinal 是 Java 中的一个关键字，可以用来修饰类、方法和变量，表示它们不可被修改。\n\n> 被 final 关键字修饰会怎么样？\n\n 1. final 修饰类：表示该类是不可继承的，即不能有子类。\n 2. final 修饰方法：表示该方法不能被子类重写，即不能被修改。\n 3. final 修饰变量：表示该变量是一个常量，只能被赋值一次，不能被修改。\n\nfinal 关键字的主要作用如下：\n\n * 提高代码的安全性：final 关键字可以保证类、方法和变量在程序运行时不被修改，从而提高了代码的安全性和可维护性。\n * 提高代码的性能：final 关键字可以使得编译器在编译时进行优化，从而提高了代码的性能。\n * 明确代码的含义：final关键字可以使得代码的含义更加明确，从而方便代码的维护和理解。\n\n\n# if 和 else if\n\nif 和 else if 是用于条件判断的控制结构。它们用于在不同的条件下执行不同的代码块。\n\n基本的语法如下：\n\nif (condition1) {\n    // 如果 condition1 为真，执行这里的代码块\n} else if (condition2) {\n    // 如果 condition1 为假，而 condition2 为真，执行这里的代码块\n} else {\n    // 如果前面的条件都为假，执行这里的代码块\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n在执行时，首先判断 condition1 是否为真。如果为真，执行 if 代码块；如果为假，继续判断 condition2。如果 condition2 为真，执行 else if 代码块；如果 condition2 为假，执行 else 代码块。\n\n重要的一点是，一旦某一个条件为真，后续的 else if 或 else 都不会再执行，因为 Java 中的 if - else if - else 结构是互斥的。\n\n以下是一个简单的例子：\n\nint number = 10;\n\nif (number > 0) {\n    System.out.println("Number is positive");\n} else if (number < 0) {\n    System.out.println("Number is negative");\n} else {\n    System.out.println("Number is zero");\n}\n\n// 输出 Number is positive\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 变量\n\n\n# 成员变量与局部变量的区别？\n\n主要是四个区别：\n\n 1. 从语法形式上看：\n    \n    * 成员变量是属于类的，\n    * 而局部变量是在代码块或方法中定义的变量或是方法的参数。\n    * 成员变量可以被 public,private,static 等修饰符所修饰，\n    * 而局部变量不能被访问控制修饰符及 static 所修饰；\n    * 但是，成员变量和局部变量都能被 final 所修饰。\n\n 2. 从变量在内存中的存储方式来看：\n    \n    * 如果成员变量是使用 static 修饰的，那么这个成员变量是属于类的，\n    \n    * 如果没有使用 static 修饰，这个成员变量是属于实例的。\n      \n      > 对象存在于堆内存，是【类的实例化】\n      > \n      > 局部变量则存在于栈内存，是【在方法里定义的】\n\n 3. 从变量在内存中的生存时间上看：\n    \n    * 成员变量是对象的一部分，它随着对象的创建而存在，\n    \n    * 而局部变量随着方法的调用而自动生成，随着方法的调用结束而消亡。\n\n 4. 从变量是否有默认值来看：\n    \n    * 成员变量如果没有被赋初始值，则会自动以类型的默认值而赋值（一种情况例外:被 final 修饰的成员变量也必须显式地赋值），\n    * 而局部变量则不会自动赋值。（Java 编译器不会对局部变量进行默认初始化，因为这些变量的值只在方法或代码块中使用，没有默认值。如果程序员没有显式地初始化局部变量，则编译器会在编译时抛出错误。即使定义包装类型的局部变量也一样）\n\n\n# 静态变量有什么用？\n\n静态变量也就是被 static 关键字修饰的变量。\n\n它可以被类的所有实例共享，无论一个类创建了多少个对象，它们都共享同一份静态变量。也就是说，静态变量只会被分配一次内存（属于类，只加载一下），即使创建多个对象，这样可以节省内存。\n\n静态变量是通过类名来访问的，例如 StaticVariableExample.staticVar（如果被 private 关键字修饰就无法这样访问了）。\n\npublic class StaticVariableExample {\n    // 静态变量\n    public static int staticVar = 0;\n}\n\n\n1\n2\n3\n4\n\n\n通常情况下，静态变量会被 final 关键字修饰成为常量。\n\npublic class ConstantVariableExample {\n    // 常量\n    public static final int constantVar = 0;\n}\n\n\n1\n2\n3\n4\n\n\n\n# 字符型常量和字符串常量的区别？\n\n 1. 形式:\n    * 字符常量是单引号引起的一个字符，\n    * 字符串常量是双引号引起的 0 个或若干个字符。\n 2. 含义:\n    * 字符常量相当于一个整型值( ASCII 值),可以参加表达式运算;\n    * 字符串常量代表一个地址值(该字符串在内存中存放位置)。\n 3. 占内存大小：\n    * 字符常量（char）只占 2 个字节;\n    * 字符串常量（String）占若干个字节。\n\n> 注意 char 在 Java 中占两个字节。\n\n\n# 方法\n\n\n# 什么是方法的返回值?方法有哪几种类型？\n\n方法的返回值 是指我们获取到的某个方法体中的代码执行后产生的结果！\n\n有四种类型：\n\n 1. 无参数无返回值的方法\n 2. 有参数无返回值的方法\n 3. 有返回值无参数的方法\n 4. 有返回值有参数的方法\n\n\n# 静态方法为什么不能调用非静态成员?\n\n这是因为\n\n * 静态方法是属于类的，在类加载的时候就会分配内存，可以通过类名直接访问。而非静态成员属于实例对象，只有在对象实例化之后才存在，需要通过类的实例对象去访问。\n * 在类的非静态成员不存在的时候静态方法就已经存在了，此时调用在内存中还不存在的非静态成员，属于非法操作。\n\n\n# 静态方法和实例方法有何不同？\n\n1、调用方式\n\n * 在外部调用静态方法时，可以使用 类名.方法名 的方式，也可以使用 对象.方法名 的方式，\n\n * 而实例方法只有后面这种方式。也就是说，调用静态方法可以无需创建对象 。\n\n2、访问类成员是否存在限制\n\n * 静态方法在访问本类的成员时，只允许访问静态成员（即静态成员变量和静态方法），不允许访问实例成员（即实例成员变量和实例方法），\n\n * 而实例方法不存在这个限制。\n\n\n# 重载和重写有什么区别？\n\n重载就是同一个类中多个同名方法根据不同的传参来执行不同的逻辑处理。\n\n重写就是子类对父类方法的重新改造，外部样子不能改变，内部逻辑可以改变。\n\n区别点    重载方法   重写方法\n发生范围   同一个类   子类\n参数列表   必须修改   一定不能修改\n返回类型   可修改    子类方法返回值类型应比父类方法返回值类型更小或相等\n异常     可修改    子类方法声明抛出的异常类应比父类方法声明抛出的异常类更小或相等\n访问修饰   可修改    一定不能做更严格的限制（可以降低限制）\n发生阶段   编译期    运行期\n\n\n# 什么是可变长参数？\n\n可变长参数是指在函数或方法中，参数的数量是可变的，即函数或方法可以接受不确定数量的参数。\n\n可变长参数必须放在参数列表的最后一个位置，并且使用省略号（...）来表示。\n\n例如：\n\npublic static int sum(int... nums) {\n    int result = 0;\n    for (int num : nums) {\n        result += num;\n    }\n    return result;\n}\n\nint sum1 = sum(1, 2, 3);     // sum1 = 6\nint sum2 = sum(1, 2, 3, 4);  // sum2 = 10\nint sum3 = sum(1);           // sum3 = 1\nint sum4 = sum();            // sum4 = 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n也可传入数组\n\nint[] nums = {1, 2, 3};\nint sum5 = sum(nums);        // sum5 = 6\n\n\n1\n2\n\n\n> 遇到方法重载时会优先匹配固定参数还是可变参数的方法呢？\n\n会优先匹配固定参数的方法，因为固定参数的方法匹配度更高。\n\n\n# 注解\n\n\n# 谈谈对 Java 注解的理解，解决了什么问题？\n\n注解可以看作是一种特殊的注释，本质上是继承了 Annotation 这一特殊接口，主要用于修饰类、方法或者变量，提供某些信息供程序在编译或者运行时使用。\n\n注解只有被解析之后才会生效。我们可以使用 JDK 提供的内置注解也可以自定义注解。\n\nJava 注解的出现主要是为了解决代码中大量重复性工作，例如：配置文件的读取、日志记录、数据校验等。可以帮助开发者更加方便地管理和维护代码（还可以实现一些特定的功能），提高程序的质量（和开发效率）。\n\n\n# 注解的解析方法有哪几种？\n\n常见的解析方法有两种：\n\n * 编译期直接扫描：编译器在编译 Java 代码的时候扫描对应的注解并处理，比如某个方法使用 @Override 注解，编译器在编译的时候就会检测当前的方法是否重写了父类对应的方法。\n\n * 运行期通过反射处理：像框架中自带的注解(比如 Spring 框架的 @Value、@Component)都是通过反射来进行处理的。\n   \n   定义一个注解 MyAnnotation：\n   \n   @Retention(RetentionPolicy.RUNTIME)\n   @Target(ElementType.TYPE)\n   public @interface MyAnnotation {\n       String value();\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n   \n   在代码中使用注解，并通过反射机制获取注解信息：\n   \n   @MyAnnotation("hello")\n   public class MyClass {\n       public static void main(String[] args) {\n           MyClass obj = new MyClass();\n           Class<?> clazz = obj.getClass();\n           MyAnnotation annotation = clazz.getAnnotation(MyAnnotation.class);\n           System.out.println(annotation.value()); // 输出 "hello"\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   \n\n * 字节码注解解析：在类加载期间，通过 ASM 或 Javassist 等字节码操作库来解析注解信息，并修改字节码文件。这种方式可以在不改变源代码的情况下，对代码进行动态的修改和增强。\n   \n   定义一个注解 MyAnnotation：\n   \n   @Retention(RetentionPolicy.RUNTIME)\n   @Target(ElementType.TYPE)\n   public @interface MyAnnotation {\n       String value();\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n   \n   使用 ASM 操作库在类加载期间解析注解信息：\n   \n   public class MyClassLoader extends ClassLoader {\n       @Override\n       protected Class<?> findClass(String name) throws ClassNotFoundException {\n           byte[] bytes = loadClassData(name);\n           Class<?> clazz = defineClass(name, bytes, 0, bytes.length);\n           // 解析注解信息\n           return clazz;\n       }\n   \n       private byte[] loadClassData(String name) {\n           // 读取类字节码文件\n       }\n   }\n   \n   MyClassLoader loader = new MyClassLoader();\n   Class<?> clazz = loader.loadClass("com.example.MyClass");\n   MyAnnotation annotation = clazz.getAnnotation(MyAnnotation.class);\n   System.out.println(annotation.value()); // 输出 "hello"\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   \n\n\n# SPI\n\n\n# 什么是 Java 的 SPI 机制？\n\nJava 的 SPI（Service Provider Interface）机制是一种用于动态加载和扩展服务的机制，它通过定义服务接口、服务提供者接口和加载配置文件的方式，实现了在运行时动态加载服务提供者实现的功能。\n\n\n# SPI 机制的优缺点是什么？\n\nSPI 机制的\n\n * 优点是可以在不修改代码的情况下，动态地扩展应用程序的功能，提高了程序的灵活性和可扩展性。\n * 缺点是容易发生冲突和重复加载等问题，需要谨慎使用。\n\n\n# 如何在 Java 中使用 SPI 机制？\n\n在 Java 中使用 SPI 机制需要完成以下步骤：\n\n * 定义服务接口和服务提供者接口；\n * 编写服务提供者实现，并将实现类打成 jar 包；\n * 在 META-INF/services 目录下创建一个名为服务接口全限定名的配置文件，文件内容为服务提供者接口的全限定类名；\n * 在程序中加载服务提供者实现，可以通过 ClassLoader 和反射机制实现。\n\n\n# 如何避免 SPI 机制中的冲突问题？\n\n为了避免 SPI 机制中的冲突问题，可以使用类加载器隔离机制，即创建多个类加载器，每个类加载器加载不同的 jar 包和配置文件，从而实现服务提供者实现的隔离。同时，也可以规范命名空间的使用，避免不同的服务提供者实现使用相同的命名空间。\n\n\n# SPI 机制和 Spring 的 BeanFactory 有什么区别？\n\nSPI 机制和 Spring 的 BeanFactory 都是用于实现插件化和扩展性的机制，但是它们的实现方式不同。SPI 机制是基于接口和配置文件的方式实现的，而 Spring 的 BeanFactory 是基于依赖注入和反射机制实现的。SPI 机制更加轻量级和灵活，适用于简单的应用场景，而 Spring 的 BeanFactory 更加强大和复杂，适用于大型的企业级应用。\n\n\n# 序列化和反序列化\n\n\n# 什么是序列化？什么是反序列化？\n\n如果我们需要持久化 Java 对象比如将 Java 对象保存在文件中，或者在网络传输 Java 对象，这些场景都需要用到序列化。\n\n简单来说：\n\n * 序列化： 将数据结构或对象转换成二进制字节流的过程\n * 反序列化：将在序列化过程中所生成的二进制字节流转换成数据结构或者对象的过程\n\n序列化的主要目的是：\n\n通过网络传输对象或者说是将对象存储到文件系统、数据库、内存中。\n\n\n# 序列化协议对应于 TCP/IP 4 层模型的哪一层？\n\n * OSI 模型中的表示层\n * TCP/IP 4 层模型中的应用层\n\n\n# 项目中，JSON 数据的传输体现在哪？\n\n在项目中，JSON 数据的传输是非常常见的方式。JSON 是一种轻量级的数据交换格式，可以方便地在前后端之间传输数据。\n\n以下是一些常见的在项目中使用 JSON 传输数据的场景：\n\n 1. 前后端 API 交互：在前后端分离的项目中，前端和后端通常通过 API 进行交互。在这种情况下，后端将数据以 JSON 格式返回给前端，前端可以使用 JavaScript 解析 JSON 数据，将其转换为对象，并在页面上渲染数据。\n\n 2. RESTful API：RESTful API 是一种基于 HTTP 协议的 API 设计风格，通常使用 JSON 作为数据传输格式。在 Java 项目中，可以使用 Spring MVC 或 JAX-RS 等框架来构建 RESTful API，并使用一些 JSON 解析库将 JSON 请求和响应转换为 Java 对象。\n\n 3. WebSocket 通信：在前后端分离的实时通信应用中，WebSocket 是一种常见的通信协议。在这种情况下，前后端可以使用 JSON 作为通信协议，将消息以 JSON 格式传输。\n\n 4. 静态资源加载：在前后端分离的项目中，前端通常使用 AJAX 或 Fetch API 从后端获取数据。在这种情况下，后端可以将数据以 JSON 格式返回给前端，前端可以使用 JavaScript 解析 JSON 数据，并在页面上渲染数据。\n\n\n# 语法糖\n\n\n# 什么是语法糖？\n\n语法糖（Syntactic sugar）代指的是编程语言为了方便程序员开发程序而设计的一种特殊语法，这种语法对编程语言的功能并没有影响。\n\n实现相同的功能，基于语法糖写出来的代码往往更简单简洁且更易阅读。\n\n> 不过，JVM 其实并不能识别语法糖，Java 语法糖要想被正确执行，需要先通过编译器进行解糖，也就是在程序编译阶段将其转换成 JVM 认识的基本语法。这也侧面说明，Java 中真正支持语法糖的是 Java 编译器而不是 JVM。如果你去看 com.sun.tools.javac.main.JavaCompiler 的源码，你会发现在 compile() 中有一个步骤就是调用 desugar()，这个方法就是负责解语法糖的实现的。\n\n\n# Java 中有哪些常见的语法糖？\n\nJava 中最常用的语法糖主要有泛型、自动拆装箱、变长参数、枚举、内部类、增强 for 循环、try-with-resources 语法、lambda 表达式等。\n\n\n# 内部类了解吗？\n\n内部类是指定义在类内部的类，它可以访问外部类的私有变量和方法，从而实现对外部类的访问和控制。\n\n内部类主要分为以下几种：\n\n 1. **成员内部类：**定义在类中的普通内部类，可以访问外部类的私有变量和方法；（类中类）\n 2. **静态内部类：**定义在类中的静态内部类，不能访问外部类的非静态变量和方法；（静态的类中类）\n 3. 局部内部类：定义在方法内的内部类，只能在方法内部使用。（方法中的类）\n\n\n# 匿名内部类了解吗？\n\n匿名内部类是指没有名字的内部类，它是一种简化的内部类语法，可以用来创建一个临时的、只使用一次的类。\n\n匿名内部类通常用于实现接口或抽象类（花括号中的内容是匿名内部类的具体实现），匿名内部类可以使得代码更加简洁，但也会使得代码的可读性和可维护性降低，因此需要谨慎使用。\n\n例如，下面的代码演示了如何使用匿名内部类实现一个 Runnable 接口：\n\nThread t = new Thread(new Runnable() {\n    public void run() {\n        // 线程执行的代码\n    }\n});\nt.start();\n\n\n1\n2\n3\n4\n5\n6\n',normalizedContent:'# java 基础小结\n\n\n# java 基础概念与常识\n\n\n# 什么是 java ?\n\njava 是 1995 年由 sun 公司推出的一门高级语言。\n\njava 的四个基本特性是面向对象、平台无关性、安全性和简单性。\n\n具体特点如下:\n\n 1. 简单易学。\n\n 2. 平台无关性。\n\n 3. 面向对象\n    \n    * 面向对象是一种程序设计技术，以木匠工作为例，使用面向对象方式实现的木匠的工作关注重点永远是制作椅子，其次才是工具。\n    \n    * 而面向过程则优先关注制作工具。\n    \n    * 与 c++ 不同的是，java 不支持多继承，取而代之的是更加简单的接口的概念。\n    \n    * 面向对象三大特性: 封装、多态、继承。\n\n 4. 编译与解释并存\n\n 5. 可靠性\n    \n    * java 通过早期检测以及运行时检测消除了容易出错的情况。\n    * 与 c++ 不同的是，c++ 在操作数组、字符串方式上利用指针模型避免了重写内存或者损坏数据的问题。\n\n 6. 安全性: java 适用于网络/分布式环境，为了达到这个目标，java 在防病毒，防篡改做出很大的努力。\n\n 7. 支持网络编程并且非常方便。\n\n 8. 支持多线程。\n\n> 什么是【编译型】语言和【解释型】语言？\n> \n> 编译型：编译型语言 会通过编译器将源代码一次性翻译成可被该平台执行的机器码。一般情况下，编译语言的执行速度比较快，开发效率比较低。常见的编译性语言有 c、c++、go、rust 等等。\n> \n> 解释型：解释型语言会通过解释器一句一句的将代码解释（interpret）为机器代码后再执行。解释型语言开发效率比较快，执行速度比较慢。常见的解释性语言有 python、javascript、php 等等。\n> \n> 而 java 是编译与解释并存，因为 java 源代码运行时需要先编译成为字节码文件 (.class)，然后再通过解释器翻译成机器码运行。\n\n\n# java 的三种技术架构\n\n 1. javase：标准版，即学生时期学习时使用的版本。\n 2. javaee：web 开发采用的技术架构。\n 3. javame：为嵌入式设备提供的解决方案\n\n\n# 什么是 jvm ?\n\njava 虚拟机（jvm）是运行 java 字节码的虚拟机。\n\njvm 有针对不同系统的特定实现（windows，linux，macos），目的是使用相同的字节码，它们都会给出相同的结果。\n\n字节码和不同系统的 jvm 实现是 java 语言 “一次编译，随处可以运行” 的关键所在。\n\njvm 并不是只有一种！只要遵守 jvm 设计规范就能开发出自己所需要的 java 虚拟机，我们日常所用的 hotspot vm 只是其中一种实现而已。\n\n\n# 什么是 jdk ?\n\njdk(java development kit) 是 java 开发工具包，包含了 jre 所有的东西，所以作为开发人员，只需要安装 jdk 即可。\n\n\n# 什么是 jre ?\n\njre(java runtime environment) 是 java 运行环境，包含运行所需要的类库以及 jvm。\n\n你可能认为如果仅仅要运行 java 程序，安装 jre 即可，但是某些 web 程序例如：需要将 jsp 转换为 java servlet 就需要 jdk 编译了，所以保守起见，无论运行还是开发，我们都建议在操作系统上安装 jdk。\n\n\n# java 与 c++ 的区别\n\n 1. java 没有指针的概念，不能像 c++ 一样直接操作内存，所以更加安全。\n 2. java 不支持多继承，但是可以通过多接口实现多继承。\n 3. java 只支持方法重载，不像 c++ 一样可以运算符重载。\n 4. java 有自动内存管理垃圾回收机制 (gc)，无需像 c++ 一样手动释放。\n\n> 什么是 gc ?\n\n\n# 基本语法\n\n\n# 注释有哪几种形式？\n\n有三种：\n\n 1. 单行注释：通常用于解释方法内某单行代码的作用。(//)\n 2. 多行注释：通常用于解释一段代码的作用。（/* */)\n 3. 文档注释：通常用于生成 java 开发文档。（即 java doc）\n\n\n# 标识符和关键字的区别是什么？\n\n标识符：简单来说就是一个名字，比如 某个店铺名。\n\n关键字：被赋予特殊含义的标识符，比如 警察局，医院。\n\n注意：所有关键字都是小写，在 ide 中会以特殊颜色展示。\n\n\n# java 有哪些关键字？\n\n\n\n\n# 访问控制关键字解析\n\n它们的作用是控制类、方法和变量的访问权限。\n\njava 中的访问控制关键字主要有以下四个：\n\n 1. public: 表示公共的，任何地方都可以访问。在同一项目中或其他项目中，都可以通过引入类或模块进行访问。\n 2. protected: 表示受保护的，只有本类和其子类以及同一包中的其他类可以访问。在其他包中的子类不可以访问。\n 3. default（即不写访问控制符）: 表示默认的，只有本类和同一包中的其他类可以访问，其他包中的类都不可以访问。\n 4. private: 表示私有的，只有本类中可以访问，其他类都不可以访问。\n\n可见性\n\n同一个类 -> 同一个包 -> 子类 -> 全局范围\n\n可见性     private   default   protected   public\n同一个类中   ✔️        ✔️        ✔️          ✔️\n同一个包中   ❌         ❌         ✔️          ✔️\n子类中     ❌         ❌         ✔️          ✔️\n全局范围    ❌         ❌         ❌           ✔️\n\n\n# final 关键字解析\n\nfinal 是 java 中的一个关键字，可以用来修饰类、方法和变量，表示它们不可被修改。\n\n> 被 final 关键字修饰会怎么样？\n\n 1. final 修饰类：表示该类是不可继承的，即不能有子类。\n 2. final 修饰方法：表示该方法不能被子类重写，即不能被修改。\n 3. final 修饰变量：表示该变量是一个常量，只能被赋值一次，不能被修改。\n\nfinal 关键字的主要作用如下：\n\n * 提高代码的安全性：final 关键字可以保证类、方法和变量在程序运行时不被修改，从而提高了代码的安全性和可维护性。\n * 提高代码的性能：final 关键字可以使得编译器在编译时进行优化，从而提高了代码的性能。\n * 明确代码的含义：final关键字可以使得代码的含义更加明确，从而方便代码的维护和理解。\n\n\n# if 和 else if\n\nif 和 else if 是用于条件判断的控制结构。它们用于在不同的条件下执行不同的代码块。\n\n基本的语法如下：\n\nif (condition1) {\n    // 如果 condition1 为真，执行这里的代码块\n} else if (condition2) {\n    // 如果 condition1 为假，而 condition2 为真，执行这里的代码块\n} else {\n    // 如果前面的条件都为假，执行这里的代码块\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n在执行时，首先判断 condition1 是否为真。如果为真，执行 if 代码块；如果为假，继续判断 condition2。如果 condition2 为真，执行 else if 代码块；如果 condition2 为假，执行 else 代码块。\n\n重要的一点是，一旦某一个条件为真，后续的 else if 或 else 都不会再执行，因为 java 中的 if - else if - else 结构是互斥的。\n\n以下是一个简单的例子：\n\nint number = 10;\n\nif (number > 0) {\n    system.out.println("number is positive");\n} else if (number < 0) {\n    system.out.println("number is negative");\n} else {\n    system.out.println("number is zero");\n}\n\n// 输出 number is positive\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 变量\n\n\n# 成员变量与局部变量的区别？\n\n主要是四个区别：\n\n 1. 从语法形式上看：\n    \n    * 成员变量是属于类的，\n    * 而局部变量是在代码块或方法中定义的变量或是方法的参数。\n    * 成员变量可以被 public,private,static 等修饰符所修饰，\n    * 而局部变量不能被访问控制修饰符及 static 所修饰；\n    * 但是，成员变量和局部变量都能被 final 所修饰。\n\n 2. 从变量在内存中的存储方式来看：\n    \n    * 如果成员变量是使用 static 修饰的，那么这个成员变量是属于类的，\n    \n    * 如果没有使用 static 修饰，这个成员变量是属于实例的。\n      \n      > 对象存在于堆内存，是【类的实例化】\n      > \n      > 局部变量则存在于栈内存，是【在方法里定义的】\n\n 3. 从变量在内存中的生存时间上看：\n    \n    * 成员变量是对象的一部分，它随着对象的创建而存在，\n    \n    * 而局部变量随着方法的调用而自动生成，随着方法的调用结束而消亡。\n\n 4. 从变量是否有默认值来看：\n    \n    * 成员变量如果没有被赋初始值，则会自动以类型的默认值而赋值（一种情况例外:被 final 修饰的成员变量也必须显式地赋值），\n    * 而局部变量则不会自动赋值。（java 编译器不会对局部变量进行默认初始化，因为这些变量的值只在方法或代码块中使用，没有默认值。如果程序员没有显式地初始化局部变量，则编译器会在编译时抛出错误。即使定义包装类型的局部变量也一样）\n\n\n# 静态变量有什么用？\n\n静态变量也就是被 static 关键字修饰的变量。\n\n它可以被类的所有实例共享，无论一个类创建了多少个对象，它们都共享同一份静态变量。也就是说，静态变量只会被分配一次内存（属于类，只加载一下），即使创建多个对象，这样可以节省内存。\n\n静态变量是通过类名来访问的，例如 staticvariableexample.staticvar（如果被 private 关键字修饰就无法这样访问了）。\n\npublic class staticvariableexample {\n    // 静态变量\n    public static int staticvar = 0;\n}\n\n\n1\n2\n3\n4\n\n\n通常情况下，静态变量会被 final 关键字修饰成为常量。\n\npublic class constantvariableexample {\n    // 常量\n    public static final int constantvar = 0;\n}\n\n\n1\n2\n3\n4\n\n\n\n# 字符型常量和字符串常量的区别？\n\n 1. 形式:\n    * 字符常量是单引号引起的一个字符，\n    * 字符串常量是双引号引起的 0 个或若干个字符。\n 2. 含义:\n    * 字符常量相当于一个整型值( ascii 值),可以参加表达式运算;\n    * 字符串常量代表一个地址值(该字符串在内存中存放位置)。\n 3. 占内存大小：\n    * 字符常量（char）只占 2 个字节;\n    * 字符串常量（string）占若干个字节。\n\n> 注意 char 在 java 中占两个字节。\n\n\n# 方法\n\n\n# 什么是方法的返回值?方法有哪几种类型？\n\n方法的返回值 是指我们获取到的某个方法体中的代码执行后产生的结果！\n\n有四种类型：\n\n 1. 无参数无返回值的方法\n 2. 有参数无返回值的方法\n 3. 有返回值无参数的方法\n 4. 有返回值有参数的方法\n\n\n# 静态方法为什么不能调用非静态成员?\n\n这是因为\n\n * 静态方法是属于类的，在类加载的时候就会分配内存，可以通过类名直接访问。而非静态成员属于实例对象，只有在对象实例化之后才存在，需要通过类的实例对象去访问。\n * 在类的非静态成员不存在的时候静态方法就已经存在了，此时调用在内存中还不存在的非静态成员，属于非法操作。\n\n\n# 静态方法和实例方法有何不同？\n\n1、调用方式\n\n * 在外部调用静态方法时，可以使用 类名.方法名 的方式，也可以使用 对象.方法名 的方式，\n\n * 而实例方法只有后面这种方式。也就是说，调用静态方法可以无需创建对象 。\n\n2、访问类成员是否存在限制\n\n * 静态方法在访问本类的成员时，只允许访问静态成员（即静态成员变量和静态方法），不允许访问实例成员（即实例成员变量和实例方法），\n\n * 而实例方法不存在这个限制。\n\n\n# 重载和重写有什么区别？\n\n重载就是同一个类中多个同名方法根据不同的传参来执行不同的逻辑处理。\n\n重写就是子类对父类方法的重新改造，外部样子不能改变，内部逻辑可以改变。\n\n区别点    重载方法   重写方法\n发生范围   同一个类   子类\n参数列表   必须修改   一定不能修改\n返回类型   可修改    子类方法返回值类型应比父类方法返回值类型更小或相等\n异常     可修改    子类方法声明抛出的异常类应比父类方法声明抛出的异常类更小或相等\n访问修饰   可修改    一定不能做更严格的限制（可以降低限制）\n发生阶段   编译期    运行期\n\n\n# 什么是可变长参数？\n\n可变长参数是指在函数或方法中，参数的数量是可变的，即函数或方法可以接受不确定数量的参数。\n\n可变长参数必须放在参数列表的最后一个位置，并且使用省略号（...）来表示。\n\n例如：\n\npublic static int sum(int... nums) {\n    int result = 0;\n    for (int num : nums) {\n        result += num;\n    }\n    return result;\n}\n\nint sum1 = sum(1, 2, 3);     // sum1 = 6\nint sum2 = sum(1, 2, 3, 4);  // sum2 = 10\nint sum3 = sum(1);           // sum3 = 1\nint sum4 = sum();            // sum4 = 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n也可传入数组\n\nint[] nums = {1, 2, 3};\nint sum5 = sum(nums);        // sum5 = 6\n\n\n1\n2\n\n\n> 遇到方法重载时会优先匹配固定参数还是可变参数的方法呢？\n\n会优先匹配固定参数的方法，因为固定参数的方法匹配度更高。\n\n\n# 注解\n\n\n# 谈谈对 java 注解的理解，解决了什么问题？\n\n注解可以看作是一种特殊的注释，本质上是继承了 annotation 这一特殊接口，主要用于修饰类、方法或者变量，提供某些信息供程序在编译或者运行时使用。\n\n注解只有被解析之后才会生效。我们可以使用 jdk 提供的内置注解也可以自定义注解。\n\njava 注解的出现主要是为了解决代码中大量重复性工作，例如：配置文件的读取、日志记录、数据校验等。可以帮助开发者更加方便地管理和维护代码（还可以实现一些特定的功能），提高程序的质量（和开发效率）。\n\n\n# 注解的解析方法有哪几种？\n\n常见的解析方法有两种：\n\n * 编译期直接扫描：编译器在编译 java 代码的时候扫描对应的注解并处理，比如某个方法使用 @override 注解，编译器在编译的时候就会检测当前的方法是否重写了父类对应的方法。\n\n * 运行期通过反射处理：像框架中自带的注解(比如 spring 框架的 @value、@component)都是通过反射来进行处理的。\n   \n   定义一个注解 myannotation：\n   \n   @retention(retentionpolicy.runtime)\n   @target(elementtype.type)\n   public @interface myannotation {\n       string value();\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n   \n   在代码中使用注解，并通过反射机制获取注解信息：\n   \n   @myannotation("hello")\n   public class myclass {\n       public static void main(string[] args) {\n           myclass obj = new myclass();\n           class<?> clazz = obj.getclass();\n           myannotation annotation = clazz.getannotation(myannotation.class);\n           system.out.println(annotation.value()); // 输出 "hello"\n       }\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   \n\n * 字节码注解解析：在类加载期间，通过 asm 或 javassist 等字节码操作库来解析注解信息，并修改字节码文件。这种方式可以在不改变源代码的情况下，对代码进行动态的修改和增强。\n   \n   定义一个注解 myannotation：\n   \n   @retention(retentionpolicy.runtime)\n   @target(elementtype.type)\n   public @interface myannotation {\n       string value();\n   }\n   \n   \n   1\n   2\n   3\n   4\n   5\n   \n   \n   使用 asm 操作库在类加载期间解析注解信息：\n   \n   public class myclassloader extends classloader {\n       @override\n       protected class<?> findclass(string name) throws classnotfoundexception {\n           byte[] bytes = loadclassdata(name);\n           class<?> clazz = defineclass(name, bytes, 0, bytes.length);\n           // 解析注解信息\n           return clazz;\n       }\n   \n       private byte[] loadclassdata(string name) {\n           // 读取类字节码文件\n       }\n   }\n   \n   myclassloader loader = new myclassloader();\n   class<?> clazz = loader.loadclass("com.example.myclass");\n   myannotation annotation = clazz.getannotation(myannotation.class);\n   system.out.println(annotation.value()); // 输出 "hello"\n   \n   \n   1\n   2\n   3\n   4\n   5\n   6\n   7\n   8\n   9\n   10\n   11\n   12\n   13\n   14\n   15\n   16\n   17\n   18\n   \n\n\n# spi\n\n\n# 什么是 java 的 spi 机制？\n\njava 的 spi（service provider interface）机制是一种用于动态加载和扩展服务的机制，它通过定义服务接口、服务提供者接口和加载配置文件的方式，实现了在运行时动态加载服务提供者实现的功能。\n\n\n# spi 机制的优缺点是什么？\n\nspi 机制的\n\n * 优点是可以在不修改代码的情况下，动态地扩展应用程序的功能，提高了程序的灵活性和可扩展性。\n * 缺点是容易发生冲突和重复加载等问题，需要谨慎使用。\n\n\n# 如何在 java 中使用 spi 机制？\n\n在 java 中使用 spi 机制需要完成以下步骤：\n\n * 定义服务接口和服务提供者接口；\n * 编写服务提供者实现，并将实现类打成 jar 包；\n * 在 meta-inf/services 目录下创建一个名为服务接口全限定名的配置文件，文件内容为服务提供者接口的全限定类名；\n * 在程序中加载服务提供者实现，可以通过 classloader 和反射机制实现。\n\n\n# 如何避免 spi 机制中的冲突问题？\n\n为了避免 spi 机制中的冲突问题，可以使用类加载器隔离机制，即创建多个类加载器，每个类加载器加载不同的 jar 包和配置文件，从而实现服务提供者实现的隔离。同时，也可以规范命名空间的使用，避免不同的服务提供者实现使用相同的命名空间。\n\n\n# spi 机制和 spring 的 beanfactory 有什么区别？\n\nspi 机制和 spring 的 beanfactory 都是用于实现插件化和扩展性的机制，但是它们的实现方式不同。spi 机制是基于接口和配置文件的方式实现的，而 spring 的 beanfactory 是基于依赖注入和反射机制实现的。spi 机制更加轻量级和灵活，适用于简单的应用场景，而 spring 的 beanfactory 更加强大和复杂，适用于大型的企业级应用。\n\n\n# 序列化和反序列化\n\n\n# 什么是序列化？什么是反序列化？\n\n如果我们需要持久化 java 对象比如将 java 对象保存在文件中，或者在网络传输 java 对象，这些场景都需要用到序列化。\n\n简单来说：\n\n * 序列化： 将数据结构或对象转换成二进制字节流的过程\n * 反序列化：将在序列化过程中所生成的二进制字节流转换成数据结构或者对象的过程\n\n序列化的主要目的是：\n\n通过网络传输对象或者说是将对象存储到文件系统、数据库、内存中。\n\n\n# 序列化协议对应于 tcp/ip 4 层模型的哪一层？\n\n * osi 模型中的表示层\n * tcp/ip 4 层模型中的应用层\n\n\n# 项目中，json 数据的传输体现在哪？\n\n在项目中，json 数据的传输是非常常见的方式。json 是一种轻量级的数据交换格式，可以方便地在前后端之间传输数据。\n\n以下是一些常见的在项目中使用 json 传输数据的场景：\n\n 1. 前后端 api 交互：在前后端分离的项目中，前端和后端通常通过 api 进行交互。在这种情况下，后端将数据以 json 格式返回给前端，前端可以使用 javascript 解析 json 数据，将其转换为对象，并在页面上渲染数据。\n\n 2. restful api：restful api 是一种基于 http 协议的 api 设计风格，通常使用 json 作为数据传输格式。在 java 项目中，可以使用 spring mvc 或 jax-rs 等框架来构建 restful api，并使用一些 json 解析库将 json 请求和响应转换为 java 对象。\n\n 3. websocket 通信：在前后端分离的实时通信应用中，websocket 是一种常见的通信协议。在这种情况下，前后端可以使用 json 作为通信协议，将消息以 json 格式传输。\n\n 4. 静态资源加载：在前后端分离的项目中，前端通常使用 ajax 或 fetch api 从后端获取数据。在这种情况下，后端可以将数据以 json 格式返回给前端，前端可以使用 javascript 解析 json 数据，并在页面上渲染数据。\n\n\n# 语法糖\n\n\n# 什么是语法糖？\n\n语法糖（syntactic sugar）代指的是编程语言为了方便程序员开发程序而设计的一种特殊语法，这种语法对编程语言的功能并没有影响。\n\n实现相同的功能，基于语法糖写出来的代码往往更简单简洁且更易阅读。\n\n> 不过，jvm 其实并不能识别语法糖，java 语法糖要想被正确执行，需要先通过编译器进行解糖，也就是在程序编译阶段将其转换成 jvm 认识的基本语法。这也侧面说明，java 中真正支持语法糖的是 java 编译器而不是 jvm。如果你去看 com.sun.tools.javac.main.javacompiler 的源码，你会发现在 compile() 中有一个步骤就是调用 desugar()，这个方法就是负责解语法糖的实现的。\n\n\n# java 中有哪些常见的语法糖？\n\njava 中最常用的语法糖主要有泛型、自动拆装箱、变长参数、枚举、内部类、增强 for 循环、try-with-resources 语法、lambda 表达式等。\n\n\n# 内部类了解吗？\n\n内部类是指定义在类内部的类，它可以访问外部类的私有变量和方法，从而实现对外部类的访问和控制。\n\n内部类主要分为以下几种：\n\n 1. **成员内部类：**定义在类中的普通内部类，可以访问外部类的私有变量和方法；（类中类）\n 2. **静态内部类：**定义在类中的静态内部类，不能访问外部类的非静态变量和方法；（静态的类中类）\n 3. 局部内部类：定义在方法内的内部类，只能在方法内部使用。（方法中的类）\n\n\n# 匿名内部类了解吗？\n\n匿名内部类是指没有名字的内部类，它是一种简化的内部类语法，可以用来创建一个临时的、只使用一次的类。\n\n匿名内部类通常用于实现接口或抽象类（花括号中的内容是匿名内部类的具体实现），匿名内部类可以使得代码更加简洁，但也会使得代码的可读性和可维护性降低，因此需要谨慎使用。\n\n例如，下面的代码演示了如何使用匿名内部类实现一个 runnable 接口：\n\nthread t = new thread(new runnable() {\n    public void run() {\n        // 线程执行的代码\n    }\n});\nt.start();\n\n\n1\n2\n3\n4\n5\n6\n',charsets:{cjk:!0}},{title:"Java基本数据类型",frontmatter:{title:"Java基本数据类型",date:"2023-06-15T11:13:54.000Z",permalink:"/pages/b3eb48/",author:{name:"陌上清风",link:"https://github.com/msqfx"},categories:["java","基础篇"],tags:[null],description:"8 种基本数据类型：byte 1，short 2，int 4，long 8，float 4，dobule 8，char 2，boolean 1",comment:!0,meta:[{name:"twitter:title",content:"Java基本数据类型"},{name:"twitter:description",content:"8 种基本数据类型：byte 1，short 2，int 4，long 8，float 4，dobule 8，char 2，boolean 1"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/01.%E5%9F%BA%E7%A1%80%E7%AF%87/02.Java%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Java基本数据类型"},{property:"og:description",content:"8 种基本数据类型：byte 1，short 2，int 4，long 8，float 4，dobule 8，char 2，boolean 1"},{property:"og:url",content:"https://www.msqfx.cc/01.java/01.%E5%9F%BA%E7%A1%80%E7%AF%87/02.Java%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-06-15T11:13:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"Java基本数据类型"},{itemprop:"description",content:"8 种基本数据类型：byte 1，short 2，int 4，long 8，float 4，dobule 8，char 2，boolean 1"}],readingShow:"top"},regularPath:"/01.java/01.%E5%9F%BA%E7%A1%80%E7%AF%87/02.Java%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html",relativePath:"01.java/01.基础篇/02.Java基本数据类型.md",key:"v-b8532098",path:"/pages/b3eb48/",headers:[{level:2,title:"Java 中的几种基本数据类型是什么？对应的包装类型是什么？各自占用多少字节？",slug:"java-中的几种基本数据类型是什么-对应的包装类型是什么-各自占用多少字节",normalizedTitle:"java 中的几种基本数据类型是什么？对应的包装类型是什么？各自占用多少字节？",charIndex:18},{level:2,title:"讲讲 int 的取值范围是多少？",slug:"讲讲-int-的取值范围是多少",normalizedTitle:"讲讲 int 的取值范围是多少？",charIndex:244},{level:2,title:"基本类型和包装类型的区别？",slug:"基本类型和包装类型的区别",normalizedTitle:"基本类型和包装类型的区别？",charIndex:497},{level:2,title:"包装类型的缓存机制了解吗？",slug:"包装类型的缓存机制了解吗",normalizedTitle:"包装类型的缓存机制了解吗？",charIndex:1062},{level:2,title:"为什么要有包装类型？",slug:"为什么要有包装类型",normalizedTitle:"为什么要有包装类型？",charIndex:1451},{level:2,title:"自动装箱与拆箱了解吗？原理是什么？",slug:"自动装箱与拆箱了解吗-原理是什么",normalizedTitle:"自动装箱与拆箱了解吗？原理是什么？",charIndex:2018},{level:2,title:"为什么浮点数运算的时候会有精度丢失的风险？",slug:"为什么浮点数运算的时候会有精度丢失的风险",normalizedTitle:"为什么浮点数运算的时候会有精度丢失的风险？",charIndex:2490},{level:2,title:"如何解决浮点数运算的精度丢失问题？",slug:"如何解决浮点数运算的精度丢失问题",normalizedTitle:"如何解决浮点数运算的精度丢失问题？",charIndex:2769},{level:2,title:"超过 long 整型的数据应该如何表示？",slug:"超过-long-整型的数据应该如何表示",normalizedTitle:"超过 long 整型的数据应该如何表示？",charIndex:3218},{level:2,title:"什么是引用类型？",slug:"什么是引用类型",normalizedTitle:"什么是引用类型？",charIndex:3849},{level:2,title:"NPE 问题？",slug:"npe-问题",normalizedTitle:"npe 问题？",charIndex:4352}],headersStr:"Java 中的几种基本数据类型是什么？对应的包装类型是什么？各自占用多少字节？ 讲讲 int 的取值范围是多少？ 基本类型和包装类型的区别？ 包装类型的缓存机制了解吗？ 为什么要有包装类型？ 自动装箱与拆箱了解吗？原理是什么？ 为什么浮点数运算的时候会有精度丢失的风险？ 如何解决浮点数运算的精度丢失问题？ 超过 long 整型的数据应该如何表示？ 什么是引用类型？ NPE 问题？",content:'# Java 基本数据类型\n\n\n# Java 中的几种基本数据类型是什么？对应的包装类型是什么？各自占用多少字节？\n\n8 种基本数据类型：byte 1，short 2，int 4，long 8，float 4，dobule 8，char 2，boolean 1\n\n对应的包装类型：Byte，Short，Interger，Long，Float，Double，Character，Boolean\n\n对应占用的字节：1，2，4，8，4，8，2，1\n\n> 注意：short 是 2 字节\n\n\n# 讲讲 int 的取值范围是多少？\n\n想想字节和取值范围的关系。\n\n * int 有 4 个字节，也就是占 32 个比特位，\n * 所以取值范围就是【-2 的 31 次方到 2 的 31 次方减 1】，即约为 -2,147,483,648 到 2,147,483,647。\n\n> 需要注意的是，这个范围是针对有符号的整数类型。\n> \n> 如果使用【无符号】的整数类型（如 Java 中的 unsigned int），则范围将从 0 到 2^32 - 1，即约为 0 到 4,294,967,295。\n\n\n# 基本类型和包装类型的区别？\n\n五大区别：\n\n用途：\n\n * 基本类型一般用来定义一些常量和局部变量，我们在其他地方比如方法参数、对象属性中很少会使用基本类型来定义变量。\n * 包装类型可用于泛型，而基本类型不可以。\n\n存储方式：\n\n * 基本数据类型的【局部变量】存放在 Java 虚拟机栈中的局部变量表中，基本数据类型的【成员变量】（未被 static 修饰 ）存放在 Java 虚拟机的堆中。\n * 包装类型属于对象类型，几乎所有对象实例都存在于堆中。\n\n占用空间：\n\n相比于包装类型（对象类型），基本数据类型占用的空间往往非常小。\n\n默认值：\n\n * 成员变量包装类型的默认值是 null，\n\n * 基本类型有默认值，但不固定。\n   \n   >  * byte：0\n   >  * short：0\n   >  * int：0\n   >  * long：0L\n   >  * float：0.0f\n   >  * double：0.0d\n   >  * char：\'\\u0000\'\n   >  * boolean：false\n\n比较方式：\n\n * 对于基本数据类型来说，== 比较的是值。\n * 对于包装数据类型来说，== 比较的是对象的内存地址。所有整型包装类对象之间值的比较，全部使用 equals() 方法。\n\n\n# 包装类型的缓存机制了解吗？\n\n另一种说法是：包装类型的常量池技术。\n\nJava 基本数据类型的包装类型大部分都用到了缓存机制来提升性能（除了浮点型）。即会默认创建相应类型的缓存数据。\n\n例如：Byte,Short,Interger,Long 这 4 种包装类默认创建了数值 [-128,127] 的相应类型的缓存数据，Character 创建了数值在 [0,127] 范围的缓存数据，Boolean 直接返回 True or False。\n\n当使用自动装箱的方式将一个基本数据类型的值转换为包装类型时，如果这个值在缓存范围内，那么就直接返回缓存中的对象，否则就创建一个新的对象。\n\n> 由于包装类型的值是存储在堆内存中的，因此在进行大量的数值计算时，使用包装类型会比直接使用基本数据类型更加耗时和占用内存。为了提高程序的性能和效率，Java 提供了包装类型的缓存机制。\n\n\n# 为什么要有包装类型？\n\n在 Java 中，包装类型是将基本数据类型（如 int、double 等）封装成对象的一种机制。\n\nJava 中引入包装类型的主要原因是为了提供一些额外的功能和灵活性，这些功能在基本数据类型上不可用。\n\n以下是一些包装类型的常见用途：\n\n 1. 包装类型可以使基本数据类型具有对象特性。例如，可以将包装类型存储在集合中（如 List、Map 等），而基本数据类型不能。\n 2. 包装类型具有面向对象的行为。例如，可以使用 toString() 方法将包装类型转换为字符串，而基本数据类型不能。\n 3. 包装类型可以为 null。例如，如果尝试将基本数据类型赋值为 null，则会引发空指针异常。但是，将包装类型赋值为 null 是可以的。（一般声明变量时用引用类型，而参数类型用基本数据类型）\n 4. 包装类型支持自动装箱和拆箱。自动装箱是指将基本数据类型自动转换为相应的包装类型，而自动拆箱是指将包装类型自动转换为相应的基本数据类型。这使得代码更加简洁和易于编写。\n\n总之，包装类型可以使 Java 代码更加灵活和易于维护。它们可以使基本数据类型具有对象特性，并提供了许多基本数据类型上不可用的功能。此外，Java 中的包装类型还可以用于处理空值和进行类型转换，这些在基本数据类型上是不可能实现的。\n\n\n# 自动装箱与拆箱了解吗？原理是什么？\n\n装箱就是将基本类型用它们对应的引用类型包装起来，原理是调用了包装类的 valueOf() 方法；\n\n拆箱是将包装类型转换为基本数据类型，相应的调用的是 xxxValue() 方法，比如 intValue() 方法。\n\n> eg：\n> \n>  * Integer i = 10 等价于 Integer i = Integer.valueOf(10) -- 装箱\n>  * int n = i 等价于 int n = i.intValue() -- 拆箱\n\n原理：\n\n基本类型与相应的包装类型用 == 号比较会怎么样？\n\nInteger a = new Integer(10);\nInteger b = new Integer(10);\n\nSystem.out.println(a == b); // 输出 false，因为比较的是引用\n\nint c = 10;\nSystem.out.println(a == c); // 输出 true，因为自动拆箱后比较的是值\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 为什么浮点数运算的时候会有精度丢失的风险？\n\n浮点数运算精度丢失代码演示：\n\nfloat a = 2.0f - 1.9f;\nfloat b = 1.8f - 1.7f;\nSystem.out.println(a); // 0.100000024\nSystem.out.println(b); // 0.099999905\nSystem.out.println(a == b); // false\n\n\n1\n2\n3\n4\n5\n\n\n这是因为计算机在表示一个数字时，宽度是有限的，无限循环的小数存储在计算机时，只能被截断，所以就会导致小数精度发生损失的情况。\n\n\n# 如何解决浮点数运算的精度丢失问题？\n\n使用 BigDecimal 可以实现对浮点数的运算，并且不会造成精度丢失。\n\n通常情况下，大部分需要浮点数精确运算结果的业务场景（比如涉及到钱的场景）都是通过 BigDecimal 来做的。\n\nBigDecimal a = new BigDecimal("1.0");\nBigDecimal b = new BigDecimal("0.9");\nBigDecimal c = new BigDecimal("0.8");\n\nBigDecimal x = a.subtract(b); // sub 减法\nBigDecimal y = b.subtract(c);\n\nSystem.out.println(x); /* 0.1 */\nSystem.out.println(y); /* 0.1 */\nSystem.out.println(Objects.equals(x, y)); /* true */\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 超过 long 整型的数据应该如何表示？\n\n> 基本数值类型都有一个表达范围，如果超过这个范围就会有数值溢出的风险。\n> \n> 在 Java 中，64 位（8字节） long 整型是最大的整数类型。\n\n如果需要表示超过 long 整型的数据，可以使用 Java 提供的 BigInteger 类。\n\nimport java.math.BigInteger;\npublic class BigIntegerDemo {\n    public static void main(String[] args) {\n        BigInteger a = new BigInteger("12345678901234567890");\n        BigInteger b = new BigInteger("98765432109876543210");\n        BigInteger c = a.add(b);\n        System.out.println(c);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n * BigInteger 类的加、减、乘、除等运算都是通过调用方法来实现的，而不是像基本数据类型那样使用运算符。\n * BigInteger 内部使用 int[] 数组来存储任意大小的整形数据。\n * 需要注意的是，BigInteger 类的运算时间和空间成本比基本数据类型高得多，即运算的效率相对较低。\n\n\n# 什么是引用类型？\n\n在 Java 中，除了基本数据类型和 void 类型以外，其它所有类型都是引用类型。\n\n * void 类型是一种特殊的类型，它表示没有返回值的方法或表达式的类型。\n * 在 Java 中，void 类型不属于基本数据类型，也不属于引用类型，而是一种独立的类型。\n\n常见的引用类型包括：\n\n 1. 类类型（Class）：代表类的类型。\n 2. 接口类型（Interface）：代表接口的类型。\n 3. 数组类型（Array）：代表数组的类型。\n 4. 枚举类型（Enum）：代表枚举的类型。\n 5. 泛型类型（Generics）：代表泛型类或泛型方法的类型。\n 6. 注解类型（Annotation）：代表注解的类型。\n 7. 自定义类型（Custom）：在程序中自定义的类型，如自定义的类、接口、枚举等。\n\nMyClass obj = new MyClass();  // 使用 new 关键字创建 MyClass 类的对象，并将对象赋值给 obj 变量\n\n\n1\n\n\n此时，obj 变量存储的是对象的内存地址，即对象的引用。因此，通过 obj 变量可以访问对象的属性和方法。\n\n\n# NPE 问题？\n\nNPE 问题就是：空指针异常（NullPointerException，NPE）问题。\n\n在 Java 中，自动拆箱是将包装类型自动转换为相应的基本数据类型的过程，而如果包装类型为null，自动拆箱就会引发空指针异常（NullPointerException，NPE）。\n\n这是因为基本数据类型不支持为 null 值，因此在尝试使用为 null 的包装类型时，Java 会尝试将其转换为基本数据类型，从而引发 NPE 异常。\n\n以下是一个简单的示例，展示了自动拆箱引发 NP E问题的情况：\n\nInteger num = null;\nint i = num; // 自动拆箱，将null转换为int类型，引发NPE异常\n\n\n1\n2\n\n\n为了避免自动拆箱引发的 NPE 问题，可以使用条件语句或显式拆箱来检查包装类型是否为 null。例如，可以使用以下代码检查包装类型是否为 null：\n\nInteger num = null;\n// 条件语句\nint i = (num != null) ? num : 0;\n\n\n1\n2\n3\n\n\n使用显式拆箱的代码如下：\n\nInteger num = null;\n// 显示拆箱\nint i = num != null ? num.intValue() : 0;\n\n\n1\n2\n3\n\n\n可以看出来，两者代码差不多，在这里其实 num 等价于 num.intValue()。\n\n最后这个代码没加括号是因为：在 Java 中，三目运算符（?:）的优先级比赋值运算符（=）高，而比相等运算符（==）和不等运算符（!=）低。因此，num != null 会先执行，代码可以不加括号而直接编写。',normalizedContent:'# java 基本数据类型\n\n\n# java 中的几种基本数据类型是什么？对应的包装类型是什么？各自占用多少字节？\n\n8 种基本数据类型：byte 1，short 2，int 4，long 8，float 4，dobule 8，char 2，boolean 1\n\n对应的包装类型：byte，short，interger，long，float，double，character，boolean\n\n对应占用的字节：1，2，4，8，4，8，2，1\n\n> 注意：short 是 2 字节\n\n\n# 讲讲 int 的取值范围是多少？\n\n想想字节和取值范围的关系。\n\n * int 有 4 个字节，也就是占 32 个比特位，\n * 所以取值范围就是【-2 的 31 次方到 2 的 31 次方减 1】，即约为 -2,147,483,648 到 2,147,483,647。\n\n> 需要注意的是，这个范围是针对有符号的整数类型。\n> \n> 如果使用【无符号】的整数类型（如 java 中的 unsigned int），则范围将从 0 到 2^32 - 1，即约为 0 到 4,294,967,295。\n\n\n# 基本类型和包装类型的区别？\n\n五大区别：\n\n用途：\n\n * 基本类型一般用来定义一些常量和局部变量，我们在其他地方比如方法参数、对象属性中很少会使用基本类型来定义变量。\n * 包装类型可用于泛型，而基本类型不可以。\n\n存储方式：\n\n * 基本数据类型的【局部变量】存放在 java 虚拟机栈中的局部变量表中，基本数据类型的【成员变量】（未被 static 修饰 ）存放在 java 虚拟机的堆中。\n * 包装类型属于对象类型，几乎所有对象实例都存在于堆中。\n\n占用空间：\n\n相比于包装类型（对象类型），基本数据类型占用的空间往往非常小。\n\n默认值：\n\n * 成员变量包装类型的默认值是 null，\n\n * 基本类型有默认值，但不固定。\n   \n   >  * byte：0\n   >  * short：0\n   >  * int：0\n   >  * long：0l\n   >  * float：0.0f\n   >  * double：0.0d\n   >  * char：\'\\u0000\'\n   >  * boolean：false\n\n比较方式：\n\n * 对于基本数据类型来说，== 比较的是值。\n * 对于包装数据类型来说，== 比较的是对象的内存地址。所有整型包装类对象之间值的比较，全部使用 equals() 方法。\n\n\n# 包装类型的缓存机制了解吗？\n\n另一种说法是：包装类型的常量池技术。\n\njava 基本数据类型的包装类型大部分都用到了缓存机制来提升性能（除了浮点型）。即会默认创建相应类型的缓存数据。\n\n例如：byte,short,interger,long 这 4 种包装类默认创建了数值 [-128,127] 的相应类型的缓存数据，character 创建了数值在 [0,127] 范围的缓存数据，boolean 直接返回 true or false。\n\n当使用自动装箱的方式将一个基本数据类型的值转换为包装类型时，如果这个值在缓存范围内，那么就直接返回缓存中的对象，否则就创建一个新的对象。\n\n> 由于包装类型的值是存储在堆内存中的，因此在进行大量的数值计算时，使用包装类型会比直接使用基本数据类型更加耗时和占用内存。为了提高程序的性能和效率，java 提供了包装类型的缓存机制。\n\n\n# 为什么要有包装类型？\n\n在 java 中，包装类型是将基本数据类型（如 int、double 等）封装成对象的一种机制。\n\njava 中引入包装类型的主要原因是为了提供一些额外的功能和灵活性，这些功能在基本数据类型上不可用。\n\n以下是一些包装类型的常见用途：\n\n 1. 包装类型可以使基本数据类型具有对象特性。例如，可以将包装类型存储在集合中（如 list、map 等），而基本数据类型不能。\n 2. 包装类型具有面向对象的行为。例如，可以使用 tostring() 方法将包装类型转换为字符串，而基本数据类型不能。\n 3. 包装类型可以为 null。例如，如果尝试将基本数据类型赋值为 null，则会引发空指针异常。但是，将包装类型赋值为 null 是可以的。（一般声明变量时用引用类型，而参数类型用基本数据类型）\n 4. 包装类型支持自动装箱和拆箱。自动装箱是指将基本数据类型自动转换为相应的包装类型，而自动拆箱是指将包装类型自动转换为相应的基本数据类型。这使得代码更加简洁和易于编写。\n\n总之，包装类型可以使 java 代码更加灵活和易于维护。它们可以使基本数据类型具有对象特性，并提供了许多基本数据类型上不可用的功能。此外，java 中的包装类型还可以用于处理空值和进行类型转换，这些在基本数据类型上是不可能实现的。\n\n\n# 自动装箱与拆箱了解吗？原理是什么？\n\n装箱就是将基本类型用它们对应的引用类型包装起来，原理是调用了包装类的 valueof() 方法；\n\n拆箱是将包装类型转换为基本数据类型，相应的调用的是 xxxvalue() 方法，比如 intvalue() 方法。\n\n> eg：\n> \n>  * integer i = 10 等价于 integer i = integer.valueof(10) -- 装箱\n>  * int n = i 等价于 int n = i.intvalue() -- 拆箱\n\n原理：\n\n基本类型与相应的包装类型用 == 号比较会怎么样？\n\ninteger a = new integer(10);\ninteger b = new integer(10);\n\nsystem.out.println(a == b); // 输出 false，因为比较的是引用\n\nint c = 10;\nsystem.out.println(a == c); // 输出 true，因为自动拆箱后比较的是值\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 为什么浮点数运算的时候会有精度丢失的风险？\n\n浮点数运算精度丢失代码演示：\n\nfloat a = 2.0f - 1.9f;\nfloat b = 1.8f - 1.7f;\nsystem.out.println(a); // 0.100000024\nsystem.out.println(b); // 0.099999905\nsystem.out.println(a == b); // false\n\n\n1\n2\n3\n4\n5\n\n\n这是因为计算机在表示一个数字时，宽度是有限的，无限循环的小数存储在计算机时，只能被截断，所以就会导致小数精度发生损失的情况。\n\n\n# 如何解决浮点数运算的精度丢失问题？\n\n使用 bigdecimal 可以实现对浮点数的运算，并且不会造成精度丢失。\n\n通常情况下，大部分需要浮点数精确运算结果的业务场景（比如涉及到钱的场景）都是通过 bigdecimal 来做的。\n\nbigdecimal a = new bigdecimal("1.0");\nbigdecimal b = new bigdecimal("0.9");\nbigdecimal c = new bigdecimal("0.8");\n\nbigdecimal x = a.subtract(b); // sub 减法\nbigdecimal y = b.subtract(c);\n\nsystem.out.println(x); /* 0.1 */\nsystem.out.println(y); /* 0.1 */\nsystem.out.println(objects.equals(x, y)); /* true */\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 超过 long 整型的数据应该如何表示？\n\n> 基本数值类型都有一个表达范围，如果超过这个范围就会有数值溢出的风险。\n> \n> 在 java 中，64 位（8字节） long 整型是最大的整数类型。\n\n如果需要表示超过 long 整型的数据，可以使用 java 提供的 biginteger 类。\n\nimport java.math.biginteger;\npublic class bigintegerdemo {\n    public static void main(string[] args) {\n        biginteger a = new biginteger("12345678901234567890");\n        biginteger b = new biginteger("98765432109876543210");\n        biginteger c = a.add(b);\n        system.out.println(c);\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n * biginteger 类的加、减、乘、除等运算都是通过调用方法来实现的，而不是像基本数据类型那样使用运算符。\n * biginteger 内部使用 int[] 数组来存储任意大小的整形数据。\n * 需要注意的是，biginteger 类的运算时间和空间成本比基本数据类型高得多，即运算的效率相对较低。\n\n\n# 什么是引用类型？\n\n在 java 中，除了基本数据类型和 void 类型以外，其它所有类型都是引用类型。\n\n * void 类型是一种特殊的类型，它表示没有返回值的方法或表达式的类型。\n * 在 java 中，void 类型不属于基本数据类型，也不属于引用类型，而是一种独立的类型。\n\n常见的引用类型包括：\n\n 1. 类类型（class）：代表类的类型。\n 2. 接口类型（interface）：代表接口的类型。\n 3. 数组类型（array）：代表数组的类型。\n 4. 枚举类型（enum）：代表枚举的类型。\n 5. 泛型类型（generics）：代表泛型类或泛型方法的类型。\n 6. 注解类型（annotation）：代表注解的类型。\n 7. 自定义类型（custom）：在程序中自定义的类型，如自定义的类、接口、枚举等。\n\nmyclass obj = new myclass();  // 使用 new 关键字创建 myclass 类的对象，并将对象赋值给 obj 变量\n\n\n1\n\n\n此时，obj 变量存储的是对象的内存地址，即对象的引用。因此，通过 obj 变量可以访问对象的属性和方法。\n\n\n# npe 问题？\n\nnpe 问题就是：空指针异常（nullpointerexception，npe）问题。\n\n在 java 中，自动拆箱是将包装类型自动转换为相应的基本数据类型的过程，而如果包装类型为null，自动拆箱就会引发空指针异常（nullpointerexception，npe）。\n\n这是因为基本数据类型不支持为 null 值，因此在尝试使用为 null 的包装类型时，java 会尝试将其转换为基本数据类型，从而引发 npe 异常。\n\n以下是一个简单的示例，展示了自动拆箱引发 np e问题的情况：\n\ninteger num = null;\nint i = num; // 自动拆箱，将null转换为int类型，引发npe异常\n\n\n1\n2\n\n\n为了避免自动拆箱引发的 npe 问题，可以使用条件语句或显式拆箱来检查包装类型是否为 null。例如，可以使用以下代码检查包装类型是否为 null：\n\ninteger num = null;\n// 条件语句\nint i = (num != null) ? num : 0;\n\n\n1\n2\n3\n\n\n使用显式拆箱的代码如下：\n\ninteger num = null;\n// 显示拆箱\nint i = num != null ? num.intvalue() : 0;\n\n\n1\n2\n3\n\n\n可以看出来，两者代码差不多，在这里其实 num 等价于 num.intvalue()。\n\n最后这个代码没加括号是因为：在 java 中，三目运算符（?:）的优先级比赋值运算符（=）高，而比相等运算符（==）和不等运算符（!=）低。因此，num != null 会先执行，代码可以不加括号而直接编写。',charsets:{cjk:!0}},{title:"Java集合概述",frontmatter:{title:"Java集合概述",date:"2023-05-11T12:12:40.000Z",permalink:"/pages/2e780e/",author:{name:"陌上清风",link:"https://github.com/msqfx"},categories:["java","集合篇"],tags:[null],description:"总结",comment:!0,meta:[{name:"image",content:"https://cmty256.github.io/imgs-blog/images/image-20230411210606868.50typmz8n440.jpg"},{name:"twitter:title",content:"Java集合概述"},{name:"twitter:description",content:"总结"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://cmty256.github.io/imgs-blog/images/image-20230411210606868.50typmz8n440.jpg"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/01.Java%E9%9B%86%E5%90%88%E6%A6%82%E8%BF%B0.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Java集合概述"},{property:"og:description",content:"总结"},{property:"og:image",content:"https://cmty256.github.io/imgs-blog/images/image-20230411210606868.50typmz8n440.jpg"},{property:"og:url",content:"https://www.msqfx.cc/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/01.Java%E9%9B%86%E5%90%88%E6%A6%82%E8%BF%B0.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-05-11T12:12:40.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"Java集合概述"},{itemprop:"description",content:"总结"},{itemprop:"image",content:"https://cmty256.github.io/imgs-blog/images/image-20230411210606868.50typmz8n440.jpg"}],readingShow:"top"},regularPath:"/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/01.Java%E9%9B%86%E5%90%88%E6%A6%82%E8%BF%B0.html",relativePath:"01.java/02.集合篇/01.Java集合概述.md",key:"v-d5c1a816",path:"/pages/2e780e/",headers:[{level:2,title:"集合与容器",slug:"集合与容器",normalizedTitle:"集合与容器",charIndex:16},{level:2,title:"Java 集合框架如下图所示",slug:"java-集合框架如下图所示",normalizedTitle:"java 集合框架如下图所示",charIndex:273},{level:2,title:"说说 List, Set, Queue, Map 四者的区别？",slug:"说说-list-set-queue-map-四者的区别",normalizedTitle:"说说 list, set, queue, map 四者的区别？",charIndex:294},{level:2,title:"无序性和不可重复性的含义是什么",slug:"无序性和不可重复性的含义是什么",normalizedTitle:"无序性和不可重复性的含义是什么",charIndex:602},{level:2,title:"集合框架底层数据结构常见实现类",slug:"集合框架底层数据结构常见实现类",normalizedTitle:"集合框架底层数据结构常见实现类",charIndex:759},{level:3,title:"1. List",slug:"_1-list",normalizedTitle:"1. list",charIndex:779},{level:3,title:"2. Set",slug:"_2-set",normalizedTitle:"2. set",charIndex:889},{level:3,title:"3. Queue",slug:"_3-queue",normalizedTitle:"3. queue",charIndex:1311},{level:3,title:"4. Map",slug:"_4-map",normalizedTitle:"4. map",charIndex:1413},{level:2,title:"哈希冲突",slug:"哈希冲突",normalizedTitle:"哈希冲突",charIndex:1487},{level:2,title:"为什么链表可以解决哈希冲突（拉链法：数组+链表）",slug:"为什么链表可以解决哈希冲突-拉链法-数组-链表",normalizedTitle:"为什么链表可以解决哈希冲突（拉链法：数组+链表）",charIndex:2167},{level:2,title:"哈希表是什么",slug:"哈希表是什么",normalizedTitle:"哈希表是什么",charIndex:2292},{level:2,title:"线程不安全的接口",slug:"线程不安全的接口",normalizedTitle:"线程不安全的接口",charIndex:2698},{level:2,title:"线程安全的接口",slug:"线程安全的接口",normalizedTitle:"线程安全的接口",charIndex:2830},{level:2,title:"为什么要使用集合",slug:"为什么要使用集合",normalizedTitle:"为什么要使用集合",charIndex:2878},{level:2,title:"学习参考",slug:"学习参考",normalizedTitle:"学习参考",charIndex:3025}],headersStr:"集合与容器 Java 集合框架如下图所示 说说 List, Set, Queue, Map 四者的区别？ 无序性和不可重复性的含义是什么 集合框架底层数据结构常见实现类 1. List 2. Set 3. Queue 4. Map 哈希冲突 为什么链表可以解决哈希冲突（拉链法：数组+链表） 哈希表是什么 线程不安全的接口 线程安全的接口 为什么要使用集合 学习参考",content:'# Java 集合概述\n\n\n# 集合与容器\n\n 1. 容器（Container）是一个更广泛的术语，用于表示可以容纳、组织和管理其他对象的对象。它是一个更高层次的概念，包括集合（Collection）在内。\n 2. 集合（Collection）是一种特定类型的容器，用于存储和操作一组对象。集合提供了对元素的添加、删除、查找和遍历等操作。List、Set、Queue 和 Map 都是集合的具体实现。\n\n总结\n\n * 容器是一个广泛的概念，用于表示可以容纳和管理其他对象的对象。\n * 集合是容器的一种特定类型，用于存储和操作一组对象。\n\n\n# Java 集合框架如下图所示\n\n\n\n\n# 说说 List, Set, Queue, Map 四者的区别？\n\n * List(对付顺序的好帮手): 存储的元素是有序的、可重复的。（可以通过索引访问和修改元素）\n * Set(注重独一无二的性质): 存储的元素是无序的、不可重复的。（无索引）\n * Queue(实现排队功能的叫号机): 按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。\n * Map(用 key 来搜索的专家): 使用键值对（key-value）存储，类似于数学上的函数 y=f(x)，"x" 代表 key，"y" 代表 value，key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。\n\n\n# 无序性和不可重复性的含义是什么\n\n * 无序性不等于随机性 ，无序性是指存储的数据在底层数组中并非按照数组索引的顺序添加 ，而是根据数据的哈希值决定的。\n * 不可重复性是指添加的元素按照 equals() 判断时 ，返回 false，需要同时重写 equals() 方法和 hashCode() 方法。\n\n\n# 集合框架底层数据结构常见实现类\n\n\n# 1. List\n\n * ArrayList： Object[] 数组\n * Vector：Object[] 数组\n * LinkedList： 双向链表(JDK1.6 之前为循环链表，JDK1.7 取消了循环)\n\n\n# 2. Set\n\n * HashSet(无序，唯一): 基于 HashMap 实现的，底层采用 HashMap 来保存元素\n\n * LinkedHashSet(有序，唯一): LinkedHashSet 是 HashSet 的子类，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的 LinkedHashMap 其内部是基于 HashMap 实现一样，不过还是有一点点区别的\n\n * TreeSet(有序，唯一): 红黑树(自平衡的排序二叉树)\n   \n   > 红黑树（Red-Black Tree）是一种自平衡的二叉查找树。它的特点是：每个节点要么是红色，要么是黑色；树的根节点是黑色的；所有叶子节点都是黑色的空节点（NIL节点）；如果一个节点是红色的，则其子节点必须是黑色的；从根节点到叶子节点的所有路径上，不能有两个连续的红色节点；从任意一个节点到其子树中每个叶子节点的路径都包含相同数目的黑色节点。\n\n\n# 3. Queue\n\n * PriorityQueue: Object[] 数组来实现二叉堆\n * ArrayQueue: Object[] 数组 + 双指针\n\n再来看看 Map 接口下面的集合。\n\n\n# 4. Map\n\n * HashMap： JDK1.8 之前 HashMap 由数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。JDK1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间\n\n * LinkedHashMap（有序的）： LinkedHashMap 继承自 HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，LinkedHashMap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。\n\n * Hashtable： 数组+链表组成的，数组是 Hashtable 的主体，链表则是主要为了解决哈希冲突而存在的\n   \n   > HashTable 是线程安全的，而 HashMap 不是。在多线程环境下，使用 HashTable 可以避免数据竞争和并发访问的问题，但是对于单线程环境，使用 HashMap 可以提高性能\n\n * TreeMap： 红黑树（自平衡的排序二叉树）\n\n\n# 哈希冲突\n\n哈希冲突是指在哈希表中，不同的关键字（Key）通过哈希函数被映射到了同一个槽位（Bucket）中，导致同一个槽位中存储了多个关键字的情况。\n\n当 HashMap 发生哈希冲突时，链表存储的是键值对（key-value pairs）。具体来说，链表中的每个元素包含一个键（key）和一个值（value）。所以，链表不仅存储元素本身，还包含键。\n\n\n# 为什么链表可以解决哈希冲突（拉链法：数组+链表）\n\n当一个桶中存储多个键值对时，可以将它们存储在一个链表中，每个节点存储一个键值对。当需要查找或删除某个键值对时，可以按照哈希函数的规则找到对应的桶，然后遍历链表中的节点，查找或删除目标键值对\n\n\n# 哈希表是什么\n\n哈希表（Hash Table），也称为散列表，是一种数据结构，用于实现关联数组（Associative Array）或映射（Map）等抽象数据类型。它通过将关键字映射到表中一个位置来访问记录，以加快查找的速度。哈希表实际上是一个数组，其中每个元素都是一个链表的头节点，每个链表中包含了哈希值相同的所有元素。 哈希表的基本思想是：将关键字通过哈希函数计算出一个哈希值，然后将该值作为数组的下标，将元素存储在对应的数组位置中。在查找元素时，通过哈希函数计算出关键字的哈希值，然后在对应的数组位置中查找元素。 哈希表的优点是查找速度快，时间复杂度为 O(1)，而不像线性表的查找时间复杂度为 O(n)。但是，哈希表的缺点是空间利用率相对较低，因为需要预留足够的空间来存储哈希冲突的元素。此外，哈希表的性能还受到哈希函数的影响，如果哈希函数设计不好，可能会导致哈希冲突率过高，降低哈希表的性能。\n\n\n# 线程不安全的接口\n\nArrayList，LinkedList， HashSet，LinkedHashSet，TreeSet，PriorityQueue ，ArrayQueue，HashMap，LinkedHashMap ，TreeMap 都是线程不安全的\n\n\n# 线程安全的接口\n\nVector，Hashtable，ConcurrentHashMap\n\n\n# 为什么要使用集合\n\n是因为数组一旦声明之后，长度就不可变了；同时，声明数组时的数据类型也决定了该数组存储的数据的类型；而且，数组存储的数据是有序的、可重复的，特点单一。 而集合提高了数据存储的灵活性，Java 集合不仅可以用来存储不同类型不同数量的对象，还可以保存具有映射关系的数据。\n\n\n# 学习参考\n\n * Java基础常见面试题总结(上) | JavaGuide(Java面试 + 学习指南)\n * Java面试题之Java集合框架篇（Java容器篇），30道Java集合框架八股文（7千字38张手绘图），面渣逆袭必看👍 | 二哥的Java进阶之路 (javabetter.cn)',normalizedContent:'# java 集合概述\n\n\n# 集合与容器\n\n 1. 容器（container）是一个更广泛的术语，用于表示可以容纳、组织和管理其他对象的对象。它是一个更高层次的概念，包括集合（collection）在内。\n 2. 集合（collection）是一种特定类型的容器，用于存储和操作一组对象。集合提供了对元素的添加、删除、查找和遍历等操作。list、set、queue 和 map 都是集合的具体实现。\n\n总结\n\n * 容器是一个广泛的概念，用于表示可以容纳和管理其他对象的对象。\n * 集合是容器的一种特定类型，用于存储和操作一组对象。\n\n\n# java 集合框架如下图所示\n\n\n\n\n# 说说 list, set, queue, map 四者的区别？\n\n * list(对付顺序的好帮手): 存储的元素是有序的、可重复的。（可以通过索引访问和修改元素）\n * set(注重独一无二的性质): 存储的元素是无序的、不可重复的。（无索引）\n * queue(实现排队功能的叫号机): 按特定的排队规则来确定先后顺序，存储的元素是有序的、可重复的。\n * map(用 key 来搜索的专家): 使用键值对（key-value）存储，类似于数学上的函数 y=f(x)，"x" 代表 key，"y" 代表 value，key 是无序的、不可重复的，value 是无序的、可重复的，每个键最多映射到一个值。\n\n\n# 无序性和不可重复性的含义是什么\n\n * 无序性不等于随机性 ，无序性是指存储的数据在底层数组中并非按照数组索引的顺序添加 ，而是根据数据的哈希值决定的。\n * 不可重复性是指添加的元素按照 equals() 判断时 ，返回 false，需要同时重写 equals() 方法和 hashcode() 方法。\n\n\n# 集合框架底层数据结构常见实现类\n\n\n# 1. list\n\n * arraylist： object[] 数组\n * vector：object[] 数组\n * linkedlist： 双向链表(jdk1.6 之前为循环链表，jdk1.7 取消了循环)\n\n\n# 2. set\n\n * hashset(无序，唯一): 基于 hashmap 实现的，底层采用 hashmap 来保存元素\n\n * linkedhashset(有序，唯一): linkedhashset 是 hashset 的子类，并且其内部是通过 linkedhashmap 来实现的。有点类似于我们之前说的 linkedhashmap 其内部是基于 hashmap 实现一样，不过还是有一点点区别的\n\n * treeset(有序，唯一): 红黑树(自平衡的排序二叉树)\n   \n   > 红黑树（red-black tree）是一种自平衡的二叉查找树。它的特点是：每个节点要么是红色，要么是黑色；树的根节点是黑色的；所有叶子节点都是黑色的空节点（nil节点）；如果一个节点是红色的，则其子节点必须是黑色的；从根节点到叶子节点的所有路径上，不能有两个连续的红色节点；从任意一个节点到其子树中每个叶子节点的路径都包含相同数目的黑色节点。\n\n\n# 3. queue\n\n * priorityqueue: object[] 数组来实现二叉堆\n * arrayqueue: object[] 数组 + 双指针\n\n再来看看 map 接口下面的集合。\n\n\n# 4. map\n\n * hashmap： jdk1.8 之前 hashmap 由数组+链表组成的，数组是 hashmap 的主体，链表则是主要为了解决哈希冲突而存在的（“拉链法”解决冲突）。jdk1.8 以后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间\n\n * linkedhashmap（有序的）： linkedhashmap 继承自 hashmap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红黑树组成。另外，linkedhashmap 在上面结构的基础上，增加了一条双向链表，使得上面的结构可以保持键值对的插入顺序。同时通过对链表进行相应的操作，实现了访问顺序相关逻辑。\n\n * hashtable： 数组+链表组成的，数组是 hashtable 的主体，链表则是主要为了解决哈希冲突而存在的\n   \n   > hashtable 是线程安全的，而 hashmap 不是。在多线程环境下，使用 hashtable 可以避免数据竞争和并发访问的问题，但是对于单线程环境，使用 hashmap 可以提高性能\n\n * treemap： 红黑树（自平衡的排序二叉树）\n\n\n# 哈希冲突\n\n哈希冲突是指在哈希表中，不同的关键字（key）通过哈希函数被映射到了同一个槽位（bucket）中，导致同一个槽位中存储了多个关键字的情况。\n\n当 hashmap 发生哈希冲突时，链表存储的是键值对（key-value pairs）。具体来说，链表中的每个元素包含一个键（key）和一个值（value）。所以，链表不仅存储元素本身，还包含键。\n\n\n# 为什么链表可以解决哈希冲突（拉链法：数组+链表）\n\n当一个桶中存储多个键值对时，可以将它们存储在一个链表中，每个节点存储一个键值对。当需要查找或删除某个键值对时，可以按照哈希函数的规则找到对应的桶，然后遍历链表中的节点，查找或删除目标键值对\n\n\n# 哈希表是什么\n\n哈希表（hash table），也称为散列表，是一种数据结构，用于实现关联数组（associative array）或映射（map）等抽象数据类型。它通过将关键字映射到表中一个位置来访问记录，以加快查找的速度。哈希表实际上是一个数组，其中每个元素都是一个链表的头节点，每个链表中包含了哈希值相同的所有元素。 哈希表的基本思想是：将关键字通过哈希函数计算出一个哈希值，然后将该值作为数组的下标，将元素存储在对应的数组位置中。在查找元素时，通过哈希函数计算出关键字的哈希值，然后在对应的数组位置中查找元素。 哈希表的优点是查找速度快，时间复杂度为 o(1)，而不像线性表的查找时间复杂度为 o(n)。但是，哈希表的缺点是空间利用率相对较低，因为需要预留足够的空间来存储哈希冲突的元素。此外，哈希表的性能还受到哈希函数的影响，如果哈希函数设计不好，可能会导致哈希冲突率过高，降低哈希表的性能。\n\n\n# 线程不安全的接口\n\narraylist，linkedlist， hashset，linkedhashset，treeset，priorityqueue ，arrayqueue，hashmap，linkedhashmap ，treemap 都是线程不安全的\n\n\n# 线程安全的接口\n\nvector，hashtable，concurrenthashmap\n\n\n# 为什么要使用集合\n\n是因为数组一旦声明之后，长度就不可变了；同时，声明数组时的数据类型也决定了该数组存储的数据的类型；而且，数组存储的数据是有序的、可重复的，特点单一。 而集合提高了数据存储的灵活性，java 集合不仅可以用来存储不同类型不同数量的对象，还可以保存具有映射关系的数据。\n\n\n# 学习参考\n\n * java基础常见面试题总结(上) | javaguide(java面试 + 学习指南)\n * java面试题之java集合框架篇（java容器篇），30道java集合框架八股文（7千字38张手绘图），面渣逆袭必看👍 | 二哥的java进阶之路 (javabetter.cn)',charsets:{cjk:!0}},{title:"List接口",frontmatter:{title:"List接口",date:"2023-06-19T12:42:58.000Z",permalink:"/pages/dcfa33/",author:{name:"陌上清风",link:"https://github.com/msqfx"},categories:["java","集合篇"],tags:[null],description:"总结",comment:!0,meta:[{name:"twitter:title",content:"List接口"},{name:"twitter:description",content:"总结"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/02.List%E6%8E%A5%E5%8F%A3.html"},{property:"og:type",content:"article"},{property:"og:title",content:"List接口"},{property:"og:description",content:"总结"},{property:"og:url",content:"https://www.msqfx.cc/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/02.List%E6%8E%A5%E5%8F%A3.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-06-19T12:42:58.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"List接口"},{itemprop:"description",content:"总结"}],readingShow:"top"},regularPath:"/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/02.List%E6%8E%A5%E5%8F%A3.html",relativePath:"01.java/02.集合篇/02.List接口.md",key:"v-0b03f7cc",path:"/pages/dcfa33/",headers:[{level:2,title:"ArrayList 和 Vector 的区别",slug:"arraylist-和-vector-的区别",normalizedTitle:"arraylist 和 vector 的区别",charIndex:16},{level:2,title:"ArrayList 与 LinkedList 区别",slug:"arraylist-与-linkedlist-区别",normalizedTitle:"arraylist 与 linkedlist 区别",charIndex:666},{level:3,title:"具体实现参考",slug:"具体实现参考",normalizedTitle:"具体实现参考",charIndex:1492},{level:3,title:"什么是迭代器",slug:"什么是迭代器",normalizedTitle:"什么是迭代器",charIndex:1567}],headersStr:"ArrayList 和 Vector 的区别 ArrayList 与 LinkedList 区别 具体实现参考 什么是迭代器",content:'# List 集合详解\n\n\n# ArrayList 和 Vector 的区别\n\n 1. 线程安全性：\n    * Vector 是线程安全的，它的方法都是同步的，多个线程可以同时访问和修改 Vector 对象；\n    * 而 ArrayList 是非线程安全的，它的方法不是同步的，多个线程访问和修改同一个 ArrayList 对象可能会导致数据竞争和并发访问的问题。\n 2. 扩容方式：Vector 和 ArrayList 在扩容时采用不同的策略。Vector 在扩容时会增加一倍的容量，而 ArrayList 则会增加 50% 的容量。\n 3. 性能：\n    * 由于 Vector 是线程安全的，它在并发访问时需要进行同步操作，因此性能相对较低；\n    * 而 ArrayList 在单线程环境下的性能较好，但在多线程环境下需要使用同步机制来保证线程安全。\n 4. 初始容量：当创建 Vector 或 ArrayList 对象时，可以指定它们的初始容量。Vector 的默认初始容量为 10，而 ArrayList 的默认初始容量为 0。在实际使用中，可以根据数据量和性能需求等因素，选择合适的初始容量。\n\n总结\n\n * Vector 和 ArrayList 都是动态数组的实现，\n * 但 Vector 是线程安全的，扩容方式和性能相对较差，初始容量为 10；\n * 而 ArrayList 是非线程安全的，扩容方式和性能相对较好，初始容量为 0。\n * 在实际使用中，应根据具体需求选择合适的动态数组实现。\n\n\n# ArrayList 与 LinkedList 区别\n\n 1. 底层数据结构：\n    \n    * ArrayList 底层采用数组实现，\n    * 而 LinkedList 底层采用链表实现。\n\n 2. 随机访问(相当于查询）和插入/删除操作的性能：\n    \n    * 由于 ArrayList 的底层实现是数组，因此随机访问的性能较好，时间复杂度为 O(1)；而插入/删除操作需要移动其他元素，时间复杂度为 O(n)。\n    \n    * 相反，LinkedList 的底层实现是链表，因此插入/删除操作的性能较好，平均时间复杂度为 O(1)；而随机访问需要遍历链表，时间复杂度为 O(n)。\n      \n      > 链表进行【插入/删除操作】时，在最坏的情况下，目标位置在链表的中间，需要遍历链表来找到目标位置，导致时间复杂度为 O(n)。\n\n 3. 内存占用：\n    \n    * 由于 ArrayList 底层采用数组实现，因此需要预先分配一定大小的连续内存空间，因此可能会浪费一些内存空间；\n    * 而 LinkedList 的底层采用链表实现，因此每个节点可以分布在不同的内存空间，内存利用率相对较高。\n\n 4. 迭代器的性能：\n    \n    * 由于 ArrayList 的底层实现是数组，因此迭代器的性能相对较好；\n    * 而 LinkedList 的底层实现是链表，因此迭代器需要遍历链表，性能较差。\n\n总结\n\nArrayList 和 LinkedList 都是线性表数据结构实现，但底层数据结构、随机访问和插入/删除操作的性能、内存占用和迭代器的性能等方面有所不同。在实际使用中，应根据具体需求选择合适的线性表数据结构实现。\n\n> 我们在项目中一般是不会使用到 LinkedList 的，需要用到 LinkedList 的场景几乎都可以使用 ArrayList 来代替，并且，性能通常会更好！\n\n\n# 具体实现参考\n\n这两种数据结构的代码实现可阅读以下两篇文章：\n\n * 【恋上数据结构】动态数组学习笔记\n\n * 【恋上数据结构】链表学习笔记\n\n\n# 什么是迭代器\n\n迭代器是一种 Java 中的接口，用于遍历集合类（Collection）和映射类（Map）中的元素。\n\n使用迭代器可以依次访问集合中的每个元素，而不需要知道集合的内部实现方式。\n\n在迭代器设计模式中，迭代器提供了一个通用的访问方法，使得可以在不暴露集合内部实现的情况下对集合进行迭代遍历。\n\n迭代器通常包含以下方法：\n\n * hasNext()：判断集合中是否还有下一个元素，如果有返回 true，否则返回 false。\n * next()：获取集合中的下一个元素。\n * remove()：从集合中删除上一次返回的元素。\n\n需要注意的是，在多线程环境下，使用迭代器遍历集合时需要进行同步操作，以避免并发修改集合导致的数据竞争和不一致性问题。\n\nimport java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.Iterator;\nimport java.util.List;\npublic class ArrayListExample {\n    public static void main(String[] args) {\n        // 创建一个 ArrayList 对象\n        List<String> arrayList = new ArrayList<>();\n        // 向 ArrayList 中添加元素\n        arrayList.add("apple");\n        arrayList.add("banana");\n        arrayList.add("orange");\n        // 创建一个同步的 ArrayList 对象\n        List<String> synchronizedArrayList = Collections.synchronizedList(arrayList);\n        // 使用迭代器遍历 ArrayList\n        synchronized (synchronizedArrayList) {\n            Iterator<String> iterator = synchronizedArrayList.iterator();\n            while (iterator.hasNext()) {\n                String element = iterator.next();\n                System.out.println(element);\n            }\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n',normalizedContent:'# list 集合详解\n\n\n# arraylist 和 vector 的区别\n\n 1. 线程安全性：\n    * vector 是线程安全的，它的方法都是同步的，多个线程可以同时访问和修改 vector 对象；\n    * 而 arraylist 是非线程安全的，它的方法不是同步的，多个线程访问和修改同一个 arraylist 对象可能会导致数据竞争和并发访问的问题。\n 2. 扩容方式：vector 和 arraylist 在扩容时采用不同的策略。vector 在扩容时会增加一倍的容量，而 arraylist 则会增加 50% 的容量。\n 3. 性能：\n    * 由于 vector 是线程安全的，它在并发访问时需要进行同步操作，因此性能相对较低；\n    * 而 arraylist 在单线程环境下的性能较好，但在多线程环境下需要使用同步机制来保证线程安全。\n 4. 初始容量：当创建 vector 或 arraylist 对象时，可以指定它们的初始容量。vector 的默认初始容量为 10，而 arraylist 的默认初始容量为 0。在实际使用中，可以根据数据量和性能需求等因素，选择合适的初始容量。\n\n总结\n\n * vector 和 arraylist 都是动态数组的实现，\n * 但 vector 是线程安全的，扩容方式和性能相对较差，初始容量为 10；\n * 而 arraylist 是非线程安全的，扩容方式和性能相对较好，初始容量为 0。\n * 在实际使用中，应根据具体需求选择合适的动态数组实现。\n\n\n# arraylist 与 linkedlist 区别\n\n 1. 底层数据结构：\n    \n    * arraylist 底层采用数组实现，\n    * 而 linkedlist 底层采用链表实现。\n\n 2. 随机访问(相当于查询）和插入/删除操作的性能：\n    \n    * 由于 arraylist 的底层实现是数组，因此随机访问的性能较好，时间复杂度为 o(1)；而插入/删除操作需要移动其他元素，时间复杂度为 o(n)。\n    \n    * 相反，linkedlist 的底层实现是链表，因此插入/删除操作的性能较好，平均时间复杂度为 o(1)；而随机访问需要遍历链表，时间复杂度为 o(n)。\n      \n      > 链表进行【插入/删除操作】时，在最坏的情况下，目标位置在链表的中间，需要遍历链表来找到目标位置，导致时间复杂度为 o(n)。\n\n 3. 内存占用：\n    \n    * 由于 arraylist 底层采用数组实现，因此需要预先分配一定大小的连续内存空间，因此可能会浪费一些内存空间；\n    * 而 linkedlist 的底层采用链表实现，因此每个节点可以分布在不同的内存空间，内存利用率相对较高。\n\n 4. 迭代器的性能：\n    \n    * 由于 arraylist 的底层实现是数组，因此迭代器的性能相对较好；\n    * 而 linkedlist 的底层实现是链表，因此迭代器需要遍历链表，性能较差。\n\n总结\n\narraylist 和 linkedlist 都是线性表数据结构实现，但底层数据结构、随机访问和插入/删除操作的性能、内存占用和迭代器的性能等方面有所不同。在实际使用中，应根据具体需求选择合适的线性表数据结构实现。\n\n> 我们在项目中一般是不会使用到 linkedlist 的，需要用到 linkedlist 的场景几乎都可以使用 arraylist 来代替，并且，性能通常会更好！\n\n\n# 具体实现参考\n\n这两种数据结构的代码实现可阅读以下两篇文章：\n\n * 【恋上数据结构】动态数组学习笔记\n\n * 【恋上数据结构】链表学习笔记\n\n\n# 什么是迭代器\n\n迭代器是一种 java 中的接口，用于遍历集合类（collection）和映射类（map）中的元素。\n\n使用迭代器可以依次访问集合中的每个元素，而不需要知道集合的内部实现方式。\n\n在迭代器设计模式中，迭代器提供了一个通用的访问方法，使得可以在不暴露集合内部实现的情况下对集合进行迭代遍历。\n\n迭代器通常包含以下方法：\n\n * hasnext()：判断集合中是否还有下一个元素，如果有返回 true，否则返回 false。\n * next()：获取集合中的下一个元素。\n * remove()：从集合中删除上一次返回的元素。\n\n需要注意的是，在多线程环境下，使用迭代器遍历集合时需要进行同步操作，以避免并发修改集合导致的数据竞争和不一致性问题。\n\nimport java.util.arraylist;\nimport java.util.collections;\nimport java.util.iterator;\nimport java.util.list;\npublic class arraylistexample {\n    public static void main(string[] args) {\n        // 创建一个 arraylist 对象\n        list<string> arraylist = new arraylist<>();\n        // 向 arraylist 中添加元素\n        arraylist.add("apple");\n        arraylist.add("banana");\n        arraylist.add("orange");\n        // 创建一个同步的 arraylist 对象\n        list<string> synchronizedarraylist = collections.synchronizedlist(arraylist);\n        // 使用迭代器遍历 arraylist\n        synchronized (synchronizedarraylist) {\n            iterator<string> iterator = synchronizedarraylist.iterator();\n            while (iterator.hasnext()) {\n                string element = iterator.next();\n                system.out.println(element);\n            }\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n',charsets:{cjk:!0}},{title:"Set接口",frontmatter:{title:"Set接口",date:"2023-06-21T14:49:19.000Z",permalink:"/pages/4d8b8b/",author:{name:"陌上清风",link:"https://github.com/msqfx"},categories:["java","集合篇"],tags:[null],description:"综上所述，Comparable 和 Comparator 都是用于比较对象的接口，但是它们之间的区别主要在于实现方式、应用场景和使用方式等方面。需要根据实际情况选择合适的接口来进行对象的比较。",comment:!0,meta:[{name:"twitter:title",content:"Set接口"},{name:"twitter:description",content:"综上所述，Comparable 和 Comparator 都是用于比较对象的接口，但是它们之间的区别主要在于实现方式、应用场景和使用方式等方面。需要根据实际情况选择合适的接口来进行对象的比较。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/03.Set%E6%8E%A5%E5%8F%A3.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Set接口"},{property:"og:description",content:"综上所述，Comparable 和 Comparator 都是用于比较对象的接口，但是它们之间的区别主要在于实现方式、应用场景和使用方式等方面。需要根据实际情况选择合适的接口来进行对象的比较。"},{property:"og:url",content:"https://www.msqfx.cc/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/03.Set%E6%8E%A5%E5%8F%A3.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-06-21T14:49:19.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"Set接口"},{itemprop:"description",content:"综上所述，Comparable 和 Comparator 都是用于比较对象的接口，但是它们之间的区别主要在于实现方式、应用场景和使用方式等方面。需要根据实际情况选择合适的接口来进行对象的比较。"}],readingShow:"top"},regularPath:"/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/03.Set%E6%8E%A5%E5%8F%A3.html",relativePath:"01.java/02.集合篇/03.Set接口.md",key:"v-7b03b51c",path:"/pages/4d8b8b/",headers:[{level:2,title:"Comparable 和 Comparator 的区别",slug:"comparable-和-comparator-的区别",normalizedTitle:"comparable 和 comparator 的区别",charIndex:15},{level:3,title:"Comparator 定制排序（直接方法中重写）",slug:"comparator-定制排序-直接方法中重写",normalizedTitle:"comparator 定制排序（直接方法中重写）",charIndex:1026},{level:3,title:"重写 compareTo 方法实现按年龄来排序（在实体类中重写方法）",slug:"重写-compareto-方法实现按年龄来排序-在实体类中重写方法",normalizedTitle:"重写 compareto 方法实现按年龄来排序（在实体类中重写方法）",charIndex:2155},{level:2,title:"比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同",slug:"比较-hashset、linkedhashset-和-treeset-三者的异同",normalizedTitle:"比较 hashset、linkedhashset 和 treeset 三者的异同",charIndex:3803},{level:2,title:"源码解析",slug:"源码解析",normalizedTitle:"源码解析",charIndex:4215},{level:3,title:"HashSet 特点",slug:"hashset-特点",normalizedTitle:"hashset 特点",charIndex:9339},{level:3,title:"解析",slug:"解析",normalizedTitle:"解析",charIndex:4217},{level:3,title:"HashSet 的实现",slug:"hashset-的实现",normalizedTitle:"hashset 的实现",charIndex:9733},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:10024}],headersStr:"Comparable 和 Comparator 的区别 Comparator 定制排序（直接方法中重写） 重写 compareTo 方法实现按年龄来排序（在实体类中重写方法） 比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同 源码解析 HashSet 特点 解析 HashSet 的实现 参考",content:'# Set 集合详解\n\n\n# Comparable 和 Comparator 的区别\n\n 1. Comparable 接口只有一个方法 compareTo()，用于比较对象自身与另一个对象的大小关系。实现 Comparable 接口的类可以直接通过调用 Arrays.sort() 或 Collections.sort() 方法进行排序。 Comparator 接口有两个方法 compare() 和 equals()，其中 compare() 方法用于比较两个对象的大小关系，可以通过 Collections.sort() 方法的重载版本或者使用 TreeMap、PriorityQueue 等需要比较对象的集合类来进行排序。equals() 方法用于比较两个对象是否相等，但在比较大小时并不会使用到。\n 2. Comparable 接口是在类的定义时就实现的，实现 Comparable 接口意味着该类支持自然排序（natural ordering），即可以根据对象自身的属性进行排序。而 Comparator 接口是在排序时作为参数传递进去的，可以根据不同的比较规则进行排序，也就是说可以定义多个 Comparator 来比较同一个类的对象。\n 3. Comparable 接口的实现在集合类中被广泛使用，例如在 TreeSet、TreeMap 等集合类中需要比较元素的大小关系时，会首先尝试使用元素自身实现的 Comparable 接口进行比较。如果元素没有实现 Comparable 接口，则需要通过传递一个 Comparator 对象来进行比较。因此，实现 Comparable 接口可以使得类更加通用，因为它可以被广泛应用于不同的集合类中。\n 4. Comparable 接口是 Java 的内部接口，定义在 java.lang 包中，而 Comparator 接口是 Java 的标准类库中的接口，定义在 java.util 包中。 综上所述，Comparable 和 Comparator 都是用于比较对象的接口，但是它们之间的区别主要在于实现方式、应用场景和使用方式等方面。需要根据实际情况选择合适的接口来进行对象的比较。\n\n> 综上所述，Comparable 和 Comparator 都是用于比较对象的接口，但是它们之间的区别主要在于实现方式、应用场景和使用方式等方面。需要根据实际情况选择合适的接口来进行对象的比较。\n\n\n# Comparator 定制排序（直接方法中重写）\n\nArrayList<Integer> arrayList = new ArrayList<Integer>();\narrayList.add(-1);\narrayList.add(3);\narrayList.add(3);\narrayList.add(-5);\narrayList.add(7);\narrayList.add(4);\narrayList.add(-9);\narrayList.add(-7);\nSystem.out.println("原始数组:");\nSystem.out.println(arrayList);\n// void reverse(List list)：反转\nCollections.reverse(arrayList);\nSystem.out.println("Collections.reverse(arrayList):");\nSystem.out.println(arrayList);\n\n// void sort(List list),按自然排序的升序排序\nCollections.sort(arrayList);\nSystem.out.println("Collections.sort(arrayList):");\nSystem.out.println(arrayList);\n// 定制排序的用法\nCollections.sort(arrayList, new Comparator<Integer>() {\n\n    @Override\n    public int compare(Integer o1, Integer o2) {\n        return o2.compareTo(o1);\n    }\n});\nSystem.out.println("定制排序后：");\nSystem.out.println(arrayList);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\nOutput:\n\n原始数组:\n[-1, 3, 3, -5, 7, 4, -9, -7]\nCollections.reverse(arrayList):\n[-7, -9, 4, 7, -5, 3, 3, -1]\nCollections.sort(arrayList):\n[-9, -7, -5, -1, 3, 3, 4, 7]\n定制排序后：\n[7, 4, 3, 3, -1, -5, -7, -9]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 重写 compareTo 方法实现按年龄来排序（在实体类中重写方法）\n\n// person对象没有实现Comparable接口，所以必须实现，这样才不会出错，才可以使treemap中的数据按顺序排列\n// 前面一个例子的String类已经默认实现了Comparable接口，详细可以查看String类的API文档，另外其他\n// 像Integer类等都已经实现了Comparable接口，所以不需要另外实现了\npublic  class Person implements Comparable<Person> {\n    private String name;\n    private int age;\n\n    public Person(String name, int age) {\n        super();\n        this.name = name;\n        this.age = age;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public int getAge() {\n        return age;\n    }\n\n    public void setAge(int age) {\n        this.age = age;\n    }\n\n    /**\n     * T重写compareTo方法实现按年龄来排序\n     */\n    @Override\n    public int compareTo(Person o) {\n        if (this.age > o.getAge()) {\n            return 1;\n        }\n        if (this.age < o.getAge()) {\n            return -1;\n        }\n        return 0;\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n\n\n public static void main(String[] args) {\n        TreeMap<Person, String> pdata = new TreeMap<Person, String>();\n        pdata.put(new Person("张三", 30), "zhangsan");\n        pdata.put(new Person("李四", 20), "lisi");\n        pdata.put(new Person("王五", 10), "wangwu");\n        pdata.put(new Person("小红", 5), "xiaohong");\n        // 得到key的值的同时得到key所对应的值\n        Set<Person> keys = pdata.keySet();\n        for (Person key : keys) {\n            System.out.println(key.getAge() + "-" + key.getName());\n\n        }\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\nOutput：\n\n5-小红\n10-王五\n20-李四\n30-张三\n\n\n1\n2\n3\n4\n\n\n\n# 比较 HashSet、LinkedHashSet 和 TreeSet 三者的异同\n\n * HashSet、LinkedHashSet 和 TreeSet 都是 Set 接口的实现类，都能保证元素唯一，并且都不是线程安全的。\n * HashSet、LinkedHashSet 和 TreeSet 的主要区别在于底层数据结构不同。HashSet 的底层数据结构是哈希表（基于 HashMap 实现）。LinkedHashSet 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 FIFO。TreeSet 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。\n * 底层数据结构不同又导致这三者的应用场景不同。HashSet 用于不需要保证元素插入和取出顺序的场景，LinkedHashSet 用于保证元素的插入和取出顺序满足 FIFO 的场景，TreeSet 用于支持对元素自定义排序规则的场景。\n\n\n# 源码解析\n\npublic class HashSet<E>  \n   extends AbstractSet<E>  \n   implements Set<E>, Cloneable, java.io.Serializable  \n{  \n   static final long serialVersionUID = -5024744406713321676L;  \n \n   // 底层使用HashMap来保存HashSet中所有元素。  \n   private transient HashMap<E,Object> map;  \n     \n   // 定义一个虚拟的Object对象作为HashMap的value，将此对象定义为static final。  \n   private static final Object PRESENT = new Object();  \n \n   /** \n    * 默认的无参构造器，构造一个空的HashSet。 \n    *  \n    * 实际底层会初始化一个空的HashMap，并使用默认初始容量为16和加载因子0.75。 \n    */  \n   public HashSet() {  \n   map = new HashMap<E,Object>();  \n   }  \n \n   /** \n    * 构造一个包含指定collection中的元素的新set。 \n    * \n    * 实际底层使用默认的加载因子0.75和足以包含指定 \n    * collection中所有元素的初始容量来创建一个HashMap。 \n    * @param c 其中的元素将存放在此set中的collection。 \n    */  \n   public HashSet(Collection<? extends E> c) {  \n   map = new HashMap<E,Object>(Math.max((int) (c.size()/.75f) + 1, 16));  \n   addAll(c);  \n   }  \n \n   /** \n    * 以指定的initialCapacity和loadFactor构造一个空的HashSet。 \n    * \n    * 实际底层以相应的参数构造一个空的HashMap。 \n    * @param initialCapacity 初始容量。 \n    * @param loadFactor 加载因子。 \n    */  \n   public HashSet(int initialCapacity, float loadFactor) {  \n   map = new HashMap<E,Object>(initialCapacity, loadFactor);  \n   }  \n \n   /** \n    * 以指定的initialCapacity构造一个空的HashSet。 \n    * \n    * 实际底层以相应的参数及加载因子loadFactor为0.75构造一个空的HashMap。 \n    * @param initialCapacity 初始容量。 \n    */  \n   public HashSet(int initialCapacity) {  \n   map = new HashMap<E,Object>(initialCapacity);  \n   }  \n \n   /** \n    * 以指定的initialCapacity和loadFactor构造一个新的空链接哈希集合。 \n    * 此构造函数为包访问权限，不对外公开，实际只是是对LinkedHashSet的支持。 \n    * \n    * 实际底层会以指定的参数构造一个空LinkedHashMap实例来实现。 \n    * @param initialCapacity 初始容量。 \n    * @param loadFactor 加载因子。 \n    * @param dummy 标记。 \n    */  \n   HashSet(int initialCapacity, float loadFactor, boolean dummy) {  \n   map = new LinkedHashMap<E,Object>(initialCapacity, loadFactor);  \n   }  \n \n   /** \n    * 返回对此set中元素进行迭代的迭代器。返回元素的顺序并不是特定的。 \n    *  \n    * 底层实际调用底层HashMap的keySet来返回所有的key。 \n    * 可见HashSet中的元素，只是存放在了底层HashMap的key上， \n    * value使用一个static final的Object对象标识。 \n    * @return 对此set中元素进行迭代的Iterator。 \n    */  \n   public Iterator<E> iterator() {  \n   return map.keySet().iterator();  \n   }  \n \n   /** \n    * 返回此set中的元素的数量（set的容量）。 \n    * \n    * 底层实际调用HashMap的size()方法返回Entry的数量，就得到该Set中元素的个数。 \n    * @return 此set中的元素的数量（set的容量）。 \n    */  \n   public int size() {  \n   return map.size();  \n   }  \n \n   /** \n    * 如果此set不包含任何元素，则返回true。 \n    * \n    * 底层实际调用HashMap的isEmpty()判断该HashSet是否为空。 \n    * @return 如果此set不包含任何元素，则返回true。 \n    */  \n   public boolean isEmpty() {  \n   return map.isEmpty();  \n   }  \n \n   /** \n    * 如果此set包含指定元素，则返回true。 \n    * 更确切地讲，当且仅当此set包含一个满足(o==null ? e==null : o.equals(e)) \n    * 的e元素时，返回true。 \n    * \n    * 底层实际调用HashMap的containsKey判断是否包含指定key。 \n    * @param o 在此set中的存在已得到测试的元素。 \n    * @return 如果此set包含指定元素，则返回true。 \n    */  \n   public boolean contains(Object o) {  \n   return map.containsKey(o);  \n   }  \n \n   /** \n    * 如果此set中尚未包含指定元素，则添加指定元素。 \n    * 更确切地讲，如果此 set 没有包含满足(e==null ? e2==null : e.equals(e2)) \n    * 的元素e2，则向此set 添加指定的元素e。 \n    * 如果此set已包含该元素，则该调用不更改set并返回false。 \n    * \n    * 底层实际将将该元素作为key放入HashMap。 \n    * 由于HashMap的put()方法添加key-value对时，当新放入HashMap的Entry中key \n    * 与集合中原有Entry的key相同（hashCode()返回值相等，通过equals比较也返回true）， \n    * 新添加的Entry的value会将覆盖原来Entry的value，但key不会有任何改变， \n    * 因此如果向HashSet中添加一个已经存在的元素时，新添加的集合元素将不会被放入HashMap中， \n    * 原来的元素也不会有任何改变，这也就满足了Set中元素不重复的特性。 \n    * @param e 将添加到此set中的元素。 \n    * @return 如果此set尚未包含指定元素，则返回true。 \n    */  \n   public boolean add(E e) {  \n   return map.put(e, PRESENT)==null;  \n   }  \n \n   /** \n    * 如果指定元素存在于此set中，则将其移除。 \n    * 更确切地讲，如果此set包含一个满足(o==null ? e==null : o.equals(e))的元素e， \n    * 则将其移除。如果此set已包含该元素，则返回true \n    * （或者：如果此set因调用而发生更改，则返回true）。（一旦调用返回，则此set不再包含该元素）。 \n    * \n    * 底层实际调用HashMap的remove方法删除指定Entry。 \n    * @param o 如果存在于此set中则需要将其移除的对象。 \n    * @return 如果set包含指定元素，则返回true。 \n    */  \n   public boolean remove(Object o) {  \n   return map.remove(o)==PRESENT;  \n   }  \n \n   /** \n    * 从此set中移除所有元素。此调用返回后，该set将为空。 \n    * \n    * 底层实际调用HashMap的clear方法清空Entry中所有元素。 \n    */  \n   public void clear() {  \n   map.clear();  \n   }  \n \n   /** \n    * 返回此HashSet实例的浅表副本：并没有复制这些元素本身。 \n    * \n    * 底层实际调用HashMap的clone()方法，获取HashMap的浅表副本，并设置到  HashSet中。 \n    */  \n   public Object clone() {  \n       try {  \n           HashSet<E> newSet = (HashSet<E>) super.clone();  \n           newSet.map = (HashMap<E, Object>) map.clone();  \n           return newSet;  \n       } catch (CloneNotSupportedException e) {  \n           throw new InternalError();  \n       }  \n   }  \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n\n\n\n# HashSet 特点\n\n * 非线程安全\n * 允许 null 值\n * 添加值得时候会先获取对象的 hashCode 方法，如果 hashCode 方法返回的值一致，则再调用 equals 方法判断是否一致，如果不一致才 add 元素。\n\n\n# 解析\n\nadd()\n\nHashSet 里面的 add 方法使用的就是 HashMap 的 put 方法，map.put(e,PRESENT)==null; 将要存入的集合元素作为键，然后把 PRESENT 这个虚拟对象作为值，而这个值是一个固定常量。\n\n查重\n\nHashSet 查重的话，应该就是利用到了 HashMap 的键唯一性来去重，新的元素会覆盖掉旧的元素，== 号的判断结果来确定是否包含要添加的元素，不包含就添加元素并返回 true，包含就忽略此添加操作并返回 false，从而保证了 HashSet 中元素的唯一性。\n\n\n# HashSet 的实现\n\nHashSet 实际上是基于 HashMap 实现的，它只使用了 HashMap 的键来存储数据。在 HashSet 中，元素被存储为 HashMap 的键，而值都是固定的一个常量对象。\n\n因此，当我们向 HashSet 添加元素时，实际上是将这个元素作为键，常量对象作为对应的值存储在 HashMap 中。\n\n在 HashSet 中，唯一性是通过 HashMap 中键的唯一性保证的，因为 HashMap 的键是唯一的。当我们使用 HashSet 来存储元素时，实际上是在利用 HashMap 的去重特性来保证 HashSet 中的元素唯一性。\n\n\n# 参考\n\nhttps://blog.csdn.net/fighterandknight/article/details/66585997',normalizedContent:'# set 集合详解\n\n\n# comparable 和 comparator 的区别\n\n 1. comparable 接口只有一个方法 compareto()，用于比较对象自身与另一个对象的大小关系。实现 comparable 接口的类可以直接通过调用 arrays.sort() 或 collections.sort() 方法进行排序。 comparator 接口有两个方法 compare() 和 equals()，其中 compare() 方法用于比较两个对象的大小关系，可以通过 collections.sort() 方法的重载版本或者使用 treemap、priorityqueue 等需要比较对象的集合类来进行排序。equals() 方法用于比较两个对象是否相等，但在比较大小时并不会使用到。\n 2. comparable 接口是在类的定义时就实现的，实现 comparable 接口意味着该类支持自然排序（natural ordering），即可以根据对象自身的属性进行排序。而 comparator 接口是在排序时作为参数传递进去的，可以根据不同的比较规则进行排序，也就是说可以定义多个 comparator 来比较同一个类的对象。\n 3. comparable 接口的实现在集合类中被广泛使用，例如在 treeset、treemap 等集合类中需要比较元素的大小关系时，会首先尝试使用元素自身实现的 comparable 接口进行比较。如果元素没有实现 comparable 接口，则需要通过传递一个 comparator 对象来进行比较。因此，实现 comparable 接口可以使得类更加通用，因为它可以被广泛应用于不同的集合类中。\n 4. comparable 接口是 java 的内部接口，定义在 java.lang 包中，而 comparator 接口是 java 的标准类库中的接口，定义在 java.util 包中。 综上所述，comparable 和 comparator 都是用于比较对象的接口，但是它们之间的区别主要在于实现方式、应用场景和使用方式等方面。需要根据实际情况选择合适的接口来进行对象的比较。\n\n> 综上所述，comparable 和 comparator 都是用于比较对象的接口，但是它们之间的区别主要在于实现方式、应用场景和使用方式等方面。需要根据实际情况选择合适的接口来进行对象的比较。\n\n\n# comparator 定制排序（直接方法中重写）\n\narraylist<integer> arraylist = new arraylist<integer>();\narraylist.add(-1);\narraylist.add(3);\narraylist.add(3);\narraylist.add(-5);\narraylist.add(7);\narraylist.add(4);\narraylist.add(-9);\narraylist.add(-7);\nsystem.out.println("原始数组:");\nsystem.out.println(arraylist);\n// void reverse(list list)：反转\ncollections.reverse(arraylist);\nsystem.out.println("collections.reverse(arraylist):");\nsystem.out.println(arraylist);\n\n// void sort(list list),按自然排序的升序排序\ncollections.sort(arraylist);\nsystem.out.println("collections.sort(arraylist):");\nsystem.out.println(arraylist);\n// 定制排序的用法\ncollections.sort(arraylist, new comparator<integer>() {\n\n    @override\n    public int compare(integer o1, integer o2) {\n        return o2.compareto(o1);\n    }\n});\nsystem.out.println("定制排序后：");\nsystem.out.println(arraylist);\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\noutput:\n\n原始数组:\n[-1, 3, 3, -5, 7, 4, -9, -7]\ncollections.reverse(arraylist):\n[-7, -9, 4, 7, -5, 3, 3, -1]\ncollections.sort(arraylist):\n[-9, -7, -5, -1, 3, 3, 4, 7]\n定制排序后：\n[7, 4, 3, 3, -1, -5, -7, -9]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 重写 compareto 方法实现按年龄来排序（在实体类中重写方法）\n\n// person对象没有实现comparable接口，所以必须实现，这样才不会出错，才可以使treemap中的数据按顺序排列\n// 前面一个例子的string类已经默认实现了comparable接口，详细可以查看string类的api文档，另外其他\n// 像integer类等都已经实现了comparable接口，所以不需要另外实现了\npublic  class person implements comparable<person> {\n    private string name;\n    private int age;\n\n    public person(string name, int age) {\n        super();\n        this.name = name;\n        this.age = age;\n    }\n\n    public string getname() {\n        return name;\n    }\n\n    public void setname(string name) {\n        this.name = name;\n    }\n\n    public int getage() {\n        return age;\n    }\n\n    public void setage(int age) {\n        this.age = age;\n    }\n\n    /**\n     * t重写compareto方法实现按年龄来排序\n     */\n    @override\n    public int compareto(person o) {\n        if (this.age > o.getage()) {\n            return 1;\n        }\n        if (this.age < o.getage()) {\n            return -1;\n        }\n        return 0;\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n\n\n public static void main(string[] args) {\n        treemap<person, string> pdata = new treemap<person, string>();\n        pdata.put(new person("张三", 30), "zhangsan");\n        pdata.put(new person("李四", 20), "lisi");\n        pdata.put(new person("王五", 10), "wangwu");\n        pdata.put(new person("小红", 5), "xiaohong");\n        // 得到key的值的同时得到key所对应的值\n        set<person> keys = pdata.keyset();\n        for (person key : keys) {\n            system.out.println(key.getage() + "-" + key.getname());\n\n        }\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\noutput：\n\n5-小红\n10-王五\n20-李四\n30-张三\n\n\n1\n2\n3\n4\n\n\n\n# 比较 hashset、linkedhashset 和 treeset 三者的异同\n\n * hashset、linkedhashset 和 treeset 都是 set 接口的实现类，都能保证元素唯一，并且都不是线程安全的。\n * hashset、linkedhashset 和 treeset 的主要区别在于底层数据结构不同。hashset 的底层数据结构是哈希表（基于 hashmap 实现）。linkedhashset 的底层数据结构是链表和哈希表，元素的插入和取出顺序满足 fifo。treeset 底层数据结构是红黑树，元素是有序的，排序的方式有自然排序和定制排序。\n * 底层数据结构不同又导致这三者的应用场景不同。hashset 用于不需要保证元素插入和取出顺序的场景，linkedhashset 用于保证元素的插入和取出顺序满足 fifo 的场景，treeset 用于支持对元素自定义排序规则的场景。\n\n\n# 源码解析\n\npublic class hashset<e>  \n   extends abstractset<e>  \n   implements set<e>, cloneable, java.io.serializable  \n{  \n   static final long serialversionuid = -5024744406713321676l;  \n \n   // 底层使用hashmap来保存hashset中所有元素。  \n   private transient hashmap<e,object> map;  \n     \n   // 定义一个虚拟的object对象作为hashmap的value，将此对象定义为static final。  \n   private static final object present = new object();  \n \n   /** \n    * 默认的无参构造器，构造一个空的hashset。 \n    *  \n    * 实际底层会初始化一个空的hashmap，并使用默认初始容量为16和加载因子0.75。 \n    */  \n   public hashset() {  \n   map = new hashmap<e,object>();  \n   }  \n \n   /** \n    * 构造一个包含指定collection中的元素的新set。 \n    * \n    * 实际底层使用默认的加载因子0.75和足以包含指定 \n    * collection中所有元素的初始容量来创建一个hashmap。 \n    * @param c 其中的元素将存放在此set中的collection。 \n    */  \n   public hashset(collection<? extends e> c) {  \n   map = new hashmap<e,object>(math.max((int) (c.size()/.75f) + 1, 16));  \n   addall(c);  \n   }  \n \n   /** \n    * 以指定的initialcapacity和loadfactor构造一个空的hashset。 \n    * \n    * 实际底层以相应的参数构造一个空的hashmap。 \n    * @param initialcapacity 初始容量。 \n    * @param loadfactor 加载因子。 \n    */  \n   public hashset(int initialcapacity, float loadfactor) {  \n   map = new hashmap<e,object>(initialcapacity, loadfactor);  \n   }  \n \n   /** \n    * 以指定的initialcapacity构造一个空的hashset。 \n    * \n    * 实际底层以相应的参数及加载因子loadfactor为0.75构造一个空的hashmap。 \n    * @param initialcapacity 初始容量。 \n    */  \n   public hashset(int initialcapacity) {  \n   map = new hashmap<e,object>(initialcapacity);  \n   }  \n \n   /** \n    * 以指定的initialcapacity和loadfactor构造一个新的空链接哈希集合。 \n    * 此构造函数为包访问权限，不对外公开，实际只是是对linkedhashset的支持。 \n    * \n    * 实际底层会以指定的参数构造一个空linkedhashmap实例来实现。 \n    * @param initialcapacity 初始容量。 \n    * @param loadfactor 加载因子。 \n    * @param dummy 标记。 \n    */  \n   hashset(int initialcapacity, float loadfactor, boolean dummy) {  \n   map = new linkedhashmap<e,object>(initialcapacity, loadfactor);  \n   }  \n \n   /** \n    * 返回对此set中元素进行迭代的迭代器。返回元素的顺序并不是特定的。 \n    *  \n    * 底层实际调用底层hashmap的keyset来返回所有的key。 \n    * 可见hashset中的元素，只是存放在了底层hashmap的key上， \n    * value使用一个static final的object对象标识。 \n    * @return 对此set中元素进行迭代的iterator。 \n    */  \n   public iterator<e> iterator() {  \n   return map.keyset().iterator();  \n   }  \n \n   /** \n    * 返回此set中的元素的数量（set的容量）。 \n    * \n    * 底层实际调用hashmap的size()方法返回entry的数量，就得到该set中元素的个数。 \n    * @return 此set中的元素的数量（set的容量）。 \n    */  \n   public int size() {  \n   return map.size();  \n   }  \n \n   /** \n    * 如果此set不包含任何元素，则返回true。 \n    * \n    * 底层实际调用hashmap的isempty()判断该hashset是否为空。 \n    * @return 如果此set不包含任何元素，则返回true。 \n    */  \n   public boolean isempty() {  \n   return map.isempty();  \n   }  \n \n   /** \n    * 如果此set包含指定元素，则返回true。 \n    * 更确切地讲，当且仅当此set包含一个满足(o==null ? e==null : o.equals(e)) \n    * 的e元素时，返回true。 \n    * \n    * 底层实际调用hashmap的containskey判断是否包含指定key。 \n    * @param o 在此set中的存在已得到测试的元素。 \n    * @return 如果此set包含指定元素，则返回true。 \n    */  \n   public boolean contains(object o) {  \n   return map.containskey(o);  \n   }  \n \n   /** \n    * 如果此set中尚未包含指定元素，则添加指定元素。 \n    * 更确切地讲，如果此 set 没有包含满足(e==null ? e2==null : e.equals(e2)) \n    * 的元素e2，则向此set 添加指定的元素e。 \n    * 如果此set已包含该元素，则该调用不更改set并返回false。 \n    * \n    * 底层实际将将该元素作为key放入hashmap。 \n    * 由于hashmap的put()方法添加key-value对时，当新放入hashmap的entry中key \n    * 与集合中原有entry的key相同（hashcode()返回值相等，通过equals比较也返回true）， \n    * 新添加的entry的value会将覆盖原来entry的value，但key不会有任何改变， \n    * 因此如果向hashset中添加一个已经存在的元素时，新添加的集合元素将不会被放入hashmap中， \n    * 原来的元素也不会有任何改变，这也就满足了set中元素不重复的特性。 \n    * @param e 将添加到此set中的元素。 \n    * @return 如果此set尚未包含指定元素，则返回true。 \n    */  \n   public boolean add(e e) {  \n   return map.put(e, present)==null;  \n   }  \n \n   /** \n    * 如果指定元素存在于此set中，则将其移除。 \n    * 更确切地讲，如果此set包含一个满足(o==null ? e==null : o.equals(e))的元素e， \n    * 则将其移除。如果此set已包含该元素，则返回true \n    * （或者：如果此set因调用而发生更改，则返回true）。（一旦调用返回，则此set不再包含该元素）。 \n    * \n    * 底层实际调用hashmap的remove方法删除指定entry。 \n    * @param o 如果存在于此set中则需要将其移除的对象。 \n    * @return 如果set包含指定元素，则返回true。 \n    */  \n   public boolean remove(object o) {  \n   return map.remove(o)==present;  \n   }  \n \n   /** \n    * 从此set中移除所有元素。此调用返回后，该set将为空。 \n    * \n    * 底层实际调用hashmap的clear方法清空entry中所有元素。 \n    */  \n   public void clear() {  \n   map.clear();  \n   }  \n \n   /** \n    * 返回此hashset实例的浅表副本：并没有复制这些元素本身。 \n    * \n    * 底层实际调用hashmap的clone()方法，获取hashmap的浅表副本，并设置到  hashset中。 \n    */  \n   public object clone() {  \n       try {  \n           hashset<e> newset = (hashset<e>) super.clone();  \n           newset.map = (hashmap<e, object>) map.clone();  \n           return newset;  \n       } catch (clonenotsupportedexception e) {  \n           throw new internalerror();  \n       }  \n   }  \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n123\n124\n125\n126\n127\n128\n129\n130\n131\n132\n133\n134\n135\n136\n137\n138\n139\n140\n141\n142\n143\n144\n145\n146\n147\n148\n149\n150\n151\n152\n153\n154\n155\n156\n157\n158\n159\n160\n161\n162\n163\n164\n165\n166\n167\n168\n169\n\n\n\n# hashset 特点\n\n * 非线程安全\n * 允许 null 值\n * 添加值得时候会先获取对象的 hashcode 方法，如果 hashcode 方法返回的值一致，则再调用 equals 方法判断是否一致，如果不一致才 add 元素。\n\n\n# 解析\n\nadd()\n\nhashset 里面的 add 方法使用的就是 hashmap 的 put 方法，map.put(e,present)==null; 将要存入的集合元素作为键，然后把 present 这个虚拟对象作为值，而这个值是一个固定常量。\n\n查重\n\nhashset 查重的话，应该就是利用到了 hashmap 的键唯一性来去重，新的元素会覆盖掉旧的元素，== 号的判断结果来确定是否包含要添加的元素，不包含就添加元素并返回 true，包含就忽略此添加操作并返回 false，从而保证了 hashset 中元素的唯一性。\n\n\n# hashset 的实现\n\nhashset 实际上是基于 hashmap 实现的，它只使用了 hashmap 的键来存储数据。在 hashset 中，元素被存储为 hashmap 的键，而值都是固定的一个常量对象。\n\n因此，当我们向 hashset 添加元素时，实际上是将这个元素作为键，常量对象作为对应的值存储在 hashmap 中。\n\n在 hashset 中，唯一性是通过 hashmap 中键的唯一性保证的，因为 hashmap 的键是唯一的。当我们使用 hashset 来存储元素时，实际上是在利用 hashmap 的去重特性来保证 hashset 中的元素唯一性。\n\n\n# 参考\n\nhttps://blog.csdn.net/fighterandknight/article/details/66585997',charsets:{cjk:!0}},{title:"Map接口",frontmatter:{title:"Map接口",date:"2023-08-10T14:51:12.000Z",permalink:"/pages/4c1680/",author:{name:"陌上清风",link:"https://github.com/msqfx"},categories:["java","集合篇"],tags:[null],description:"线程安全性：",comment:!0,meta:[{name:"image",content:"https://cmty256.github.io/imgs-blog/images/image-20230412165201719.2bc46rnd9474.jpg"},{name:"twitter:title",content:"Map接口"},{name:"twitter:description",content:"线程安全性："},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://cmty256.github.io/imgs-blog/images/image-20230412165201719.2bc46rnd9474.jpg"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/05.Map%E6%8E%A5%E5%8F%A3.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Map接口"},{property:"og:description",content:"线程安全性："},{property:"og:image",content:"https://cmty256.github.io/imgs-blog/images/image-20230412165201719.2bc46rnd9474.jpg"},{property:"og:url",content:"https://www.msqfx.cc/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/05.Map%E6%8E%A5%E5%8F%A3.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-08-10T14:51:12.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"Map接口"},{itemprop:"description",content:"线程安全性："},{itemprop:"image",content:"https://cmty256.github.io/imgs-blog/images/image-20230412165201719.2bc46rnd9474.jpg"}],readingShow:"top"},regularPath:"/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/05.Map%E6%8E%A5%E5%8F%A3.html",relativePath:"01.java/02.集合篇/05.Map接口.md",key:"v-f9a862c8",path:"/pages/4c1680/",headers:[{level:2,title:"HashMap 和 Hashtable 的区别",slug:"hashmap-和-hashtable-的区别",normalizedTitle:"hashmap 和 hashtable 的区别",charIndex:15},{level:2,title:"HashMap 和 HashSet 区别",slug:"hashmap-和-hashset-区别",normalizedTitle:"hashmap 和 hashset 区别",charIndex:888},{level:2,title:"hashCode 源码",slug:"hashcode-源码",normalizedTitle:"hashcode 源码",charIndex:1577},{level:2,title:"为什么哈希函数能降低哈希碰撞？",slug:"为什么哈希函数能降低哈希碰撞",normalizedTitle:"为什么哈希函数能降低哈希碰撞？",charIndex:2178},{level:2,title:"HashMap 和 TreeMap 区别",slug:"hashmap-和-treemap-区别",normalizedTitle:"hashmap 和 treemap 区别",charIndex:2261},{level:2,title:"HashSet 如何检查重复?",slug:"hashset-如何检查重复",normalizedTitle:"hashset 如何检查重复?",charIndex:3784},{level:2,title:"HashMap的底层实现",slug:"hashmap的底层实现",normalizedTitle:"hashmap的底层实现",charIndex:4881},{level:3,title:"JDK1.8 之前",slug:"jdk1-8-之前",normalizedTitle:"jdk1.8 之前",charIndex:4898},{level:3,title:"JDK1.8 之后",slug:"jdk1-8-之后",normalizedTitle:"jdk1.8 之后",charIndex:5139},{level:3,title:"JDK1.7和JDK1.8的hash方法源码对比：",slug:"jdk1-7和jdk1-8的hash方法源码对比",normalizedTitle:"jdk1.7和jdk1.8的hash方法源码对比：",charIndex:5373},{level:2,title:"HashMap 的长度为什么是 2 的幂次方",slug:"hashmap-的长度为什么是-2-的幂次方",normalizedTitle:"hashmap 的长度为什么是 2 的幂次方",charIndex:5533},{level:2,title:"HashMap 多线程操作导致死循环问题",slug:"hashmap-多线程操作导致死循环问题",normalizedTitle:"hashmap 多线程操作导致死循环问题",charIndex:6012},{level:2,title:"HashMap 有哪几种常见的遍历方式?",slug:"hashmap-有哪几种常见的遍历方式",normalizedTitle:"hashmap 有哪几种常见的遍历方式?",charIndex:6608},{level:2,title:"ConcurrentHashMap 和 Hashtable 的区别",slug:"concurrenthashmap-和-hashtable-的区别",normalizedTitle:"concurrenthashmap 和 hashtable 的区别",charIndex:6658},{level:2,title:"ConcurrentHashMap 线程安全底层具体实现",slug:"concurrenthashmap-线程安全底层具体实现",normalizedTitle:"concurrenthashmap 线程安全底层具体实现",charIndex:7815},{level:3,title:"JDK1.8 之前",slug:"jdk1-8-之前-2",normalizedTitle:"jdk1.8 之前",charIndex:4898},{level:3,title:"JDK1.8 之后",slug:"jdk1-8-之后-2",normalizedTitle:"jdk1.8 之后",charIndex:5139},{level:3,title:"锁粒度解析",slug:"锁粒度解析",normalizedTitle:"锁粒度解析",charIndex:8681},{level:2,title:"JDK 1.7 和 JDK 1.8 的 ConcurrentHashMap 实现有什么不同？",slug:"jdk-1-7-和-jdk-1-8-的-concurrenthashmap-实现有什么不同",normalizedTitle:"jdk 1.7 和 jdk 1.8 的 concurrenthashmap 实现有什么不同？",charIndex:9001},{level:3,title:"为什么 HashMap 链表转红黑树的阈值为 8 呢？",slug:"为什么-hashmap-链表转红黑树的阈值为-8-呢",normalizedTitle:"为什么 hashmap 链表转红黑树的阈值为 8 呢？",charIndex:9389},{level:2,title:"HashMap 的扩容机制了解吗？",slug:"hashmap-的扩容机制了解吗",normalizedTitle:"hashmap 的扩容机制了解吗？",charIndex:9579},{level:3,title:"扩容在什么时候呢？为什么扩容因子是 0.75？",slug:"扩容在什么时候呢-为什么扩容因子是-0-75",normalizedTitle:"扩容在什么时候呢？为什么扩容因子是 0.75？",charIndex:9986},{level:3,title:"为什么是 2 倍？",slug:"为什么是-2-倍",normalizedTitle:"为什么是 2 倍？",charIndex:10289}],headersStr:"HashMap 和 Hashtable 的区别 HashMap 和 HashSet 区别 hashCode 源码 为什么哈希函数能降低哈希碰撞？ HashMap 和 TreeMap 区别 HashSet 如何检查重复? HashMap的底层实现 JDK1.8 之前 JDK1.8 之后 JDK1.7和JDK1.8的hash方法源码对比： HashMap 的长度为什么是 2 的幂次方 HashMap 多线程操作导致死循环问题 HashMap 有哪几种常见的遍历方式? ConcurrentHashMap 和 Hashtable 的区别 ConcurrentHashMap 线程安全底层具体实现 JDK1.8 之前 JDK1.8 之后 锁粒度解析 JDK 1.7 和 JDK 1.8 的 ConcurrentHashMap 实现有什么不同？ 为什么 HashMap 链表转红黑树的阈值为 8 呢？ HashMap 的扩容机制了解吗？ 扩容在什么时候呢？为什么扩容因子是 0.75？ 为什么是 2 倍？",content:'# Map 集合详解\n\n\n# HashMap 和 Hashtable 的区别\n\n线程安全性：\n\nHashMap 是非线程安全的，Hashtable 是线程安全的,因为 Hashtable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 ConcurrentHashMap 吧！）；\n\n效率：\n\n因为线程安全的问题，HashMap 要比 Hashtable 效率高一点。另外，Hashtable 基本被淘汰，不要在代码中使用它；\n\n对 null 键 和 null 值 的支持：\n\nHashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；Hashtable 不允许有 null 键和 null 值，否则会抛出 NullPointerException。\n\n初始容量大小和每次扩充容量大小的不同 ：\n\n① 创建时如果不指定容量初始值，Hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。HashMap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。\n\n② 创建时如果给定了容量初始值，那么 Hashtable 会直接使用你给定的大小，而 HashMap 会将其扩充为 2 的幂次方大小（HashMap 中的tableSizeFor()方法保证，利用右位移运算）。也就是说 HashMap 总是使用 2 的幂作为哈希表的大小,后面会介绍到为什么是 2 的幂次方。\n\n底层数据结构：\n\n * JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间（后文中我会结合源码对这一过程进行分析）。\n   \n   > 桶数组是用来存储数据元素，链表是用来解决冲突，红黑树是为了提高查询的效率。\n\n * Hashtable 没有这样的机制。\n\n\n# HashMap 和 HashSet 区别\n\n\n\n用途：\n\n * HashMap：用于存储键值对（Key-Value）映射关系的数据结构，其中每个键唯一对应一个值。\n * HashSet：用于存储不重复元素的集合，它基于 HashMap 实现，只存储元素而没有键值对的映射关系。\n\n存储方式：\n\n * HashMap：存储键值对，通过键查找值。键可以是任何非空对象，值可以是任何对象。\n * HashSet：存储不重复的元素，通过元素本身来进行查找和判重。\n\n内部实现：\n\n * HashMap：内部使用数组和链表（或红黑树）的组合来实现，通过哈希函数将键映射到数组的索引位置，以提高键的查找效率。\n * HashSet：基于 HashMap 实现，它的元素就是 HashMap 的键，值则是一个固定的常量（一直是一个 Object 对象）。\n\n操作和用法：\n\n * HashMap：适用于需要存储键值对关系的情况，例如缓存、映射关系等。\n * HashSet：适用于存储不重复元素的情况，例如需要快速判断某个元素是否存在等。\n\n性能：\n\n * HashMap：相对于 HashSet，HashMap 需要存储键值对，因此额外占用一些内存，但可以存储更多的信息。\n * HashSet：相对于 HashMap，HashSet 只需要存储元素，占用的内存较少，但不能存储键值对关系。\n\n总之，HashMap 适用于存储键值对关系，而 HashSet 适用于存储不重复元素的集合。实际上，HashSet 在内部使用了 HashMap 来实现，它们之间存在一定的关联和相似性。\n\n\n# hashCode 源码\n\nhashCode() 方法返回的值是一个 int 类型的数字，用于表示对象的哈希值。这个哈希值不一定是对象的地址，也不一定是唯一的。在计算哈希值时，一般会使用对象的属性来计算。例如，如果一个 Person 类具有 name 和 age 两个属性，那么可以将它们的哈希值合并起来计算：\n\npublic int hashCode() {\n    int result = 17;\n    result = 31 * result + name.hashCode();\n    result = 31 * result + age;\n    return result;\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n这段代码中使用了一个经典的哈希算法，称为“31 哈希法”。这个算法将初始值设为一个质数 17，然后将属性的哈希值依次乘以 31 并相加，得到最终的哈希值。由于 31 是一个奇素数，可以保证乘法过程不会产生哈希冲突。\n\n> 需要注意的是，虽然哈希值不一定是地址，但是在 Java 中，如果没有为对象指定 hashCode() 方法的实现，那么默认情况下，它的 hashCode() 方法会返回对象的地址，因此在这种情况下，两个对象的哈希值可能会相同，但这并不是一个好的哈希算法。因此，在实现自定义的哈希算法时，需要保证哈希值的分布尽可能均匀，并且不容易产生哈希冲突。\n\n\n# 为什么哈希函数能降低哈希碰撞？\n\n因为好的哈希函数可以将输入的数据均匀、随机地映射到哈希空间，降低了碰撞的可能性，从而提高了哈希表等数据结构的性能和稳定性。\n\n\n# HashMap 和 TreeMap 区别\n\nTreeMap 和HashMap 都继承自AbstractMap ，但是需要注意的是TreeMap它还实现了NavigableMap接口和SortedMap 接口。\n\n\n\n实现 NavigableMap 接口让 TreeMap 有了对集合内元素的搜索的能力。\n\n实现SortedMap接口让 TreeMap 有了对集合中的元素根据键排序的能力。默认是按 key 的升序排序，不过我们也可以指定排序的比较器。示例代码如下：\n\npublic class Person {\n    private Integer age;\n    public Person(Integer age) {\n        this.age = age;\n    }\n    public Integer getAge() {\n        return age;\n    }\n\n    public static void main(String[] args) {\n        TreeMap<Person, String> treeMap = new TreeMap<>(new Comparator<Person>() {\n            @Override\n            public int compare(Person person1, Person person2) {\n                int num = person1.getAge() - person2.getAge();\n                return Integer.compare(num, 0);\n            }\n        });\n        treeMap.put(new Person(3), "person1");\n        treeMap.put(new Person(18), "person2");\n        treeMap.put(new Person(35), "person3");\n        treeMap.put(new Person(16), "person4");\n        treeMap.entrySet().stream().forEach(personStringEntry -> {\n            System.out.println(personStringEntry.getValue());\n        });\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n可以看出，TreeMap 中的元素已经是按照 Person 的 age 字段的升序来排列了。\n\n上面，我们是通过传入匿名内部类的方式实现的，你可以将代码替换成 Lambda 表达式实现的方式：\n\nTreeMap<Person, String> treeMap = new TreeMap<>((person1, person2) -> {\n  int num = person1.getAge() - person2.getAge();\n  return Integer.compare(num, 0);\n});\n\n\n1\n2\n3\n4\n\n\n综上，相比于HashMap来说 TreeMap 主要多了对集合中的元素根据键排序的能力（SortedMap）以及对集合内元素的搜索的能力（NavigableMap）。\n\n\n# HashSet 如何检查重复?\n\n> 当你把对象加入HashSet时，HashSet 会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，HashSet 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，HashSet 就不会让加入操作成功。\n\n直接看一下HashSet中的源码：\n\n在 JDK1.8 中，实际上无论 HashSet 中是否已经存在了某元素，HashSet 都会直接插入，只是会在 add() 方法的返回值处告诉我们插入前是否存在相同元素\n\n// Returns: true if this set did not already contain the specified element\n// 返回值：当 set 中没有包含 add 的元素时返回真\npublic boolean add(E e) {\n        return map.put(e, PRESENT)==null;\n}\n\n\n1\n2\n3\n4\n5\n\n\nHashSet 通过 HashMap 的键的唯一性来实现对元素的重复检查。在 HashSet 中，元素被存储为 HashMap 的键，而值都是固定的一个常量对象。当我们向 HashSet 添加元素时，实际上是将这个元素作为键，常量对象作为对应的值存储在 HashMap 中。\n\n在 HashMap 中，键是唯一的，这意味着当我们尝试将相同的元素作为键添加到 HashMap 中时，新的元素会覆盖掉旧的元素。因此，当我们向 HashSet 添加元素时，实际上是在利用 HashMap 的去重特性来保证 HashSet 中的元素唯一性。\n\n例如，考虑以下代码：\n\nHashSet<Integer> set = new HashSet<>();\nset.add(1);\nset.add(2);\nset.add(3);\nset.add(1);  // 尝试添加重复元素\nSystem.out.println(set.size());  // 输出为 3，因为重复元素被去重\n\n\n1\n2\n3\n4\n5\n6\n\n\n在上述示例中，尝试向 HashSet 中添加重复的元素 1 时，并没有导致 HashSet 中出现重复元素，这是因为 HashSet 利用了 HashMap 的键唯一性来进行去重。\n\n因此，HashSet 能够自动检查并防止重复元素的存在。\n\n\n# HashMap的底层实现\n\n\n# JDK1.8 之前\n\nJDK1.8 之前 HashMap 底层是 数组和链表 结合在一起使用也就是 链表散列。HashMap 通过 key 的 hashcode 经过扰动函数（hash方法）处理过后得到 hash 值，然后通过 (n - 1) & hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法（数组+链表）解决冲突。\n\n\n# JDK1.8 之后\n\n相比于之前的版本， JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。\n\n> TreeMap、TreeSet 以及 JDK1.8 之后的 HashMap 底层都用到了红黑树。红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。\n\n\n# JDK1.7和JDK1.8的hash方法源码对比：\n\n 1. JDK 1.8 的 hash 方法 （运用了三目运算符）相比于 JDK 1.7 hash 方法更加简化，但是原理不变；\n 2. JDK 1.7 的 hash 方法的性能会稍差一点点，因为扰动了 4 次\n\n使用扰动函数（hash方法）之后可以减少碰撞\n\n\n# HashMap 的长度为什么是 2 的幂次方\n\n这是因为 HashMap 在计算 key 的哈希值后，需要通过哈希值和数组长度计算出该 key 在数组中的位置。\n\n具体的计算方式是 (n - 1) & hash（数组的长度减一的差和 key 的哈希值相与），其中 n 是数组的长度，hash 是 key 的哈希值。\n\n这个计算方式的作用是将哈希值的高位和低位进行一次异或运算，得到 key 在数组中的位置。 如果数组的长度不是 2 的幂次方，那么在计算 (n - 1) & hash 时，得到的结果可能会存在一些哈希值无法均匀分布到数组中的位置的情况，从而导致某些位置上的链表或红黑树会变得过长，影响 HashMap 的性能。因此，为了避免这种情况的发生，HashMap 的长度总是保持为 2 的幂次方。 另外，对于长度为 2 的幂次方的数组，计算 (n - 1) & hash 时，等价于对数组长度取模，这种计算方式的效率比较高，而且可以保证均匀分布。因此，HashMap 采用长度为 2 的幂次方的数组，可以提高 HashMap 的性能和效率。\n\n\n# HashMap 多线程操作导致死循环问题\n\n在多线程环境下，如果多个线程同时对 HashMap 进行操作，可能会导致 HashMap 的链表或红黑树出现环形，从而导致死循环问题。这种问题通常发生在以下情况下：\n\n 1. 多个线程同时调用 put() 方法，导致链表或红黑树的结构发生变化，从而导致链表或红黑树出现环形。\n 2. 多个线程同时调用 resize() 方法，导致数组扩容时链表或红黑树的结构发生变化，从而导致链表或红黑树出现环形。 当出现链表或红黑树环形时，会导致 HashMap 的遍历操作进入死循环，从而影响程序的性能和可靠性。\n\n为了解决这个问题，可以采用以下几种方式：\n\n 1. 使用线程安全的 ConcurrentHashMap，它是线程安全的 HashMap，可以安全地在多线程环境下进行操作。\n 2. 对于需要在多线程环境下使用 HashMap 的情况，可以使用锁来保证同一时间只有一个线程能够对 HashMap 进行操作。\n 3. 避免多个线程同时对 HashMap 进行操作，可以将对 HashMap 的操作放在同步块中，确保同一时间只有一个线程能够对 HashMap 进行修改。\n 4. 通过使用线程安全的并发数据结构，例如 ConcurrentLinkedQueue、ConcurrentHashMap 等，避免在多线程环境下使用 HashMap。\n\n\n# HashMap 有哪几种常见的遍历方式?\n\nHashMap 的 7 种遍历方式与性能分析！\n\n\n# ConcurrentHashMap 和 Hashtable 的区别\n\nConcurrentHashMap 和 Hashtable 都是线程安全的集合类，但是它们在实现和性能上有一些区别：\n\n 1. 底层数据结构：\n    * JDK1.7 的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟 HashMap1.8 的结构一样，数组+链表/红黑二叉树。\n    * Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的；\n 2. 实现线程安全的方式（重要）：\n\n * 在 JDK1.7 的时候，ConcurrentHashMap 对整个桶数组进行了分割分段(Segment，分段锁)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。\n * 到了 JDK1.8 的时候，ConcurrentHashMap 已经摒弃了 Segment 的概念，而是直接用 Node 数组+链表 / 红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6 以后 synchronized 锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在 JDK1.8 中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；\n * Hashtable(同一把锁): 使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。\n\n 3. 对 null 值的支持不同：\n    \n    * Hashtable 不允许 key 为 null，\n    * 而 ConcurrentHashMap 则**（ JDK7 时）**允许 key 和 value 均为 null，JDK8 后不再允许（因为使用了 CAS -- 保证线程安全的，对 null 值的支持发生了变化）。\n\n 4. 扩容机制不同：Hashtable 在扩容时使用的是原来容量的 2 倍加 1，而 ConcurrentHashMap 在扩容时采用的则是分段锁技术，当一个段需要进行扩容时，只需要锁定这个段，而不需要锁定整个哈希表。\n    \n    > ConcurrentHashMap 在设计上更加注重并发性能，通过分段锁来减小锁粒度，而不是仅对一个段进行扩容。\n\n\n# ConcurrentHashMap 线程安全底层具体实现\n\n\n# JDK1.8 之前\n\nConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。\n\nSegment 继承了 ReentrantLock,所以 Segment 是一种可重入锁，扮演锁的角色。HashEntry 用于存储键值对数据。\n\n一个 ConcurrentHashMap 里包含一个 Segment 数组，Segment 的个数一旦初始化就不能改变。 Segment 数组的大小默认是 16，也就是说默认可以同时支持 16 个线程并发写。\n\nSegment 的结构和 HashMap 类似，是一种数组和链表结构，一个 Segment 包含一个 HashEntry 数组，每个 HashEntry 是一个链表结构的元素，每个 Segment 守护着一个 HashEntry 数组里的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得对应的 Segment 的锁。也就是说，对同一 Segment 的并发写入会被阻塞，不同 Segment 的写入是可以并发执行的。\n\n\n# JDK1.8 之后\n\n * Java 8 几乎完全重写了 ConcurrentHashMap，代码量从原来 Java 7 中的 1000 多行，变成了现在的 6000 多行。\n * ConcurrentHashMap 取消了 Segment 分段锁，采用 Node + CAS + synchronized 来保证并发安全。数据结构跟 HashMap 1.8 的结构类似，数组+链表/红黑二叉树。Java 8 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))）。\n * Java 8 中，锁粒度更细，synchronized 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 Node 的读写，效率大幅提升。\n\n\n# 锁粒度解析\n\n锁粒度指的是锁定的范围大小，通常分为粗粒度锁和细粒度锁两种类型。\n\n 1. 粗粒度锁 粗粒度锁指的是锁定范围较大的锁，通常是对整个对象或整个方法进行加锁。粗粒度锁的优点是实现简单，易于控制，缺点是锁定范围太大，会导致并发性能下降，降低程序的并发度。\n 2. 细粒度锁 细粒度锁指的是锁定范围较小的锁，通常是对对象中的某个属性或某一段代码进行加锁。细粒度锁的优点是锁定范围小，可以提高程序的并发度，缺点是实现复杂，容易出现死锁等问题。\n\n在实际开发中，应该根据实际情况选择合适的锁粒度。如果锁的范围太大，会导致并发性能下降，如果锁的范围太小，会增加锁的竞争，降低程序的并发度。可以通过压力测试等方式来确定合适的锁粒度。\n\n\n# JDK 1.7 和 JDK 1.8 的 ConcurrentHashMap 实现有什么不同？\n\n线程安全实现方式 ：\n\n * JDK 1.7 采用 Segment 分段锁来保证安全， Segment 是继承自 ReentrantLock。\n * JDK1.8 放弃了 Segment 分段锁的设计，采用 Node + CAS + synchronized 保证线程安全，锁粒度更细，synchronized 只锁定当前链表或红黑二叉树的首节点。\n\nHash 碰撞解决方法 :\n\n * JDK 1.7 采用拉链法，\n * JDK1.8 采用拉链法结合红黑树（链表长度超过一定阈值时，将链表转换为红黑树）。\n\n并发度 ：\n\n * JDK 1.7 最大并发度是 Segment 的个数，默认是 16。\n * JDK 1.8 最大并发度是 Node 数组的大小，并发度更大。\n\n\n# 为什么 HashMap 链表转红黑树的阈值为 8 呢？\n\n这是一个经验性的设定。这个设定是为了在哈希表中维护合适的性能和空间开销之间找到平衡。\n\n选择 8 是基于一系列性能测试和实际应用场景得出的。当链表长度超过这个阈值时，链表的查找性能可能会下降，而转换为红黑树可以提高性能。然而，如果链表长度较短，转换为红黑树可能会带来额外的开销，所以选择一个合适的阈值是一个权衡。\n\n\n# HashMap 的扩容机制了解吗？\n\n了解。当 HashMap 中的元素数量达到一定阈值时，就会触发扩容操作，以保持哈希桶的负载因子在一个合适的范围内，从而减少哈希冲突，提高查找、插入和删除的性能。\n\nHashMap 的扩容机制主要包括以下 3 个步骤：\n\n 1. 创建新的哈希桶数组：当 HashMap 中的元素数量达到阈值时，创建一个新的数组，其大小是原数组的两倍。\n 2. 将旧数据转移到新数组：遍历旧的哈希桶数组中的每个元素，将其重新计算哈希值后放入新的哈希桶数组中。这是一个耗时操作，但只需要进行一次。\n 3. 更新引用：将 HashMap 的哈希桶数组引用指向新的数组，同时更新阈值等信息。\n\n扩容操作会在 HashMap 的插入操作中触发，具体的触发时机是当元素数量超过了负载因子乘以当前数组容量时。默认情况下，负载因子为 0.75，即当元素数量超过当前数组容量的 75% 时，会触发扩容。\n\n\n# 扩容在什么时候呢？为什么扩容因子是 0.75？\n\nHashMap 在进行扩容的时候，通常是当当前容器中的元素数量超过了容器大小的 75% 时触发扩容操作。\n\n这个扩容因子（load factor）的选择是为了在空间和时间上达到一个平衡，从而保证 HashMap 在不至于浪费过多内存的情况下，仍能保持较低的哈希冲突，提供高效的查找、插入和删除操作。\n\n为什么扩容因子选择 0.75 呢？\n\n这是一个折中的选择，考虑了时间和空间的平衡。如果扩容因子设置得太小，会导致哈希冲突过多，影响了 HashMap 的性能；如果设置得太大，虽然哈希冲突可能减少，但是会导致 HashMap 占用更多的内存空间。\n\n\n# 为什么是 2 倍？\n\n使用 2 的次幂作为数组的容量可以确保 hashCode 的高位和低位能够更好地均匀分布在数组的索引位置上。这样一来，在计算元素存放位置时，只需要进行位运算，而不需要使用取模等耗时的操作，提高了计算效率。\n\n另外，使用 2 的次幂作为容量也方便进行扩容操作，因为 2 的次幂的二进制表示只有一个 1，这样在扩容时只需要将高位多出的 1 变为 0，就可以得到新的容量。这种设计可以减少内存空间的浪费。\n\n总的来说就是：\n\n * 这样设计在计算元素存放位置时可以提高计算效率；\n * 在进行扩容时可以减少内存空间的浪费。\n * 既提高了效率又减少了时间。\n\n> 高位是在左边',normalizedContent:'# map 集合详解\n\n\n# hashmap 和 hashtable 的区别\n\n线程安全性：\n\nhashmap 是非线程安全的，hashtable 是线程安全的,因为 hashtable 内部的方法基本都经过synchronized 修饰。（如果你要保证线程安全的话就使用 concurrenthashmap 吧！）；\n\n效率：\n\n因为线程安全的问题，hashmap 要比 hashtable 效率高一点。另外，hashtable 基本被淘汰，不要在代码中使用它；\n\n对 null 键 和 null 值 的支持：\n\nhashmap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；hashtable 不允许有 null 键和 null 值，否则会抛出 nullpointerexception。\n\n初始容量大小和每次扩充容量大小的不同 ：\n\n① 创建时如果不指定容量初始值，hashtable 默认的初始大小为 11，之后每次扩充，容量变为原来的 2n+1。hashmap 默认的初始化大小为 16。之后每次扩充，容量变为原来的 2 倍。\n\n② 创建时如果给定了容量初始值，那么 hashtable 会直接使用你给定的大小，而 hashmap 会将其扩充为 2 的幂次方大小（hashmap 中的tablesizefor()方法保证，利用右位移运算）。也就是说 hashmap 总是使用 2 的幂作为哈希表的大小,后面会介绍到为什么是 2 的幂次方。\n\n底层数据结构：\n\n * jdk1.8 以后的 hashmap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间（后文中我会结合源码对这一过程进行分析）。\n   \n   > 桶数组是用来存储数据元素，链表是用来解决冲突，红黑树是为了提高查询的效率。\n\n * hashtable 没有这样的机制。\n\n\n# hashmap 和 hashset 区别\n\n\n\n用途：\n\n * hashmap：用于存储键值对（key-value）映射关系的数据结构，其中每个键唯一对应一个值。\n * hashset：用于存储不重复元素的集合，它基于 hashmap 实现，只存储元素而没有键值对的映射关系。\n\n存储方式：\n\n * hashmap：存储键值对，通过键查找值。键可以是任何非空对象，值可以是任何对象。\n * hashset：存储不重复的元素，通过元素本身来进行查找和判重。\n\n内部实现：\n\n * hashmap：内部使用数组和链表（或红黑树）的组合来实现，通过哈希函数将键映射到数组的索引位置，以提高键的查找效率。\n * hashset：基于 hashmap 实现，它的元素就是 hashmap 的键，值则是一个固定的常量（一直是一个 object 对象）。\n\n操作和用法：\n\n * hashmap：适用于需要存储键值对关系的情况，例如缓存、映射关系等。\n * hashset：适用于存储不重复元素的情况，例如需要快速判断某个元素是否存在等。\n\n性能：\n\n * hashmap：相对于 hashset，hashmap 需要存储键值对，因此额外占用一些内存，但可以存储更多的信息。\n * hashset：相对于 hashmap，hashset 只需要存储元素，占用的内存较少，但不能存储键值对关系。\n\n总之，hashmap 适用于存储键值对关系，而 hashset 适用于存储不重复元素的集合。实际上，hashset 在内部使用了 hashmap 来实现，它们之间存在一定的关联和相似性。\n\n\n# hashcode 源码\n\nhashcode() 方法返回的值是一个 int 类型的数字，用于表示对象的哈希值。这个哈希值不一定是对象的地址，也不一定是唯一的。在计算哈希值时，一般会使用对象的属性来计算。例如，如果一个 person 类具有 name 和 age 两个属性，那么可以将它们的哈希值合并起来计算：\n\npublic int hashcode() {\n    int result = 17;\n    result = 31 * result + name.hashcode();\n    result = 31 * result + age;\n    return result;\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n这段代码中使用了一个经典的哈希算法，称为“31 哈希法”。这个算法将初始值设为一个质数 17，然后将属性的哈希值依次乘以 31 并相加，得到最终的哈希值。由于 31 是一个奇素数，可以保证乘法过程不会产生哈希冲突。\n\n> 需要注意的是，虽然哈希值不一定是地址，但是在 java 中，如果没有为对象指定 hashcode() 方法的实现，那么默认情况下，它的 hashcode() 方法会返回对象的地址，因此在这种情况下，两个对象的哈希值可能会相同，但这并不是一个好的哈希算法。因此，在实现自定义的哈希算法时，需要保证哈希值的分布尽可能均匀，并且不容易产生哈希冲突。\n\n\n# 为什么哈希函数能降低哈希碰撞？\n\n因为好的哈希函数可以将输入的数据均匀、随机地映射到哈希空间，降低了碰撞的可能性，从而提高了哈希表等数据结构的性能和稳定性。\n\n\n# hashmap 和 treemap 区别\n\ntreemap 和hashmap 都继承自abstractmap ，但是需要注意的是treemap它还实现了navigablemap接口和sortedmap 接口。\n\n\n\n实现 navigablemap 接口让 treemap 有了对集合内元素的搜索的能力。\n\n实现sortedmap接口让 treemap 有了对集合中的元素根据键排序的能力。默认是按 key 的升序排序，不过我们也可以指定排序的比较器。示例代码如下：\n\npublic class person {\n    private integer age;\n    public person(integer age) {\n        this.age = age;\n    }\n    public integer getage() {\n        return age;\n    }\n\n    public static void main(string[] args) {\n        treemap<person, string> treemap = new treemap<>(new comparator<person>() {\n            @override\n            public int compare(person person1, person person2) {\n                int num = person1.getage() - person2.getage();\n                return integer.compare(num, 0);\n            }\n        });\n        treemap.put(new person(3), "person1");\n        treemap.put(new person(18), "person2");\n        treemap.put(new person(35), "person3");\n        treemap.put(new person(16), "person4");\n        treemap.entryset().stream().foreach(personstringentry -> {\n            system.out.println(personstringentry.getvalue());\n        });\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n可以看出，treemap 中的元素已经是按照 person 的 age 字段的升序来排列了。\n\n上面，我们是通过传入匿名内部类的方式实现的，你可以将代码替换成 lambda 表达式实现的方式：\n\ntreemap<person, string> treemap = new treemap<>((person1, person2) -> {\n  int num = person1.getage() - person2.getage();\n  return integer.compare(num, 0);\n});\n\n\n1\n2\n3\n4\n\n\n综上，相比于hashmap来说 treemap 主要多了对集合中的元素根据键排序的能力（sortedmap）以及对集合内元素的搜索的能力（navigablemap）。\n\n\n# hashset 如何检查重复?\n\n> 当你把对象加入hashset时，hashset 会先计算对象的hashcode值来判断对象加入的位置，同时也会与其他加入的对象的 hashcode 值作比较，如果没有相符的 hashcode，hashset 会假设对象没有重复出现。但是如果发现有相同 hashcode 值的对象，这时会调用equals()方法来检查 hashcode 相等的对象是否真的相同。如果两者相同，hashset 就不会让加入操作成功。\n\n直接看一下hashset中的源码：\n\n在 jdk1.8 中，实际上无论 hashset 中是否已经存在了某元素，hashset 都会直接插入，只是会在 add() 方法的返回值处告诉我们插入前是否存在相同元素\n\n// returns: true if this set did not already contain the specified element\n// 返回值：当 set 中没有包含 add 的元素时返回真\npublic boolean add(e e) {\n        return map.put(e, present)==null;\n}\n\n\n1\n2\n3\n4\n5\n\n\nhashset 通过 hashmap 的键的唯一性来实现对元素的重复检查。在 hashset 中，元素被存储为 hashmap 的键，而值都是固定的一个常量对象。当我们向 hashset 添加元素时，实际上是将这个元素作为键，常量对象作为对应的值存储在 hashmap 中。\n\n在 hashmap 中，键是唯一的，这意味着当我们尝试将相同的元素作为键添加到 hashmap 中时，新的元素会覆盖掉旧的元素。因此，当我们向 hashset 添加元素时，实际上是在利用 hashmap 的去重特性来保证 hashset 中的元素唯一性。\n\n例如，考虑以下代码：\n\nhashset<integer> set = new hashset<>();\nset.add(1);\nset.add(2);\nset.add(3);\nset.add(1);  // 尝试添加重复元素\nsystem.out.println(set.size());  // 输出为 3，因为重复元素被去重\n\n\n1\n2\n3\n4\n5\n6\n\n\n在上述示例中，尝试向 hashset 中添加重复的元素 1 时，并没有导致 hashset 中出现重复元素，这是因为 hashset 利用了 hashmap 的键唯一性来进行去重。\n\n因此，hashset 能够自动检查并防止重复元素的存在。\n\n\n# hashmap的底层实现\n\n\n# jdk1.8 之前\n\njdk1.8 之前 hashmap 底层是 数组和链表 结合在一起使用也就是 链表散列。hashmap 通过 key 的 hashcode 经过扰动函数（hash方法）处理过后得到 hash 值，然后通过 (n - 1) & hash 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 hash 值以及 key 是否相同，如果相同的话，直接覆盖，不相同就通过拉链法（数组+链表）解决冲突。\n\n\n# jdk1.8 之后\n\n相比于之前的版本， jdk1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。\n\n> treemap、treeset 以及 jdk1.8 之后的 hashmap 底层都用到了红黑树。红黑树就是为了解决二叉查找树的缺陷，因为二叉查找树在某些情况下会退化成一个线性结构。\n\n\n# jdk1.7和jdk1.8的hash方法源码对比：\n\n 1. jdk 1.8 的 hash 方法 （运用了三目运算符）相比于 jdk 1.7 hash 方法更加简化，但是原理不变；\n 2. jdk 1.7 的 hash 方法的性能会稍差一点点，因为扰动了 4 次\n\n使用扰动函数（hash方法）之后可以减少碰撞\n\n\n# hashmap 的长度为什么是 2 的幂次方\n\n这是因为 hashmap 在计算 key 的哈希值后，需要通过哈希值和数组长度计算出该 key 在数组中的位置。\n\n具体的计算方式是 (n - 1) & hash（数组的长度减一的差和 key 的哈希值相与），其中 n 是数组的长度，hash 是 key 的哈希值。\n\n这个计算方式的作用是将哈希值的高位和低位进行一次异或运算，得到 key 在数组中的位置。 如果数组的长度不是 2 的幂次方，那么在计算 (n - 1) & hash 时，得到的结果可能会存在一些哈希值无法均匀分布到数组中的位置的情况，从而导致某些位置上的链表或红黑树会变得过长，影响 hashmap 的性能。因此，为了避免这种情况的发生，hashmap 的长度总是保持为 2 的幂次方。 另外，对于长度为 2 的幂次方的数组，计算 (n - 1) & hash 时，等价于对数组长度取模，这种计算方式的效率比较高，而且可以保证均匀分布。因此，hashmap 采用长度为 2 的幂次方的数组，可以提高 hashmap 的性能和效率。\n\n\n# hashmap 多线程操作导致死循环问题\n\n在多线程环境下，如果多个线程同时对 hashmap 进行操作，可能会导致 hashmap 的链表或红黑树出现环形，从而导致死循环问题。这种问题通常发生在以下情况下：\n\n 1. 多个线程同时调用 put() 方法，导致链表或红黑树的结构发生变化，从而导致链表或红黑树出现环形。\n 2. 多个线程同时调用 resize() 方法，导致数组扩容时链表或红黑树的结构发生变化，从而导致链表或红黑树出现环形。 当出现链表或红黑树环形时，会导致 hashmap 的遍历操作进入死循环，从而影响程序的性能和可靠性。\n\n为了解决这个问题，可以采用以下几种方式：\n\n 1. 使用线程安全的 concurrenthashmap，它是线程安全的 hashmap，可以安全地在多线程环境下进行操作。\n 2. 对于需要在多线程环境下使用 hashmap 的情况，可以使用锁来保证同一时间只有一个线程能够对 hashmap 进行操作。\n 3. 避免多个线程同时对 hashmap 进行操作，可以将对 hashmap 的操作放在同步块中，确保同一时间只有一个线程能够对 hashmap 进行修改。\n 4. 通过使用线程安全的并发数据结构，例如 concurrentlinkedqueue、concurrenthashmap 等，避免在多线程环境下使用 hashmap。\n\n\n# hashmap 有哪几种常见的遍历方式?\n\nhashmap 的 7 种遍历方式与性能分析！\n\n\n# concurrenthashmap 和 hashtable 的区别\n\nconcurrenthashmap 和 hashtable 都是线程安全的集合类，但是它们在实现和性能上有一些区别：\n\n 1. 底层数据结构：\n    * jdk1.7 的 concurrenthashmap 底层采用 分段的数组+链表 实现，jdk1.8 采用的数据结构跟 hashmap1.8 的结构一样，数组+链表/红黑二叉树。\n    * hashtable 和 jdk1.8 之前的 hashmap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 hashmap 的主体，链表则是主要为了解决哈希冲突而存在的；\n 2. 实现线程安全的方式（重要）：\n\n * 在 jdk1.7 的时候，concurrenthashmap 对整个桶数组进行了分割分段(segment，分段锁)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。\n * 到了 jdk1.8 的时候，concurrenthashmap 已经摒弃了 segment 的概念，而是直接用 node 数组+链表 / 红黑树的数据结构来实现，并发控制使用 synchronized 和 cas 来操作。（jdk1.6 以后 synchronized 锁做了很多优化） 整个看起来就像是优化过且线程安全的 hashmap，虽然在 jdk1.8 中还能看到 segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；\n * hashtable(同一把锁): 使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。\n\n 3. 对 null 值的支持不同：\n    \n    * hashtable 不允许 key 为 null，\n    * 而 concurrenthashmap 则**（ jdk7 时）**允许 key 和 value 均为 null，jdk8 后不再允许（因为使用了 cas -- 保证线程安全的，对 null 值的支持发生了变化）。\n\n 4. 扩容机制不同：hashtable 在扩容时使用的是原来容量的 2 倍加 1，而 concurrenthashmap 在扩容时采用的则是分段锁技术，当一个段需要进行扩容时，只需要锁定这个段，而不需要锁定整个哈希表。\n    \n    > concurrenthashmap 在设计上更加注重并发性能，通过分段锁来减小锁粒度，而不是仅对一个段进行扩容。\n\n\n# concurrenthashmap 线程安全底层具体实现\n\n\n# jdk1.8 之前\n\nconcurrenthashmap 是由 segment 数组结构和 hashentry 数组结构组成。\n\nsegment 继承了 reentrantlock,所以 segment 是一种可重入锁，扮演锁的角色。hashentry 用于存储键值对数据。\n\n一个 concurrenthashmap 里包含一个 segment 数组，segment 的个数一旦初始化就不能改变。 segment 数组的大小默认是 16，也就是说默认可以同时支持 16 个线程并发写。\n\nsegment 的结构和 hashmap 类似，是一种数组和链表结构，一个 segment 包含一个 hashentry 数组，每个 hashentry 是一个链表结构的元素，每个 segment 守护着一个 hashentry 数组里的元素，当对 hashentry 数组的数据进行修改时，必须首先获得对应的 segment 的锁。也就是说，对同一 segment 的并发写入会被阻塞，不同 segment 的写入是可以并发执行的。\n\n\n# jdk1.8 之后\n\n * java 8 几乎完全重写了 concurrenthashmap，代码量从原来 java 7 中的 1000 多行，变成了现在的 6000 多行。\n * concurrenthashmap 取消了 segment 分段锁，采用 node + cas + synchronized 来保证并发安全。数据结构跟 hashmap 1.8 的结构类似，数组+链表/红黑二叉树。java 8 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 o(n)）转换为红黑树（寻址时间复杂度为 o(log(n))）。\n * java 8 中，锁粒度更细，synchronized 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 node 的读写，效率大幅提升。\n\n\n# 锁粒度解析\n\n锁粒度指的是锁定的范围大小，通常分为粗粒度锁和细粒度锁两种类型。\n\n 1. 粗粒度锁 粗粒度锁指的是锁定范围较大的锁，通常是对整个对象或整个方法进行加锁。粗粒度锁的优点是实现简单，易于控制，缺点是锁定范围太大，会导致并发性能下降，降低程序的并发度。\n 2. 细粒度锁 细粒度锁指的是锁定范围较小的锁，通常是对对象中的某个属性或某一段代码进行加锁。细粒度锁的优点是锁定范围小，可以提高程序的并发度，缺点是实现复杂，容易出现死锁等问题。\n\n在实际开发中，应该根据实际情况选择合适的锁粒度。如果锁的范围太大，会导致并发性能下降，如果锁的范围太小，会增加锁的竞争，降低程序的并发度。可以通过压力测试等方式来确定合适的锁粒度。\n\n\n# jdk 1.7 和 jdk 1.8 的 concurrenthashmap 实现有什么不同？\n\n线程安全实现方式 ：\n\n * jdk 1.7 采用 segment 分段锁来保证安全， segment 是继承自 reentrantlock。\n * jdk1.8 放弃了 segment 分段锁的设计，采用 node + cas + synchronized 保证线程安全，锁粒度更细，synchronized 只锁定当前链表或红黑二叉树的首节点。\n\nhash 碰撞解决方法 :\n\n * jdk 1.7 采用拉链法，\n * jdk1.8 采用拉链法结合红黑树（链表长度超过一定阈值时，将链表转换为红黑树）。\n\n并发度 ：\n\n * jdk 1.7 最大并发度是 segment 的个数，默认是 16。\n * jdk 1.8 最大并发度是 node 数组的大小，并发度更大。\n\n\n# 为什么 hashmap 链表转红黑树的阈值为 8 呢？\n\n这是一个经验性的设定。这个设定是为了在哈希表中维护合适的性能和空间开销之间找到平衡。\n\n选择 8 是基于一系列性能测试和实际应用场景得出的。当链表长度超过这个阈值时，链表的查找性能可能会下降，而转换为红黑树可以提高性能。然而，如果链表长度较短，转换为红黑树可能会带来额外的开销，所以选择一个合适的阈值是一个权衡。\n\n\n# hashmap 的扩容机制了解吗？\n\n了解。当 hashmap 中的元素数量达到一定阈值时，就会触发扩容操作，以保持哈希桶的负载因子在一个合适的范围内，从而减少哈希冲突，提高查找、插入和删除的性能。\n\nhashmap 的扩容机制主要包括以下 3 个步骤：\n\n 1. 创建新的哈希桶数组：当 hashmap 中的元素数量达到阈值时，创建一个新的数组，其大小是原数组的两倍。\n 2. 将旧数据转移到新数组：遍历旧的哈希桶数组中的每个元素，将其重新计算哈希值后放入新的哈希桶数组中。这是一个耗时操作，但只需要进行一次。\n 3. 更新引用：将 hashmap 的哈希桶数组引用指向新的数组，同时更新阈值等信息。\n\n扩容操作会在 hashmap 的插入操作中触发，具体的触发时机是当元素数量超过了负载因子乘以当前数组容量时。默认情况下，负载因子为 0.75，即当元素数量超过当前数组容量的 75% 时，会触发扩容。\n\n\n# 扩容在什么时候呢？为什么扩容因子是 0.75？\n\nhashmap 在进行扩容的时候，通常是当当前容器中的元素数量超过了容器大小的 75% 时触发扩容操作。\n\n这个扩容因子（load factor）的选择是为了在空间和时间上达到一个平衡，从而保证 hashmap 在不至于浪费过多内存的情况下，仍能保持较低的哈希冲突，提供高效的查找、插入和删除操作。\n\n为什么扩容因子选择 0.75 呢？\n\n这是一个折中的选择，考虑了时间和空间的平衡。如果扩容因子设置得太小，会导致哈希冲突过多，影响了 hashmap 的性能；如果设置得太大，虽然哈希冲突可能减少，但是会导致 hashmap 占用更多的内存空间。\n\n\n# 为什么是 2 倍？\n\n使用 2 的次幂作为数组的容量可以确保 hashcode 的高位和低位能够更好地均匀分布在数组的索引位置上。这样一来，在计算元素存放位置时，只需要进行位运算，而不需要使用取模等耗时的操作，提高了计算效率。\n\n另外，使用 2 的次幂作为容量也方便进行扩容操作，因为 2 的次幂的二进制表示只有一个 1，这样在扩容时只需要将高位多出的 1 变为 0，就可以得到新的容量。这种设计可以减少内存空间的浪费。\n\n总的来说就是：\n\n * 这样设计在计算元素存放位置时可以提高计算效率；\n * 在进行扩容时可以减少内存空间的浪费。\n * 既提高了效率又减少了时间。\n\n> 高位是在左边',charsets:{cjk:!0}},{title:"Java并发基础小结",frontmatter:{title:"Java并发基础小结",date:"2023-06-12T22:24:58.000Z",permalink:"/pages/846d88/",author:{name:"陌上清风",link:"https://msqfx.github.io"},categories:["java","并发篇"],tags:[null],description:"进程是系统运行程序的基本单位，我们计算机启动的每一个应用程序都是一个进程。如下图所示，在 Windows 中这一个个 exe 文件，都是一个进程。而在 JVM 下，每一个启动的 Main 方法都可以看作一个进程。",comment:!0,meta:[{name:"image",content:"https://cmty256.github.io/imgs-blog/Java/image.1nbsrx7zj5ds.webp"},{name:"twitter:title",content:"Java并发基础小结"},{name:"twitter:description",content:"进程是系统运行程序的基本单位，我们计算机启动的每一个应用程序都是一个进程。如下图所示，在 Windows 中这一个个 exe 文件，都是一个进程。而在 JVM 下，每一个启动的 Main 方法都可以看作一个进程。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://cmty256.github.io/imgs-blog/Java/image.1nbsrx7zj5ds.webp"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/01.Java%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Java并发基础小结"},{property:"og:description",content:"进程是系统运行程序的基本单位，我们计算机启动的每一个应用程序都是一个进程。如下图所示，在 Windows 中这一个个 exe 文件，都是一个进程。而在 JVM 下，每一个启动的 Main 方法都可以看作一个进程。"},{property:"og:image",content:"https://cmty256.github.io/imgs-blog/Java/image.1nbsrx7zj5ds.webp"},{property:"og:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/01.Java%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-06-12T22:24:58.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"Java并发基础小结"},{itemprop:"description",content:"进程是系统运行程序的基本单位，我们计算机启动的每一个应用程序都是一个进程。如下图所示，在 Windows 中这一个个 exe 文件，都是一个进程。而在 JVM 下，每一个启动的 Main 方法都可以看作一个进程。"},{itemprop:"image",content:"https://cmty256.github.io/imgs-blog/Java/image.1nbsrx7zj5ds.webp"}],readingShow:"top"},regularPath:"/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/01.Java%E5%B9%B6%E5%8F%91%E5%9F%BA%E7%A1%80%E5%B0%8F%E7%BB%93.html",relativePath:"01.java/03.并发篇/01.Java并发基础小结.md",key:"v-6bd8e8aa",path:"/pages/846d88/",headers:[{level:2,title:"线程和进程的区别",slug:"线程和进程的区别",normalizedTitle:"线程和进程的区别",charIndex:17},{level:3,title:"什么是进程？",slug:"什么是进程",normalizedTitle:"什么是进程？",charIndex:30},{level:3,title:"什么是线程？",slug:"什么是线程",normalizedTitle:"什么是线程？",charIndex:151},{level:3,title:"区别",slug:"区别",normalizedTitle:"区别",charIndex:23},{level:2,title:"堆和方法区了解吗？",slug:"堆和方法区了解吗",normalizedTitle:"堆和方法区了解吗？",charIndex:687},{level:2,title:"并发与并行的区别",slug:"并发与并行的区别",normalizedTitle:"并发与并行的区别",charIndex:814},{level:2,title:"同步和异步的区别",slug:"同步和异步的区别",normalizedTitle:"同步和异步的区别",charIndex:903},{level:2,title:"为什么要使用多线程?",slug:"为什么要使用多线程",normalizedTitle:"为什么要使用多线程?",charIndex:991},{level:2,title:"说说线程的生命周期和状态？",slug:"说说线程的生命周期和状态",normalizedTitle:"说说线程的生命周期和状态？",charIndex:1223},{level:2,title:"如何创建一个线程？",slug:"如何创建一个线程",normalizedTitle:"如何创建一个线程？",charIndex:2033},{level:2,title:"什么是线程上下文切换?",slug:"什么是线程上下文切换",normalizedTitle:"什么是线程上下文切换?",charIndex:3398},{level:2,title:"sleep() 和 wait() 方法对比",slug:"sleep-和-wait-方法对比",normalizedTitle:"sleep() 和 wait() 方法对比",charIndex:3903},{level:3,title:"共同点",slug:"共同点",normalizedTitle:"共同点",charIndex:3929},{level:3,title:"区别",slug:"区别-2",normalizedTitle:"区别",charIndex:23},{level:2,title:"为什么 wait() 方法不定义在 Thread 中？",slug:"为什么-wait-方法不定义在-thread-中",normalizedTitle:"为什么 wait() 方法不定义在 thread 中？",charIndex:4230},{level:3,title:"什么是对象锁",slug:"什么是对象锁",normalizedTitle:"什么是对象锁",charIndex:4799},{level:2,title:"为什么 sleep() 方法定义在 Thread 中？",slug:"为什么-sleep-方法定义在-thread-中",normalizedTitle:"为什么 sleep() 方法定义在 thread 中？",charIndex:4977},{level:2,title:"可以直接调用 Thread 类的 run 方法吗？",slug:"可以直接调用-thread-类的-run-方法吗",normalizedTitle:"可以直接调用 thread 类的 run 方法吗？",charIndex:5051},{level:2,title:"守护线程了解吗？",slug:"守护线程了解吗",normalizedTitle:"守护线程了解吗？",charIndex:5362},{level:2,title:"讲一下 JMM(Java 内存模型)",slug:"讲一下-jmm-java-内存模型",normalizedTitle:"讲一下 jmm(java 内存模型)",charIndex:5684},{level:2,title:"AQS",slug:"aqs",normalizedTitle:"aqs",charIndex:6521},{level:3,title:"什么是 AQS",slug:"什么是-aqs",normalizedTitle:"什么是 aqs",charIndex:6529},{level:3,title:"AQS 原理了解么？",slug:"aqs-原理了解么",normalizedTitle:"aqs 原理了解么？",charIndex:6640},{level:3,title:"用过 CountDownLatch 么？什么场景下用的？",slug:"用过-countdownlatch-么-什么场景下用的",normalizedTitle:"用过 countdownlatch 么？什么场景下用的？",charIndex:6813},{level:2,title:"参考文献",slug:"参考文献",normalizedTitle:"参考文献",charIndex:7415}],headersStr:"线程和进程的区别 什么是进程？ 什么是线程？ 区别 堆和方法区了解吗？ 并发与并行的区别 同步和异步的区别 为什么要使用多线程? 说说线程的生命周期和状态？ 如何创建一个线程？ 什么是线程上下文切换? sleep() 和 wait() 方法对比 共同点 区别 为什么 wait() 方法不定义在 Thread 中？ 什么是对象锁 为什么 sleep() 方法定义在 Thread 中？ 可以直接调用 Thread 类的 run 方法吗？ 守护线程了解吗？ 讲一下 JMM(Java 内存模型) AQS 什么是 AQS AQS 原理了解么？ 用过 CountDownLatch 么？什么场景下用的？ 参考文献",content:'# Java并发基础小结\n\n\n# 线程和进程的区别\n\n\n# 什么是进程？\n\n进程是系统运行程序的基本单位，我们计算机启动的每一个应用程序都是一个进程。如下图所示，在 Windows 中这一个个 exe 文件，都是一个进程。而在 JVM 下，每一个启动的 Main 方法都可以看作一个进程。\n\n\n\n\n# 什么是线程？\n\n线程是一个比进程更小的执行单位，是 CPU 调度的基本单位。一个进程在其执行的过程中可以产生多个线程。所以在进行线程切换时的开销会远远小于进程，线程也常常被称为轻量级进程。\n\n与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈。\n\n\n# 区别\n\n 1. 线程是轻量级的执行单元，而进程是重量级的执行单元。在 Java 中，线程由 Java 虚拟机来创建和管理，一个进程可以包含多个线程。\n 2. 线程共享进程的内存空间和资源，可以通过共享内存来进行通信和同步。进程拥有自己的内存空间和资源，需要通过进程间通信（IPC）来进行通信和同步。\n 3. 线程之间的切换开销比进程小，因为线程共享进程的资源，不需要切换进程的内存空间和资源。线程之间的切换只需要切换线程的执行上下文即可。\n 4. 线程之间的同步和通信比进程更容易，因为线程之间共享进程的内存空间，可以直接共享数据和对象。而进程之间需要通过 IPC 机制来进行通信和同步，开销较大。\n 5. 线程的生命周期受到进程的影响，一个进程退出时，它包含的所有线程都会被强制退出。而进程的生命周期不受其他进程的影响，一个进程可以独立于其他进程运行。\n\n\n# 堆和方法区了解吗？\n\n堆和方法区是所有线程共享的资源。\n\n * 其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (几乎所有对象都在这里分配内存)，\n * 方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n\n\n# 并发与并行的区别\n\n * 并发：两个及两个以上的作业在同一 时间段 内执行。\n * 并行：两个及两个以上的作业在同一 时刻 执行。\n\n最关键的点是：是否是 同时 执行。\n\n\n# 同步和异步的区别\n\n * 同步：发出一个调用之后，在没有得到结果之前， 该调用就不可以返回，一直等待。\n * 异步：调用在发出之后，不用等待返回结果，该调用直接返回。\n\n\n# 为什么要使用多线程?\n\n主要是为了提高程序的性能和并发能力。\n\n * **从计算机底层来说：**线程可以比作是轻量级的进程，是程序执行的最小单位，线程间的切换和调度的成本远远小于进程。另外，多核 CPU 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。\n * **从当代互联网发展趋势来说：**现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。\n\n\n# 说说线程的生命周期和状态？\n\nJava 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态：\n\n 1. NEW: 初始状态，线程被创建出来但没有被调用 start() 。\n 2. RUNNABLE: 运行状态，线程被调用了 start() 等待运行的状态。\n 3. BLOCKED：阻塞状态，需要等待锁释放。\n 4. WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。\n 5. TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。\n 6. TERMINATED：终止状态，表示该线程已经运行完毕。\n\n线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。\n\n具体来说：\n\n 1. 线程创建之后它将处于 **NEW（新建）**状态，\n\n 2. 调用 start() 方法后开始运行，线程这时候处于 **READY（可运行）**状态。\n\n 3. 可运行状态的线程获得了 CPU 时间片（timeslice）后就处于 **RUNNING（运行）**状态。\n    \n    * TIMED_WAITING(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将线程置于 TIMED_WAITING 状态。当超时时间结束后，线程将会返回到 RUNNABLE 状态。\n    * 当线程进入 synchronized 方法/块或者调用 wait 后（被 notify）重新进入 synchronized 方法/块，但是锁被其它线程占有，这个时候线程就会进入 BLOCKED（阻塞） 状态。\n\n 4. 线程在执行完了 run()方法之后将会进入到 TERMINATED（终止） 状态。\n\n\n# 如何创建一个线程？\n\n常见的有 5 种方式：\n\n 1. 继承 Thread 类： 这是一种比较传统的创建线程的方式。你可以创建一个类，继承自 Thread 类，并重写 run 方法来定义线程的执行逻辑。\n\nclass MyThread extends Thread {\n    @Override\n    public void run() {\n        // 线程的执行逻辑\n    }\n}\n\n// 创建并启动线程\nMyThread thread = new MyThread();\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n 2. 实现 Runnable 接口：这种方式更常用，它避免了 Java 的单继承限制，你可以实现 Runnable 接口，然后将其实例作为参数传递给 Thread 构造函数。\n\nclass MyRunnable implements Runnable {\n    @Override\n    public void run() {\n        // 线程的执行逻辑\n    }\n}\n\n// 创建并启动线程\nThread thread = new Thread(new MyRunnable());\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n 3. 使用匿名内部类：你可以在创建线程时使用匿名内部类，实现 Runnable 接口的 run 方法。\n\nThread thread = new Thread(new Runnable() {\n    @Override\n    public void run() {\n        // 线程的执行逻辑\n    }\n});\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n\n 4. 使用 Java 8 的 Lambda 表达式：如果 Runnable 接口只有一个抽象方法，你可以使用 Lambda 表达式简化代码。\n\nThread thread = new Thread(() -> {\n    // 线程的执行逻辑\n});\nthread.start();\n\n\n1\n2\n3\n4\n\n 5. 实现 Callable 接口： Callable 接口允许线程返回结果或抛出异常。需要通过 ExecutorService 来执行。\n\nclass MyCallable implements Callable<String> {\n    @Override\n    public String call() throws Exception {\n        // 线程的执行逻辑\n        return "Hello from Callable";\n    }\n}\n\nExecutorService executor = Executors.newFixedThreadPool(1);\nFuture<String> future = executor.submit(new MyCallable());\nString result = future.get(); // 获取线程执行结果\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 什么是线程上下文切换?\n\n线程上下文切换是指：CPU 从一个线程中断执行转而执行另一个线程的过程。\n\n在多线程编程中，线程上下文切换是非常常见的操作。\n\n这个过程需要耗费一定的时间和资源，因此线程上下文切换的频繁发生会导致系统的性能下降。\n\n\n\n> 1、什么是上下文\n\n线程在执行过程中会有自己的运行条件和状态（也称上下文）。\n\n比如程序计数器，栈信息等。当出现如下情况的时候，线程会从占用 CPU 状态中退出。（上下文切换通常发生在以下几种情况）\n\n * 主动让出 CPU，比如调用了 sleep(), wait() 等。\n * 时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。\n * 调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。\n * 被终止或结束运行。\n\n> 2、为了减少线程上下文切换带来的性能损失，可以采取以下措施：\n\n * 减少线程数，避免无谓的上下文切换；\n * 采用线程池技术，避免线程的频繁创建和销毁；\n * 使用非阻塞式 I/O，避免线程等待 I/O 完成时的上下文切换；\n * 优化线程的调度算法，减少线程上下文切换的次数。\n\n\n# sleep() 和 wait() 方法对比\n\n\n# 共同点\n\n两者都可以暂停线程的执行。\n\n\n# 区别\n\n 1. sleep() 方法没有释放锁，而 wait() 方法释放了锁 。\n 2. wait() 通常被用于线程间交互/通信，sleep() 通常被用于暂停执行。\n 3. wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒，或者也可以使用 wait(long timeout) 超时后线程会自动苏醒。\n 4. sleep() 是 Thread 类的静态本地方法，wait() 则是 Object 类的本地方法。\n\n\n# 为什么 wait() 方法不定义在 Thread 中？\n\n因为 wait() 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。\n\n>  * 这句话指出了 wait() 方法的两个关键作用：等待和释放对象锁。\n>  * 当一个线程调用了对象的 wait() 方法，它会进入等待状态，等待其他线程通过 notify() 或 notifyAll() 方法唤醒它。\n>  * 同时，该线程会自动释放它当前占有的对象锁，这使得其他等待这个对象锁的线程有机会获得锁并执行临界区代码。\n\n每个对象（Object）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入 WAITING 状态，自然是要操作对应的对象（Object）而非当前的线程（Thread）。\n\nwait() 方法是针对对象锁进行操作，而不是针对线程本身的操作。\n\n>  * 这句话强调了对象锁是和对象绑定的，而不是与线程绑定的。\n>  * 每个 Java 对象都有一个关联的对象锁（监视器锁），这个锁用于对该对象的同步访问。\n>  * 当线程调用了某个对象的 wait() 方法，它会让出这个对象的锁，让其他线程有机会进入临界区或执行同步代码。\n>  * 释放的是对象锁，而不是当前线程的锁。这也是为什么在使用 wait() 时需要明确调用的是哪个对象的锁。\n\n\n# 什么是对象锁\n\n对象锁是一种多线程同步机制，它用于保护对象的状态和操作，以确保在多线程环境下对象的数据一致性和线程安全性。\n\n在 Java 中，每个对象都有一个关联的对象锁，也称为监视器锁或内置锁。对象锁的作用是防止多个线程同时访问一个对象的临界区代码，从而避免并发访问造成的数据错误和不一致性。\n\n可用 synchronized 关键字来实现。\n\n\n# 为什么 sleep() 方法定义在 Thread 中？\n\n因为 sleep() 是让当前线程暂停执行，不涉及到对象类，也不需要获得对象锁。\n\n\n# 可以直接调用 Thread 类的 run 方法吗？\n\n 1. new 一个 Thread，线程进入了新建状态。\n 2. 调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。\n 3. start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。\n\n但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。\n\n总结：\n\n调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。\n\n\n# 守护线程了解吗？\n\nJava 中的线程分为两类，分别为 daemon 线程（守护线程）和 user 线程（用户线程）。\n\n在 JVM 启动时会调用 main 函数，main 函数所在的线程就是一个用户线程。其实在 JVM 内部同时还启动了很多守护线程，守护线程是用来服务用户线程的线程，比如垃圾回收线程。多用于执行后台任务。\n\n那么守护线程和用户线程有什么区别呢？\n\n区别之一是当最后一个非守护线程束时，JVM 会正常退出，而不管当前是否存在守护线程，也就是说守护线程是否结束并不影响 JVM 退出。换而言之，只要有一个用户线程还没结束，正常情况下 JVM 就不会退出。\n\n简单来说就是用户线程会阻止 JVM 的退出，而守护线程不会。\n\n\n# 讲一下 JMM(Java 内存模型)\n\nJava 内存模型（Java Memory Model，JMM）是 Java 虚拟机规范中的一部分，它定义了 Java 程序中各种变量的访问方式和存储方式。\n\nJMM 的作用是：解决并发编程中的线程安全问题，确保多线程环境下程序的正确性和稳定性。\n\n主要包括以下几个方面：\n\n 1. 主内存和工作内存：Java 内存模型将内存分为主内存和工作内存两部分。\n    \n    * 主内存是所有线程共享的内存区域，而每个线程都有自己的工作内存，工作内存中保存了该线程使用到的变量的副本。\n    \n    * 线程不能直接对主内存进行操作，而是需要先将变量的副本从主内存中读取到工作内存中，然后再对变量进行操作，操作完成后再将变量的副本写回到主内存中。\n\n 2. 内存屏障：内存屏障（Memory Barrier）是一种机制，用于确保线程之间的内存可见性和操作的有序性。\n    \n    * JMM 中定义了四种内存屏障：Load Barrier、Store Barrier、Read Barrier、Write Barrier，分别用于确保变量的读、写和读写操作的顺序和可见性。\n\n 3. happens-before 关系：happens-before 是 Java 内存模型中的一个概念，用于描述变量之间的先后顺序和可见性。\n    \n    * 如果一个操作 happens-before 另一个操作，那么第一个操作的结果对第二个操作是可见的，而且第一个操作的执行顺序在第二个操作之前。\n\n 4. 原子性、可见性和有序性：JMM 保证了原子性、可见性和有序性的内存操作。\n    \n    * 原子性指的是一个操作是不可分割的整体，要么全部执行，要么全部不执行；\n    \n    * 可见性指的是一个线程对变量的修改对其他线程是可见的；\n    \n    * 有序性指的是指令的执行顺序是有序的，保证了程序的正确性。\n\n\n# AQS\n\n\n# 什么是 AQS\n\nAQS，全称为 AbstractQueuedSynchronizer，是 Java 并发编程中的一个重要组件。\n\n它提供了一种灵活的框架，可以用来实现各种同步工具，比如锁、信号量、倒计时门栓等。\n\n\n# AQS 原理了解么？\n\nAQS 的核心思想是使用一个 FIFO 的等待队列来管理线程的获取和释放资源。\n\nAQS 维护一个 state 变量，用来表示同步状态，同时通过一个双向链表来实现等待队列，并提供了 acquire、release、tryAcquire、tryRelease 等方法，允许子类通过重写这些方法来实现特定的同步逻辑。\n\n\n# 用过 CountDownLatch 么？什么场景下用的？\n\n> 概念\n\nCountDownLatch 是 Java 并发编程中的一个同步工具，它允许一个或多个线程等待其他线程完成操作后再执行。\n\n> 原理\n\nCountDownLatch 的核心思想是：通过一个计数器来实现，计数器初始值为线程数，每个线程完成操作后会将计数器 -1，当计数器减为 0 时，所有等待的线程都会被唤醒。\n\n> 用法\n\nCountDownLatch 的用法如下：\n\n 1. 创建 CountDownLatch 对象，并指定计数器的初始值。\n 2. 各个线程执行任务，并在任务完成后调用 CountDownLatch 的 countDown 方法，将计数器 -1。\n 3. 主线程调用 CountDownLatch 的 await 方法，等待所有任务完成。\n\n> 应用场景\n\nCountDownLatch 的应用场景包括：\n\n 1. 主线程等待多个子线程完成任务后再执行，可以使用 CountDownLatch 来实现。\n 2. 一些任务需要等待其他任务完成后才能执行，可以使用 CountDownLatch 来实现。\n 3. 测试场景中，可以使用 CountDownLatch 来控制测试用例的执行顺序。\n 4. 多个线程并发执行，需要等待所有线程完成后再进行合并操作，可以使用 CountDownLatch 来实现。\n\n\n# 参考文献\n\n * Java并发常见面试题总结（上）\n * 面渣逆袭（Java并发编程面试题八股文）必看👍',normalizedContent:'# java并发基础小结\n\n\n# 线程和进程的区别\n\n\n# 什么是进程？\n\n进程是系统运行程序的基本单位，我们计算机启动的每一个应用程序都是一个进程。如下图所示，在 windows 中这一个个 exe 文件，都是一个进程。而在 jvm 下，每一个启动的 main 方法都可以看作一个进程。\n\n\n\n\n# 什么是线程？\n\n线程是一个比进程更小的执行单位，是 cpu 调度的基本单位。一个进程在其执行的过程中可以产生多个线程。所以在进行线程切换时的开销会远远小于进程，线程也常常被称为轻量级进程。\n\n与进程不同的是同类的多个线程共享进程的堆和方法区资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈。\n\n\n# 区别\n\n 1. 线程是轻量级的执行单元，而进程是重量级的执行单元。在 java 中，线程由 java 虚拟机来创建和管理，一个进程可以包含多个线程。\n 2. 线程共享进程的内存空间和资源，可以通过共享内存来进行通信和同步。进程拥有自己的内存空间和资源，需要通过进程间通信（ipc）来进行通信和同步。\n 3. 线程之间的切换开销比进程小，因为线程共享进程的资源，不需要切换进程的内存空间和资源。线程之间的切换只需要切换线程的执行上下文即可。\n 4. 线程之间的同步和通信比进程更容易，因为线程之间共享进程的内存空间，可以直接共享数据和对象。而进程之间需要通过 ipc 机制来进行通信和同步，开销较大。\n 5. 线程的生命周期受到进程的影响，一个进程退出时，它包含的所有线程都会被强制退出。而进程的生命周期不受其他进程的影响，一个进程可以独立于其他进程运行。\n\n\n# 堆和方法区了解吗？\n\n堆和方法区是所有线程共享的资源。\n\n * 其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (几乎所有对象都在这里分配内存)，\n * 方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n\n\n# 并发与并行的区别\n\n * 并发：两个及两个以上的作业在同一 时间段 内执行。\n * 并行：两个及两个以上的作业在同一 时刻 执行。\n\n最关键的点是：是否是 同时 执行。\n\n\n# 同步和异步的区别\n\n * 同步：发出一个调用之后，在没有得到结果之前， 该调用就不可以返回，一直等待。\n * 异步：调用在发出之后，不用等待返回结果，该调用直接返回。\n\n\n# 为什么要使用多线程?\n\n主要是为了提高程序的性能和并发能力。\n\n * **从计算机底层来说：**线程可以比作是轻量级的进程，是程序执行的最小单位，线程间的切换和调度的成本远远小于进程。另外，多核 cpu 时代意味着多个线程可以同时运行，这减少了线程上下文切换的开销。\n * **从当代互联网发展趋势来说：**现在的系统动不动就要求百万级甚至千万级的并发量，而多线程并发编程正是开发高并发系统的基础，利用好多线程机制可以大大提高系统整体的并发能力以及性能。\n\n\n# 说说线程的生命周期和状态？\n\njava 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态：\n\n 1. new: 初始状态，线程被创建出来但没有被调用 start() 。\n 2. runnable: 运行状态，线程被调用了 start() 等待运行的状态。\n 3. blocked：阻塞状态，需要等待锁释放。\n 4. waiting：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。\n 5. time_waiting：超时等待状态，可以在指定的时间后自行返回而不是像 waiting 那样一直等待。\n 6. terminated：终止状态，表示该线程已经运行完毕。\n\n线程在生命周期中并不是固定处于某一个状态而是随着代码的执行在不同状态之间切换。\n\n具体来说：\n\n 1. 线程创建之后它将处于 **new（新建）**状态，\n\n 2. 调用 start() 方法后开始运行，线程这时候处于 **ready（可运行）**状态。\n\n 3. 可运行状态的线程获得了 cpu 时间片（timeslice）后就处于 **running（运行）**状态。\n    \n    * timed_waiting(超时等待) 状态相当于在等待状态的基础上增加了超时限制，比如通过 sleep（long millis）方法或 wait（long millis）方法可以将线程置于 timed_waiting 状态。当超时时间结束后，线程将会返回到 runnable 状态。\n    * 当线程进入 synchronized 方法/块或者调用 wait 后（被 notify）重新进入 synchronized 方法/块，但是锁被其它线程占有，这个时候线程就会进入 blocked（阻塞） 状态。\n\n 4. 线程在执行完了 run()方法之后将会进入到 terminated（终止） 状态。\n\n\n# 如何创建一个线程？\n\n常见的有 5 种方式：\n\n 1. 继承 thread 类： 这是一种比较传统的创建线程的方式。你可以创建一个类，继承自 thread 类，并重写 run 方法来定义线程的执行逻辑。\n\nclass mythread extends thread {\n    @override\n    public void run() {\n        // 线程的执行逻辑\n    }\n}\n\n// 创建并启动线程\nmythread thread = new mythread();\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n 2. 实现 runnable 接口：这种方式更常用，它避免了 java 的单继承限制，你可以实现 runnable 接口，然后将其实例作为参数传递给 thread 构造函数。\n\nclass myrunnable implements runnable {\n    @override\n    public void run() {\n        // 线程的执行逻辑\n    }\n}\n\n// 创建并启动线程\nthread thread = new thread(new myrunnable());\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n 3. 使用匿名内部类：你可以在创建线程时使用匿名内部类，实现 runnable 接口的 run 方法。\n\nthread thread = new thread(new runnable() {\n    @override\n    public void run() {\n        // 线程的执行逻辑\n    }\n});\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n\n 4. 使用 java 8 的 lambda 表达式：如果 runnable 接口只有一个抽象方法，你可以使用 lambda 表达式简化代码。\n\nthread thread = new thread(() -> {\n    // 线程的执行逻辑\n});\nthread.start();\n\n\n1\n2\n3\n4\n\n 5. 实现 callable 接口： callable 接口允许线程返回结果或抛出异常。需要通过 executorservice 来执行。\n\nclass mycallable implements callable<string> {\n    @override\n    public string call() throws exception {\n        // 线程的执行逻辑\n        return "hello from callable";\n    }\n}\n\nexecutorservice executor = executors.newfixedthreadpool(1);\nfuture<string> future = executor.submit(new mycallable());\nstring result = future.get(); // 获取线程执行结果\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 什么是线程上下文切换?\n\n线程上下文切换是指：cpu 从一个线程中断执行转而执行另一个线程的过程。\n\n在多线程编程中，线程上下文切换是非常常见的操作。\n\n这个过程需要耗费一定的时间和资源，因此线程上下文切换的频繁发生会导致系统的性能下降。\n\n\n\n> 1、什么是上下文\n\n线程在执行过程中会有自己的运行条件和状态（也称上下文）。\n\n比如程序计数器，栈信息等。当出现如下情况的时候，线程会从占用 cpu 状态中退出。（上下文切换通常发生在以下几种情况）\n\n * 主动让出 cpu，比如调用了 sleep(), wait() 等。\n * 时间片用完，因为操作系统要防止一个线程或者进程长时间占用 cpu 导致其他线程或者进程饿死。\n * 调用了阻塞类型的系统中断，比如请求 io，线程被阻塞。\n * 被终止或结束运行。\n\n> 2、为了减少线程上下文切换带来的性能损失，可以采取以下措施：\n\n * 减少线程数，避免无谓的上下文切换；\n * 采用线程池技术，避免线程的频繁创建和销毁；\n * 使用非阻塞式 i/o，避免线程等待 i/o 完成时的上下文切换；\n * 优化线程的调度算法，减少线程上下文切换的次数。\n\n\n# sleep() 和 wait() 方法对比\n\n\n# 共同点\n\n两者都可以暂停线程的执行。\n\n\n# 区别\n\n 1. sleep() 方法没有释放锁，而 wait() 方法释放了锁 。\n 2. wait() 通常被用于线程间交互/通信，sleep() 通常被用于暂停执行。\n 3. wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyall() 方法。sleep() 方法执行完成后，线程会自动苏醒，或者也可以使用 wait(long timeout) 超时后线程会自动苏醒。\n 4. sleep() 是 thread 类的静态本地方法，wait() 则是 object 类的本地方法。\n\n\n# 为什么 wait() 方法不定义在 thread 中？\n\n因为 wait() 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。\n\n>  * 这句话指出了 wait() 方法的两个关键作用：等待和释放对象锁。\n>  * 当一个线程调用了对象的 wait() 方法，它会进入等待状态，等待其他线程通过 notify() 或 notifyall() 方法唤醒它。\n>  * 同时，该线程会自动释放它当前占有的对象锁，这使得其他等待这个对象锁的线程有机会获得锁并执行临界区代码。\n\n每个对象（object）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入 waiting 状态，自然是要操作对应的对象（object）而非当前的线程（thread）。\n\nwait() 方法是针对对象锁进行操作，而不是针对线程本身的操作。\n\n>  * 这句话强调了对象锁是和对象绑定的，而不是与线程绑定的。\n>  * 每个 java 对象都有一个关联的对象锁（监视器锁），这个锁用于对该对象的同步访问。\n>  * 当线程调用了某个对象的 wait() 方法，它会让出这个对象的锁，让其他线程有机会进入临界区或执行同步代码。\n>  * 释放的是对象锁，而不是当前线程的锁。这也是为什么在使用 wait() 时需要明确调用的是哪个对象的锁。\n\n\n# 什么是对象锁\n\n对象锁是一种多线程同步机制，它用于保护对象的状态和操作，以确保在多线程环境下对象的数据一致性和线程安全性。\n\n在 java 中，每个对象都有一个关联的对象锁，也称为监视器锁或内置锁。对象锁的作用是防止多个线程同时访问一个对象的临界区代码，从而避免并发访问造成的数据错误和不一致性。\n\n可用 synchronized 关键字来实现。\n\n\n# 为什么 sleep() 方法定义在 thread 中？\n\n因为 sleep() 是让当前线程暂停执行，不涉及到对象类，也不需要获得对象锁。\n\n\n# 可以直接调用 thread 类的 run 方法吗？\n\n 1. new 一个 thread，线程进入了新建状态。\n 2. 调用 start()方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。\n 3. start() 会执行线程的相应准备工作，然后自动执行 run() 方法的内容，这是真正的多线程工作。\n\n但是，直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。\n\n总结：\n\n调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。\n\n\n# 守护线程了解吗？\n\njava 中的线程分为两类，分别为 daemon 线程（守护线程）和 user 线程（用户线程）。\n\n在 jvm 启动时会调用 main 函数，main 函数所在的线程就是一个用户线程。其实在 jvm 内部同时还启动了很多守护线程，守护线程是用来服务用户线程的线程，比如垃圾回收线程。多用于执行后台任务。\n\n那么守护线程和用户线程有什么区别呢？\n\n区别之一是当最后一个非守护线程束时，jvm 会正常退出，而不管当前是否存在守护线程，也就是说守护线程是否结束并不影响 jvm 退出。换而言之，只要有一个用户线程还没结束，正常情况下 jvm 就不会退出。\n\n简单来说就是用户线程会阻止 jvm 的退出，而守护线程不会。\n\n\n# 讲一下 jmm(java 内存模型)\n\njava 内存模型（java memory model，jmm）是 java 虚拟机规范中的一部分，它定义了 java 程序中各种变量的访问方式和存储方式。\n\njmm 的作用是：解决并发编程中的线程安全问题，确保多线程环境下程序的正确性和稳定性。\n\n主要包括以下几个方面：\n\n 1. 主内存和工作内存：java 内存模型将内存分为主内存和工作内存两部分。\n    \n    * 主内存是所有线程共享的内存区域，而每个线程都有自己的工作内存，工作内存中保存了该线程使用到的变量的副本。\n    \n    * 线程不能直接对主内存进行操作，而是需要先将变量的副本从主内存中读取到工作内存中，然后再对变量进行操作，操作完成后再将变量的副本写回到主内存中。\n\n 2. 内存屏障：内存屏障（memory barrier）是一种机制，用于确保线程之间的内存可见性和操作的有序性。\n    \n    * jmm 中定义了四种内存屏障：load barrier、store barrier、read barrier、write barrier，分别用于确保变量的读、写和读写操作的顺序和可见性。\n\n 3. happens-before 关系：happens-before 是 java 内存模型中的一个概念，用于描述变量之间的先后顺序和可见性。\n    \n    * 如果一个操作 happens-before 另一个操作，那么第一个操作的结果对第二个操作是可见的，而且第一个操作的执行顺序在第二个操作之前。\n\n 4. 原子性、可见性和有序性：jmm 保证了原子性、可见性和有序性的内存操作。\n    \n    * 原子性指的是一个操作是不可分割的整体，要么全部执行，要么全部不执行；\n    \n    * 可见性指的是一个线程对变量的修改对其他线程是可见的；\n    \n    * 有序性指的是指令的执行顺序是有序的，保证了程序的正确性。\n\n\n# aqs\n\n\n# 什么是 aqs\n\naqs，全称为 abstractqueuedsynchronizer，是 java 并发编程中的一个重要组件。\n\n它提供了一种灵活的框架，可以用来实现各种同步工具，比如锁、信号量、倒计时门栓等。\n\n\n# aqs 原理了解么？\n\naqs 的核心思想是使用一个 fifo 的等待队列来管理线程的获取和释放资源。\n\naqs 维护一个 state 变量，用来表示同步状态，同时通过一个双向链表来实现等待队列，并提供了 acquire、release、tryacquire、tryrelease 等方法，允许子类通过重写这些方法来实现特定的同步逻辑。\n\n\n# 用过 countdownlatch 么？什么场景下用的？\n\n> 概念\n\ncountdownlatch 是 java 并发编程中的一个同步工具，它允许一个或多个线程等待其他线程完成操作后再执行。\n\n> 原理\n\ncountdownlatch 的核心思想是：通过一个计数器来实现，计数器初始值为线程数，每个线程完成操作后会将计数器 -1，当计数器减为 0 时，所有等待的线程都会被唤醒。\n\n> 用法\n\ncountdownlatch 的用法如下：\n\n 1. 创建 countdownlatch 对象，并指定计数器的初始值。\n 2. 各个线程执行任务，并在任务完成后调用 countdownlatch 的 countdown 方法，将计数器 -1。\n 3. 主线程调用 countdownlatch 的 await 方法，等待所有任务完成。\n\n> 应用场景\n\ncountdownlatch 的应用场景包括：\n\n 1. 主线程等待多个子线程完成任务后再执行，可以使用 countdownlatch 来实现。\n 2. 一些任务需要等待其他任务完成后才能执行，可以使用 countdownlatch 来实现。\n 3. 测试场景中，可以使用 countdownlatch 来控制测试用例的执行顺序。\n 4. 多个线程并发执行，需要等待所有线程完成后再进行合并操作，可以使用 countdownlatch 来实现。\n\n\n# 参考文献\n\n * java并发常见面试题总结（上）\n * 面渣逆袭（java并发编程面试题八股文）必看👍',charsets:{cjk:!0}},{title:"锁详解",frontmatter:{title:"锁详解",date:"2023-06-14T20:16:24.000Z",permalink:"/pages/5a6aca/",author:{name:"陌上清风",link:"https://msqfx.github.io"},categories:["java","并发篇"],tags:[null],description:"线程死锁是指：两个或多个线程互相持有对方所需要的资源而互相等待的状态，导致程序无法继续执行下去，进而陷入死循环，无法完成任务。",comment:!0,meta:[{name:"twitter:title",content:"锁详解"},{name:"twitter:description",content:"线程死锁是指：两个或多个线程互相持有对方所需要的资源而互相等待的状态，导致程序无法继续执行下去，进而陷入死循环，无法完成任务。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/02.%E9%94%81%E8%AF%A6%E8%A7%A3.html"},{property:"og:type",content:"article"},{property:"og:title",content:"锁详解"},{property:"og:description",content:"线程死锁是指：两个或多个线程互相持有对方所需要的资源而互相等待的状态，导致程序无法继续执行下去，进而陷入死循环，无法完成任务。"},{property:"og:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/02.%E9%94%81%E8%AF%A6%E8%A7%A3.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-06-14T20:16:24.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"锁详解"},{itemprop:"description",content:"线程死锁是指：两个或多个线程互相持有对方所需要的资源而互相等待的状态，导致程序无法继续执行下去，进而陷入死循环，无法完成任务。"}],readingShow:"top"},regularPath:"/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/02.%E9%94%81%E8%AF%A6%E8%A7%A3.html",relativePath:"01.java/03.并发篇/02.锁详解.md",key:"v-5a7b351e",path:"/pages/5a6aca/",headers:[{level:2,title:"死锁问题",slug:"死锁问题",normalizedTitle:"死锁问题",charIndex:10},{level:3,title:"什么是线程死锁?",slug:"什么是线程死锁",normalizedTitle:"什么是线程死锁?",charIndex:19},{level:3,title:"死锁产生的原因",slug:"死锁产生的原因",normalizedTitle:"死锁产生的原因",charIndex:97},{level:3,title:"死锁产生的条件",slug:"死锁产生的条件",normalizedTitle:"死锁产生的条件",charIndex:151},{level:3,title:"如何预防死锁？",slug:"如何预防死锁",normalizedTitle:"如何预防死锁？",charIndex:345},{level:3,title:"如何避免死锁？",slug:"如何避免死锁",normalizedTitle:"如何避免死锁？",charIndex:513},{level:2,title:"乐观锁和悲观锁",slug:"乐观锁和悲观锁",normalizedTitle:"乐观锁和悲观锁",charIndex:575},{level:3,title:"什么是乐观锁？",slug:"什么是乐观锁",normalizedTitle:"什么是乐观锁？",charIndex:587},{level:3,title:"什么是悲观锁？",slug:"什么是悲观锁",normalizedTitle:"什么是悲观锁？",charIndex:968},{level:3,title:"如何实现乐观锁？",slug:"如何实现乐观锁",normalizedTitle:"如何实现乐观锁？",charIndex:1252},{level:4,title:"版本控制",slug:"版本控制",normalizedTitle:"版本控制",charIndex:1264},{level:4,title:"CAS 算法",slug:"cas-算法",normalizedTitle:"cas 算法",charIndex:757},{level:3,title:"如何实现悲观锁？",slug:"如何实现悲观锁",normalizedTitle:"如何实现悲观锁？",charIndex:1543},{level:2,title:"学习参考",slug:"学习参考",normalizedTitle:"学习参考",charIndex:2129}],headersStr:"死锁问题 什么是线程死锁? 死锁产生的原因 死锁产生的条件 如何预防死锁？ 如何避免死锁？ 乐观锁和悲观锁 什么是乐观锁？ 什么是悲观锁？ 如何实现乐观锁？ 版本控制 CAS 算法 如何实现悲观锁？ 学习参考",content:"# 锁详解\n\n\n# 死锁问题\n\n\n# 什么是线程死锁?\n\n线程死锁是指：两个或多个线程互相持有对方所需要的资源而互相等待的状态，导致程序无法继续执行下去，进而陷入死循环，无法完成任务。\n\n\n# 死锁产生的原因\n\n通常情况下，线程死锁产生的原因是: 两个或多个线程对资源的竞争和不当的资源分配。\n\n\n# 死锁产生的条件\n\n线程死锁的产生通常需要同时满足以下四个条件：\n\n 1. 互斥条件：该资源任意一个时刻只由一个线程占用。\n 2. 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。\n 3. 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。\n 4. 循环等待条件: 若干线程之间形成一种头尾相接的循环等待资源关系。\n\n\n# 如何预防死锁？\n\n预防死锁只要破坏死锁产生的必要条件即可：\n\n 1. 破坏请求与保持条件：一次性申请所有的资源。\n 2. 破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。\n 3. 破坏循环等待条件：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。\n\n\n# 如何避免死锁？\n\n避免死锁就是在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。\n\n\n# 乐观锁和悲观锁\n\n\n# 什么是乐观锁？\n\n乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源是否被其它线程修改了。\n\n优点\n\n不会造成线程阻塞\n\n缺点\n\n在并发更新的情况下，可能会出现 ABA 问题，需要使用版本号或时间戳等机制来解决。\n\n> ABA 问题是: 在使用 CAS 算法时可能出现的一个问题。\n> \n> 它的本质是: 由于线程之间的竞争，导致共享数据的值在某个时间点被修改为 A，然后又被修改为 B，最后再被修改回 A，\n> \n> 这时候使用 CAS 算法时，比较的是共享数据的值是否等于 A，如果等于 A，则执行操作，但实际上共享数据的值已经被修改过了。\n> \n> 简单来说，就是在使用 CAS 算法的时候发生了误判。\n\n典型代表\n\n比如：使用版本号机制、CAS 算法\n\n\n# 什么是悲观锁？\n\n悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。\n\n优点\n\n安全，能够保证数据操作的正确性和一致性。\n\n缺点\n\n悲观锁的缺点是在高并发的情况下，会造成大量的线程阻塞，降低系统的性能。\n\n典型代表\n\n比如：Java 中 的 synchronized 和 ReentrantLock 等独占锁，数据库中的行级锁和表级锁。\n\n\n# 如何实现乐观锁？\n\n# 版本控制\n\n在操作共享资源之前，先读取数据的版本号，然后将操作结果与当前版本号进行比较，如果版本号一致，则可以进行操作，如果版本号不一致，则说明数据已被其他线程修改，需要回滚并重试。\n\n# CAS 算法\n\nCAS 的全称是 Compare And Swap（比较与交换），用于实现乐观锁，被广泛应用于各大框架中。\n\nCAS 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。\n\n是一个原子操作，底层依赖于一条 CPU 的原子指令。\n\n> 原子操作 即最小不可拆分的操作，也就是说操作一旦开始，就不能被打断，直到操作完成。\n\n\n# 如何实现悲观锁？\n\n悲观锁的实现方式主要有两种：基于数据库的悲观锁和基于代码的悲观锁。\n\n 1. 基于数据库的悲观锁\n    \n    基于数据库的悲观锁是通过数据库的锁机制来实现的。在数据库中，可以通过 SELECT ... FOR UPDATE 语句或 SELECT ... FOR SHARE 语句来获取悲观锁。\n    \n    * 当一个事务执行 SELECT ... FOR UPDATE 语句时，数据库会将所选的行加上排他锁，其他事务不能修改这些行；\n    * 当一个事务执行 SELECT ... FOR SHARE 语句时，数据库会将所选的行加上共享锁，其他事务只能读取这些行，不能修改。在使用完锁后，需要及时释放锁，避免长时间占用数据库资源。\n\n 2. 基于代码的悲观锁\n    \n    基于代码的悲观锁是通过程序代码来实现的。在 Java 中，可以使用 synchronized 关键字或 Lock 接口来实现悲观锁。\n    \n    * 使用 synchronized 关键字时，需要在方法或代码块上加锁，以确保同一时间只有一个线程可以执行这段代码；\n    * 使用 Lock 接口时，需要先获取锁（调用 lock() 方法），然后执行操作，最后释放锁（调用 unlock() 方法），以确保同一时间只有一个线程可以操作共享资源。\n\n\n# 学习参考\n\n * Java并发常见面试题总结（中） | JavaGuide(Java面试 + 学习指南)\n\n * JUC包下各种锁使用详解 | Shark Chili",normalizedContent:"# 锁详解\n\n\n# 死锁问题\n\n\n# 什么是线程死锁?\n\n线程死锁是指：两个或多个线程互相持有对方所需要的资源而互相等待的状态，导致程序无法继续执行下去，进而陷入死循环，无法完成任务。\n\n\n# 死锁产生的原因\n\n通常情况下，线程死锁产生的原因是: 两个或多个线程对资源的竞争和不当的资源分配。\n\n\n# 死锁产生的条件\n\n线程死锁的产生通常需要同时满足以下四个条件：\n\n 1. 互斥条件：该资源任意一个时刻只由一个线程占用。\n 2. 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。\n 3. 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。\n 4. 循环等待条件: 若干线程之间形成一种头尾相接的循环等待资源关系。\n\n\n# 如何预防死锁？\n\n预防死锁只要破坏死锁产生的必要条件即可：\n\n 1. 破坏请求与保持条件：一次性申请所有的资源。\n 2. 破坏不剥夺条件：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。\n 3. 破坏循环等待条件：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。\n\n\n# 如何避免死锁？\n\n避免死锁就是在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。\n\n\n# 乐观锁和悲观锁\n\n\n# 什么是乐观锁？\n\n乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源是否被其它线程修改了。\n\n优点\n\n不会造成线程阻塞\n\n缺点\n\n在并发更新的情况下，可能会出现 aba 问题，需要使用版本号或时间戳等机制来解决。\n\n> aba 问题是: 在使用 cas 算法时可能出现的一个问题。\n> \n> 它的本质是: 由于线程之间的竞争，导致共享数据的值在某个时间点被修改为 a，然后又被修改为 b，最后再被修改回 a，\n> \n> 这时候使用 cas 算法时，比较的是共享数据的值是否等于 a，如果等于 a，则执行操作，但实际上共享数据的值已经被修改过了。\n> \n> 简单来说，就是在使用 cas 算法的时候发生了误判。\n\n典型代表\n\n比如：使用版本号机制、cas 算法\n\n\n# 什么是悲观锁？\n\n悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。\n\n优点\n\n安全，能够保证数据操作的正确性和一致性。\n\n缺点\n\n悲观锁的缺点是在高并发的情况下，会造成大量的线程阻塞，降低系统的性能。\n\n典型代表\n\n比如：java 中 的 synchronized 和 reentrantlock 等独占锁，数据库中的行级锁和表级锁。\n\n\n# 如何实现乐观锁？\n\n# 版本控制\n\n在操作共享资源之前，先读取数据的版本号，然后将操作结果与当前版本号进行比较，如果版本号一致，则可以进行操作，如果版本号不一致，则说明数据已被其他线程修改，需要回滚并重试。\n\n# cas 算法\n\ncas 的全称是 compare and swap（比较与交换），用于实现乐观锁，被广泛应用于各大框架中。\n\ncas 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。\n\n是一个原子操作，底层依赖于一条 cpu 的原子指令。\n\n> 原子操作 即最小不可拆分的操作，也就是说操作一旦开始，就不能被打断，直到操作完成。\n\n\n# 如何实现悲观锁？\n\n悲观锁的实现方式主要有两种：基于数据库的悲观锁和基于代码的悲观锁。\n\n 1. 基于数据库的悲观锁\n    \n    基于数据库的悲观锁是通过数据库的锁机制来实现的。在数据库中，可以通过 select ... for update 语句或 select ... for share 语句来获取悲观锁。\n    \n    * 当一个事务执行 select ... for update 语句时，数据库会将所选的行加上排他锁，其他事务不能修改这些行；\n    * 当一个事务执行 select ... for share 语句时，数据库会将所选的行加上共享锁，其他事务只能读取这些行，不能修改。在使用完锁后，需要及时释放锁，避免长时间占用数据库资源。\n\n 2. 基于代码的悲观锁\n    \n    基于代码的悲观锁是通过程序代码来实现的。在 java 中，可以使用 synchronized 关键字或 lock 接口来实现悲观锁。\n    \n    * 使用 synchronized 关键字时，需要在方法或代码块上加锁，以确保同一时间只有一个线程可以执行这段代码；\n    * 使用 lock 接口时，需要先获取锁（调用 lock() 方法），然后执行操作，最后释放锁（调用 unlock() 方法），以确保同一时间只有一个线程可以操作共享资源。\n\n\n# 学习参考\n\n * java并发常见面试题总结（中） | javaguide(java面试 + 学习指南)\n\n * juc包下各种锁使用详解 | shark chili",charsets:{cjk:!0}},{title:"Synchronized和Volatile的使用与区别",frontmatter:{title:"Synchronized和Volatile的使用与区别",date:"2023-06-14T20:16:57.000Z",permalink:"/pages/e19c5d/",author:{name:"陌上清风",link:"https://msqfx.github.io"},categories:["java","并发篇"],tags:[null],description:"synchronized 是 Java 中的一个关键字，翻译成中文是同步的意思。",comment:!0,meta:[{name:"twitter:title",content:"Synchronized和Volatile的使用与区别"},{name:"twitter:description",content:"synchronized 是 Java 中的一个关键字，翻译成中文是同步的意思。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/03.Synchronized%E5%92%8CVolatile%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%8C%BA%E5%88%AB.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Synchronized和Volatile的使用与区别"},{property:"og:description",content:"synchronized 是 Java 中的一个关键字，翻译成中文是同步的意思。"},{property:"og:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/03.Synchronized%E5%92%8CVolatile%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%8C%BA%E5%88%AB.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-06-14T20:16:57.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"Synchronized和Volatile的使用与区别"},{itemprop:"description",content:"synchronized 是 Java 中的一个关键字，翻译成中文是同步的意思。"}],readingShow:"top"},regularPath:"/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/03.Synchronized%E5%92%8CVolatile%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E5%8C%BA%E5%88%AB.html",relativePath:"01.java/03.并发篇/03.Synchronized和Volatile的使用与区别.md",key:"v-0379b906",path:"/pages/e19c5d/",headers:[{level:2,title:"synchronized 关键字",slug:"synchronized-关键字",normalizedTitle:"synchronized 关键字",charIndex:34},{level:3,title:"什么是 synchronized 关键字？",slug:"什么是-synchronized-关键字",normalizedTitle:"什么是 synchronized 关键字？",charIndex:55},{level:3,title:"构造方法可以用 synchronized 修饰么？",slug:"构造方法可以用-synchronized-修饰么",normalizedTitle:"构造方法可以用 synchronized 修饰么？",charIndex:242},{level:3,title:"synchronized 的底层原理是什么？",slug:"synchronized-的底层原理是什么",normalizedTitle:"synchronized 的底层原理是什么？",charIndex:310},{level:2,title:"volatile 关键字",slug:"volatile-关键字",normalizedTitle:"volatile 关键字",charIndex:573},{level:3,title:"什么是 volatile 关键字？",slug:"什么是-volatile-关键字",normalizedTitle:"什么是 volatile 关键字？",charIndex:590},{level:3,title:"volatile 关键字解决了什么问题？",slug:"volatile-关键字解决了什么问题",normalizedTitle:"volatile 关键字解决了什么问题？",charIndex:685},{level:2,title:"synchronized 和 volatile 有什么区别？",slug:"synchronized-和-volatile-有什么区别",normalizedTitle:"synchronized 和 volatile 有什么区别？",charIndex:1114},{level:2,title:"volatile 的实现原理了解吗？",slug:"volatile-的实现原理了解吗",normalizedTitle:"volatile 的实现原理了解吗？",charIndex:1451},{level:2,title:"说一下你对 Java 内存模型（JMM）的理解？",slug:"说一下你对-java-内存模型-jmm-的理解",normalizedTitle:"说一下你对 java 内存模型（jmm）的理解？",charIndex:2048},{level:2,title:"学习参考",slug:"学习参考",normalizedTitle:"学习参考",charIndex:3284}],headersStr:"synchronized 关键字 什么是 synchronized 关键字？ 构造方法可以用 synchronized 修饰么？ synchronized 的底层原理是什么？ volatile 关键字 什么是 volatile 关键字？ volatile 关键字解决了什么问题？ synchronized 和 volatile 有什么区别？ volatile 的实现原理了解吗？ 说一下你对 Java 内存模型（JMM）的理解？ 学习参考",content:'# Synchronized和Volatile的使用与区别\n\n\n# synchronized 关键字\n\n\n# 什么是 synchronized 关键字？\n\nsynchronized 是 Java 中的一个关键字，翻译成中文是同步的意思。\n\n主要解决的是：多个线程之间访问资源的同步性。可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。\n\n使用方式\n\n使用 synchronized 关键字时，需要在方法或代码块上加锁，以确保同一时间只有一个线程可以执行这段代码；\n\n\n# 构造方法可以用 synchronized 修饰么？\n\n不可以。\n\n因为构造方法本身就属于线程安全的，不存在同步的构造方法一说。\n\n\n# synchronized 的底层原理是什么？\n\n * synchronized 同步语句块时\n   \n   使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。\n\n * synchronized 修饰方法时\n   \n   没有 monitorenter 指令和 monitorexit 指令，取而代之的是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。\n\n\n# volatile 关键字\n\n\n# 什么是 volatile 关键字？\n\nvolatile 关键字是 Java 中用于保证变量可见性和禁止指令重排序优化的一种机制。只能保证单个变量的原子性，不能保证复合操作的原子性。\n\n\n# volatile 关键字解决了什么问题？\n\nvolatile 关键字主要解决了两个问题：可见性问题和指令重排序问题。\n\n 1. 可见性问题\n    \n    在多线程环境下，每个线程都有自己的工作内存，用于存储线程需要使用的变量。当一个线程修改了某个变量的值时，这个变量的值并不会立即被其他线程看到，需要将该变量的值同步到主内存中，其他线程才能看到该变量的最新值。\n    \n    而 volatile 关键字可以保证变量的修改对其他线程可见，从而避免了可见性问题。\n\n 2. 指令重排序问题\n    \n    在多线程环境下，为了提高程序性能，CPU 可能会对指令进行重排序，但指令重排序可能会导致程序出现意想不到的结果。例如，在一个双重检查锁定中，如果不使用 volatile 关键字，可能会导致另一个线程获取到未完全初始化的对象，从而出现问题。\n    \n    而使用 volatile 关键字可以禁止指令重排序优化，保证了程序的正确性。\n\n\n# synchronized 和 volatile 有什么区别？\n\nsynchronized 关键字和 volatile 关键字是两个互补的存在，而不是对立的存在！\n\n * volatile 关键字是线程同步的轻量级实现，所以 volatile 性能肯定比 synchronized 关键字要好 。但是 volatile 关键字只能用于单个变量而 synchronized 关键字可以修饰方法以及代码块。\n * volatile 关键字能保证数据的可见性，但不能保证数据的原子性。synchronized 关键字两者都能保证。\n * volatile 关键字主要用于解决单个变量在多个线程之间的可见性，而 synchronized 关键字解决的是多线程之间的资源同步。\n\n\n# volatile 的实现原理了解吗？\n\n> 先讲下 volatile 是怎么保证可见性的吧\n\nvolatile 可以确保对某个变量的更新对其他线程马上可见，一个变量被声明为 volatile 时，线程在写入变量时不会把值缓存在寄存器或者其他地方，而是会把值刷新回主内存 当其它线程读取该共享变量，会从主内存重新获取最新值，而不是使用当前线程的本地内存中的值。\n\n例如，我们声明一个 volatile 变量 volatile int x = 0，线程 A 修改 x=1，修改完之后就会把新的值刷新回主内存，线程 B 读取 x 的时候，就会清空本地内存变量，然后再从主内存获取最新值。\n\n那线程 B 是怎么知道 x 被修改了的呢？\n\n在 Java 内存模型中，当一个线程修改了 volatile 变量的值，会将这个变量的新值刷新回主内存，并且通知其他线程，告诉它们这个变量的值已经发生了改变。当其他线程（比如线程B）需要读取这个 volatile 变量的值时，它们会从主内存中获取最新的值，而不是从本地内存中读取。\n\n具体来说，当线程 A 修改了 volatile 变量 x 的值为 1，并将新的值刷新回主内存后，主内存会记录这个变化，并在内部维护一个变量版本号。其他线程（如线程 B）在读取 volatile 变量时，会从主内存中获取最新的值，并检查版本号，以确保它们读取的是最新的值。\n\n\n# 说一下你对 Java 内存模型（JMM）的理解？\n\nJava 内存模型（JMM）是一种规范，是一种抽象的模型，用于定义在多线程环境下，线程之间如何与主内存和工作内存进行交互，以及如何保证线程之间的可见性、有序性和原子性。\n\nJMM 主要关注以下几个概念：\n\n 1. **主内存和工作内存：**主内存是所有线程共享的内存区域，而每个线程都有自己的工作内存，工作内存存储了主内存的副本。线程对变量的操作首先在工作内存中进行，然后通过特定的操作将结果同步到主内存。\n 2. **可见性：**JMM 保证一个线程对共享变量的修改对其他线程是可见的。通过 volatile 关键字和 synchronized 关键字等机制，可以确保变量的更新在不同线程间可见。\n 3. **有序性：**JMM 定义了不同操作之间的执行顺序。编译器和处理器可能会对指令重排序，但是 JMM 规定了一些规则来确保程序的执行顺序符合预期。\n 4. **原子性：**JMM 保证一些操作的原子性，如对 volatile 变量的读写操作具有原子性。此外，可以通过 synchronized 关键字或 Lock 机制来保证代码块的原子性。\n\n总的来说，Java 内存模型是为了解决多线程环境下可能出现的可见性、有序性和原子性问题而设计的。它规定了线程之间如何与内存交互，以及如何保证线程安全。了解 JMM 对于编写并发安全的多线程程序至关重要，因为它帮助开发人员理解线程之间的交互规则，从而避免出现意外的并发问题。\n\n为什么对 volatile 变量的读写操作具有原子性？\n\n在 Java 中，对 volatile 变量的读写操作具有原子性，这意味着单个读取或写入 volatile 变量的操作在执行过程中不会被中断，也不会受到其他线程的干扰，从而确保了操作的完整性。\n\n-- 这种特性是由 Java 内存模型（JMM）所规定的。\n\n 1. **内存可见性：**volatile 关键字不仅保证了对变量的修改对其他线程是可见的，还保证了单个读取或写入操作在主内存和工作内存之间的同步。这样，线程在读取 volatile 变量时，总是能够看到最新的值。（更新可见）\n 2. **禁止指令重排序：**volatile 关键字也会禁止编译器和处理器对 volatile 变量的读写指令进行重排序。这意味着在写入 volatile 变量后，该操作之前的所有操作都会被完成，而在读取 volatile 变量前，该操作之后的所有操作都会被延迟。（最终执行结果不会变）\n 3. **操作不具备原子性：**需要注意的是，虽然对 volatile 变量的单个读写操作具有原子性，但是多个操作组合在一起可能不具备原子性。例如，递增操作 "x++" 是一个复合操作（x+1 为一次，x=x+1 为一次），虽然单个的读取和写入操作都是原子的，但是组合在一起时并不是原子的。在这种情况下，应该使用锁或其他同步机制来确保原子性。\n\n\n# 学习参考\n\n * Java并发常见面试题总结（中） | JavaGuide(Java面试 + 学习指南)\n\n * 聊聊Java关键字synchronized | Shark Chili\n\n * 面渣逆袭 | Java并发编程',normalizedContent:'# synchronized和volatile的使用与区别\n\n\n# synchronized 关键字\n\n\n# 什么是 synchronized 关键字？\n\nsynchronized 是 java 中的一个关键字，翻译成中文是同步的意思。\n\n主要解决的是：多个线程之间访问资源的同步性。可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。\n\n使用方式\n\n使用 synchronized 关键字时，需要在方法或代码块上加锁，以确保同一时间只有一个线程可以执行这段代码；\n\n\n# 构造方法可以用 synchronized 修饰么？\n\n不可以。\n\n因为构造方法本身就属于线程安全的，不存在同步的构造方法一说。\n\n\n# synchronized 的底层原理是什么？\n\n * synchronized 同步语句块时\n   \n   使用的是 monitorenter 和 monitorexit 指令，其中 monitorenter 指令指向同步代码块的开始位置，monitorexit 指令则指明同步代码块的结束位置。\n\n * synchronized 修饰方法时\n   \n   没有 monitorenter 指令和 monitorexit 指令，取而代之的是 acc_synchronized 标识，该标识指明了该方法是一个同步方法。\n\n\n# volatile 关键字\n\n\n# 什么是 volatile 关键字？\n\nvolatile 关键字是 java 中用于保证变量可见性和禁止指令重排序优化的一种机制。只能保证单个变量的原子性，不能保证复合操作的原子性。\n\n\n# volatile 关键字解决了什么问题？\n\nvolatile 关键字主要解决了两个问题：可见性问题和指令重排序问题。\n\n 1. 可见性问题\n    \n    在多线程环境下，每个线程都有自己的工作内存，用于存储线程需要使用的变量。当一个线程修改了某个变量的值时，这个变量的值并不会立即被其他线程看到，需要将该变量的值同步到主内存中，其他线程才能看到该变量的最新值。\n    \n    而 volatile 关键字可以保证变量的修改对其他线程可见，从而避免了可见性问题。\n\n 2. 指令重排序问题\n    \n    在多线程环境下，为了提高程序性能，cpu 可能会对指令进行重排序，但指令重排序可能会导致程序出现意想不到的结果。例如，在一个双重检查锁定中，如果不使用 volatile 关键字，可能会导致另一个线程获取到未完全初始化的对象，从而出现问题。\n    \n    而使用 volatile 关键字可以禁止指令重排序优化，保证了程序的正确性。\n\n\n# synchronized 和 volatile 有什么区别？\n\nsynchronized 关键字和 volatile 关键字是两个互补的存在，而不是对立的存在！\n\n * volatile 关键字是线程同步的轻量级实现，所以 volatile 性能肯定比 synchronized 关键字要好 。但是 volatile 关键字只能用于单个变量而 synchronized 关键字可以修饰方法以及代码块。\n * volatile 关键字能保证数据的可见性，但不能保证数据的原子性。synchronized 关键字两者都能保证。\n * volatile 关键字主要用于解决单个变量在多个线程之间的可见性，而 synchronized 关键字解决的是多线程之间的资源同步。\n\n\n# volatile 的实现原理了解吗？\n\n> 先讲下 volatile 是怎么保证可见性的吧\n\nvolatile 可以确保对某个变量的更新对其他线程马上可见，一个变量被声明为 volatile 时，线程在写入变量时不会把值缓存在寄存器或者其他地方，而是会把值刷新回主内存 当其它线程读取该共享变量，会从主内存重新获取最新值，而不是使用当前线程的本地内存中的值。\n\n例如，我们声明一个 volatile 变量 volatile int x = 0，线程 a 修改 x=1，修改完之后就会把新的值刷新回主内存，线程 b 读取 x 的时候，就会清空本地内存变量，然后再从主内存获取最新值。\n\n那线程 b 是怎么知道 x 被修改了的呢？\n\n在 java 内存模型中，当一个线程修改了 volatile 变量的值，会将这个变量的新值刷新回主内存，并且通知其他线程，告诉它们这个变量的值已经发生了改变。当其他线程（比如线程b）需要读取这个 volatile 变量的值时，它们会从主内存中获取最新的值，而不是从本地内存中读取。\n\n具体来说，当线程 a 修改了 volatile 变量 x 的值为 1，并将新的值刷新回主内存后，主内存会记录这个变化，并在内部维护一个变量版本号。其他线程（如线程 b）在读取 volatile 变量时，会从主内存中获取最新的值，并检查版本号，以确保它们读取的是最新的值。\n\n\n# 说一下你对 java 内存模型（jmm）的理解？\n\njava 内存模型（jmm）是一种规范，是一种抽象的模型，用于定义在多线程环境下，线程之间如何与主内存和工作内存进行交互，以及如何保证线程之间的可见性、有序性和原子性。\n\njmm 主要关注以下几个概念：\n\n 1. **主内存和工作内存：**主内存是所有线程共享的内存区域，而每个线程都有自己的工作内存，工作内存存储了主内存的副本。线程对变量的操作首先在工作内存中进行，然后通过特定的操作将结果同步到主内存。\n 2. **可见性：**jmm 保证一个线程对共享变量的修改对其他线程是可见的。通过 volatile 关键字和 synchronized 关键字等机制，可以确保变量的更新在不同线程间可见。\n 3. **有序性：**jmm 定义了不同操作之间的执行顺序。编译器和处理器可能会对指令重排序，但是 jmm 规定了一些规则来确保程序的执行顺序符合预期。\n 4. **原子性：**jmm 保证一些操作的原子性，如对 volatile 变量的读写操作具有原子性。此外，可以通过 synchronized 关键字或 lock 机制来保证代码块的原子性。\n\n总的来说，java 内存模型是为了解决多线程环境下可能出现的可见性、有序性和原子性问题而设计的。它规定了线程之间如何与内存交互，以及如何保证线程安全。了解 jmm 对于编写并发安全的多线程程序至关重要，因为它帮助开发人员理解线程之间的交互规则，从而避免出现意外的并发问题。\n\n为什么对 volatile 变量的读写操作具有原子性？\n\n在 java 中，对 volatile 变量的读写操作具有原子性，这意味着单个读取或写入 volatile 变量的操作在执行过程中不会被中断，也不会受到其他线程的干扰，从而确保了操作的完整性。\n\n-- 这种特性是由 java 内存模型（jmm）所规定的。\n\n 1. **内存可见性：**volatile 关键字不仅保证了对变量的修改对其他线程是可见的，还保证了单个读取或写入操作在主内存和工作内存之间的同步。这样，线程在读取 volatile 变量时，总是能够看到最新的值。（更新可见）\n 2. **禁止指令重排序：**volatile 关键字也会禁止编译器和处理器对 volatile 变量的读写指令进行重排序。这意味着在写入 volatile 变量后，该操作之前的所有操作都会被完成，而在读取 volatile 变量前，该操作之后的所有操作都会被延迟。（最终执行结果不会变）\n 3. **操作不具备原子性：**需要注意的是，虽然对 volatile 变量的单个读写操作具有原子性，但是多个操作组合在一起可能不具备原子性。例如，递增操作 "x++" 是一个复合操作（x+1 为一次，x=x+1 为一次），虽然单个的读取和写入操作都是原子的，但是组合在一起时并不是原子的。在这种情况下，应该使用锁或其他同步机制来确保原子性。\n\n\n# 学习参考\n\n * java并发常见面试题总结（中） | javaguide(java面试 + 学习指南)\n\n * 聊聊java关键字synchronized | shark chili\n\n * 面渣逆袭 | java并发编程',charsets:{cjk:!0}},{title:"Queue接口",frontmatter:{title:"Queue接口",date:"2023-07-12T14:50:53.000Z",permalink:"/pages/887881/",author:{name:"陌上清风",link:"https://github.com/msqfx"},categories:["java","集合篇"],tags:[null],description:"Queue 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 先进先出（FIFO） 规则。",comment:!0,meta:[{name:"twitter:title",content:"Queue接口"},{name:"twitter:description",content:"Queue 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 先进先出（FIFO） 规则。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/04.Queue%E6%8E%A5%E5%8F%A3.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Queue接口"},{property:"og:description",content:"Queue 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 先进先出（FIFO） 规则。"},{property:"og:url",content:"https://www.msqfx.cc/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/04.Queue%E6%8E%A5%E5%8F%A3.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-07-12T14:50:53.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"Queue接口"},{itemprop:"description",content:"Queue 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 先进先出（FIFO） 规则。"}],readingShow:"top"},regularPath:"/01.java/02.%E9%9B%86%E5%90%88%E7%AF%87/04.Queue%E6%8E%A5%E5%8F%A3.html",relativePath:"01.java/02.集合篇/04.Queue接口.md",key:"v-3223b15c",path:"/pages/887881/",headers:[{level:2,title:"Queue 与 Deque 的区别",slug:"queue-与-deque-的区别",normalizedTitle:"queue 与 deque 的区别",charIndex:17},{level:2,title:"ArrayDeque 与 LinkedList 的区别",slug:"arraydeque-与-linkedlist-的区别",normalizedTitle:"arraydeque 与 linkedlist 的区别",charIndex:715},{level:2,title:"说一说 PriorityQueue（优先级队列）",slug:"说一说-priorityqueue-优先级队列",normalizedTitle:"说一说 priorityqueue（优先级队列）",charIndex:1135}],headersStr:"Queue 与 Deque 的区别 ArrayDeque 与 LinkedList 的区别 说一说 PriorityQueue（优先级队列）",content:"# Queue 集合详解\n\n\n# Queue 与 Deque 的区别\n\nQueue 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 先进先出（FIFO） 规则。\n\nQueue 扩展了 Collection 的接口，根据 因为容量问题而导致操作失败后处理方式的不同 可以分为两类方法: 一种在操作失败后会抛出异常，另一种则会返回特殊值。\n\nQUEUE 接口   抛出异常        返回特殊值\n插入队尾       add(E e)    offer(E e)\n删除队首       remove()    poll()\n查询队首元素     element()   peek()\n\nDeque 是双端队列，在队列的两端均可以插入或删除元素。\n\nDeque 扩展了 Queue 的接口, 增加了在队首和队尾进行插入和删除的方法，同样根据失败后处理方式的不同分为两类：\n\nDEQUE 接口   抛出异常            返回特殊值\n插入队首       addFirst(E e)   offerFirst(E e)\n插入队尾       addLast(E e)    offerLast(E e)\n删除队首       removeFirst()   pollFirst()\n删除队尾       removeLast()    pollLast()\n查询队首元素     getFirst()      peekFirst()\n查询队尾元素     getLast()       peekLast()\n\n事实上，Deque 还提供有 push() 和 pop() 等其他方法，可用于模拟栈。\n\n\n# ArrayDeque 与 LinkedList 的区别\n\nArrayDeque 和 LinkedList 都实现了 Deque 接口，两者都具有队列的功能，但两者有什么区别呢？\n\n * ArrayDeque 是基于可变长的数组和双指针来实现，而 LinkedList 则通过链表来实现。\n * ArrayDeque 不支持存储 NULL 数据，但 LinkedList 支持。\n * ArrayDeque 是在 JDK1.6 才被引入的，而LinkedList 早在 JDK1.2 时就已经存在。\n * ArrayDeque 插入时可能存在扩容过程, 不过均摊后的插入操作依然为 O(1)。虽然 LinkedList 不需要扩容，但是每次插入数据时均需要申请新的堆空间，均摊性能相比更慢。\n\n> 从性能的角度上，选用 ArrayDeque 来实现队列要比 LinkedList 更好。此外，ArrayDeque 也可以用于实现栈。\n\n\n# 说一说 PriorityQueue（优先级队列）\n\nPriorityQueue 是在 JDK1.5 中被引入的, 其与 Queue 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。\n\n这里列举其相关的一些要点：\n\n * PriorityQueue 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据\n * PriorityQueue 通过堆元素的上浮和下沉，实现了在 O(logn) 的时间复杂度内插入元素和删除堆顶元素。\n * PriorityQueue 是非线程安全的，且不支持存储 NULL 和 non-comparable 的对象。\n * PriorityQueue 默认是小顶堆，但可以接收一个 Comparator 作为构造参数，从而来自定义元素优先级的先后。\n\n> 二叉堆（binary heap）是一种基于完全二叉树的数据结构，它满足如下两个性质：\n> \n>  1. 父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值。\n>  2. 每个节点的左子树和右子树都是一个二叉堆（称为堆的性质）。 根据性质1，我们可以将二叉堆划分为两种类型：最大堆和最小堆。\n> \n>  * 在最大堆中，父节点的键值总是大于或等于任何一个子节点的键值。\n>  * 在最小堆中，父节点的键值总是小于或等于任何一个子节点的键值。\n> \n> PriorityQueue 在面试中可能更多的会出现在手撕算法的时候，典型例题包括堆排序、求第K大的数、带权图的遍历等，所以需要会熟练使用才行。",normalizedContent:"# queue 集合详解\n\n\n# queue 与 deque 的区别\n\nqueue 是单端队列，只能从一端插入元素，另一端删除元素，实现上一般遵循 先进先出（fifo） 规则。\n\nqueue 扩展了 collection 的接口，根据 因为容量问题而导致操作失败后处理方式的不同 可以分为两类方法: 一种在操作失败后会抛出异常，另一种则会返回特殊值。\n\nqueue 接口   抛出异常        返回特殊值\n插入队尾       add(e e)    offer(e e)\n删除队首       remove()    poll()\n查询队首元素     element()   peek()\n\ndeque 是双端队列，在队列的两端均可以插入或删除元素。\n\ndeque 扩展了 queue 的接口, 增加了在队首和队尾进行插入和删除的方法，同样根据失败后处理方式的不同分为两类：\n\ndeque 接口   抛出异常            返回特殊值\n插入队首       addfirst(e e)   offerfirst(e e)\n插入队尾       addlast(e e)    offerlast(e e)\n删除队首       removefirst()   pollfirst()\n删除队尾       removelast()    polllast()\n查询队首元素     getfirst()      peekfirst()\n查询队尾元素     getlast()       peeklast()\n\n事实上，deque 还提供有 push() 和 pop() 等其他方法，可用于模拟栈。\n\n\n# arraydeque 与 linkedlist 的区别\n\narraydeque 和 linkedlist 都实现了 deque 接口，两者都具有队列的功能，但两者有什么区别呢？\n\n * arraydeque 是基于可变长的数组和双指针来实现，而 linkedlist 则通过链表来实现。\n * arraydeque 不支持存储 null 数据，但 linkedlist 支持。\n * arraydeque 是在 jdk1.6 才被引入的，而linkedlist 早在 jdk1.2 时就已经存在。\n * arraydeque 插入时可能存在扩容过程, 不过均摊后的插入操作依然为 o(1)。虽然 linkedlist 不需要扩容，但是每次插入数据时均需要申请新的堆空间，均摊性能相比更慢。\n\n> 从性能的角度上，选用 arraydeque 来实现队列要比 linkedlist 更好。此外，arraydeque 也可以用于实现栈。\n\n\n# 说一说 priorityqueue（优先级队列）\n\npriorityqueue 是在 jdk1.5 中被引入的, 其与 queue 的区别在于元素出队顺序是与优先级相关的，即总是优先级最高的元素先出队。\n\n这里列举其相关的一些要点：\n\n * priorityqueue 利用了二叉堆的数据结构来实现的，底层使用可变长的数组来存储数据\n * priorityqueue 通过堆元素的上浮和下沉，实现了在 o(logn) 的时间复杂度内插入元素和删除堆顶元素。\n * priorityqueue 是非线程安全的，且不支持存储 null 和 non-comparable 的对象。\n * priorityqueue 默认是小顶堆，但可以接收一个 comparator 作为构造参数，从而来自定义元素优先级的先后。\n\n> 二叉堆（binary heap）是一种基于完全二叉树的数据结构，它满足如下两个性质：\n> \n>  1. 父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值。\n>  2. 每个节点的左子树和右子树都是一个二叉堆（称为堆的性质）。 根据性质1，我们可以将二叉堆划分为两种类型：最大堆和最小堆。\n> \n>  * 在最大堆中，父节点的键值总是大于或等于任何一个子节点的键值。\n>  * 在最小堆中，父节点的键值总是小于或等于任何一个子节点的键值。\n> \n> priorityqueue 在面试中可能更多的会出现在手撕算法的时候，典型例题包括堆排序、求第k大的数、带权图的遍历等，所以需要会熟练使用才行。",charsets:{cjk:!0}},{title:"线程池详解",frontmatter:{title:"线程池详解",date:"2023-06-14T20:18:11.000Z",permalink:"/pages/040070/",author:{name:"陌上清风",link:"https://msqfx.github.io"},categories:["java","并发篇"],tags:[null],description:"这是一种比较传统的创建线程的方式。你可以创建一个类，继承自 Thread 类，并重写 run 方法来定义线程的执行逻辑。",comment:!0,meta:[{name:"image",content:"https://cmty256.github.io/imgs-blog/Java/image.6282d56i3hg0.webp"},{name:"twitter:title",content:"线程池详解"},{name:"twitter:description",content:"这是一种比较传统的创建线程的方式。你可以创建一个类，继承自 Thread 类，并重写 run 方法来定义线程的执行逻辑。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://cmty256.github.io/imgs-blog/Java/image.6282d56i3hg0.webp"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/04.%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%AF%A6%E8%A7%A3.html"},{property:"og:type",content:"article"},{property:"og:title",content:"线程池详解"},{property:"og:description",content:"这是一种比较传统的创建线程的方式。你可以创建一个类，继承自 Thread 类，并重写 run 方法来定义线程的执行逻辑。"},{property:"og:image",content:"https://cmty256.github.io/imgs-blog/Java/image.6282d56i3hg0.webp"},{property:"og:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/04.%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%AF%A6%E8%A7%A3.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-06-14T20:18:11.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"线程池详解"},{itemprop:"description",content:"这是一种比较传统的创建线程的方式。你可以创建一个类，继承自 Thread 类，并重写 run 方法来定义线程的执行逻辑。"},{itemprop:"image",content:"https://cmty256.github.io/imgs-blog/Java/image.6282d56i3hg0.webp"}],readingShow:"top"},regularPath:"/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/04.%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%AF%A6%E8%A7%A3.html",relativePath:"01.java/03.并发篇/04.线程池详解.md",key:"v-8cb0bf1a",path:"/pages/040070/",headers:[{level:2,title:"首先回顾一下单个线程的创建方式",slug:"首先回顾一下单个线程的创建方式",normalizedTitle:"首先回顾一下单个线程的创建方式",charIndex:12},{level:3,title:"1、继承 Thread 类",slug:"_1、继承-thread-类",normalizedTitle:"1、继承 thread 类",charIndex:32},{level:3,title:"2、实现 Runnable 接口",slug:"_2、实现-runnable-接口",normalizedTitle:"2、实现 runnable 接口",charIndex:296},{level:3,title:"3、使用匿名内部类",slug:"_3、使用匿名内部类",normalizedTitle:"3、使用匿名内部类",charIndex:591},{level:3,title:"4、使用 Java 8 的 Lambda 表达式",slug:"_4、使用-java-8-的-lambda-表达式",normalizedTitle:"4、使用 java 8 的 lambda 表达式",charIndex:792},{level:3,title:"5、实现 Callable 接口",slug:"_5、实现-callable-接口",normalizedTitle:"5、实现 callable 接口",charIndex:949},{level:3,title:"实现 Runnable 接口和 Callable 接口的区别？",slug:"实现-runnable-接口和-callable-接口的区别",normalizedTitle:"实现 runnable 接口和 callable 接口的区别？",charIndex:1382},{level:2,title:"什么是线程池？",slug:"什么是线程池",normalizedTitle:"什么是线程池？",charIndex:1990},{level:2,title:"为什么要用线程池？",slug:"为什么要用线程池",normalizedTitle:"为什么要用线程池？",charIndex:2073},{level:2,title:"讲讲线程池的工作流程",slug:"讲讲线程池的工作流程",normalizedTitle:"讲讲线程池的工作流程",charIndex:2401},{level:2,title:"线程池使用入门",slug:"线程池使用入门",normalizedTitle:"线程池使用入门",charIndex:2910},{level:2,title:"Executor 框架介绍",slug:"executor-框架介绍",normalizedTitle:"executor 框架介绍",charIndex:4003},{level:3,title:"概述",slug:"概述",normalizedTitle:"概述",charIndex:4021},{level:3,title:"结构",slug:"结构",normalizedTitle:"结构",charIndex:4367},{level:3,title:"使用流程",slug:"使用流程",normalizedTitle:"使用流程",charIndex:4660},{level:2,title:"线程池原理解析",slug:"线程池原理解析",normalizedTitle:"线程池原理解析",charIndex:6522},{level:3,title:"线程池有哪些参数？",slug:"线程池有哪些参数",normalizedTitle:"线程池有哪些参数？",charIndex:6534},{level:3,title:"讲讲核心线程数和最大线程数的区别？",slug:"讲讲核心线程数和最大线程数的区别",normalizedTitle:"讲讲核心线程数和最大线程数的区别？",charIndex:7200},{level:3,title:"讲讲有哪些拒绝策略？",slug:"讲讲有哪些拒绝策略",normalizedTitle:"讲讲有哪些拒绝策略？",charIndex:7323},{level:3,title:"阻塞队列有哪些？",slug:"阻塞队列有哪些",normalizedTitle:"阻塞队列有哪些？",charIndex:7508},{level:3,title:"新线程添加的流程?",slug:"新线程添加的流程",normalizedTitle:"新线程添加的流程?",charIndex:7812},{level:3,title:"线程池的两种创建方式",slug:"线程池的两种创建方式",normalizedTitle:"线程池的两种创建方式",charIndex:8095},{level:4,title:"ThreadPoolExecutor",slug:"threadpoolexecutor",normalizedTitle:"threadpoolexecutor",charIndex:4553},{level:4,title:"Executors",slug:"executors",normalizedTitle:"executors",charIndex:1217},{level:3,title:"线程池提交 execute 和 submit 有什么区别？",slug:"线程池提交-execute-和-submit-有什么区别",normalizedTitle:"线程池提交 execute 和 submit 有什么区别？",charIndex:9145},{level:3,title:"线程池的关闭方式",slug:"线程池的关闭方式",normalizedTitle:"线程池的关闭方式",charIndex:9730},{level:2,title:"学习参考",slug:"学习参考",normalizedTitle:"学习参考",charIndex:9883}],headersStr:"首先回顾一下单个线程的创建方式 1、继承 Thread 类 2、实现 Runnable 接口 3、使用匿名内部类 4、使用 Java 8 的 Lambda 表达式 5、实现 Callable 接口 实现 Runnable 接口和 Callable 接口的区别？ 什么是线程池？ 为什么要用线程池？ 讲讲线程池的工作流程 线程池使用入门 Executor 框架介绍 概述 结构 使用流程 线程池原理解析 线程池有哪些参数？ 讲讲核心线程数和最大线程数的区别？ 讲讲有哪些拒绝策略？ 阻塞队列有哪些？ 新线程添加的流程? 线程池的两种创建方式 ThreadPoolExecutor Executors 线程池提交 execute 和 submit 有什么区别？ 线程池的关闭方式 学习参考",content:'# 线程池详解\n\n\n# 首先回顾一下单个线程的创建方式\n\n\n# 1、继承 Thread 类\n\n这是一种比较传统的创建线程的方式。你可以创建一个类，继承自 Thread 类，并重写 run 方法来定义线程的执行逻辑。\n\nclass MyThread extends Thread {\n    @Override\n    public void run() {\n        // 线程的执行逻辑\n    }\n}\n\n// 创建并启动线程\nMyThread thread = new MyThread();\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 2、实现 Runnable 接口\n\n这种方式更常用，它避免了 Java 的单继承限制，你可以实现 Runnable 接口，然后将其实例作为参数传递给 Thread 构造函数。\n\nclass MyRunnable implements Runnable {\n    @Override\n    public void run() {\n        // 线程的执行逻辑\n    }\n}\n\n// 创建并启动线程\nThread thread = new Thread(new MyRunnable());\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 3、使用匿名内部类\n\n你可以在创建线程时使用匿名内部类，实现 Runnable 接口的 run 方法。\n\nThread thread = new Thread(new Runnable() {\n    @Override\n    public void run() {\n        // 线程的执行逻辑\n    }\n});\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 4、使用 Java 8 的 Lambda 表达式\n\n如果 Runnable 接口只有一个抽象方法，你可以使用 Lambda 表达式简化代码。\n\nThread thread = new Thread(() -> {\n    // 线程的执行逻辑\n});\nthread.start();\n\n\n1\n2\n3\n4\n\n\n\n# 5、实现 Callable 接口\n\nCallable 接口允许线程返回结果或抛出异常。需要通过 ExecutorService 来执行。\n\nclass MyCallable implements Callable<String> {\n    @Override\n    public String call() throws Exception {\n        // 线程的执行逻辑\n        return "Hello from Callable";\n    }\n}\n\nExecutorService executor = Executors.newFixedThreadPool(1);\nFuture<String> future = executor.submit(new MyCallable());\nString result = future.get(); // 获取线程执行结果\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 实现 Runnable 接口和 Callable 接口的区别？\n\nJava 中的 Runnable 接口和 Callable 接口都是用来创建多线程的接口，它们的区别如下：\n\n 1. 方法名不同。\n    \n    * Runnable 接口只有一个 run() 方法，\n    * 而 Callable 接口只有一个 call() 方法。\n\n 2. 返回值不同。\n    \n    * Runnable 的 run() 方法没有返回值，\n    \n    * 而 Callable 的 call() 方法可以返回执行结果。\n\n 3. 异常处理不同。\n    \n    * Runnable 的 run() 方法不能抛出异常，\n    * 而 Callable 的 call() 方法可以抛出异常，并且需要在调用 Future.get() 方法时进行异常处理。\n\n 4. 调用方式不同。\n    \n    * Runnable 接口可以通过 Thread 类的构造方法来创建一个新的线程并启动它，\n    * 而 Callable 接口则需要借助 Executor 框架来执行。\n\n 5. 用途不同。\n    \n    * Runnable 接口通常用于需要执行一些简单的任务的场景，\n    * Callable 接口通常用于需要返回结果、或者需要抛出异常、或者需要在执行任务前进行一些初始化操作的场景。\n\n\n# 什么是线程池？\n\n线程池就是管理一系列线程的资源池。\n\n当有任务要处理时，直接从线程池中获取线程来处理，处理完之后线程并不会立即被销毁，而是等待下一个任务。\n\n\n# 为什么要用线程池？\n\n简单来说，是因为使用线程池可以提高资源的利用率。\n\n> 线程池可以帮我们管理线程，避免增加创建线程和销毁线程的资源损耗。\n> \n> 我们写代码的过程中，学会池化思想，最直接相关的就是使用线程池而不是去new一个线程。\n\n使用线程池有三大好处：\n\n 1. 提高响应速度。通过线程池创建一系列线程，使用时直接通过线程池获取，不再需要手动创建线程，响应速度自然就大大提高了。\n 2. 降低资源消耗。由于线程池被池化管理了，我们无需为了某些功能去手动创建和销毁线程，资源消耗自然降低。\n 3. 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。\n\n\n# 讲讲线程池的工作流程\n\n 1. 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。\n 2. 当调用 execute() 方法添加一个任务时，线程池会做如下判断：\n    * 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务；\n    * 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列；\n    * 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务；\n    * 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会根据拒绝策略来对应处理。\n 3. 当一个线程完成任务时，它会从队列中取下一个任务来执行。\n 4. 当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于 corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corePoolSize 的大小。\n\n图解：\n\n\n\n\n# 线程池使用入门\n\n 1. 首先创建一个含有 3 个线程的线程，\n 2. 然后提交 3 个任务到线程池中，让线程池中的线程池执行，\n 3. 完成后通过 shutdown 停止线程池，线程池收到通知后会将手头的任务都执行完，再将线程池停止。\n\n这里使用 isTerminated 判断线程池是否完全停止了。只有状态为 terminated 才能说明线程池关闭了，结束循环，退出方法。\n\n @Test\n    void contextLoads() {\n        //创建含有3个线程的线程池\n        ExecutorService threadPool = Executors.newFixedThreadPool(3);\n\n        //提交3个任务到线程池中\n        for (int i = 0; i < 3; i++) {\n            final int taskNo = i;\n            threadPool.execute(() -> {\n                logger.info("执行任务{}", taskNo);\n            });\n        }\n\n        //关闭线程池\n        threadPool.shutdown();\n        //如果线程池还没达到Terminated状态，说明线程池中还有任务没有执行完，则继续循环等待线程池执行完任务\n        while (!threadPool.isTerminated()) {\n\n        }\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n输出结果\n\n2023-03-21 23:01:16.198  INFO 40176 --- [pool-4-thread-1] .j.JavaCommonMistakes100ApplicationTests : 执行任务0\n2023-03-21 23:01:16.198  INFO 40176 --- [pool-4-thread-2] .j.JavaCommonMistakes100ApplicationTests : 执行任务1\n2023-03-21 23:01:16.225  INFO 40176 --- [pool-4-thread-3] .j.JavaCommonMistakes100ApplicationTests : 执行任务2\n\n\n1\n2\n3\n\n\n\n# Executor 框架介绍\n\n\n# 概述\n\n在 Java 5 之后，通过 Executor 来启动线程比使用 Thread 的 start 方法更好，除了更易管理，效率更好（用线程池实现，节约开销）外，还有关键的一点：有助于避免 this 逃逸问题。\n\n这是因为线程池的执行过程会等待构造完成后再进行任务的执行，从而避免了 this 逃逸问题的发生。\n\n什么是 this 逃逸问题？\n\n在 Java 中，对象的构造过程可能会涉及到多个线程，而当一个对象尚未完全构造完成但已经被其他线程引用时，就可能产生 this 逃逸问题。\n\n具体来说，当一个对象正在构造过程中，它的引用就被发布到了其他线程，这时其他线程可能会使用这个尚未完全构造的对象，从而导致意料之外的行为和错误。这可能会因为对象的状态不稳定而引发线程安全问题。\n\n\n# 结构\n\nExecutor 框架结构主要由三大部分组成：\n\n 1. 任务。包括被执行任务需要实现的接口：Runnable 接口或 Callable 接口。\n 2. 任务的执行。包括任务执行机制的核心接口 Executor，以及继承自 Executor 的 ExecutorService 接口。Executor 框架有两个关键类实现了 ExecutorService 接口（ThreadPoolExecutor 和 ScheduleThreadPoolExecutor）。\n 3. 异步计算的结果。包括接口 Future 和实现 Future 接口的 FutureTask 类。\n\n\n# 使用流程\n\n 1. 主线程首先要创建实现 Runnable 或者 Callable 接口的任务对象。\n 2. 把创建完成的实现 Runnable/Callable 接口的【对象】直接交给 ExecutorService 执行: ExecutorService.execute（Runnable command）或者也可以把 Runnable 对象或Callable 对象提交给 ExecutorService 执行（ExecutorService.submit（Runnable task）或 ExecutorService.submit（Callable <T> task））。\n 3. 如果执行 ExecutorService.submit（…），ExecutorService 将返回一个实现Future接口的对象（我们刚刚也提到过了执行 execute()方法和 submit()方法的区别，submit()会返回一个 FutureTask 对象）。由于 FutureTask 实现了 Runnable，我们也可以创建 FutureTask，然后直接交给 ExecutorService 执行。\n 4. 最后，主线程可以执行 FutureTask.get()方法来等待任务执行完成。主线程也可以执行 FutureTask.cancel（boolean mayInterruptIfRunning）来取消此任务的执行。\n\n代码示例：\n\nimport java.util.concurrent.*;\n\npublic class ThreadPoolExample {\n    public static void main(String[] args) {\n        // 创建一个线程池\n        ExecutorService executorService = Executors.newFixedThreadPool(2);\n\n        // 创建实现Runnable接口的任务\n        Runnable task1 = () -> {\n            System.out.println("Task 1 is running on thread: " + Thread.currentThread().getName());\n        };\n\n        // 创建实现Callable接口的任务\n        Callable<String> task2 = () -> {\n            System.out.println("Task 2 is running on thread: " + Thread.currentThread().getName());\n            return "Task 2 Result";\n        };\n\n        try {\n            // 执行Runnable任务\n            executorService.execute(task1);\n\n            // 提交Callable任务，并获取Future对象\n            Future<String> future = executorService.submit(task2);\n\n            // 主线程等待Callable任务执行完成，并获取结果\n            String result = future.get();\n            System.out.println("Task 2 Result: " + result);\n\n        } catch (InterruptedException | ExecutionException e) {\n            e.printStackTrace();\n        } finally {\n            // 关闭线程池\n            executorService.shutdown();\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n\n\n\n# 线程池原理解析\n\n\n# 线程池有哪些参数？\n\n通过 Executors 框架创建的线程池，从源码可以看到，它底层是通过 ThreadPoolExecutor 完成线程池的创建，具体参数如下：\n\n public static ExecutorService newFixedThreadPool(int nThreads) {\n        return new ThreadPoolExecutor(nThreads, nThreads,\n                                      0L, TimeUnit.MILLISECONDS,\n                                      new LinkedBlockingQueue<Runnable>());\n    }\n\n\n1\n2\n3\n4\n5\n\n\n 1. corePoolSize：线程池的核心线程数，即线程池中始终保持的线程数。\n\n 2. maximumPoolSize：线程池中最大的线程数，包括核心线程数和非核心线程数。\n\n 3. keepAliveTime：非核心线程的闲置时间，超过该时间后将被回收。\n\n 4. unit：keepAliveTime 非核心线程的闲置时间的单位。\n\n 5. workQueue：任务队列，用于存储还未被执行的任务。\n\n 6. threadFactory：线程工厂，用于创建线程。\n\n 7. handler：饱和策略，即当线程池中的线程都在执行任务时，新的任务会如何处理。（也称为拒绝策略）\n\n\n# 讲讲核心线程数和最大线程数的区别？\n\n核心线程数和最大线程数的区别在于：\n\n在任务数超过核心线程数时，线程池会优先创建核心线程来执行任务，只有当任务队列已满且核心线程都在执行任务时，才会创建非核心线程来执行任务，直到达到最大线程数为止。\n\n\n# 讲讲有哪些拒绝策略？\n\n有四种常见的拒绝策略：\n\n 1. AbortPolicy（默认）：直接抛出异常，阻止系统正常运行。\n 2. CallerRunsPolicy：只用调用者所在线程来执行任务。\n 3. DiscardOldestPolicy：丢弃队列中最老的一个任务，尝试再次提交当前任务。\n 4. DiscardPolicy：直接丢弃任务，不做任何处理。\n\n\n# 阻塞队列有哪些？\n\nJava 中常用的阻塞队列有以下 4 种：\n\n 1. ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列，按照先进先出的原则对元素进行排序。\n\n 2. LinkedBlockingQueue：一个由链表结构组成的可选有界阻塞队列，按照先进先出的原则对元素进行排序。\n    \n    如果队列容量没有限制，则为无界阻塞队列。\n\n 3. PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。\n\n 4. SynchronousQueue：一个不存储元素的阻塞队列，每个插入操作必须等待另一个线程的移除操作，否则插入操作一直处于阻塞状态。\n\n\n# 新线程添加的流程?\n\n新线程的添加有以下 4 个流程：\n\n 1. 如果当前线程池中的线程数小于核心线程数，那么就创建一个新的核心线程来执行这个任务；\n\n 2. 如果当前线程池中的线程数已经达到了核心线程数，那么就将任务添加到任务队列中等待执行；\n\n 3. 如果任务队列已满，但当前线程池中的线程数还没有达到最大线程数，那么就创建一个新的非核心线程来执行这个任务；\n    \n    > 非核心线程在执行完任务之后会被回收，直到线程池中的线程数又重新降至核心线程数。\n\n 4. 如果当前线程池中的线程数已经达到了最大线程数，那么就根据饱和策略来处理这个任务。\n\n\n# 线程池的两种创建方式\n\n# ThreadPoolExecutor\n\n方式一：通过 ThreadPoolExecutor 构造函数来创建（推荐）。\n\n我们可以创建多种类型的 ThreadPoolExecutor：\n\n * FixedThreadPool：该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。\n * SingleThreadExecutor：该方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。\n * CachedThreadPool： 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。\n * ScheduledThreadPool：该返回一个用来在给定的延迟后运行任务或者定期执行任务的线程池。\n\n# Executors\n\n方式二：通过 Executor 框架的工具类 Executors 来创建。\n\nExecutors 返回线程池对象的弊端如下：\n\n * FixedThreadPool 和 SingleThreadExecutor：使用的是无界的 LinkedBlockingQueue，任务队列最大长度为 Integer.MAX_VALUE,可能堆积大量的请求，从而导致 OOM。\n\n * CachedThreadPool：使用的是同步队列 SynchronousQueue, 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。\n\n * ScheduledThreadPool 和 SingleThreadScheduledExecutor : 使用的无界的延迟阻塞队列 DelayedWorkQueue，任务队列最大长度为 Integer.MAX_VALUE, 可能堆积大量的请求，从而导致 OOM。\n   \n   > OOM（Out of Memory）是指内存溢出，即程序在运行过程中申请的内存超过了JVM所能提供的最大内存限制，导致无法继续分配内存，从而抛出内存溢出异常。\n\n\n# 线程池提交 execute 和 submit 有什么区别？\n\n 1. execute 用于提交不需要返回值的任务\n\nthreadsPool.execute(new Runnable() { \n    @Override public void run() { \n        // TODO Auto-generated method stub } \n    });\n\n\n1\n2\n3\n4\n\n\n 2. submit() 方法用于提交需要返回值的任务\n    \n    线程池会返回一个 future 类型的对象，通过这个 future 对象可以判断任务是否执行成功，并且可以通过 future 的 get() 方法来获取返回值。\n\nFuture<Object> future = executor.submit(harReturnValuetask); \ntry { Object s = future.get(); } catch (InterruptedException e) { \n    // 处理中断异常 \n} catch (ExecutionException e) { \n    // 处理无法执行任务异常 \n} finally { \n    // 关闭线程池 executor.shutdown();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 线程池的关闭方式\n\n线程池的停止方式有两种:\n\n 1. shutdown: 使用这个方法之后，我们无法提交新的任务进来，线程池会继续工作，将手头的任务执行完再停止。\n 2. shutdownNow: 这种停止方式比较粗暴，线程池会直接将手头的任务都强行停止，且不接受新任务进来，线程停止立即生效。\n\n\n# 学习参考\n\n * Java 线程池详解 | JavaGuide)\n * Java线程池详解 | Shark Chili\n * 面渣逆袭-Java并发编程\n * Executor框架详解\n * 实战总结！18种接口优化方案的总结',normalizedContent:'# 线程池详解\n\n\n# 首先回顾一下单个线程的创建方式\n\n\n# 1、继承 thread 类\n\n这是一种比较传统的创建线程的方式。你可以创建一个类，继承自 thread 类，并重写 run 方法来定义线程的执行逻辑。\n\nclass mythread extends thread {\n    @override\n    public void run() {\n        // 线程的执行逻辑\n    }\n}\n\n// 创建并启动线程\nmythread thread = new mythread();\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 2、实现 runnable 接口\n\n这种方式更常用，它避免了 java 的单继承限制，你可以实现 runnable 接口，然后将其实例作为参数传递给 thread 构造函数。\n\nclass myrunnable implements runnable {\n    @override\n    public void run() {\n        // 线程的执行逻辑\n    }\n}\n\n// 创建并启动线程\nthread thread = new thread(new myrunnable());\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 3、使用匿名内部类\n\n你可以在创建线程时使用匿名内部类，实现 runnable 接口的 run 方法。\n\nthread thread = new thread(new runnable() {\n    @override\n    public void run() {\n        // 线程的执行逻辑\n    }\n});\nthread.start();\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 4、使用 java 8 的 lambda 表达式\n\n如果 runnable 接口只有一个抽象方法，你可以使用 lambda 表达式简化代码。\n\nthread thread = new thread(() -> {\n    // 线程的执行逻辑\n});\nthread.start();\n\n\n1\n2\n3\n4\n\n\n\n# 5、实现 callable 接口\n\ncallable 接口允许线程返回结果或抛出异常。需要通过 executorservice 来执行。\n\nclass mycallable implements callable<string> {\n    @override\n    public string call() throws exception {\n        // 线程的执行逻辑\n        return "hello from callable";\n    }\n}\n\nexecutorservice executor = executors.newfixedthreadpool(1);\nfuture<string> future = executor.submit(new mycallable());\nstring result = future.get(); // 获取线程执行结果\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 实现 runnable 接口和 callable 接口的区别？\n\njava 中的 runnable 接口和 callable 接口都是用来创建多线程的接口，它们的区别如下：\n\n 1. 方法名不同。\n    \n    * runnable 接口只有一个 run() 方法，\n    * 而 callable 接口只有一个 call() 方法。\n\n 2. 返回值不同。\n    \n    * runnable 的 run() 方法没有返回值，\n    \n    * 而 callable 的 call() 方法可以返回执行结果。\n\n 3. 异常处理不同。\n    \n    * runnable 的 run() 方法不能抛出异常，\n    * 而 callable 的 call() 方法可以抛出异常，并且需要在调用 future.get() 方法时进行异常处理。\n\n 4. 调用方式不同。\n    \n    * runnable 接口可以通过 thread 类的构造方法来创建一个新的线程并启动它，\n    * 而 callable 接口则需要借助 executor 框架来执行。\n\n 5. 用途不同。\n    \n    * runnable 接口通常用于需要执行一些简单的任务的场景，\n    * callable 接口通常用于需要返回结果、或者需要抛出异常、或者需要在执行任务前进行一些初始化操作的场景。\n\n\n# 什么是线程池？\n\n线程池就是管理一系列线程的资源池。\n\n当有任务要处理时，直接从线程池中获取线程来处理，处理完之后线程并不会立即被销毁，而是等待下一个任务。\n\n\n# 为什么要用线程池？\n\n简单来说，是因为使用线程池可以提高资源的利用率。\n\n> 线程池可以帮我们管理线程，避免增加创建线程和销毁线程的资源损耗。\n> \n> 我们写代码的过程中，学会池化思想，最直接相关的就是使用线程池而不是去new一个线程。\n\n使用线程池有三大好处：\n\n 1. 提高响应速度。通过线程池创建一系列线程，使用时直接通过线程池获取，不再需要手动创建线程，响应速度自然就大大提高了。\n 2. 降低资源消耗。由于线程池被池化管理了，我们无需为了某些功能去手动创建和销毁线程，资源消耗自然降低。\n 3. 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。\n\n\n# 讲讲线程池的工作流程\n\n 1. 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。\n 2. 当调用 execute() 方法添加一个任务时，线程池会做如下判断：\n    * 如果正在运行的线程数量小于 corepoolsize，那么马上创建线程运行这个任务；\n    * 如果正在运行的线程数量大于或等于 corepoolsize，那么将这个任务放入队列；\n    * 如果这时候队列满了，而且正在运行的线程数量小于 maximumpoolsize，那么还是要创建非核心线程立刻运行这个任务；\n    * 如果队列满了，而且正在运行的线程数量大于或等于 maximumpoolsize，那么线程池会根据拒绝策略来对应处理。\n 3. 当一个线程完成任务时，它会从队列中取下一个任务来执行。\n 4. 当一个线程无事可做，超过一定的时间（keepalivetime）时，线程池会判断，如果当前运行的线程数大于 corepoolsize，那么这个线程就被停掉。所以线程池的所有任务完成后，它最终会收缩到 corepoolsize 的大小。\n\n图解：\n\n\n\n\n# 线程池使用入门\n\n 1. 首先创建一个含有 3 个线程的线程，\n 2. 然后提交 3 个任务到线程池中，让线程池中的线程池执行，\n 3. 完成后通过 shutdown 停止线程池，线程池收到通知后会将手头的任务都执行完，再将线程池停止。\n\n这里使用 isterminated 判断线程池是否完全停止了。只有状态为 terminated 才能说明线程池关闭了，结束循环，退出方法。\n\n @test\n    void contextloads() {\n        //创建含有3个线程的线程池\n        executorservice threadpool = executors.newfixedthreadpool(3);\n\n        //提交3个任务到线程池中\n        for (int i = 0; i < 3; i++) {\n            final int taskno = i;\n            threadpool.execute(() -> {\n                logger.info("执行任务{}", taskno);\n            });\n        }\n\n        //关闭线程池\n        threadpool.shutdown();\n        //如果线程池还没达到terminated状态，说明线程池中还有任务没有执行完，则继续循环等待线程池执行完任务\n        while (!threadpool.isterminated()) {\n\n        }\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n输出结果\n\n2023-03-21 23:01:16.198  info 40176 --- [pool-4-thread-1] .j.javacommonmistakes100applicationtests : 执行任务0\n2023-03-21 23:01:16.198  info 40176 --- [pool-4-thread-2] .j.javacommonmistakes100applicationtests : 执行任务1\n2023-03-21 23:01:16.225  info 40176 --- [pool-4-thread-3] .j.javacommonmistakes100applicationtests : 执行任务2\n\n\n1\n2\n3\n\n\n\n# executor 框架介绍\n\n\n# 概述\n\n在 java 5 之后，通过 executor 来启动线程比使用 thread 的 start 方法更好，除了更易管理，效率更好（用线程池实现，节约开销）外，还有关键的一点：有助于避免 this 逃逸问题。\n\n这是因为线程池的执行过程会等待构造完成后再进行任务的执行，从而避免了 this 逃逸问题的发生。\n\n什么是 this 逃逸问题？\n\n在 java 中，对象的构造过程可能会涉及到多个线程，而当一个对象尚未完全构造完成但已经被其他线程引用时，就可能产生 this 逃逸问题。\n\n具体来说，当一个对象正在构造过程中，它的引用就被发布到了其他线程，这时其他线程可能会使用这个尚未完全构造的对象，从而导致意料之外的行为和错误。这可能会因为对象的状态不稳定而引发线程安全问题。\n\n\n# 结构\n\nexecutor 框架结构主要由三大部分组成：\n\n 1. 任务。包括被执行任务需要实现的接口：runnable 接口或 callable 接口。\n 2. 任务的执行。包括任务执行机制的核心接口 executor，以及继承自 executor 的 executorservice 接口。executor 框架有两个关键类实现了 executorservice 接口（threadpoolexecutor 和 schedulethreadpoolexecutor）。\n 3. 异步计算的结果。包括接口 future 和实现 future 接口的 futuretask 类。\n\n\n# 使用流程\n\n 1. 主线程首先要创建实现 runnable 或者 callable 接口的任务对象。\n 2. 把创建完成的实现 runnable/callable 接口的【对象】直接交给 executorservice 执行: executorservice.execute（runnable command）或者也可以把 runnable 对象或callable 对象提交给 executorservice 执行（executorservice.submit（runnable task）或 executorservice.submit（callable <t> task））。\n 3. 如果执行 executorservice.submit（…），executorservice 将返回一个实现future接口的对象（我们刚刚也提到过了执行 execute()方法和 submit()方法的区别，submit()会返回一个 futuretask 对象）。由于 futuretask 实现了 runnable，我们也可以创建 futuretask，然后直接交给 executorservice 执行。\n 4. 最后，主线程可以执行 futuretask.get()方法来等待任务执行完成。主线程也可以执行 futuretask.cancel（boolean mayinterruptifrunning）来取消此任务的执行。\n\n代码示例：\n\nimport java.util.concurrent.*;\n\npublic class threadpoolexample {\n    public static void main(string[] args) {\n        // 创建一个线程池\n        executorservice executorservice = executors.newfixedthreadpool(2);\n\n        // 创建实现runnable接口的任务\n        runnable task1 = () -> {\n            system.out.println("task 1 is running on thread: " + thread.currentthread().getname());\n        };\n\n        // 创建实现callable接口的任务\n        callable<string> task2 = () -> {\n            system.out.println("task 2 is running on thread: " + thread.currentthread().getname());\n            return "task 2 result";\n        };\n\n        try {\n            // 执行runnable任务\n            executorservice.execute(task1);\n\n            // 提交callable任务，并获取future对象\n            future<string> future = executorservice.submit(task2);\n\n            // 主线程等待callable任务执行完成，并获取结果\n            string result = future.get();\n            system.out.println("task 2 result: " + result);\n\n        } catch (interruptedexception | executionexception e) {\n            e.printstacktrace();\n        } finally {\n            // 关闭线程池\n            executorservice.shutdown();\n        }\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n\n\n\n# 线程池原理解析\n\n\n# 线程池有哪些参数？\n\n通过 executors 框架创建的线程池，从源码可以看到，它底层是通过 threadpoolexecutor 完成线程池的创建，具体参数如下：\n\n public static executorservice newfixedthreadpool(int nthreads) {\n        return new threadpoolexecutor(nthreads, nthreads,\n                                      0l, timeunit.milliseconds,\n                                      new linkedblockingqueue<runnable>());\n    }\n\n\n1\n2\n3\n4\n5\n\n\n 1. corepoolsize：线程池的核心线程数，即线程池中始终保持的线程数。\n\n 2. maximumpoolsize：线程池中最大的线程数，包括核心线程数和非核心线程数。\n\n 3. keepalivetime：非核心线程的闲置时间，超过该时间后将被回收。\n\n 4. unit：keepalivetime 非核心线程的闲置时间的单位。\n\n 5. workqueue：任务队列，用于存储还未被执行的任务。\n\n 6. threadfactory：线程工厂，用于创建线程。\n\n 7. handler：饱和策略，即当线程池中的线程都在执行任务时，新的任务会如何处理。（也称为拒绝策略）\n\n\n# 讲讲核心线程数和最大线程数的区别？\n\n核心线程数和最大线程数的区别在于：\n\n在任务数超过核心线程数时，线程池会优先创建核心线程来执行任务，只有当任务队列已满且核心线程都在执行任务时，才会创建非核心线程来执行任务，直到达到最大线程数为止。\n\n\n# 讲讲有哪些拒绝策略？\n\n有四种常见的拒绝策略：\n\n 1. abortpolicy（默认）：直接抛出异常，阻止系统正常运行。\n 2. callerrunspolicy：只用调用者所在线程来执行任务。\n 3. discardoldestpolicy：丢弃队列中最老的一个任务，尝试再次提交当前任务。\n 4. discardpolicy：直接丢弃任务，不做任何处理。\n\n\n# 阻塞队列有哪些？\n\njava 中常用的阻塞队列有以下 4 种：\n\n 1. arrayblockingqueue：一个由数组结构组成的有界阻塞队列，按照先进先出的原则对元素进行排序。\n\n 2. linkedblockingqueue：一个由链表结构组成的可选有界阻塞队列，按照先进先出的原则对元素进行排序。\n    \n    如果队列容量没有限制，则为无界阻塞队列。\n\n 3. priorityblockingqueue：一个支持优先级排序的无界阻塞队列。\n\n 4. synchronousqueue：一个不存储元素的阻塞队列，每个插入操作必须等待另一个线程的移除操作，否则插入操作一直处于阻塞状态。\n\n\n# 新线程添加的流程?\n\n新线程的添加有以下 4 个流程：\n\n 1. 如果当前线程池中的线程数小于核心线程数，那么就创建一个新的核心线程来执行这个任务；\n\n 2. 如果当前线程池中的线程数已经达到了核心线程数，那么就将任务添加到任务队列中等待执行；\n\n 3. 如果任务队列已满，但当前线程池中的线程数还没有达到最大线程数，那么就创建一个新的非核心线程来执行这个任务；\n    \n    > 非核心线程在执行完任务之后会被回收，直到线程池中的线程数又重新降至核心线程数。\n\n 4. 如果当前线程池中的线程数已经达到了最大线程数，那么就根据饱和策略来处理这个任务。\n\n\n# 线程池的两种创建方式\n\n# threadpoolexecutor\n\n方式一：通过 threadpoolexecutor 构造函数来创建（推荐）。\n\n我们可以创建多种类型的 threadpoolexecutor：\n\n * fixedthreadpool：该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线程空闲时，便处理在任务队列中的任务。\n * singlethreadexecutor：该方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。\n * cachedthreadpool： 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。\n * scheduledthreadpool：该返回一个用来在给定的延迟后运行任务或者定期执行任务的线程池。\n\n# executors\n\n方式二：通过 executor 框架的工具类 executors 来创建。\n\nexecutors 返回线程池对象的弊端如下：\n\n * fixedthreadpool 和 singlethreadexecutor：使用的是无界的 linkedblockingqueue，任务队列最大长度为 integer.max_value,可能堆积大量的请求，从而导致 oom。\n\n * cachedthreadpool：使用的是同步队列 synchronousqueue, 允许创建的线程数量为 integer.max_value ，可能会创建大量线程，从而导致 oom。\n\n * scheduledthreadpool 和 singlethreadscheduledexecutor : 使用的无界的延迟阻塞队列 delayedworkqueue，任务队列最大长度为 integer.max_value, 可能堆积大量的请求，从而导致 oom。\n   \n   > oom（out of memory）是指内存溢出，即程序在运行过程中申请的内存超过了jvm所能提供的最大内存限制，导致无法继续分配内存，从而抛出内存溢出异常。\n\n\n# 线程池提交 execute 和 submit 有什么区别？\n\n 1. execute 用于提交不需要返回值的任务\n\nthreadspool.execute(new runnable() { \n    @override public void run() { \n        // todo auto-generated method stub } \n    });\n\n\n1\n2\n3\n4\n\n\n 2. submit() 方法用于提交需要返回值的任务\n    \n    线程池会返回一个 future 类型的对象，通过这个 future 对象可以判断任务是否执行成功，并且可以通过 future 的 get() 方法来获取返回值。\n\nfuture<object> future = executor.submit(harreturnvaluetask); \ntry { object s = future.get(); } catch (interruptedexception e) { \n    // 处理中断异常 \n} catch (executionexception e) { \n    // 处理无法执行任务异常 \n} finally { \n    // 关闭线程池 executor.shutdown();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 线程池的关闭方式\n\n线程池的停止方式有两种:\n\n 1. shutdown: 使用这个方法之后，我们无法提交新的任务进来，线程池会继续工作，将手头的任务执行完再停止。\n 2. shutdownnow: 这种停止方式比较粗暴，线程池会直接将手头的任务都强行停止，且不接受新任务进来，线程停止立即生效。\n\n\n# 学习参考\n\n * java 线程池详解 | javaguide)\n * java线程池详解 | shark chili\n * 面渣逆袭-java并发编程\n * executor框架详解\n * 实战总结！18种接口优化方案的总结',charsets:{cjk:!0}},{title:"JVM常问",frontmatter:{title:"JVM常问",date:"2023-08-29T21:24:27.000Z",permalink:"/pages/ff3623/",author:{name:"陌上清风",link:"https://msqfx.github.io"},categories:["java","JVM"],tags:[null],description:"答案： Java虚拟机（JVM）是Java编程语言的运行时环境，它负责将Java源代码编译为字节码并执行。它提供了内存管理、垃圾回收、类加载、即时编译等功能。",comment:!0,meta:[{name:"twitter:title",content:"JVM常问"},{name:"twitter:description",content:"答案： Java虚拟机（JVM）是Java编程语言的运行时环境，它负责将Java源代码编译为字节码并执行。它提供了内存管理、垃圾回收、类加载、即时编译等功能。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/04.JVM/02.JVM%E5%B8%B8%E9%97%AE.html"},{property:"og:type",content:"article"},{property:"og:title",content:"JVM常问"},{property:"og:description",content:"答案： Java虚拟机（JVM）是Java编程语言的运行时环境，它负责将Java源代码编译为字节码并执行。它提供了内存管理、垃圾回收、类加载、即时编译等功能。"},{property:"og:url",content:"https://www.msqfx.cc/01.java/04.JVM/02.JVM%E5%B8%B8%E9%97%AE.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-08-29T21:24:27.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"JVM常问"},{itemprop:"description",content:"答案： Java虚拟机（JVM）是Java编程语言的运行时环境，它负责将Java源代码编译为字节码并执行。它提供了内存管理、垃圾回收、类加载、即时编译等功能。"}],readingShow:"top"},regularPath:"/01.java/04.JVM/02.JVM%E5%B8%B8%E9%97%AE.html",relativePath:"01.java/04.JVM/02.JVM常问.md",key:"v-4d95c10a",path:"/pages/ff3623/",headers:[{level:2,title:"问题 1：什么是JVM？",slug:"问题-1-什么是jvm",normalizedTitle:"问题 1：什么是jvm？",charIndex:13},{level:2,title:"问题 2：JVM的主要组成部分有哪些？",slug:"问题-2-jvm的主要组成部分有哪些",normalizedTitle:"问题 2：jvm的主要组成部分有哪些？",charIndex:111},{level:2,title:"问题 3：JVM的内存模型是什么？",slug:"问题-3-jvm的内存模型是什么",normalizedTitle:"问题 3：jvm的内存模型是什么？",charIndex:224},{level:2,title:"问题 4：什么是Java堆？它的作用是什么？",slug:"问题-4-什么是java堆-它的作用是什么",normalizedTitle:"问题 4：什么是java堆？它的作用是什么？",charIndex:364},{level:2,title:"问题 5：Java堆中的永久代（PermGen）已被废弃，取而代之的是什么？",slug:"问题-5-java堆中的永久代-permgen-已被废弃-取而代之的是什么",normalizedTitle:"问题 5：java堆中的永久代（permgen）已被废弃，取而代之的是什么？",charIndex:584},{level:2,title:"问题 6：什么是垃圾回收（Garbage Collection）？它的目的是什么？",slug:"问题-6-什么是垃圾回收-garbage-collection-它的目的是什么",normalizedTitle:"问题 6：什么是垃圾回收（garbage collection）？它的目的是什么？",charIndex:706},{level:2,title:"问题 7：谈谈垃圾回收算法的类型和原理。",slug:"问题-7-谈谈垃圾回收算法的类型和原理。",normalizedTitle:"问题 7：谈谈垃圾回收算法的类型和原理。",charIndex:819},{level:2,title:"问题 8：什么是Java内存溢出（OutOfMemoryError）？怎么避免？",slug:"问题-8-什么是java内存溢出-outofmemoryerror-怎么避免",normalizedTitle:"问题 8：什么是java内存溢出（outofmemoryerror）？怎么避免？",charIndex:993},{level:2,title:"问题 9：什么是Java内存泄漏？如何避免？",slug:"问题-9-什么是java内存泄漏-如何避免",normalizedTitle:"问题 9：什么是java内存泄漏？如何避免？",charIndex:1119},{level:2,title:"问题 10：什么是类加载器（Class Loader）？有哪些类加载器？",slug:"问题-10-什么是类加载器-class-loader-有哪些类加载器",normalizedTitle:"问题 10：什么是类加载器（class loader）？有哪些类加载器？",charIndex:1230},{level:2,title:"问题 11：什么是双亲委派模型（Parent Delegation Model）？它的作用是什么？",slug:"问题-11-什么是双亲委派模型-parent-delegation-model-它的作用是什么",normalizedTitle:"问题 11：什么是双亲委派模型（parent delegation model）？它的作用是什么？",charIndex:1341},{level:2,title:"问题 12：什么是类初始化和实例初始化？它们的执行顺序是怎样的？",slug:"问题-12-什么是类初始化和实例初始化-它们的执行顺序是怎样的",normalizedTitle:"问题 12：什么是类初始化和实例初始化？它们的执行顺序是怎样的？",charIndex:1475},{level:2,title:"面试题",slug:"面试题",normalizedTitle:"面试题",charIndex:1662},{level:3,title:"JVM 内存区域划分",slug:"jvm-内存区域划分",normalizedTitle:"jvm 内存区域划分",charIndex:1670},{level:3,title:"类加载机制",slug:"类加载机制",normalizedTitle:"类加载机制",charIndex:1802},{level:3,title:"对象创建过程",slug:"对象创建过程",normalizedTitle:"对象创建过程",charIndex:1903},{level:3,title:"垃圾回收算法",slug:"垃圾回收算法",normalizedTitle:"垃圾回收算法",charIndex:826},{level:3,title:"常见的垃圾收集器",slug:"常见的垃圾收集器",normalizedTitle:"常见的垃圾收集器",charIndex:2102},{level:3,title:"JVM 调优",slug:"jvm-调优",normalizedTitle:"jvm 调优",charIndex:2192}],headersStr:"问题 1：什么是JVM？ 问题 2：JVM的主要组成部分有哪些？ 问题 3：JVM的内存模型是什么？ 问题 4：什么是Java堆？它的作用是什么？ 问题 5：Java堆中的永久代（PermGen）已被废弃，取而代之的是什么？ 问题 6：什么是垃圾回收（Garbage Collection）？它的目的是什么？ 问题 7：谈谈垃圾回收算法的类型和原理。 问题 8：什么是Java内存溢出（OutOfMemoryError）？怎么避免？ 问题 9：什么是Java内存泄漏？如何避免？ 问题 10：什么是类加载器（Class Loader）？有哪些类加载器？ 问题 11：什么是双亲委派模型（Parent Delegation Model）？它的作用是什么？ 问题 12：什么是类初始化和实例初始化？它们的执行顺序是怎样的？ 面试题 JVM 内存区域划分 类加载机制 对象创建过程 垃圾回收算法 常见的垃圾收集器 JVM 调优",content:"# JVM 常问\n\n\n# 问题 1：什么是JVM？\n\n答案： Java虚拟机（JVM）是Java编程语言的运行时环境，它负责将Java源代码编译为字节码并执行。它提供了内存管理、垃圾回收、类加载、即时编译等功能。\n\n\n# 问题 2：JVM的主要组成部分有哪些？\n\n答案： JVM由三个主要的子系统组成：类加载器（Class Loader）、运行时数据区（Runtime Data Area）和执行引擎（Execution Engine）。\n\n\n# 问题 3：JVM的内存模型是什么？\n\n答案： JVM的内存模型分为线程私有区域和线程共享区域。\n\n 1. 线程私有区域包括\n    * 程序计数器、\n    * 虚拟机栈和本地方法栈。\n 2. 线程共享区域包括\n    * 堆、\n    * 方法区（元空间）和直接内存。\n\n\n# 问题 4：什么是Java堆？它的作用是什么？\n\n答案： Java堆是存储对象实例的地方，也是垃圾回收的主要区域。所有线程共享堆，它可以分为新生代和老年代，新生代又分为Eden空间、Survivor空间。\n\n老年代是用于存放生命周期较长的对象，经过多次垃圾回收仍然存活的对象会被移到老年代。老年代相对于新生代而言，其垃圾回收频率较低。\n\n这种分代的设计可以优化垃圾回收的效率，将对象按照生命周期进行分类，有助于提高内存利用率和性能。\n\n\n# 问题 5：Java堆中的永久代（PermGen）已被废弃，取而代之的是什么？\n\n答案： Java堆中的永久代已被元空间（Metaspace）取代。元空间存储【类的元数据信息】，如类名、方法、字段等，避免了永久代可能引起的内存溢出问题。\n\n\n# 问题 6：什么是垃圾回收（Garbage Collection）？它的目的是什么？\n\n答案： 垃圾回收是JVM自动管理内存的过程，用于释放不再被引用的对象所占用的内存。其目的是避免内存泄漏，使程序能够有效地使用内存。\n\n\n# 问题 7：谈谈垃圾回收算法的类型和原理。\n\n答案： 垃圾回收算法有 标记-清除、复制、标记-整理 等。\n\n其中\n\n * 标记-清除通过标记不再被引用的对象，然后清除它们；\n * 复制算法将堆分为两个区域，每次只使用其中一个，将存活对象复制到另一个区域；\n * 标记-整理通过标记存活对象并整理内存，将存活对象移动到一端，然后清除其余部分。\n\n\n# 问题 8：什么是Java内存溢出（OutOfMemoryError）？怎么避免？\n\n答案： Java内存溢出是指JVM中没有足够内存分配给新的对象。\n\n可以通过增加堆大小、优化代码、释放不再使用的对象、使用合适的数据结构等方式来避免内存溢出。\n\n\n# 问题 9：什么是Java内存泄漏？如何避免？\n\n答案： Java内存泄漏是指不再使用的对象仍然被保留在内存中，导致内存占用不断增加。\n\n避免内存泄漏的方法包括正确地关闭资源、使用弱引用、及时清除不再使用的引用等。\n\n\n# 问题 10：什么是类加载器（Class Loader）？有哪些类加载器？\n\n答案： 类加载器负责将类的字节码加载到JVM中并生成对应的Class对象。主要的类加载器有引导类加载器、扩展类加载器和应用程序类加载器。\n\n\n# 问题 11：什么是双亲委派模型（Parent Delegation Model）？它的作用是什么？\n\n答案： 双亲委派模型是指类加载器在加载类时首先委派给父类加载器，只有在父类加载器找不到对应的类时才尝试自己加载。这种模型保证了类的一致性和防止类的重复加载。\n\n\n# 问题 12：什么是类初始化和实例初始化？它们的执行顺序是怎样的？\n\n答案：\n\n * 类初始化是在类加载过程中执行的静态初始化代码块，\n * 实例初始化是在创建对象时执行的实例初始化代码块。\n\n类初始化在类加载过程中只执行一次，实例初始化在每次创建对象时都会执行。\n\n执行顺序是：父类的类初始化 -> 子类的类初始化 -> 父类的实例初始化 -> 子类的实例初始化。\n\n\n# 面试题\n\n\n# JVM 内存区域划分\n\n * 介绍 JVM 内存区域的划分，包括堆、方法区（元空间）、栈、本地方法栈和程序计数器。\n * 详细解释堆内存和方法区（元空间）的作用和区别。\n * 什么是永久代（PermGen）？Java 8 及以后版本的 JVM 有何不同？\n\n\n# 类加载机制\n\n * 什么是类加载器？Java 中有哪些内置的类加载器？\n * 解释类加载的双亲委派模型。\n * 什么是类加载过程，包括加载、连接和初始化阶段。\n * 什么是类加载器的委托机制？\n\n\n# 对象创建过程\n\n * 描述对象的创建过程，包括对象的内存分配和初始化。\n * 什么是对象头，它包含哪些信息？\n * 如何优化对象的创建，例如使用对象池或延迟初始化？\n\n\n# 垃圾回收算法\n\n * 解释垃圾回收的目的和原理。\n * 介绍常见的垃圾回收算法，如标记-清除、复制、标记-整理等。\n * 什么是分代垃圾回收，为什么要使用它？\n * 解释新生代和老年代之间的对象流动和垃圾回收策略。\n\n\n# 常见的垃圾收集器\n\n * 描述并区分常见的垃圾收集器，如Serial GC、Parallel GC、CMS、G1 等。\n * 针对不同应用场景，哪个垃圾收集器更适合使用？\n\n\n# JVM 调优\n\n 1. 如何监控 JVM 的性能和内存使用情况？\n\n 2. 什么是垃圾回收日志（GC 日志）？如何分析它来优化应用程序性能？\n\n 3. 介绍 JVM 参数（例如-Xmx、-Xms、-XX、-Xss）的作用和用法。\n\n 4. 现在我有一个服务，部署后分配了 4g 的堆内存，请从你的角度来分析下怎么优化 jvm\n    \n    为了优化 JVM 性能，您可以考虑以下几个关键方面：合理配置堆内存大小、选择适当的垃圾回收器和策略、精心管理线程和类加载、优化代码和资源使用、并发控制、实时监控和分析性能，以及定期升级 JVM 版本。\n\n * 内存分配：\n   * 堆内存大小：根据应用程序的需求和服务器的资源，合理设置堆内存大小。通常，不要将堆内存设置得过大，以避免过长的垃圾回收停顿时间。建议使用Xmx和Xms参数来配置堆内存大小。\n * 垃圾回收：\n   * 选择合适的垃圾回收器：根据应用程序的性质和需求，选择合适的垃圾回收器。例如，G1垃圾回收器适用于具有大堆内存的应用程序，而CMS适用于低延迟要求的应用程序。\n   * 调整垃圾回收策略：根据应用程序的内存使用情况，可以调整垃圾回收策略的参数，如新生代和老年代的比例、GC停顿时间等。\n   * 监控垃圾回收：使用JVM的垃圾回收日志和工具（如VisualVM、Grafana、Prometheus）来监控垃圾回收性能，及时发现问题并进行调整。\n * 线程管理：\n   * 控制线程数量：合理控制应用程序中的线程数量，以避免线程过多导致内存和CPU资源的浪费。\n   * 使用线程池：使用线程池来管理线程，以避免线程的频繁创建和销毁。\n * 类加载优化：\n   * 预热类加载：通过预热（Warm-Up）机制，在应用程序启动之前加载一些常用的类，提高应用程序的启动性能。\n   * 避免不必要的类加载：避免不必要的动态类加载操作，减少类加载器的负担。\n * 代码优化：\n   * 避免过多的对象创建：减少对象的创建和销毁，尤其是在循环中。\n   * 优化算法：选择高效的算法和数据结构，避免性能低下的操作。\n * 资源管理：\n   * 关闭不需要的资源：及时关闭文件、数据库连接、网络连接等资源，以释放系统资源。\n   * 使用连接池：使用数据库连接池、连接池等资源池，以便有效地管理和复用资源。\n * 并发管理：\n   * 使用并发工具：使用Java的并发工具库，如ConcurrentHashMap、线程池，来管理并发访问。\n   * 避免竞态条件：使用锁和同步机制来避免多线程竞态条件导致的问题。\n * 监控和分析：\n   * 实时监控：使用监控工具来实时监控应用程序的性能指标，及时发现问题。\n   * 分析工具：使用性能分析工具来识别性能瓶颈和内存泄漏问题。\n * 版本升级：\n   * JVM版本：升级到最新的JVM版本，以获取性能和安全性的改进。\n * 容器化：\n   * 如果应用程序运行在容器中，合理配置容器的资源限制，以避免资源争用。",normalizedContent:"# jvm 常问\n\n\n# 问题 1：什么是jvm？\n\n答案： java虚拟机（jvm）是java编程语言的运行时环境，它负责将java源代码编译为字节码并执行。它提供了内存管理、垃圾回收、类加载、即时编译等功能。\n\n\n# 问题 2：jvm的主要组成部分有哪些？\n\n答案： jvm由三个主要的子系统组成：类加载器（class loader）、运行时数据区（runtime data area）和执行引擎（execution engine）。\n\n\n# 问题 3：jvm的内存模型是什么？\n\n答案： jvm的内存模型分为线程私有区域和线程共享区域。\n\n 1. 线程私有区域包括\n    * 程序计数器、\n    * 虚拟机栈和本地方法栈。\n 2. 线程共享区域包括\n    * 堆、\n    * 方法区（元空间）和直接内存。\n\n\n# 问题 4：什么是java堆？它的作用是什么？\n\n答案： java堆是存储对象实例的地方，也是垃圾回收的主要区域。所有线程共享堆，它可以分为新生代和老年代，新生代又分为eden空间、survivor空间。\n\n老年代是用于存放生命周期较长的对象，经过多次垃圾回收仍然存活的对象会被移到老年代。老年代相对于新生代而言，其垃圾回收频率较低。\n\n这种分代的设计可以优化垃圾回收的效率，将对象按照生命周期进行分类，有助于提高内存利用率和性能。\n\n\n# 问题 5：java堆中的永久代（permgen）已被废弃，取而代之的是什么？\n\n答案： java堆中的永久代已被元空间（metaspace）取代。元空间存储【类的元数据信息】，如类名、方法、字段等，避免了永久代可能引起的内存溢出问题。\n\n\n# 问题 6：什么是垃圾回收（garbage collection）？它的目的是什么？\n\n答案： 垃圾回收是jvm自动管理内存的过程，用于释放不再被引用的对象所占用的内存。其目的是避免内存泄漏，使程序能够有效地使用内存。\n\n\n# 问题 7：谈谈垃圾回收算法的类型和原理。\n\n答案： 垃圾回收算法有 标记-清除、复制、标记-整理 等。\n\n其中\n\n * 标记-清除通过标记不再被引用的对象，然后清除它们；\n * 复制算法将堆分为两个区域，每次只使用其中一个，将存活对象复制到另一个区域；\n * 标记-整理通过标记存活对象并整理内存，将存活对象移动到一端，然后清除其余部分。\n\n\n# 问题 8：什么是java内存溢出（outofmemoryerror）？怎么避免？\n\n答案： java内存溢出是指jvm中没有足够内存分配给新的对象。\n\n可以通过增加堆大小、优化代码、释放不再使用的对象、使用合适的数据结构等方式来避免内存溢出。\n\n\n# 问题 9：什么是java内存泄漏？如何避免？\n\n答案： java内存泄漏是指不再使用的对象仍然被保留在内存中，导致内存占用不断增加。\n\n避免内存泄漏的方法包括正确地关闭资源、使用弱引用、及时清除不再使用的引用等。\n\n\n# 问题 10：什么是类加载器（class loader）？有哪些类加载器？\n\n答案： 类加载器负责将类的字节码加载到jvm中并生成对应的class对象。主要的类加载器有引导类加载器、扩展类加载器和应用程序类加载器。\n\n\n# 问题 11：什么是双亲委派模型（parent delegation model）？它的作用是什么？\n\n答案： 双亲委派模型是指类加载器在加载类时首先委派给父类加载器，只有在父类加载器找不到对应的类时才尝试自己加载。这种模型保证了类的一致性和防止类的重复加载。\n\n\n# 问题 12：什么是类初始化和实例初始化？它们的执行顺序是怎样的？\n\n答案：\n\n * 类初始化是在类加载过程中执行的静态初始化代码块，\n * 实例初始化是在创建对象时执行的实例初始化代码块。\n\n类初始化在类加载过程中只执行一次，实例初始化在每次创建对象时都会执行。\n\n执行顺序是：父类的类初始化 -> 子类的类初始化 -> 父类的实例初始化 -> 子类的实例初始化。\n\n\n# 面试题\n\n\n# jvm 内存区域划分\n\n * 介绍 jvm 内存区域的划分，包括堆、方法区（元空间）、栈、本地方法栈和程序计数器。\n * 详细解释堆内存和方法区（元空间）的作用和区别。\n * 什么是永久代（permgen）？java 8 及以后版本的 jvm 有何不同？\n\n\n# 类加载机制\n\n * 什么是类加载器？java 中有哪些内置的类加载器？\n * 解释类加载的双亲委派模型。\n * 什么是类加载过程，包括加载、连接和初始化阶段。\n * 什么是类加载器的委托机制？\n\n\n# 对象创建过程\n\n * 描述对象的创建过程，包括对象的内存分配和初始化。\n * 什么是对象头，它包含哪些信息？\n * 如何优化对象的创建，例如使用对象池或延迟初始化？\n\n\n# 垃圾回收算法\n\n * 解释垃圾回收的目的和原理。\n * 介绍常见的垃圾回收算法，如标记-清除、复制、标记-整理等。\n * 什么是分代垃圾回收，为什么要使用它？\n * 解释新生代和老年代之间的对象流动和垃圾回收策略。\n\n\n# 常见的垃圾收集器\n\n * 描述并区分常见的垃圾收集器，如serial gc、parallel gc、cms、g1 等。\n * 针对不同应用场景，哪个垃圾收集器更适合使用？\n\n\n# jvm 调优\n\n 1. 如何监控 jvm 的性能和内存使用情况？\n\n 2. 什么是垃圾回收日志（gc 日志）？如何分析它来优化应用程序性能？\n\n 3. 介绍 jvm 参数（例如-xmx、-xms、-xx、-xss）的作用和用法。\n\n 4. 现在我有一个服务，部署后分配了 4g 的堆内存，请从你的角度来分析下怎么优化 jvm\n    \n    为了优化 jvm 性能，您可以考虑以下几个关键方面：合理配置堆内存大小、选择适当的垃圾回收器和策略、精心管理线程和类加载、优化代码和资源使用、并发控制、实时监控和分析性能，以及定期升级 jvm 版本。\n\n * 内存分配：\n   * 堆内存大小：根据应用程序的需求和服务器的资源，合理设置堆内存大小。通常，不要将堆内存设置得过大，以避免过长的垃圾回收停顿时间。建议使用xmx和xms参数来配置堆内存大小。\n * 垃圾回收：\n   * 选择合适的垃圾回收器：根据应用程序的性质和需求，选择合适的垃圾回收器。例如，g1垃圾回收器适用于具有大堆内存的应用程序，而cms适用于低延迟要求的应用程序。\n   * 调整垃圾回收策略：根据应用程序的内存使用情况，可以调整垃圾回收策略的参数，如新生代和老年代的比例、gc停顿时间等。\n   * 监控垃圾回收：使用jvm的垃圾回收日志和工具（如visualvm、grafana、prometheus）来监控垃圾回收性能，及时发现问题并进行调整。\n * 线程管理：\n   * 控制线程数量：合理控制应用程序中的线程数量，以避免线程过多导致内存和cpu资源的浪费。\n   * 使用线程池：使用线程池来管理线程，以避免线程的频繁创建和销毁。\n * 类加载优化：\n   * 预热类加载：通过预热（warm-up）机制，在应用程序启动之前加载一些常用的类，提高应用程序的启动性能。\n   * 避免不必要的类加载：避免不必要的动态类加载操作，减少类加载器的负担。\n * 代码优化：\n   * 避免过多的对象创建：减少对象的创建和销毁，尤其是在循环中。\n   * 优化算法：选择高效的算法和数据结构，避免性能低下的操作。\n * 资源管理：\n   * 关闭不需要的资源：及时关闭文件、数据库连接、网络连接等资源，以释放系统资源。\n   * 使用连接池：使用数据库连接池、连接池等资源池，以便有效地管理和复用资源。\n * 并发管理：\n   * 使用并发工具：使用java的并发工具库，如concurrenthashmap、线程池，来管理并发访问。\n   * 避免竞态条件：使用锁和同步机制来避免多线程竞态条件导致的问题。\n * 监控和分析：\n   * 实时监控：使用监控工具来实时监控应用程序的性能指标，及时发现问题。\n   * 分析工具：使用性能分析工具来识别性能瓶颈和内存泄漏问题。\n * 版本升级：\n   * jvm版本：升级到最新的jvm版本，以获取性能和安全性的改进。\n * 容器化：\n   * 如果应用程序运行在容器中，合理配置容器的资源限制，以避免资源争用。",charsets:{cjk:!0}},{title:"JVM基础入门",frontmatter:{title:"JVM基础入门",date:"2023-08-11T22:29:07.000Z",permalink:"/pages/562a37/",author:{name:"陌上清风",link:"https://msqfx.github.io"},categories:["java","JVM"],tags:[null],description:"假设我们有一个文件 x.Java，你执行 javac，它就会变成 x.class。",comment:!0,meta:[{name:"image",content:"https://cmty256.github.io/imgs-blog/Java/image-20230811223459658.ku0m0cn1b0g.png"},{name:"twitter:title",content:"JVM基础入门"},{name:"twitter:description",content:"假设我们有一个文件 x.Java，你执行 javac，它就会变成 x.class。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://cmty256.github.io/imgs-blog/Java/image-20230811223459658.ku0m0cn1b0g.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/04.JVM/01.JVM%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"JVM基础入门"},{property:"og:description",content:"假设我们有一个文件 x.Java，你执行 javac，它就会变成 x.class。"},{property:"og:image",content:"https://cmty256.github.io/imgs-blog/Java/image-20230811223459658.ku0m0cn1b0g.png"},{property:"og:url",content:"https://www.msqfx.cc/01.java/04.JVM/01.JVM%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-08-11T22:29:07.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"JVM基础入门"},{itemprop:"description",content:"假设我们有一个文件 x.Java，你执行 javac，它就会变成 x.class。"},{itemprop:"image",content:"https://cmty256.github.io/imgs-blog/Java/image-20230811223459658.ku0m0cn1b0g.png"}],readingShow:"top"},regularPath:"/01.java/04.JVM/01.JVM%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8.html",relativePath:"01.java/04.JVM/01.JVM基础入门.md",key:"v-47b0b8a9",path:"/pages/562a37/",headers:[{level:2,title:"JVM 基础",slug:"jvm-基础",normalizedTitle:"jvm 基础",charIndex:2},{level:3,title:"聊一聊 Java 从编码到执行到底是一个怎么样的过程？",slug:"聊一聊-java-从编码到执行到底是一个怎么样的过程",normalizedTitle:"聊一聊 java 从编码到执行到底是一个怎么样的过程？",charIndex:26},{level:3,title:"什么是 JVM?",slug:"什么是-jvm",normalizedTitle:"什么是 jvm?",charIndex:733},{level:3,title:"常见的 JVM 实现",slug:"常见的-jvm-实现",normalizedTitle:"常见的 jvm 实现",charIndex:1064},{level:3,title:"JDK JRE JVM 的关系",slug:"jdk-jre-jvm-的关系",normalizedTitle:"jdk jre jvm 的关系",charIndex:1475},{level:2,title:"Class 文件格式",slug:"class-文件格式",normalizedTitle:"class 文件格式",charIndex:1614},{level:2,title:"类加载 - 初始化",slug:"类加载-初始化",normalizedTitle:"类加载 - 初始化",charIndex:3164},{level:3,title:"加载过程",slug:"加载过程",normalizedTitle:"加载过程",charIndex:3178},{level:3,title:"类加载器",slug:"类加载器",normalizedTitle:"类加载器",charIndex:4636},{level:3,title:"双亲委派",slug:"双亲委派",normalizedTitle:"双亲委派",charIndex:4971},{level:4,title:"为什么类加载器要使用双亲委派？（重要）",slug:"为什么类加载器要使用双亲委派-重要",normalizedTitle:"为什么类加载器要使用双亲委派？（重要）",charIndex:6716},{level:3,title:"类加载器范围",slug:"类加载器范围",normalizedTitle:"类加载器范围",charIndex:6780},{level:3,title:"自定义类加载器",slug:"自定义类加载器",normalizedTitle:"自定义类加载器",charIndex:6538},{level:4,title:"loadClass 源码解析",slug:"loadclass-源码解析",normalizedTitle:"loadclass 源码解析",charIndex:10875},{level:4,title:"自定义一个类加载器需要做什么？",slug:"自定义一个类加载器需要做什么",normalizedTitle:"自定义一个类加载器需要做什么？",charIndex:13144},{level:4,title:"加密",slug:"加密",normalizedTitle:"加密",charIndex:13291},{level:3,title:"编译器",slug:"编译器",normalizedTitle:"编译器",charIndex:284},{level:3,title:"懒加载",slug:"懒加载",normalizedTitle:"懒加载",charIndex:16691},{level:3,title:"拓展知识",slug:"拓展知识",normalizedTitle:"拓展知识",charIndex:17044},{level:4,title:"双亲委派如何打破？",slug:"双亲委派如何打破",normalizedTitle:"双亲委派如何打破？",charIndex:17052},{level:4,title:"类加载器涉及到了哪些设计模式？",slug:"类加载器涉及到了哪些设计模式",normalizedTitle:"类加载器涉及到了哪些设计模式？",charIndex:17385}],headersStr:"JVM 基础 聊一聊 Java 从编码到执行到底是一个怎么样的过程？ 什么是 JVM? 常见的 JVM 实现 JDK JRE JVM 的关系 Class 文件格式 类加载 - 初始化 加载过程 类加载器 双亲委派 为什么类加载器要使用双亲委派？（重要） 类加载器范围 自定义类加载器 loadClass 源码解析 自定义一个类加载器需要做什么？ 加密 编译器 懒加载 拓展知识 双亲委派如何打破？ 类加载器涉及到了哪些设计模式？",content:'# JVM 基础入门\n\n\n# JVM 基础\n\n\n# 聊一聊 Java 从编码到执行到底是一个怎么样的过程？\n\n\n\n假设我们有一个文件 x.Java，你执行 javac，它就会变成 x.class。\n\n这个 class 怎么执行的？\n\n当我们调用 Java 命令的时候，class 会被 load 到内存，这块叫【Classloader】，会被 Classloader 装载到内存里。\n\n一般的情况下，我们写自己的类文件的时候也会用到 【Java 的类库】，所以他会把 Java 类库相关的这些个类也要装载到内存里，装载完成之后会调用【字节码解释器】或者是【JIT 即时编译器】来进行解释或编译，编译完之后由【执行引擎】开始执行，这以及下面面对的，那就是操作系统和硬件了。\n\nJava 编译好了之后变成 class， class 会被 load 到内存，与此同时像什么 string， object 这些个 class 也都会被 load 到内存。\n\nJava 是这个解释执行的还是编译执行的？\n\n其实解释和编译是可以混合的，特别常用的一些代码，代码用到的次数特别多，这个时候他会把代码做成一个及时的编译，做成一个本地的编译。\n\n你可以理解为就像 c 语言在 Windows 上执行的时候，把它编译成 exe 一样，那么下次再执行这段代码的时候，就不需要通过解释器来一句一句解释来执行了，执行引擎可以直接交给操作系统去让它调用，这个效率要高很多，不是所有的代码都要都会被 GIT 进行及时编译的，如果是这样的话，那整个 Java 就完全变成了不能跨平台了。\n\n所以有一些特定的，执行起来执行次数好多好多，用的特别多的时候，这个时候会进行一个即时编译器的编译。\n\n\n# 什么是 JVM?\n\n所谓的 JVM 虚拟机，其实它本身是一个规范，是虚构出来的一台计算机。拥有自己的操作系统，是一个跨语言平台。\n\n为什么 JVM 虚拟机能够支持多种语言运行在上面呢？\n\n最关键的原因是就是因为 class 这个东西，我们可以说任何的语言，只要你能编译成 class，符合 class 文件的规范，你就可以扔在 Java 虚拟机上去执行。\n\n注意：JVM 只和 class 文件有关，与 java 无关。\n\nJDK 官网：Java SE Specifications (oracle.com)\n\n维基百科：Java虚拟机 - 维基百科，自由的百科全书 (wikipedia.org)\n\n甲骨文中国：Java 软件 | Oracle 中国\n\n\n# 常见的 JVM 实现\n\n 1. Hotspot（最常用）\n    \n    * oracle 官方，我们做实验用的 JVM，Java 虚拟机\n    * java -version 命令可查看使用的是什么 JVM\n    * Hotspot 8 之后要收费，但 Open JDK 是开源的版本，免费\n\n 2. Jrockit\n    \n    * BEA 曾经号称世界上最快的 JVM\n    * 被 Oracle 收购，合并于 hotspot\n\n 3. TaobaoVM（免费）\n    \n    * hotspot 深度定制版\n\n 4. LiquidVM\n    \n    * 直接针对硬件\n\n 5. azul zing（特别贵）\n    \n    * 最新垃圾回收的业界标杆（号称 1ms 以内）\n    * www.azul.com\n\n 6. J9-IBM\n    \n    * Microsoft VM\n\n\n# JDK JRE JVM 的关系\n\n包含关系。\n\nJVM -- 运行 java 字节码的虚拟机\n\nJRE -- java 运行环境 == jvm + core（核心类库）\n\nJDK -- java 开发工具包 == jre + development kit（开发工具）\n\n\n# Class 文件格式\n\nClass 文件格式（File Format）\n\n * 二进制字节流（由 java 虚拟机解释）\n * 数据类型: u1 u2 u4 u8 和 _info (表类型)\n   * info 的来源是 hotspot 源码中的写法\n * 查看 16 进制格式的 ClassFile\n   * 软件 - sublime / notepad /\n   * IDEA 插件 - BinEd\n * 有很多可以更好观察 ByteCode 的方法\n   * 终端命令：javap <class文件路径>，-v 参数详细查看\n   * JBE 可以直接修改\n   * JClassLib - IDEA 插件之一\n * 文件结构\n   * General Information（通用信息）： 这个部分包含了一些通用的信息，比如文件的魔数（magic number），文件版本号等。\n   * Constant Pool（常量池）： 常量池是一个重要的数据结构，它存储了一系列常量，包括字面值、符号引用、类和接口的名称等。常量池在字节码文件中起到了存储和管理常量数据的作用。\n   * Interfaces（接口）： 这部分定义了该类实现的接口。\n   * Fields（字段）： 这部分描述了类的字段（成员变量），包括字段的名称、类型以及修饰符等信息。\n   * Methods（方法）： 这部分描述了类的方法，包括方法的名称、参数列表、返回类型、字节码指令等。\n   * Attributes（属性）： 属性提供了关于类、字段或方法的其他信息，例如源代码行号、注解等。这个部分可以包含多个不同类型的属性，每个属性都有一个名称和相应的数据。\n\n如下图示：\n\n\n\n * magic：魔数，是一个固定的字节序列，用于标识 Java 字节码文件。它的值为 0xCAFEBABE，用于确定文件是否是有效的 Java 字节码文件。\n * minor version：次版本号，指示 Java 编译器版本的次要更新。用于描述字节码文件与Java虚拟机版本的兼容性。\n * major version：主版本号，指示 Java 编译器版本的主要更新。同样用于描述字节码文件与 Java 虚拟机版本的兼容性。\n * constant_pool_count：常量池计数，表示常量池中常量的数量。十六进制 0010 转化为十进制为 16。常量池真正存储内容的时候存了 16 -1 项。后面的内容都是引用它。\n * #1:：常量池项，通常以 # 开头，表示一个常量池中的单个项。\n * access flags：访问标志，描述类或接口的访问级别和特性。\n * this_class：当前类的索引，指示当前类在常量池中的位置。\n * super class：父类的索引，指示父类在常量池中的位置。\n * interface_count：接口数量，表示该类实现的接口数量。\n * interfaces：接口列表，描述该类实现的接口在常量池中的位置。\n * fields_count：字段数量，表示该类中声明的字段数量。\n * methods_count：方法数量，表示该类中声明的方法数量。\n * method_info：方法信息，描述方法的访问标志、方法名、参数列表等。\n * attribute_count：属性数量，表示该类的属性数量。\n\n每个部分描述了 Java 字节码文件的不同方面，从类的声明到方法的定义，以及与常量池等相关的信息。这些信息在 Java 虚拟机中被解析和使用，以正确地加载和执行 Java 类。\n\n> Java 的汇编指令有 200 多条。\n> \n> 好文分享：class类文件结构\n\n\n# 类加载 - 初始化\n\n\n# 加载过程\n\n加载、链接和初始化是 Java 程序运行时的三个主要阶段。\n\n 1. Loading -- 加载\n\n 2. Linking -- 链接\n    \n    * Verification -- 验证\n    * Preparation -- 准备\n    * Resolution -- 解析\n\n 3. Initializing -- 初始化\n\n具体来说：\n\n 1. Loading（加载）： 这是类加载过程的第一个阶段。在这个阶段，Java 虚拟机（JVM）会从类的外部源加载类的二进制数据，通常是从磁盘文件中加载，但也可以是网络、内存等。\n    \n    加载器将类的二进制数据（class文件）从外部源加载到内存中，并将其放置在运行时数据区的方法区内。\n\n 2. Linking（链接）： 这是加载过程的第二个阶段，它将类的二进制数据链接到 JVM 的运行时状态。\n    \n    链接过程分为以下三个步骤：\n    \n    * Verification（验证）：确保类的二进制数据符合 JVM 规范，不违反类加载的安全性要求。这个步骤确保类的结构正确，不会引发运行时错误。\n    * Preparation（准备）：为类的静态变量分配内存空间，并设置默认的初始值（通常为零值）。这个步骤为类变量分配内存并初始化，但不会为实例变量分配内存。（把 class 文件的静态变量赋默认值，比如 int 类型的默认值为 0）\n    * Resolution（解析）：将（class文件里面的常量池里面用到的）符号引用转换为直接引用，解析动作可以在运行时再完成，也可以在编译时静态完成。这个步骤处理类、接口、方法和字段的符号引用，将其解析为实际的引用。\n\n 3. Initializing（初始化）： 这是链接过程的最后一个阶段，也是类加载的最终阶段。在这个阶段，类的静态初始化器会被执行，初始化静态字段和执行静态块。这个阶段是在类被首次使用时触发的，例如创建类的实例、访问类的静态字段等。（调用类初始化代码 <clinit>，给静态成员变量赋初始值）\n\n总结来说，类加载过程涉及到从外部源加载类的二进制数据，然后将其链接到 JVM 的运行时状态，最终进行初始化。链接阶段包括验证、准备和解析，而初始化阶段则会执行类的静态初始化器。这个过程确保类在 Java 虚拟机中正确加载和使用。\n\n加载之后会发生什么？\n\n任何一个 class 被加载到内存之后，会生成了两块内容。\n\n * 第一块内容是这个二进制的，这块东西确实被落到内存，放到了内存的一块区域，可以原封不动的扔进去。\n * 第二个，它生成了一个 class 类的对象，通过以后其他的那些我们自己写的对象去访问这个对象，通过这个对象去访问 class 类的文件，所以生成一个 class 的对象，这个 class 对象是指向了这块内容。\n\n在 Java 虚拟机中，类的元数据，包括类的结构信息、字段、方法、父类、接口等，都会被加载到方法区（元空间Metaspace，替代了永久代PermGen）中。Class 对象本身也是类的元数据之一，因此 Class 对象也存放在方法区中。 Class 对象在内存中的位置可以看作是类的描述符，用来操作该类的字节码以及其他相关的元数据。\n\n可以看看下面这两篇文章：\n\n * 方法区与Metaspace\n * Java8取消permgen，使用mataspace有什么好处，内存结构有什么本质的变化？\n\n\n# 类加载器\n\nJVM 它本身有一个类加载器的层次，这个类加载器就是一个普通的 class，JVM 有一个类加载器的层次，分别来加载不同的 class。或者说，JVM 里面所有的 class 都是被类加载器给加载到内存的，那么这个类加载器简单说我们可以把它叫做 ClassLoader。\n\n\n\n注意：从下往上，是委托给父加载器，不是继承关系，是语法上的一种关系。\n\n在 Java 虚拟机中，类加载器按照层次结构进行组织，分为三个主要层次：启动类加载器（Bootstrap ClassLoader）、扩展类加载器（Extension ClassLoader）和应用程序类加载器（Application ClassLoader，也称为系统类加载器）。这些类加载器形成了类加载器的双亲委派模型。\n\n 1. 启动类加载器（Bootstrap ClassLoader）：这是 Java 虚拟机的一部分，用于加载 Java 核心库（例如 java.lang 包中的类）。它是所有其他类加载器的父加载器，但它本身不是一个普通的 Java 类，因此在源码中并没有对应的类。它位于虚拟机内部，通常用本地代码实现。它是最顶层的类加载器，负责加载 Java 核心类库。\n 2. 扩展类加载器（Extension ClassLoader）： 扩展类加载器用于加载 Java 虚拟机的扩展类库，位于 jre/lib/ext 目录中的类。它的父加载器是启动类加载器。\n 3. 应用程序类加载器（Application ClassLoader）：这个加载器也称为系统类加载器，它负责加载应用程序的类，包括用户自定义的类和第三方库中的类。它的父加载器是扩展类加载器。\n\n启动类加载器、扩展类加载器和应用程序类加载器构成了类加载器的层次结构，通过双亲委派模型来保证类的加载的一致性和安全性。在加载一个类时，首先会尝试由父加载器加载，只有在父加载器无法加载时，子加载器才会尝试加载。这个模型可以防止类的重复加载，同时保证了类的隔离性。\n\n在启动类加载器加载的类中，有一部分是虚拟机内部的类，比如 java.lang.Object、java.lang.String 等。这些类并不是普通的 Java 类，因此没有对应的源码。而在 Java 虚拟机的源码中，通常会对这些类的加载过程进行描述，但实际上它们是由虚拟机的实现提供的。\n\n最顶层加载器 Bootstrap 会返回一个空值。\n\npublic class T004_ParentAndChild {\n    public static void main(String[] args) {\n        System.out.println(T004_ParentAndChild.class.getClassLoader());\n        System.out.println(T004_ParentAndChild.class.getClassLoader().getClass().getClassLoader()); // App\n        System.out.println(T004_ParentAndChild.class.getClassLoader().getParent()); // Extension\n        System.out.println(T004_ParentAndChild.class.getClassLoader().getParent().getParent()); // Bootstrap，返回 null\n        // System.out.println(T004_ParentAndChild.class.getClassLoader().getParent().getParent().getParent()); // 解开注释就会报空指针异常\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n输出结果：\n\nsun.misc.Launcher$AppClassLoader@18b4aac2\nnull\nsun.misc.Launcher$ExtClassLoader@4554617c\nnull\n\n\n1\n2\n3\n4\n\n\n\n# 双亲委派\n\n 1. 父加载器\n    * 父加载器不是【类加载器的加载器】！！！也不是【类加载器的父类加载器】\n 2. 双亲委派是一个孩子向父亲方向，然后父亲向孩子方向的双亲委派过程\n 3. 思考：为什么要搞双亲委派？\n    * java.lang.String 类由自定义类加载器加载行不行？ -- 不行，因为不安全\n\n先是自底向上检查是否已经加载，然后再回过头来找 class 并加载，查看是否加载成功，一直到底都没加载成功就会抛出一个 class 找不到异常。\n\n\n\n这个缓存是在哪缓存？\n\n可以简单的认为是它自己内部维护的一个容器，一个 list 或者一个数组加载的东西都扔在里面。每个加载器都有自己的缓存。\n\n# 为什么类加载器要使用双亲委派？（重要）\n\n主要是为了安全。次要原因是资源浪费问题，避免重新加载问题（防止类重复加载）。\n\n\n# 类加载器范围\n\n来自 Launcher 源码\n\n 1. 启动类加载器 Bootstrap ClassLoader：\n    * 加载路径：sun.boot.class.path\n    * 范围：它负责加载 Java 核心类库，这些类库包括 Java API 中的基础类，如 java.lang 包下的类等。\n    * 作用：它是 Java 类加载器中最顶层的类加载器，负责加载虚拟机自身需要的类，以及在运行期间会被系统使用的类。由于 Bootstrap ClassLoader 是用本地代码来实现的，所以在 Java 中无法直接获取到该类加载器的引用。\n 2. 扩展类加载器 ExtensionClassLoader：\n    * 加载路径：java.ext.dirs\n    * 范围：它负责加载 Java 的扩展库，这些库位于 JRE 的 lib/ext 目录或者由系统变量 java.ext.dirs 指定的路径。\n    * 作用：它负责加载一些 Java 标准扩展库以及一些自定义的扩展库，这些库通常是一些可选的功能。扩展类加载器是由 sun.misc.Launcher$ExtClassLoader 实现的。\n 3. 系统类加载器 AppClassLoader：\n    * 加载路径：java.class.path\n    * 范围：也被称为系统类加载器，它负责加载用户类路径（Classpath）上指定的类。\n    * 作用：它负责加载应用程序中的类，包括开发者自己编写的类以及引用的第三方类库。应用类加载器是由 sun.misc.Launcher$AppClassLoader 实现的。\n\n代码查看：\n\npublic class T003_ClassLoaderScope {\n    public static void main(String[] args) {\n        System.out.println("根目录下加载");\n        String pathBoot = System.getProperty("sun.boot.class.path");\n        System.out.println(pathBoot.replaceAll(";", System.lineSeparator()));\n\n        System.out.println("--------------------");\n        System.out.println("ext 下加载");\n        String pathExt = System.getProperty("java.ext.dirs");\n        System.out.println(pathExt.replaceAll(";", System.lineSeparator()));\n\n        System.out.println("--------------------");\n        System.out.println("App 下加载");\n        String pathApp = System.getProperty("java.class.path");\n        System.out.println(pathApp.replaceAll(";", System.lineSeparator()));\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n输出结果：\n\n根目录下加载\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\resources.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\rt.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\sunrsasign.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\jsse.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\jce.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\charsets.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\jfr.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\classes\n--------------------\next 下加载\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\nC:\\WINDOWS\\Sun\\Java\\lib\\ext\n--------------------\nApp 下加载\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\charsets.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\deploy.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\access-bridge-64.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\cldrdata.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\dnsns.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\jaccess.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\jfxrt.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\localedata.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\nashorn.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\sunec.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\sunjce_provider.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\sunmscapi.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\sunpkcs11.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\ext\\zipfs.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\javaws.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\jce.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\jfr.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\jfxswt.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\jsse.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\management-agent.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\plugin.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\resources.jar\nC:\\Program Files\\Java\\jdk1.8.0_321\\jre\\lib\\rt.jar\nD:\\笔记\\学习资料\\马士兵\\JVM视频源码\\out\\production\\JVM\t\t\t\t// 项目路径\nD:\\software\\idea2022\\IntelliJ IDEA 2022.1.3\\lib\\idea_rt.jar\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n\n\n\n# 自定义类加载器\n\n当你想加载某个类的时候，可以调用 loadClass 方法\n\npublic class T005_LoadClassByHand {\n    public static void main(String[] args) throws ClassNotFoundException {\n        Class clazz = T005_LoadClassByHand.class.getClassLoader().loadClass("com.mashibing.jvm.c2_classloader.T002_ClassLoaderLevel");\n        System.out.println(clazz.getName());\n\n        //利用类加载器加载资源，参考坦克图片的加载\n        //T005_LoadClassByHand.class.getClassLoader().getResourceAsStream("");\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n# loadClass 源码解析\n\nloadClass 方法是在双亲委派模型下实现的。\n\nfindInCache -> parent.loadClass -> findClass()\n\nprivate final ClassLoader parent; // final 关键字修饰\n\nprotected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException\n    {\n        synchronized (getClassLoadingLock(name)) {\n            // 首先，检查类是否已经加载\n            Class<?> c = findLoadedClass(name);\n            if (c == null) {\n                long t0 = System.nanoTime();\n                try {\n                    // 如果类不在已加载类中，则委派给父类加载器加载\n                    if (parent != null) {\n                        c = parent.loadClass(name, false);\n                    } else {\n                        // 如果没有父加载器，则使用系统类加载器加载\n                        c = findBootstrapClassOrNull(name);\n                    }\n                } catch (ClassNotFoundException e) {\n                    // 如果找不到类，抛出ClassNotFoundException\n                    // 从非空父类装入器\n                }\n              \n\t\t\t\t\t\t\t // 如果父加载器也找不到，则尝试自己加载\n                if (c == null) {\n                    // 如果仍未找到，则按顺序调用 findClass\n                    // to find the class. 要找到这个类\n                    long t1 = System.nanoTime();\n                    c = findClass(name);\n\n                    // 这是定义类装入器；记录统计数据\n                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);\n                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);\n                    sun.misc.PerfCounter.getFindClasses().increment();\n                }\n            }\n            if (resolve) {\n                resolveClass(c);\n            }\n            return c;\n        }\n    }\n\n    protected Class<?> findClass(String name) throws ClassNotFoundException { // findClass被protected修饰，保护起来\n        throw new ClassNotFoundException(name);\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n\n\n主要步骤如下：\n\n 1. 首先，方法会尝试从已加载的类中查找目标类是否已经加载，如果已经加载，则直接返回该类。\n 2. 如果目标类未加载，它会尝试委派给父类加载器来加载。这是双亲委派模型的核心思想之一。父类加载器会重复这个过程，直到到达启动类加载器（Bootstrap ClassLoader）为止。\n 3. 如果父类加载器也无法加载目标类，则 loadClass 方法会调用 findClass 方法，尝试自己加载目标类。这是子类加载器在加载自己类的最后一步。\n 4. 最后，如果 resolve 参数为 true，则会调用 resolveClass 方法，用于解析加载的类，确保类的完整性和正确性。\n\n什么时候需要自己去加载？\n\n加载进去就生成 class 对象吗？\n\n不是，要经过 初始化 才生成 class 对象。\n\n# 自定义一个类加载器需要做什么？\n\n只需要做一件事，就是定义自己的 findClass 就可以了。\n\n具体来说：\n\n * 继承 ClassLoader\n\n * 重写模板方法 findClass\n   \n   * 调用 defineClass(byte[] -> Class clazz)\n\n * 加密：可自定义类加载器加载自加密的 class\n   \n   * 防止反编译\n   * 防止篡改\n\n代码如下：\n\n首先继承 ClassLoader 这个类\n\n// 自定义类加载器继承自ClassLoader\npublic class T006_MSBClassLoader extends ClassLoader {\n\n    // 重写findClass方法，用于加载类字节码\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n        // 根据类名构建文件路径\n        File f = new File("c:/test/", name.replace(".", "/").concat(".class"));\n        try {\n            // 读取字节码文件\n            FileInputStream fis = new FileInputStream(f);\n            ByteArrayOutputStream baos = new ByteArrayOutputStream();\n            int b = 0;\n\n            // 读取文件内容并写入字节数组输出流\n            while ((b=fis.read()) !=0) {\n                baos.write(b);\n            }\n\n            // 将字节数组转换为字节数组\n            byte[] bytes = baos.toByteArray();\n            baos.close();\n            fis.close(); // 关闭流\n\n            // 使用defineClass方法定义并返回类\n            return defineClass(name, bytes, 0, bytes.length);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        // 若加载失败，则调用父类的findClass方法\n        return super.findClass(name); // throws ClassNotFoundException\n    }\n\n    // 主函数\n    public static void main(String[] args) throws Exception {\n        // 创建自定义类加载器实例\n        ClassLoader l = new T006_MSBClassLoader();\n        \n        // 通过自定义类加载器加载类\n        Class clazz = l.loadClass("com.mashibing.jvm.Hello");\n        Class clazz1 = l.loadClass("com.mashibing.jvm.Hello");\n\n        // 输出两次加载的类是否相同\n        System.out.println(clazz == clazz1);\n\n        // 创建加载的类的实例并调用方法\n        Hello h = (Hello) clazz.newInstance();\n        h.m();\n\n        // 输出类加载器信息\n        System.out.println(l.getClass().getClassLoader()); // 输出自定义类加载器的类加载器\n        System.out.println(l.getParent()); // 输出自定义类加载器的父类加载器\n\n        System.out.println(getSystemClassLoader()); // 输出系统类加载器\n    }\n}\n\npublic class Hello {\n    public void m() {\n        System.out.println("Hello JVM!");\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n\n\n这段代码实现了一个自定义的类加载器 T006_MSBClassLoader，该类加载器继承自 ClassLoader，重写了 findClass 方法来加载类的字节码。在主函数中，使用这个自定义的类加载器加载类，并输出加载的类是否相同，然后创建该类的实例并调用方法。最后，输出了自定义类加载器的类加载器和父类加载器信息，以及系统类加载器的信息。这种自定义类加载器的方式允许你从非标准的位置加载类文件，并且可以通过不同的类加载器实现类的隔离。\n\n----------------------------------------\n\ndefineClass 方法是 ClassLoader 类中的一个重要方法，用于将字节数组转换为一个 Class 对象。该方法的作用是将一个【字节数组中的类字节码】转换为一个【Java 类的实例】。当一个类加载器调用 defineClass 方法时，它会将字节数组中的类字节码转换为一个 Class 对象，并返回该对象。(不会验证字节码的正确性)\n\n> 输出结果\n\ntrue\nHello JVM!\nsun.misc.Launcher$AppClassLoader@18b4aac2\nsun.misc.Launcher$AppClassLoader@18b4aac2\nsun.misc.Launcher$AppClassLoader@18b4aac2\n\n\n1\n2\n3\n4\n5\n\n\n# 加密\n\n大家都知道 java 的代码 class 文件很容易就被反编译了。\n\n但是我要是定义自己的格式，我不想让别人反编译，这时候怎么办？\n\n你可以通过自定义的 class loader 来进行。然后在写逻辑的时候加一个加密操作。\n\n\n# 编译器\n\n三大模式：\n\n * 解释器（bytecode intepreter） -- 解释模式\n * JIT（Just In-Time compiler） -- 编译模式\n * 混合模式\n   * 混合使用解释器 + 热点代码编译（编译成本地代码，就不用在解释器里面解释来执行了，效率提升）\n   * 起始阶段采用解释执行\n   * 热点代码检测\n     * 多次被调用的方法(方法计数器:监测方法执行频率)\n     * 多次被调用的循环(循环计数器:检测循环执行频率)\n     * 进行编译\n\n为什么不干脆直接编译成本地代码，那执行效率不更高吗？\n\n有两个原因。\n\n 1. 第一，Java 的解释器，现在它的效率也已经非常高了，在一些简单代码的执行上，它并不输于你编译成本地代码。\n 2. 第二，如果你一个执行的文件特别多，各种各样的类库的时候，好几十个 class，你上来二话不说先在内存里编译一遍，这个启动过程会长得吓人。所以它现在默认的模式是混合模式。\n\n可以用指明参数的方式指定用什么模式\n\n 1. -Xmixed 默认为混合模式\n    \n    开始解释执行，启动速度较快，对热点代码实行检测和编译\n\n 2. -Xint 使用解释模式，启动很快，执行稍慢\n\n 3. -Xcomp 使用纯编译模式，执行很快，启动很慢（要编译的类少的时候，启动也会很快）\n\n\n# 懒加载\n\nlazyloading\n\n * 严格讲应该叫 lazylnitializing\n * JVM 规范并没有规定何时加载\n * 但是严格规定了什么时候必须初始化，五种情况\n   1. 使用 new，getstatic，putstatic，invokestatic 指令时，访问 final 变量除外\n   2. java.lang.reflect 对类进行反射调用时\n   3. 初始化子类的时候，父类必须首先初始化\n   4. 虚拟机启动时，被执行的主类必须初始化\n   5. 动态语言支持 java.lang.invoke.MethodHandle 解析的结果为 REF_getstatic, REF_putstatic, REF_invokestatic 的方法句柄时，该类必须初始化\n\n\n# 拓展知识\n\n# 双亲委派如何打破？\n\nparent 是如何指定的，打破双亲委派\n\n 1. 用 super(parent) 指定\n 2. 双亲委派的打破\n    1. 如何打破：重写 loadClass() 方法\n    2. 何时打破过？\n       1. JDK1.2 之前，自定义 ClassLoader 都必须重写 loadClass()\n       2. ThreadContextClassLoader 可以实现基础类调用实现类代码，通过 thread.setContextClassLoader 指定\n       3. 热启动，热部署\n          * osgi tomcat 都有自己的模块指定 classloader（可以加载同一类库的不同版本）\n\n# 类加载器涉及到了哪些设计模式？\n\n在 Java 虚拟机 (JVM) 中的类加载器 (ClassLoader) 实现中，通常使用了以下两种设计模式：\n\n 1. 委托模式 (Delegation Pattern)：ClassLoader 的实现通常使用了委托模式来处理类加载请求。委托模式指的是当一个对象收到请求时，它将请求委托给其他对象来处理。在类加载器的情况下，当一个类加载器接收到加载类的请求时，它首先会将请求委托给父类加载器进行处理。如果父类加载器无法加载该类，子类加载器才会尝试加载类。这种委托模式的设计方式可以实现类加载器的层次结构，从而实现类加载器的隔离和类加载的委派。\n 2. 单一职责模式 (Single Responsibility Pattern)：ClassLoader 的主要责任是加载类文件并定义对应的类。ClassLoader 的设计符合单一职责模式，即一个类应该只负责一项职责。ClassLoader 将类加载的职责封装在一个独立的类中，从而使得类加载的逻辑与其他功能解耦，提高了代码的可维护性和可扩展性。\n\n除了委托模式和单一职责模式，ClassLoader 的实现可能还涉及其他设计模式，具体取决于实际的实现细节和需求。例如，一些类加载器的缓存机制可能使用了享元模式 (Flyweight Pattern) 来提高性能和资源利用效率。',normalizedContent:'# jvm 基础入门\n\n\n# jvm 基础\n\n\n# 聊一聊 java 从编码到执行到底是一个怎么样的过程？\n\n\n\n假设我们有一个文件 x.java，你执行 javac，它就会变成 x.class。\n\n这个 class 怎么执行的？\n\n当我们调用 java 命令的时候，class 会被 load 到内存，这块叫【classloader】，会被 classloader 装载到内存里。\n\n一般的情况下，我们写自己的类文件的时候也会用到 【java 的类库】，所以他会把 java 类库相关的这些个类也要装载到内存里，装载完成之后会调用【字节码解释器】或者是【jit 即时编译器】来进行解释或编译，编译完之后由【执行引擎】开始执行，这以及下面面对的，那就是操作系统和硬件了。\n\njava 编译好了之后变成 class， class 会被 load 到内存，与此同时像什么 string， object 这些个 class 也都会被 load 到内存。\n\njava 是这个解释执行的还是编译执行的？\n\n其实解释和编译是可以混合的，特别常用的一些代码，代码用到的次数特别多，这个时候他会把代码做成一个及时的编译，做成一个本地的编译。\n\n你可以理解为就像 c 语言在 windows 上执行的时候，把它编译成 exe 一样，那么下次再执行这段代码的时候，就不需要通过解释器来一句一句解释来执行了，执行引擎可以直接交给操作系统去让它调用，这个效率要高很多，不是所有的代码都要都会被 git 进行及时编译的，如果是这样的话，那整个 java 就完全变成了不能跨平台了。\n\n所以有一些特定的，执行起来执行次数好多好多，用的特别多的时候，这个时候会进行一个即时编译器的编译。\n\n\n# 什么是 jvm?\n\n所谓的 jvm 虚拟机，其实它本身是一个规范，是虚构出来的一台计算机。拥有自己的操作系统，是一个跨语言平台。\n\n为什么 jvm 虚拟机能够支持多种语言运行在上面呢？\n\n最关键的原因是就是因为 class 这个东西，我们可以说任何的语言，只要你能编译成 class，符合 class 文件的规范，你就可以扔在 java 虚拟机上去执行。\n\n注意：jvm 只和 class 文件有关，与 java 无关。\n\njdk 官网：java se specifications (oracle.com)\n\n维基百科：java虚拟机 - 维基百科，自由的百科全书 (wikipedia.org)\n\n甲骨文中国：java 软件 | oracle 中国\n\n\n# 常见的 jvm 实现\n\n 1. hotspot（最常用）\n    \n    * oracle 官方，我们做实验用的 jvm，java 虚拟机\n    * java -version 命令可查看使用的是什么 jvm\n    * hotspot 8 之后要收费，但 open jdk 是开源的版本，免费\n\n 2. jrockit\n    \n    * bea 曾经号称世界上最快的 jvm\n    * 被 oracle 收购，合并于 hotspot\n\n 3. taobaovm（免费）\n    \n    * hotspot 深度定制版\n\n 4. liquidvm\n    \n    * 直接针对硬件\n\n 5. azul zing（特别贵）\n    \n    * 最新垃圾回收的业界标杆（号称 1ms 以内）\n    * www.azul.com\n\n 6. j9-ibm\n    \n    * microsoft vm\n\n\n# jdk jre jvm 的关系\n\n包含关系。\n\njvm -- 运行 java 字节码的虚拟机\n\njre -- java 运行环境 == jvm + core（核心类库）\n\njdk -- java 开发工具包 == jre + development kit（开发工具）\n\n\n# class 文件格式\n\nclass 文件格式（file format）\n\n * 二进制字节流（由 java 虚拟机解释）\n * 数据类型: u1 u2 u4 u8 和 _info (表类型)\n   * info 的来源是 hotspot 源码中的写法\n * 查看 16 进制格式的 classfile\n   * 软件 - sublime / notepad /\n   * idea 插件 - bined\n * 有很多可以更好观察 bytecode 的方法\n   * 终端命令：javap <class文件路径>，-v 参数详细查看\n   * jbe 可以直接修改\n   * jclasslib - idea 插件之一\n * 文件结构\n   * general information（通用信息）： 这个部分包含了一些通用的信息，比如文件的魔数（magic number），文件版本号等。\n   * constant pool（常量池）： 常量池是一个重要的数据结构，它存储了一系列常量，包括字面值、符号引用、类和接口的名称等。常量池在字节码文件中起到了存储和管理常量数据的作用。\n   * interfaces（接口）： 这部分定义了该类实现的接口。\n   * fields（字段）： 这部分描述了类的字段（成员变量），包括字段的名称、类型以及修饰符等信息。\n   * methods（方法）： 这部分描述了类的方法，包括方法的名称、参数列表、返回类型、字节码指令等。\n   * attributes（属性）： 属性提供了关于类、字段或方法的其他信息，例如源代码行号、注解等。这个部分可以包含多个不同类型的属性，每个属性都有一个名称和相应的数据。\n\n如下图示：\n\n\n\n * magic：魔数，是一个固定的字节序列，用于标识 java 字节码文件。它的值为 0xcafebabe，用于确定文件是否是有效的 java 字节码文件。\n * minor version：次版本号，指示 java 编译器版本的次要更新。用于描述字节码文件与java虚拟机版本的兼容性。\n * major version：主版本号，指示 java 编译器版本的主要更新。同样用于描述字节码文件与 java 虚拟机版本的兼容性。\n * constant_pool_count：常量池计数，表示常量池中常量的数量。十六进制 0010 转化为十进制为 16。常量池真正存储内容的时候存了 16 -1 项。后面的内容都是引用它。\n * #1:：常量池项，通常以 # 开头，表示一个常量池中的单个项。\n * access flags：访问标志，描述类或接口的访问级别和特性。\n * this_class：当前类的索引，指示当前类在常量池中的位置。\n * super class：父类的索引，指示父类在常量池中的位置。\n * interface_count：接口数量，表示该类实现的接口数量。\n * interfaces：接口列表，描述该类实现的接口在常量池中的位置。\n * fields_count：字段数量，表示该类中声明的字段数量。\n * methods_count：方法数量，表示该类中声明的方法数量。\n * method_info：方法信息，描述方法的访问标志、方法名、参数列表等。\n * attribute_count：属性数量，表示该类的属性数量。\n\n每个部分描述了 java 字节码文件的不同方面，从类的声明到方法的定义，以及与常量池等相关的信息。这些信息在 java 虚拟机中被解析和使用，以正确地加载和执行 java 类。\n\n> java 的汇编指令有 200 多条。\n> \n> 好文分享：class类文件结构\n\n\n# 类加载 - 初始化\n\n\n# 加载过程\n\n加载、链接和初始化是 java 程序运行时的三个主要阶段。\n\n 1. loading -- 加载\n\n 2. linking -- 链接\n    \n    * verification -- 验证\n    * preparation -- 准备\n    * resolution -- 解析\n\n 3. initializing -- 初始化\n\n具体来说：\n\n 1. loading（加载）： 这是类加载过程的第一个阶段。在这个阶段，java 虚拟机（jvm）会从类的外部源加载类的二进制数据，通常是从磁盘文件中加载，但也可以是网络、内存等。\n    \n    加载器将类的二进制数据（class文件）从外部源加载到内存中，并将其放置在运行时数据区的方法区内。\n\n 2. linking（链接）： 这是加载过程的第二个阶段，它将类的二进制数据链接到 jvm 的运行时状态。\n    \n    链接过程分为以下三个步骤：\n    \n    * verification（验证）：确保类的二进制数据符合 jvm 规范，不违反类加载的安全性要求。这个步骤确保类的结构正确，不会引发运行时错误。\n    * preparation（准备）：为类的静态变量分配内存空间，并设置默认的初始值（通常为零值）。这个步骤为类变量分配内存并初始化，但不会为实例变量分配内存。（把 class 文件的静态变量赋默认值，比如 int 类型的默认值为 0）\n    * resolution（解析）：将（class文件里面的常量池里面用到的）符号引用转换为直接引用，解析动作可以在运行时再完成，也可以在编译时静态完成。这个步骤处理类、接口、方法和字段的符号引用，将其解析为实际的引用。\n\n 3. initializing（初始化）： 这是链接过程的最后一个阶段，也是类加载的最终阶段。在这个阶段，类的静态初始化器会被执行，初始化静态字段和执行静态块。这个阶段是在类被首次使用时触发的，例如创建类的实例、访问类的静态字段等。（调用类初始化代码 <clinit>，给静态成员变量赋初始值）\n\n总结来说，类加载过程涉及到从外部源加载类的二进制数据，然后将其链接到 jvm 的运行时状态，最终进行初始化。链接阶段包括验证、准备和解析，而初始化阶段则会执行类的静态初始化器。这个过程确保类在 java 虚拟机中正确加载和使用。\n\n加载之后会发生什么？\n\n任何一个 class 被加载到内存之后，会生成了两块内容。\n\n * 第一块内容是这个二进制的，这块东西确实被落到内存，放到了内存的一块区域，可以原封不动的扔进去。\n * 第二个，它生成了一个 class 类的对象，通过以后其他的那些我们自己写的对象去访问这个对象，通过这个对象去访问 class 类的文件，所以生成一个 class 的对象，这个 class 对象是指向了这块内容。\n\n在 java 虚拟机中，类的元数据，包括类的结构信息、字段、方法、父类、接口等，都会被加载到方法区（元空间metaspace，替代了永久代permgen）中。class 对象本身也是类的元数据之一，因此 class 对象也存放在方法区中。 class 对象在内存中的位置可以看作是类的描述符，用来操作该类的字节码以及其他相关的元数据。\n\n可以看看下面这两篇文章：\n\n * 方法区与metaspace\n * java8取消permgen，使用mataspace有什么好处，内存结构有什么本质的变化？\n\n\n# 类加载器\n\njvm 它本身有一个类加载器的层次，这个类加载器就是一个普通的 class，jvm 有一个类加载器的层次，分别来加载不同的 class。或者说，jvm 里面所有的 class 都是被类加载器给加载到内存的，那么这个类加载器简单说我们可以把它叫做 classloader。\n\n\n\n注意：从下往上，是委托给父加载器，不是继承关系，是语法上的一种关系。\n\n在 java 虚拟机中，类加载器按照层次结构进行组织，分为三个主要层次：启动类加载器（bootstrap classloader）、扩展类加载器（extension classloader）和应用程序类加载器（application classloader，也称为系统类加载器）。这些类加载器形成了类加载器的双亲委派模型。\n\n 1. 启动类加载器（bootstrap classloader）：这是 java 虚拟机的一部分，用于加载 java 核心库（例如 java.lang 包中的类）。它是所有其他类加载器的父加载器，但它本身不是一个普通的 java 类，因此在源码中并没有对应的类。它位于虚拟机内部，通常用本地代码实现。它是最顶层的类加载器，负责加载 java 核心类库。\n 2. 扩展类加载器（extension classloader）： 扩展类加载器用于加载 java 虚拟机的扩展类库，位于 jre/lib/ext 目录中的类。它的父加载器是启动类加载器。\n 3. 应用程序类加载器（application classloader）：这个加载器也称为系统类加载器，它负责加载应用程序的类，包括用户自定义的类和第三方库中的类。它的父加载器是扩展类加载器。\n\n启动类加载器、扩展类加载器和应用程序类加载器构成了类加载器的层次结构，通过双亲委派模型来保证类的加载的一致性和安全性。在加载一个类时，首先会尝试由父加载器加载，只有在父加载器无法加载时，子加载器才会尝试加载。这个模型可以防止类的重复加载，同时保证了类的隔离性。\n\n在启动类加载器加载的类中，有一部分是虚拟机内部的类，比如 java.lang.object、java.lang.string 等。这些类并不是普通的 java 类，因此没有对应的源码。而在 java 虚拟机的源码中，通常会对这些类的加载过程进行描述，但实际上它们是由虚拟机的实现提供的。\n\n最顶层加载器 bootstrap 会返回一个空值。\n\npublic class t004_parentandchild {\n    public static void main(string[] args) {\n        system.out.println(t004_parentandchild.class.getclassloader());\n        system.out.println(t004_parentandchild.class.getclassloader().getclass().getclassloader()); // app\n        system.out.println(t004_parentandchild.class.getclassloader().getparent()); // extension\n        system.out.println(t004_parentandchild.class.getclassloader().getparent().getparent()); // bootstrap，返回 null\n        // system.out.println(t004_parentandchild.class.getclassloader().getparent().getparent().getparent()); // 解开注释就会报空指针异常\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n输出结果：\n\nsun.misc.launcher$appclassloader@18b4aac2\nnull\nsun.misc.launcher$extclassloader@4554617c\nnull\n\n\n1\n2\n3\n4\n\n\n\n# 双亲委派\n\n 1. 父加载器\n    * 父加载器不是【类加载器的加载器】！！！也不是【类加载器的父类加载器】\n 2. 双亲委派是一个孩子向父亲方向，然后父亲向孩子方向的双亲委派过程\n 3. 思考：为什么要搞双亲委派？\n    * java.lang.string 类由自定义类加载器加载行不行？ -- 不行，因为不安全\n\n先是自底向上检查是否已经加载，然后再回过头来找 class 并加载，查看是否加载成功，一直到底都没加载成功就会抛出一个 class 找不到异常。\n\n\n\n这个缓存是在哪缓存？\n\n可以简单的认为是它自己内部维护的一个容器，一个 list 或者一个数组加载的东西都扔在里面。每个加载器都有自己的缓存。\n\n# 为什么类加载器要使用双亲委派？（重要）\n\n主要是为了安全。次要原因是资源浪费问题，避免重新加载问题（防止类重复加载）。\n\n\n# 类加载器范围\n\n来自 launcher 源码\n\n 1. 启动类加载器 bootstrap classloader：\n    * 加载路径：sun.boot.class.path\n    * 范围：它负责加载 java 核心类库，这些类库包括 java api 中的基础类，如 java.lang 包下的类等。\n    * 作用：它是 java 类加载器中最顶层的类加载器，负责加载虚拟机自身需要的类，以及在运行期间会被系统使用的类。由于 bootstrap classloader 是用本地代码来实现的，所以在 java 中无法直接获取到该类加载器的引用。\n 2. 扩展类加载器 extensionclassloader：\n    * 加载路径：java.ext.dirs\n    * 范围：它负责加载 java 的扩展库，这些库位于 jre 的 lib/ext 目录或者由系统变量 java.ext.dirs 指定的路径。\n    * 作用：它负责加载一些 java 标准扩展库以及一些自定义的扩展库，这些库通常是一些可选的功能。扩展类加载器是由 sun.misc.launcher$extclassloader 实现的。\n 3. 系统类加载器 appclassloader：\n    * 加载路径：java.class.path\n    * 范围：也被称为系统类加载器，它负责加载用户类路径（classpath）上指定的类。\n    * 作用：它负责加载应用程序中的类，包括开发者自己编写的类以及引用的第三方类库。应用类加载器是由 sun.misc.launcher$appclassloader 实现的。\n\n代码查看：\n\npublic class t003_classloaderscope {\n    public static void main(string[] args) {\n        system.out.println("根目录下加载");\n        string pathboot = system.getproperty("sun.boot.class.path");\n        system.out.println(pathboot.replaceall(";", system.lineseparator()));\n\n        system.out.println("--------------------");\n        system.out.println("ext 下加载");\n        string pathext = system.getproperty("java.ext.dirs");\n        system.out.println(pathext.replaceall(";", system.lineseparator()));\n\n        system.out.println("--------------------");\n        system.out.println("app 下加载");\n        string pathapp = system.getproperty("java.class.path");\n        system.out.println(pathapp.replaceall(";", system.lineseparator()));\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n输出结果：\n\n根目录下加载\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\resources.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\rt.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\sunrsasign.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\jsse.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\jce.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\charsets.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\jfr.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\classes\n--------------------\next 下加载\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\nc:\\windows\\sun\\java\\lib\\ext\n--------------------\napp 下加载\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\charsets.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\deploy.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\access-bridge-64.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\cldrdata.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\dnsns.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\jaccess.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\jfxrt.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\localedata.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\nashorn.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\sunec.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\sunjce_provider.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\sunmscapi.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\sunpkcs11.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\ext\\zipfs.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\javaws.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\jce.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\jfr.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\jfxswt.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\jsse.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\management-agent.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\plugin.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\resources.jar\nc:\\program files\\java\\jdk1.8.0_321\\jre\\lib\\rt.jar\nd:\\笔记\\学习资料\\马士兵\\jvm视频源码\\out\\production\\jvm\t\t\t\t// 项目路径\nd:\\software\\idea2022\\intellij idea 2022.1.3\\lib\\idea_rt.jar\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n\n\n\n# 自定义类加载器\n\n当你想加载某个类的时候，可以调用 loadclass 方法\n\npublic class t005_loadclassbyhand {\n    public static void main(string[] args) throws classnotfoundexception {\n        class clazz = t005_loadclassbyhand.class.getclassloader().loadclass("com.mashibing.jvm.c2_classloader.t002_classloaderlevel");\n        system.out.println(clazz.getname());\n\n        //利用类加载器加载资源，参考坦克图片的加载\n        //t005_loadclassbyhand.class.getclassloader().getresourceasstream("");\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n# loadclass 源码解析\n\nloadclass 方法是在双亲委派模型下实现的。\n\nfindincache -> parent.loadclass -> findclass()\n\nprivate final classloader parent; // final 关键字修饰\n\nprotected class<?> loadclass(string name, boolean resolve) throws classnotfoundexception\n    {\n        synchronized (getclassloadinglock(name)) {\n            // 首先，检查类是否已经加载\n            class<?> c = findloadedclass(name);\n            if (c == null) {\n                long t0 = system.nanotime();\n                try {\n                    // 如果类不在已加载类中，则委派给父类加载器加载\n                    if (parent != null) {\n                        c = parent.loadclass(name, false);\n                    } else {\n                        // 如果没有父加载器，则使用系统类加载器加载\n                        c = findbootstrapclassornull(name);\n                    }\n                } catch (classnotfoundexception e) {\n                    // 如果找不到类，抛出classnotfoundexception\n                    // 从非空父类装入器\n                }\n              \n\t\t\t\t\t\t\t // 如果父加载器也找不到，则尝试自己加载\n                if (c == null) {\n                    // 如果仍未找到，则按顺序调用 findclass\n                    // to find the class. 要找到这个类\n                    long t1 = system.nanotime();\n                    c = findclass(name);\n\n                    // 这是定义类装入器；记录统计数据\n                    sun.misc.perfcounter.getparentdelegationtime().addtime(t1 - t0);\n                    sun.misc.perfcounter.getfindclasstime().addelapsedtimefrom(t1);\n                    sun.misc.perfcounter.getfindclasses().increment();\n                }\n            }\n            if (resolve) {\n                resolveclass(c);\n            }\n            return c;\n        }\n    }\n\n    protected class<?> findclass(string name) throws classnotfoundexception { // findclass被protected修饰，保护起来\n        throw new classnotfoundexception(name);\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n\n\n主要步骤如下：\n\n 1. 首先，方法会尝试从已加载的类中查找目标类是否已经加载，如果已经加载，则直接返回该类。\n 2. 如果目标类未加载，它会尝试委派给父类加载器来加载。这是双亲委派模型的核心思想之一。父类加载器会重复这个过程，直到到达启动类加载器（bootstrap classloader）为止。\n 3. 如果父类加载器也无法加载目标类，则 loadclass 方法会调用 findclass 方法，尝试自己加载目标类。这是子类加载器在加载自己类的最后一步。\n 4. 最后，如果 resolve 参数为 true，则会调用 resolveclass 方法，用于解析加载的类，确保类的完整性和正确性。\n\n什么时候需要自己去加载？\n\n加载进去就生成 class 对象吗？\n\n不是，要经过 初始化 才生成 class 对象。\n\n# 自定义一个类加载器需要做什么？\n\n只需要做一件事，就是定义自己的 findclass 就可以了。\n\n具体来说：\n\n * 继承 classloader\n\n * 重写模板方法 findclass\n   \n   * 调用 defineclass(byte[] -> class clazz)\n\n * 加密：可自定义类加载器加载自加密的 class\n   \n   * 防止反编译\n   * 防止篡改\n\n代码如下：\n\n首先继承 classloader 这个类\n\n// 自定义类加载器继承自classloader\npublic class t006_msbclassloader extends classloader {\n\n    // 重写findclass方法，用于加载类字节码\n    @override\n    protected class<?> findclass(string name) throws classnotfoundexception {\n        // 根据类名构建文件路径\n        file f = new file("c:/test/", name.replace(".", "/").concat(".class"));\n        try {\n            // 读取字节码文件\n            fileinputstream fis = new fileinputstream(f);\n            bytearrayoutputstream baos = new bytearrayoutputstream();\n            int b = 0;\n\n            // 读取文件内容并写入字节数组输出流\n            while ((b=fis.read()) !=0) {\n                baos.write(b);\n            }\n\n            // 将字节数组转换为字节数组\n            byte[] bytes = baos.tobytearray();\n            baos.close();\n            fis.close(); // 关闭流\n\n            // 使用defineclass方法定义并返回类\n            return defineclass(name, bytes, 0, bytes.length);\n        } catch (exception e) {\n            e.printstacktrace();\n        }\n        // 若加载失败，则调用父类的findclass方法\n        return super.findclass(name); // throws classnotfoundexception\n    }\n\n    // 主函数\n    public static void main(string[] args) throws exception {\n        // 创建自定义类加载器实例\n        classloader l = new t006_msbclassloader();\n        \n        // 通过自定义类加载器加载类\n        class clazz = l.loadclass("com.mashibing.jvm.hello");\n        class clazz1 = l.loadclass("com.mashibing.jvm.hello");\n\n        // 输出两次加载的类是否相同\n        system.out.println(clazz == clazz1);\n\n        // 创建加载的类的实例并调用方法\n        hello h = (hello) clazz.newinstance();\n        h.m();\n\n        // 输出类加载器信息\n        system.out.println(l.getclass().getclassloader()); // 输出自定义类加载器的类加载器\n        system.out.println(l.getparent()); // 输出自定义类加载器的父类加载器\n\n        system.out.println(getsystemclassloader()); // 输出系统类加载器\n    }\n}\n\npublic class hello {\n    public void m() {\n        system.out.println("hello jvm!");\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n\n\n这段代码实现了一个自定义的类加载器 t006_msbclassloader，该类加载器继承自 classloader，重写了 findclass 方法来加载类的字节码。在主函数中，使用这个自定义的类加载器加载类，并输出加载的类是否相同，然后创建该类的实例并调用方法。最后，输出了自定义类加载器的类加载器和父类加载器信息，以及系统类加载器的信息。这种自定义类加载器的方式允许你从非标准的位置加载类文件，并且可以通过不同的类加载器实现类的隔离。\n\n----------------------------------------\n\ndefineclass 方法是 classloader 类中的一个重要方法，用于将字节数组转换为一个 class 对象。该方法的作用是将一个【字节数组中的类字节码】转换为一个【java 类的实例】。当一个类加载器调用 defineclass 方法时，它会将字节数组中的类字节码转换为一个 class 对象，并返回该对象。(不会验证字节码的正确性)\n\n> 输出结果\n\ntrue\nhello jvm!\nsun.misc.launcher$appclassloader@18b4aac2\nsun.misc.launcher$appclassloader@18b4aac2\nsun.misc.launcher$appclassloader@18b4aac2\n\n\n1\n2\n3\n4\n5\n\n\n# 加密\n\n大家都知道 java 的代码 class 文件很容易就被反编译了。\n\n但是我要是定义自己的格式，我不想让别人反编译，这时候怎么办？\n\n你可以通过自定义的 class loader 来进行。然后在写逻辑的时候加一个加密操作。\n\n\n# 编译器\n\n三大模式：\n\n * 解释器（bytecode intepreter） -- 解释模式\n * jit（just in-time compiler） -- 编译模式\n * 混合模式\n   * 混合使用解释器 + 热点代码编译（编译成本地代码，就不用在解释器里面解释来执行了，效率提升）\n   * 起始阶段采用解释执行\n   * 热点代码检测\n     * 多次被调用的方法(方法计数器:监测方法执行频率)\n     * 多次被调用的循环(循环计数器:检测循环执行频率)\n     * 进行编译\n\n为什么不干脆直接编译成本地代码，那执行效率不更高吗？\n\n有两个原因。\n\n 1. 第一，java 的解释器，现在它的效率也已经非常高了，在一些简单代码的执行上，它并不输于你编译成本地代码。\n 2. 第二，如果你一个执行的文件特别多，各种各样的类库的时候，好几十个 class，你上来二话不说先在内存里编译一遍，这个启动过程会长得吓人。所以它现在默认的模式是混合模式。\n\n可以用指明参数的方式指定用什么模式\n\n 1. -xmixed 默认为混合模式\n    \n    开始解释执行，启动速度较快，对热点代码实行检测和编译\n\n 2. -xint 使用解释模式，启动很快，执行稍慢\n\n 3. -xcomp 使用纯编译模式，执行很快，启动很慢（要编译的类少的时候，启动也会很快）\n\n\n# 懒加载\n\nlazyloading\n\n * 严格讲应该叫 lazylnitializing\n * jvm 规范并没有规定何时加载\n * 但是严格规定了什么时候必须初始化，五种情况\n   1. 使用 new，getstatic，putstatic，invokestatic 指令时，访问 final 变量除外\n   2. java.lang.reflect 对类进行反射调用时\n   3. 初始化子类的时候，父类必须首先初始化\n   4. 虚拟机启动时，被执行的主类必须初始化\n   5. 动态语言支持 java.lang.invoke.methodhandle 解析的结果为 ref_getstatic, ref_putstatic, ref_invokestatic 的方法句柄时，该类必须初始化\n\n\n# 拓展知识\n\n# 双亲委派如何打破？\n\nparent 是如何指定的，打破双亲委派\n\n 1. 用 super(parent) 指定\n 2. 双亲委派的打破\n    1. 如何打破：重写 loadclass() 方法\n    2. 何时打破过？\n       1. jdk1.2 之前，自定义 classloader 都必须重写 loadclass()\n       2. threadcontextclassloader 可以实现基础类调用实现类代码，通过 thread.setcontextclassloader 指定\n       3. 热启动，热部署\n          * osgi tomcat 都有自己的模块指定 classloader（可以加载同一类库的不同版本）\n\n# 类加载器涉及到了哪些设计模式？\n\n在 java 虚拟机 (jvm) 中的类加载器 (classloader) 实现中，通常使用了以下两种设计模式：\n\n 1. 委托模式 (delegation pattern)：classloader 的实现通常使用了委托模式来处理类加载请求。委托模式指的是当一个对象收到请求时，它将请求委托给其他对象来处理。在类加载器的情况下，当一个类加载器接收到加载类的请求时，它首先会将请求委托给父类加载器进行处理。如果父类加载器无法加载该类，子类加载器才会尝试加载类。这种委托模式的设计方式可以实现类加载器的层次结构，从而实现类加载器的隔离和类加载的委派。\n 2. 单一职责模式 (single responsibility pattern)：classloader 的主要责任是加载类文件并定义对应的类。classloader 的设计符合单一职责模式，即一个类应该只负责一项职责。classloader 将类加载的职责封装在一个独立的类中，从而使得类加载的逻辑与其他功能解耦，提高了代码的可维护性和可扩展性。\n\n除了委托模式和单一职责模式，classloader 的实现可能还涉及其他设计模式，具体取决于实际的实现细节和需求。例如，一些类加载器的缓存机制可能使用了享元模式 (flyweight pattern) 来提高性能和资源利用效率。',charsets:{cjk:!0}},{title:"容器的本质",frontmatter:{title:"容器的本质",date:"2022-08-10T00:11:48.000Z",permalink:"/pages/f3cf17/",tags:["docker","云原生"],author:{name:"陌上清风",link:"https://github.com/msqfx"},description:"容器实现的主要技术：namespace、cgroup、chroot, 通过代码实现一个容器来深入理解其本质。",feed:{enable:!0},categories:["云原生","docker"],comment:!0,meta:[{name:"twitter:title",content:"容器的本质"},{name:"twitter:description",content:"容器实现的主要技术：namespace、cgroup、chroot, 通过代码实现一个容器来深入理解其本质。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/01.%E5%AE%B9%E5%99%A8%E7%9A%84%E6%9C%AC%E8%B4%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"容器的本质"},{property:"og:description",content:"容器实现的主要技术：namespace、cgroup、chroot, 通过代码实现一个容器来深入理解其本质。"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/01.%E5%AE%B9%E5%99%A8%E7%9A%84%E6%9C%AC%E8%B4%A8.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:11:48.000Z"},{property:"article:tag",content:"docker"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"容器的本质"},{itemprop:"description",content:"容器实现的主要技术：namespace、cgroup、chroot, 通过代码实现一个容器来深入理解其本质。"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/01.%E5%AE%B9%E5%99%A8%E7%9A%84%E6%9C%AC%E8%B4%A8.html",relativePath:"01.云原生/06.docker/01.容器的本质.md",key:"v-437ba2ee",path:"/pages/f3cf17/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"NameSpace",slug:"namespace",normalizedTitle:"namespace",charIndex:8},{level:2,title:"chroot",slug:"chroot",normalizedTitle:"chroot",charIndex:95},{level:2,title:"手动构造一个容器",slug:"手动构造一个容器",normalizedTitle:"手动构造一个容器",charIndex:819},{level:2,title:"cgroup",slug:"cgroup",normalizedTitle:"cgroup",charIndex:3796}],headersStr:"前言 NameSpace chroot 手动构造一个容器 cgroup",content:'# 前言\n\n使用NameSpace技术来修改进程视图，创建出独立的文件系统、主机名、进程号、网络等资源空间，再使用Cgroups来实现对进程的 CPU、内存等资源的优先级和配额限制，最后使用chroot更改进程的根目录，也就是限制访问文件系统\n\n\n# NameSpace\n\n可以创建出独立的文件系统、主机名、进程号、网络等资源空间，实现系统全局资源和进程局部资源的隔离。\n\nNameSpace有多种隔离类型，像常见的有PID NameSpace可以隔离进程ID、NET Namespace隔离网络设备端口号等。\n\n举个例子\n\nNameSpace可以让当前进程只能看到当前Namespace里的进程，看不到宿主机创建的进程。并且运行容器的命令为1号进程。\n\n# docker run -it busybox /bin/sh\n\n/ # ps aux\nPID   USER     COMMAND\n    1 root     /bin/sh\n    8 root     ps aux\n\n/ # echo $$\n1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在宿主机中可以看到该容器进程ID并不为1。再次证明容器也只是宿主机中的一个进程而已。\n\n[root@k8s-master ~]# ps aux | grep /bin/sh | grep -v grep\nroot     1398061  0.1  0.3 1368728 54104 pts/1   Sl+  10:36   0:00 docker run -it mirrors.sangfor.com/busybox /bin/sh\nroot     1398102  0.8  0.0   3176   188 pts/0    Ss+  10:36   0:00 /bin/sh\n\n\n1\n2\n3\n\n\n\n# chroot\n\n可以更改进程的根目录，限制访问文件系统。\n\n\n# 手动构造一个容器\n\n我们使用clone创建一个子进程，传入的参数是CLONE_NEWPID代表着启用了PID NameSpace，当前进程看到的是一个全新的进程空间，在该命名空间中，自己是1号进程。\n\n#define _GNU_SOURCE\n#include <sys/mount.h> \n#include <sys/types.h>\n#include <sys/wait.h>\n#include <stdio.h>\n#include <sched.h>\n#include <signal.h>\n#include <unistd.h>\n#define STACK_SIZE (1024 * 1024)\nstatic char container_stack[STACK_SIZE];\nchar* const container_args[] = {\n  "/bin/bash",\n  NULL\n};\n\nint container_main(void* arg)\n{  \n  printf("Container - inside the container!\\n");\n  execv(container_args[0], container_args);\n  printf("Something\'s wrong!\\n");\n  return 1;\n}\n\nint main()\n{\n  printf("Parent - start a container!\\n");\n  int container_pid = clone(container_main, container_stack+STACK_SIZE, CLONE_NEWPID | SIGCHLD , NULL);\n  waitpid(container_pid, NULL, 0);\n  printf("Parent - container stopped!\\n");\n  return 0;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n[root@k8s-master k8s]# gcc a.c -o a\n\n[root@k8s-master k8s]# ./a \nParent - start a container!\nContainer - inside the container!\n\n[root@k8s-master k8s]# echo $$\n1\n\n[root@k8s-master k8s]# exit\nParent - container stopped!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n但是我们在使用ps aux时，还是看到整个宿主机的进程，并且进程ID为1的还是Systemd，为什么呢？\n\n这是因为ps命令是读/proc文件系统的，所以我们还需要进行文件系统的隔离。\n\n我们再使用Mount NameSpace进行文件系统的隔离，在clone中使用CLONE_NEWNS参数。\n\nint main()\n{\n  printf("Parent - start a container!\\n");\n  int container_pid = clone(container_main, container_stack+STACK_SIZE, CLONE_NEWPID | CLONE_NEWNS  | SIGCHLD , NULL);\n  waitpid(container_pid, NULL, 0);\n  printf("Parent - container stopped!\\n");\n  return 0;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n编译运行后，发现当前文件系统并未发生变化，这个是因为，创建子进程时，会继承父进程的挂载点。\n\n所以我们需要在子进程中修改当前的挂载点，并且子进程在新的namespace的挂载动作只影响自身的挂载文件系统。\n\n先拷贝一个文件系统出来作为我们容器的根文件系统\n\ndocker export 48ab2ddd04dc | tar -C ./testfs -xvf -\n\n\n1\n\n\n再挂载proc，并且将testfs作为该进程的根目录\n\nint container_main(void* arg)\n{  \n  printf("Container - inside the container!\\n");\n\n  if (mount("proc", "testfs/proc", "proc", 0, NULL)) {\n     perror("proc");\n  }\n\n  if ( chdir("./testfs")!=0 ||  chroot("./") != 0) {\n     perror("chroot");\n  }\n\n  execv(container_args[0], container_args);\n  printf("Something\'s wrong!\\n");\n  return 1;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n再次运行进入容器中，当前的根目录是上面我们构造的testfs，并且ps aux命令只能看到当前namespace的进程，而看不到宿主机namespace的进程了。\n\n[root@k8s-worker1 k8s]# ./a\nParent - start a container!\nContainer - inside the container!\nroot@k8s-worker1:/# ls\nbin  boot  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\nroot@k8s-worker1:/# ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.0  0.0  26680  5452 ?        S    07:42   0:00 /bin/bash\nroot          94  0.0  0.0   5352   692 ?        S    07:49   0:00 ./a\nroot          95  0.0  0.0   4620  3872 ?        S    07:49   0:00 /bin/bash\nroot          99  0.0  0.0   7056  1556 ?        R+   07:49   0:00 ps aux\nroot@k8s-worker1:/# echo $$\n1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# cgroup\n\n可以实现对进程的CPU、内存等资源的配额限制\n\ncgroup在操作系统中暴露出来的接口是文件系统，会以文件和目录在/sys/fs/cgroup/目录中展示，下面的目录都是子系统，可以限制各种资源：\n\n[root@iZwz93q4afq8ck02cesqh4Z ~]# ls /sys/fs/cgroup/\nblkio  cpuacct      cpuset   freezer  memory   net_cls,net_prio  perf_event  systemd\ncpu    cpu,cpuacct  devices  hugetlb  net_cls  net_prio          pids\n\n\n1\n2\n3\n\n\n如何限制进程CPU\n\n执行以下命令将CPU吃到100%\n\n$ while : ; do : ; done &\n\n\n1\n\n\n使用top命令查看是否cpu是否满负载\n\n# top\n\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                                                              \n2503037 root      20   0   26672   5412   3520 R  99.0   0.0   0:46.09 -bash                                                                                  99.49%\n\n\n1\n2\n3\n4\n\n\n在目录/sys/fs/cgroup/cpu,cpuacct/下创建目录container，操作系统会自动创建资源限制文件\n\n[root@k8s-worker1 container]# mkdir container\n[root@k8s-worker1 container]# ls\ncgroup.clone_children  cpuacct.usage         cpuacct.usage_percpu_sys   cpuacct.usage_user  cpu.rt_period_us   cpu.stat\ncgroup.procs           cpuacct.usage_all     cpuacct.usage_percpu_user  cpu.cfs_period_us   cpu.rt_runtime_us  notify_on_release\ncpuacct.stat           cpuacct.usage_percpu  cpuacct.usage_sys          cpu.cfs_quota_us    cpu.shares         tasks\n\n\n1\n2\n3\n4\n5\n\n\n在文件夹下面可以查看到cpu.cfs_quota_us的默认值是-1，代表没有限制，cpu.cfs_period_us默认值为100ms(100000us)\n\n# cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us\n100000\n# cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us\n-1\n\n\n1\n2\n3\n4\n\n\n\n向cpu.cfs_quota_us写入20ms(20000us)，也就是每100ms时间里，限制的进程只能适用20ms，也就是这个进程只能使用到20%的CPU带宽\n\necho 20000 > /sys/fs/cgroup/cpu//cpu.cfs_quota_us\n\n\n1\n\n\n再将限制的进程ID写入到tasks文件中，可以看到该文件中已经包含了该容器进程ID\n\n# echo 2503037 > tasks\n# cat tasks\n2503037\n\n\n1\n2\n3\n\n\n再使用top可以发现该进程的cpu被限制在20%\n\n# top\n\nPID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                                                                              \n2503037 root      20   0   26672   5412   3520 R  20.4   0.0   6:43.71 -bash\n\n\n1\n2\n3\n4\n\n\n容器被cgroup的情况\n\n当然docker已经封装好了，直接调用以下命令即可实现上面CPU的限制\n\ndocker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash\n\n\n1\n\n\n可以看到在/sys/fs/cgroup/cpu,cpuacct/docker目录下创建了该容器的目录，目录下面包含了资源限制文件\n\n[root@k8s-worker1 docker]# pwd\n/sys/fs/cgroup/cpu,cpuacct/docker\n[root@k8s-worker1 docker]# ls\n87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c  cpuacct.usage             cpuacct.usage_percpu_user  cpu.cfs_quota_us   cpu.stat\ncgroup.clone_children                                             cpuacct.usage_all         cpuacct.usage_sys          cpu.rt_period_us   notify_on_release\ncgroup.procs                                                      cpuacct.usage_percpu      cpuacct.usage_user         cpu.rt_runtime_us  tasks\ncpuacct.stat\n[root@k8s-worker1 docker]# cd 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c/\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# ls\ncgroup.clone_children  cpuacct.usage         cpuacct.usage_percpu_sys   cpuacct.usage_user  cpu.rt_period_us   cpu.stat\ncgroup.procs           cpuacct.usage_all     cpuacct.usage_percpu_user  cpu.cfs_period_us   cpu.rt_runtime_us  notify_on_release\ncpuacct.stat           cpuacct.usage_percpu  cpuacct.usage_sys          cpu.cfs_quota_us    cpu.shares         tasks\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n在该目录下可以看到cpu.cfs_quota_us设置成了20000，并且tasks中包含了该容器进程的ID\n\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# cat cpu.cfs_quota_us \n20000\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# cat tasks\n2560954\n\n\n1\n2\n3\n4\n',normalizedContent:'# 前言\n\n使用namespace技术来修改进程视图，创建出独立的文件系统、主机名、进程号、网络等资源空间，再使用cgroups来实现对进程的 cpu、内存等资源的优先级和配额限制，最后使用chroot更改进程的根目录，也就是限制访问文件系统\n\n\n# namespace\n\n可以创建出独立的文件系统、主机名、进程号、网络等资源空间，实现系统全局资源和进程局部资源的隔离。\n\nnamespace有多种隔离类型，像常见的有pid namespace可以隔离进程id、net namespace隔离网络设备端口号等。\n\n举个例子\n\nnamespace可以让当前进程只能看到当前namespace里的进程，看不到宿主机创建的进程。并且运行容器的命令为1号进程。\n\n# docker run -it busybox /bin/sh\n\n/ # ps aux\npid   user     command\n    1 root     /bin/sh\n    8 root     ps aux\n\n/ # echo $$\n1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在宿主机中可以看到该容器进程id并不为1。再次证明容器也只是宿主机中的一个进程而已。\n\n[root@k8s-master ~]# ps aux | grep /bin/sh | grep -v grep\nroot     1398061  0.1  0.3 1368728 54104 pts/1   sl+  10:36   0:00 docker run -it mirrors.sangfor.com/busybox /bin/sh\nroot     1398102  0.8  0.0   3176   188 pts/0    ss+  10:36   0:00 /bin/sh\n\n\n1\n2\n3\n\n\n\n# chroot\n\n可以更改进程的根目录，限制访问文件系统。\n\n\n# 手动构造一个容器\n\n我们使用clone创建一个子进程，传入的参数是clone_newpid代表着启用了pid namespace，当前进程看到的是一个全新的进程空间，在该命名空间中，自己是1号进程。\n\n#define _gnu_source\n#include <sys/mount.h> \n#include <sys/types.h>\n#include <sys/wait.h>\n#include <stdio.h>\n#include <sched.h>\n#include <signal.h>\n#include <unistd.h>\n#define stack_size (1024 * 1024)\nstatic char container_stack[stack_size];\nchar* const container_args[] = {\n  "/bin/bash",\n  null\n};\n\nint container_main(void* arg)\n{  \n  printf("container - inside the container!\\n");\n  execv(container_args[0], container_args);\n  printf("something\'s wrong!\\n");\n  return 1;\n}\n\nint main()\n{\n  printf("parent - start a container!\\n");\n  int container_pid = clone(container_main, container_stack+stack_size, clone_newpid | sigchld , null);\n  waitpid(container_pid, null, 0);\n  printf("parent - container stopped!\\n");\n  return 0;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n[root@k8s-master k8s]# gcc a.c -o a\n\n[root@k8s-master k8s]# ./a \nparent - start a container!\ncontainer - inside the container!\n\n[root@k8s-master k8s]# echo $$\n1\n\n[root@k8s-master k8s]# exit\nparent - container stopped!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n但是我们在使用ps aux时，还是看到整个宿主机的进程，并且进程id为1的还是systemd，为什么呢？\n\n这是因为ps命令是读/proc文件系统的，所以我们还需要进行文件系统的隔离。\n\n我们再使用mount namespace进行文件系统的隔离，在clone中使用clone_newns参数。\n\nint main()\n{\n  printf("parent - start a container!\\n");\n  int container_pid = clone(container_main, container_stack+stack_size, clone_newpid | clone_newns  | sigchld , null);\n  waitpid(container_pid, null, 0);\n  printf("parent - container stopped!\\n");\n  return 0;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n编译运行后，发现当前文件系统并未发生变化，这个是因为，创建子进程时，会继承父进程的挂载点。\n\n所以我们需要在子进程中修改当前的挂载点，并且子进程在新的namespace的挂载动作只影响自身的挂载文件系统。\n\n先拷贝一个文件系统出来作为我们容器的根文件系统\n\ndocker export 48ab2ddd04dc | tar -c ./testfs -xvf -\n\n\n1\n\n\n再挂载proc，并且将testfs作为该进程的根目录\n\nint container_main(void* arg)\n{  \n  printf("container - inside the container!\\n");\n\n  if (mount("proc", "testfs/proc", "proc", 0, null)) {\n     perror("proc");\n  }\n\n  if ( chdir("./testfs")!=0 ||  chroot("./") != 0) {\n     perror("chroot");\n  }\n\n  execv(container_args[0], container_args);\n  printf("something\'s wrong!\\n");\n  return 1;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n再次运行进入容器中，当前的根目录是上面我们构造的testfs，并且ps aux命令只能看到当前namespace的进程，而看不到宿主机namespace的进程了。\n\n[root@k8s-worker1 k8s]# ./a\nparent - start a container!\ncontainer - inside the container!\nroot@k8s-worker1:/# ls\nbin  boot  dev  etc  home  lib  lib32  lib64  libx32  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\nroot@k8s-worker1:/# ps aux\nuser         pid %cpu %mem    vsz   rss tty      stat start   time command\nroot           1  0.0  0.0  26680  5452 ?        s    07:42   0:00 /bin/bash\nroot          94  0.0  0.0   5352   692 ?        s    07:49   0:00 ./a\nroot          95  0.0  0.0   4620  3872 ?        s    07:49   0:00 /bin/bash\nroot          99  0.0  0.0   7056  1556 ?        r+   07:49   0:00 ps aux\nroot@k8s-worker1:/# echo $$\n1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# cgroup\n\n可以实现对进程的cpu、内存等资源的配额限制\n\ncgroup在操作系统中暴露出来的接口是文件系统，会以文件和目录在/sys/fs/cgroup/目录中展示，下面的目录都是子系统，可以限制各种资源：\n\n[root@izwz93q4afq8ck02cesqh4z ~]# ls /sys/fs/cgroup/\nblkio  cpuacct      cpuset   freezer  memory   net_cls,net_prio  perf_event  systemd\ncpu    cpu,cpuacct  devices  hugetlb  net_cls  net_prio          pids\n\n\n1\n2\n3\n\n\n如何限制进程cpu\n\n执行以下命令将cpu吃到100%\n\n$ while : ; do : ; done &\n\n\n1\n\n\n使用top命令查看是否cpu是否满负载\n\n# top\n\npid user      pr  ni    virt    res    shr s  %cpu  %mem     time+ command                                                                              \n2503037 root      20   0   26672   5412   3520 r  99.0   0.0   0:46.09 -bash                                                                                  99.49%\n\n\n1\n2\n3\n4\n\n\n在目录/sys/fs/cgroup/cpu,cpuacct/下创建目录container，操作系统会自动创建资源限制文件\n\n[root@k8s-worker1 container]# mkdir container\n[root@k8s-worker1 container]# ls\ncgroup.clone_children  cpuacct.usage         cpuacct.usage_percpu_sys   cpuacct.usage_user  cpu.rt_period_us   cpu.stat\ncgroup.procs           cpuacct.usage_all     cpuacct.usage_percpu_user  cpu.cfs_period_us   cpu.rt_runtime_us  notify_on_release\ncpuacct.stat           cpuacct.usage_percpu  cpuacct.usage_sys          cpu.cfs_quota_us    cpu.shares         tasks\n\n\n1\n2\n3\n4\n5\n\n\n在文件夹下面可以查看到cpu.cfs_quota_us的默认值是-1，代表没有限制，cpu.cfs_period_us默认值为100ms(100000us)\n\n# cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us\n100000\n# cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us\n-1\n\n\n1\n2\n3\n4\n\n\n\n向cpu.cfs_quota_us写入20ms(20000us)，也就是每100ms时间里，限制的进程只能适用20ms，也就是这个进程只能使用到20%的cpu带宽\n\necho 20000 > /sys/fs/cgroup/cpu//cpu.cfs_quota_us\n\n\n1\n\n\n再将限制的进程id写入到tasks文件中，可以看到该文件中已经包含了该容器进程id\n\n# echo 2503037 > tasks\n# cat tasks\n2503037\n\n\n1\n2\n3\n\n\n再使用top可以发现该进程的cpu被限制在20%\n\n# top\n\npid user      pr  ni    virt    res    shr s  %cpu  %mem     time+ command                                                                              \n2503037 root      20   0   26672   5412   3520 r  20.4   0.0   6:43.71 -bash\n\n\n1\n2\n3\n4\n\n\n容器被cgroup的情况\n\n当然docker已经封装好了，直接调用以下命令即可实现上面cpu的限制\n\ndocker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash\n\n\n1\n\n\n可以看到在/sys/fs/cgroup/cpu,cpuacct/docker目录下创建了该容器的目录，目录下面包含了资源限制文件\n\n[root@k8s-worker1 docker]# pwd\n/sys/fs/cgroup/cpu,cpuacct/docker\n[root@k8s-worker1 docker]# ls\n87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c  cpuacct.usage             cpuacct.usage_percpu_user  cpu.cfs_quota_us   cpu.stat\ncgroup.clone_children                                             cpuacct.usage_all         cpuacct.usage_sys          cpu.rt_period_us   notify_on_release\ncgroup.procs                                                      cpuacct.usage_percpu      cpuacct.usage_user         cpu.rt_runtime_us  tasks\ncpuacct.stat\n[root@k8s-worker1 docker]# cd 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c/\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# ls\ncgroup.clone_children  cpuacct.usage         cpuacct.usage_percpu_sys   cpuacct.usage_user  cpu.rt_period_us   cpu.stat\ncgroup.procs           cpuacct.usage_all     cpuacct.usage_percpu_user  cpu.cfs_period_us   cpu.rt_runtime_us  notify_on_release\ncpuacct.stat           cpuacct.usage_percpu  cpuacct.usage_sys          cpu.cfs_quota_us    cpu.shares         tasks\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n在该目录下可以看到cpu.cfs_quota_us设置成了20000，并且tasks中包含了该容器进程的id\n\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# cat cpu.cfs_quota_us \n20000\n[root@k8s-worker1 87ee72386a6079ba6411ac8f3030c12407558652d28a1cd16c03f4434581500c]# cat tasks\n2560954\n\n\n1\n2\n3\n4\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"docker容器单机网络",frontmatter:{title:"docker容器单机网络",date:"2023-01-08T10:52:41.000Z",permalink:"/pages/0ddeb7/",tags:["docker","云原生","容器"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文主要讲述docker容器的四种网络模式：host、bridge、container、null，并介绍它们的使用方法及实现原理。",feed:{enable:!0},categories:["云原生","docker"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16731831018681673183100953.png"},{name:"twitter:title",content:"docker容器单机网络"},{name:"twitter:description",content:"本文主要讲述docker容器的四种网络模式：host、bridge、container、null，并介绍它们的使用方法及实现原理。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16731831018681673183100953.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/04.docker%E5%AE%B9%E5%99%A8%E5%8D%95%E6%9C%BA%E7%BD%91%E7%BB%9C.html"},{property:"og:type",content:"article"},{property:"og:title",content:"docker容器单机网络"},{property:"og:description",content:"本文主要讲述docker容器的四种网络模式：host、bridge、container、null，并介绍它们的使用方法及实现原理。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16731831018681673183100953.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/04.docker%E5%AE%B9%E5%99%A8%E5%8D%95%E6%9C%BA%E7%BD%91%E7%BB%9C.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-01-08T10:52:41.000Z"},{property:"article:tag",content:"docker"},{property:"article:tag",content:"云原生"},{property:"article:tag",content:"容器"},{itemprop:"name",content:"docker容器单机网络"},{itemprop:"description",content:"本文主要讲述docker容器的四种网络模式：host、bridge、container、null，并介绍它们的使用方法及实现原理。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16731831018681673183100953.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/04.docker%E5%AE%B9%E5%99%A8%E5%8D%95%E6%9C%BA%E7%BD%91%E7%BB%9C.html",relativePath:"01.云原生/06.docker/04.docker容器单机网络.md",key:"v-7413a666",path:"/pages/0ddeb7/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"host",slug:"host",normalizedTitle:"host",charIndex:146},{level:2,title:"bridge",slug:"bridge",normalizedTitle:"bridge",charIndex:548},{level:3,title:"原理",slug:"原理",normalizedTitle:"原理",charIndex:138},{level:3,title:"验证",slug:"验证",normalizedTitle:"验证",charIndex:856},{level:3,title:"容器网络互通",slug:"容器网络互通",normalizedTitle:"容器网络互通",charIndex:3442},{level:3,title:"容器连接其他主机",slug:"容器连接其他主机",normalizedTitle:"容器连接其他主机",charIndex:5783},{level:2,title:"container",slug:"container",normalizedTitle:"container",charIndex:6181},{level:2,title:"none",slug:"none",normalizedTitle:"none",charIndex:7668}],headersStr:"前言 host bridge 原理 验证 容器网络互通 容器连接其他主机 container none",content:"# 前言\n\n通过文章 容器的本质可知，容器只是一个进程，而容器所能看到的网络栈，是隔离在自己的 Network Namespace 中。docker 容器单机网络支持四种网络模式，也都是基于 Network Namespace 实现的。本文主要是介绍这四种模式的使用方法及实现原理。\n\n\n# host\n\n使用该模式的容器和宿主机是在同一个 Network Namespace 中的，所以和宿主机用的是同一个网络栈，那么容器暴露的端口，也就是宿主机上端口。\n\n> 注意，使用该模式，需要关注端口冲突\n\n通过添加 --net=host 参数即可开启 host 模式\n\ndocker run -d --net=host nginx\n\n\n1\n\n\n因为和宿主机使用的是同一个网络栈，所以容器与宿主机是可以互相连通的，在宿主机上直接可以通过 127.0.0.1 访问到该容器的的端口。\n\ncurl 127.0.0.1\n\n\n1\n\n\n运行另一个容器进入其中执行 curl 127.0.0.1 可以看到一样可以访问到 nginx 暴露的 80 端口，因为都是使用宿主机网络栈。\n\n docker run -it --net=host curlimages/curl curl 127.0.0.1\n\n\n1\n\n\n\n# bridge\n\n\n# 原理\n\n该模式为桥接模式，创建容器时会创建属于自己的 Network Namepsace，该容器和宿主机使用的是不同的 Network Namespace，也就是说它们使用的是不同的网络栈。\n\nbridge 网络模型的实现原理可以参考文章 手动实现docker容器bridge网络模型\n\n宿主机创建了 docker0 作为虚拟网桥，其作用主要是作为交换机在二层网络，再将使用 bridge 模式创建的容器通过 veth pair 连接到 dcoker0 上，这样连接到 docker0 上的容器都可以互相网络通信。\n\n> veth pair 类似一个管道，数据包会从一端到另一端。\n\n\n\n\n# 验证\n\n默认运行容器时使用的就是 bridge 模式，docker 会自动为容器添加 veth pair 并配置好其 ip 地址，这里的 eth0 就是其中的一端，可以看到其 ip 地址为 172.17.0.2\n\n[root@localhost ~]# docker run -d --name nginx1 nginx\n\n[root@localhost ~]# docker exec -it nginx1 ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n20: eth0@if21: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\nveth pair 的另一端会接入到 docker0 上，在容器中执行以下命令可以看到 veth pair 另一端的序号\n\n[root@localhost ~]# docker exec nginx1 cat /sys/class/net/eth0/iflink\n21\n\n\n1\n2\n\n\n在宿主机上可以看到 21 序号上的 veth pair 的名称是 veth702ba20，也就是管道的另一端。\n\n[root@localhost ~]# ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: ens18: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether fe:fc:fe:af:4b:ea brd ff:ff:ff:ff:ff:ff\n    inet 10.61.74.37/23 brd 10.61.75.255 scope global noprefixroute ens18\n       valid_lft forever preferred_lft forever\n    inet6 fe80::1bdd:fe7:4a90:1a67/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: docker0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:84:c1:3b:ea brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:84ff:fec1:3bea/64 scope link \n       valid_lft forever preferred_lft forever\n21: veth702ba20@if20: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master docker0 state UP group default \n    link/ether 0a:21:51:0c:7e:db brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet6 fe80::821:51ff:fe0c:7edb/64 scope link \n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再查看 docker0 插入的设备可以发现 veth702ba20 是插入在 docker0 上的。\n\n[root@localhost ~]# brctl show\nbridge name     bridge id               STP enabled     interfaces\ndocker0         8000.024284c13bea       no              veth702ba20\n\n\n1\n2\n3\n\n\n\n# 容器网络互通\n\n再创建另一个容器 nginx2，查看其 ip 为 172.17.0.3，可以发现 nginx1 是可以 ping 通 nginx2 的该 ip 的。\n\n[root@localhost ~]# docker run -d --name nginx2 nginx\n[root@localhost ~]# docker exec nginx2 ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n54: eth0@if55: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n为什么可以互通呢？\n\n我们来看下 nginx1 的路由，当 ping nginx2 的 ip 时，会匹配到第二条路由，然后走 eth0 网卡，因为其是 veth pair 的一端，数据包会在另一端出现，另一端接入到了 docker0 上，最终数据包到达 docker0\n\n[root@localhost ~]# docker exec nginx1 ip r\ndefault via 172.17.0.1 dev eth0 \n172.17.0.0/16 dev eth0  proto kernel  scope link  src 172.17.0.2 \n\n\n1\n2\n3\n\n\n当通过 nginx1 ping nginx2 的 ip 时，我过监听 docker0 网卡看一下数据包：\n\n[root@localhost ~]# docker exec -it nginx1 ping 172.17.0.3 -c 3\n\n[root@localhost ~]# tcpdump -i docker0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on docker0, link-type EN10MB (Ethernet), capture size 262144 bytes\n04:32:57.596814 ARP, Request who-has 172.17.0.3 tell 172.17.0.2, length 28\n04:32:57.596848 ARP, Reply 172.17.0.3 is-at 02:42:ac:11:00:03 (oui Unknown), length 28\n04:32:57.596853 IP 172.17.0.2 > 172.17.0.3: ICMP echo request, id 17, seq 1, length 64\n04:32:57.596896 IP 172.17.0.3 > 172.17.0.2: ICMP echo reply, id 17, seq 1, length 64\n04:32:58.596437 IP 172.17.0.2 > 172.17.0.3: ICMP echo request, id 17, seq 2, length 64\n04:32:58.596492 IP 172.17.0.3 > 172.17.0.2: ICMP echo reply, id 17, seq 2, length 64\n04:32:59.596444 IP 172.17.0.2 > 172.17.0.3: ICMP echo request, id 17, seq 3, length 64\n04:32:59.596491 IP 172.17.0.3 > 172.17.0.2: ICMP echo reply, id 17, seq 3, length 64\n04:33:02.598361 ARP, Request who-has 172.17.0.2 tell 172.17.0.3, length 28\n04:33:02.598386 ARP, Reply 172.17.0.2 is-at 02:42:ac:11:00:02 (oui Unknown), length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n由上可知，nginx1(10.17.0.2) 会发送 ARP 获取 nginx2(10.17.0.3) 的 mac 地址，然后使用该 mac 地址通过二层设备 bridge 向 nginx2 转发数据包，进入到了 nginx2 的 Network Namespace 中，由它的网络栈处理该数据包，最后回包。\n\n\n\n\n# 容器连接其他主机\n\n容器内连接其他主机时，比如 ping 10.65.132.187 时，会先通过 docker0 达到宿主机上，然后通过宿主机的网络栈处理。\n\n通过查看宿主机路由表，到达宿主机的数据表会走第一条默认路由，通过 eth0 网卡下一跳到 10.61.74.1，然后最终达到另一台主机的 eth0 中。\n\n[root@localhost ~]# ip r\ndefault via 10.61.74.1 dev eth0 proto static metric 100 \n10.61.74.0/23 dev eth0 proto kernel scope link src 10.61.74.37 metric 100 \n172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1\n\n\n1\n2\n3\n4\n\n\n\n\n\n# container\n\n使用该模式的容器会加入到指定容器的 Network Namespace 中，也就是两个容器共用同一个网络栈。\n\n首先使用 bridge 模式创建容器 nginx1，该容器会拥有自己的 Network Namespace，然后再使用 container 模式创建 nginx2 容器并加入 nginx1 的 Network Namespace 中。\n\n通过查看两个容器的网卡可以发现两个是一样的。\n\n[root@localhost ~]# docker run -d --name nginx1 nginx\n[root@localhost ~]# docker exec -it nginx1 ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n56: eth0@if57: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n[root@localhost ~]# docker run -it --name nginx2 --net=container:nginx1 nginx /bin/bash\n\n[ root@20069e4c2bde:/etc/nginx ]$ ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n56: eth0@if57: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n\n\n# none\n\n该模式创建容器也会创建新的属于自己的 Network Namespace，但是容器内不会有任何的网络配置，没有网卡、路由、路由等信息，需要由我们自己去配置。\n\n[root@localhost ~]# docker run -it --name nginx --net=none nginx /bin/bash\n\n[ root@52480b0a4725:/etc/nginx ]$ ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n[ root@52480b0a4725:/etc/nginx ]$ ip r\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n",normalizedContent:"# 前言\n\n通过文章 容器的本质可知，容器只是一个进程，而容器所能看到的网络栈，是隔离在自己的 network namespace 中。docker 容器单机网络支持四种网络模式，也都是基于 network namespace 实现的。本文主要是介绍这四种模式的使用方法及实现原理。\n\n\n# host\n\n使用该模式的容器和宿主机是在同一个 network namespace 中的，所以和宿主机用的是同一个网络栈，那么容器暴露的端口，也就是宿主机上端口。\n\n> 注意，使用该模式，需要关注端口冲突\n\n通过添加 --net=host 参数即可开启 host 模式\n\ndocker run -d --net=host nginx\n\n\n1\n\n\n因为和宿主机使用的是同一个网络栈，所以容器与宿主机是可以互相连通的，在宿主机上直接可以通过 127.0.0.1 访问到该容器的的端口。\n\ncurl 127.0.0.1\n\n\n1\n\n\n运行另一个容器进入其中执行 curl 127.0.0.1 可以看到一样可以访问到 nginx 暴露的 80 端口，因为都是使用宿主机网络栈。\n\n docker run -it --net=host curlimages/curl curl 127.0.0.1\n\n\n1\n\n\n\n# bridge\n\n\n# 原理\n\n该模式为桥接模式，创建容器时会创建属于自己的 network namepsace，该容器和宿主机使用的是不同的 network namespace，也就是说它们使用的是不同的网络栈。\n\nbridge 网络模型的实现原理可以参考文章 手动实现docker容器bridge网络模型\n\n宿主机创建了 docker0 作为虚拟网桥，其作用主要是作为交换机在二层网络，再将使用 bridge 模式创建的容器通过 veth pair 连接到 dcoker0 上，这样连接到 docker0 上的容器都可以互相网络通信。\n\n> veth pair 类似一个管道，数据包会从一端到另一端。\n\n\n\n\n# 验证\n\n默认运行容器时使用的就是 bridge 模式，docker 会自动为容器添加 veth pair 并配置好其 ip 地址，这里的 eth0 就是其中的一端，可以看到其 ip 地址为 172.17.0.2\n\n[root@localhost ~]# docker run -d --name nginx1 nginx\n\n[root@localhost ~]# docker exec -it nginx1 ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n20: eth0@if21: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\nveth pair 的另一端会接入到 docker0 上，在容器中执行以下命令可以看到 veth pair 另一端的序号\n\n[root@localhost ~]# docker exec nginx1 cat /sys/class/net/eth0/iflink\n21\n\n\n1\n2\n\n\n在宿主机上可以看到 21 序号上的 veth pair 的名称是 veth702ba20，也就是管道的另一端。\n\n[root@localhost ~]# ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host \n       valid_lft forever preferred_lft forever\n2: ens18: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state up group default qlen 1000\n    link/ether fe:fc:fe:af:4b:ea brd ff:ff:ff:ff:ff:ff\n    inet 10.61.74.37/23 brd 10.61.75.255 scope global noprefixroute ens18\n       valid_lft forever preferred_lft forever\n    inet6 fe80::1bdd:fe7:4a90:1a67/64 scope link noprefixroute \n       valid_lft forever preferred_lft forever\n3: docker0: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default \n    link/ether 02:42:84:c1:3b:ea brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:84ff:fec1:3bea/64 scope link \n       valid_lft forever preferred_lft forever\n21: veth702ba20@if20: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue master docker0 state up group default \n    link/ether 0a:21:51:0c:7e:db brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet6 fe80::821:51ff:fe0c:7edb/64 scope link \n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再查看 docker0 插入的设备可以发现 veth702ba20 是插入在 docker0 上的。\n\n[root@localhost ~]# brctl show\nbridge name     bridge id               stp enabled     interfaces\ndocker0         8000.024284c13bea       no              veth702ba20\n\n\n1\n2\n3\n\n\n\n# 容器网络互通\n\n再创建另一个容器 nginx2，查看其 ip 为 172.17.0.3，可以发现 nginx1 是可以 ping 通 nginx2 的该 ip 的。\n\n[root@localhost ~]# docker run -d --name nginx2 nginx\n[root@localhost ~]# docker exec nginx2 ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n54: eth0@if55: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default \n    link/ether 02:42:ac:11:00:03 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.3/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n为什么可以互通呢？\n\n我们来看下 nginx1 的路由，当 ping nginx2 的 ip 时，会匹配到第二条路由，然后走 eth0 网卡，因为其是 veth pair 的一端，数据包会在另一端出现，另一端接入到了 docker0 上，最终数据包到达 docker0\n\n[root@localhost ~]# docker exec nginx1 ip r\ndefault via 172.17.0.1 dev eth0 \n172.17.0.0/16 dev eth0  proto kernel  scope link  src 172.17.0.2 \n\n\n1\n2\n3\n\n\n当通过 nginx1 ping nginx2 的 ip 时，我过监听 docker0 网卡看一下数据包：\n\n[root@localhost ~]# docker exec -it nginx1 ping 172.17.0.3 -c 3\n\n[root@localhost ~]# tcpdump -i docker0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on docker0, link-type en10mb (ethernet), capture size 262144 bytes\n04:32:57.596814 arp, request who-has 172.17.0.3 tell 172.17.0.2, length 28\n04:32:57.596848 arp, reply 172.17.0.3 is-at 02:42:ac:11:00:03 (oui unknown), length 28\n04:32:57.596853 ip 172.17.0.2 > 172.17.0.3: icmp echo request, id 17, seq 1, length 64\n04:32:57.596896 ip 172.17.0.3 > 172.17.0.2: icmp echo reply, id 17, seq 1, length 64\n04:32:58.596437 ip 172.17.0.2 > 172.17.0.3: icmp echo request, id 17, seq 2, length 64\n04:32:58.596492 ip 172.17.0.3 > 172.17.0.2: icmp echo reply, id 17, seq 2, length 64\n04:32:59.596444 ip 172.17.0.2 > 172.17.0.3: icmp echo request, id 17, seq 3, length 64\n04:32:59.596491 ip 172.17.0.3 > 172.17.0.2: icmp echo reply, id 17, seq 3, length 64\n04:33:02.598361 arp, request who-has 172.17.0.2 tell 172.17.0.3, length 28\n04:33:02.598386 arp, reply 172.17.0.2 is-at 02:42:ac:11:00:02 (oui unknown), length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n由上可知，nginx1(10.17.0.2) 会发送 arp 获取 nginx2(10.17.0.3) 的 mac 地址，然后使用该 mac 地址通过二层设备 bridge 向 nginx2 转发数据包，进入到了 nginx2 的 network namespace 中，由它的网络栈处理该数据包，最后回包。\n\n\n\n\n# 容器连接其他主机\n\n容器内连接其他主机时，比如 ping 10.65.132.187 时，会先通过 docker0 达到宿主机上，然后通过宿主机的网络栈处理。\n\n通过查看宿主机路由表，到达宿主机的数据表会走第一条默认路由，通过 eth0 网卡下一跳到 10.61.74.1，然后最终达到另一台主机的 eth0 中。\n\n[root@localhost ~]# ip r\ndefault via 10.61.74.1 dev eth0 proto static metric 100 \n10.61.74.0/23 dev eth0 proto kernel scope link src 10.61.74.37 metric 100 \n172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1\n\n\n1\n2\n3\n4\n\n\n\n\n\n# container\n\n使用该模式的容器会加入到指定容器的 network namespace 中，也就是两个容器共用同一个网络栈。\n\n首先使用 bridge 模式创建容器 nginx1，该容器会拥有自己的 network namespace，然后再使用 container 模式创建 nginx2 容器并加入 nginx1 的 network namespace 中。\n\n通过查看两个容器的网卡可以发现两个是一样的。\n\n[root@localhost ~]# docker run -d --name nginx1 nginx\n[root@localhost ~]# docker exec -it nginx1 ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n56: eth0@if57: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n[root@localhost ~]# docker run -it --name nginx2 --net=container:nginx1 nginx /bin/bash\n\n[ root@20069e4c2bde:/etc/nginx ]$ ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n56: eth0@if57: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default \n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n\n\n# none\n\n该模式创建容器也会创建新的属于自己的 network namespace，但是容器内不会有任何的网络配置，没有网卡、路由、路由等信息，需要由我们自己去配置。\n\n[root@localhost ~]# docker run -it --name nginx --net=none nginx /bin/bash\n\n[ root@52480b0a4725:/etc/nginx ]$ ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n[ root@52480b0a4725:/etc/nginx ]$ ip r\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n",charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之Pod",frontmatter:{tags:["k8s","容器","云原生"],author:{name:"msqfx",link:"https://github.com/msqfx"},title:"k8s之Pod",date:"2022-08-30T12:48:34.000Z",permalink:"/pages/2b547f/",description:"介绍k8s中的pod资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220331113937.png#crop=0&crop=0&crop=1&crop=1&id=mo242&originHeight=381&originWidth=481&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:title",content:"k8s之Pod"},{name:"twitter:description",content:"介绍k8s中的pod资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220331113937.png#crop=0&crop=0&crop=1&crop=1&id=mo242&originHeight=381&originWidth=481&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/03.k8s%E4%B9%8Bpod.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之Pod"},{property:"og:description",content:"介绍k8s中的pod资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220331113937.png#crop=0&crop=0&crop=1&crop=1&id=mo242&originHeight=381&originWidth=481&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/03.k8s%E4%B9%8Bpod.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-30T12:48:34.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之Pod"},{itemprop:"description",content:"介绍k8s中的pod资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220331113937.png#crop=0&crop=0&crop=1&crop=1&id=mo242&originHeight=381&originWidth=481&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/03.k8s%E4%B9%8Bpod.html",relativePath:"01.云原生/07.k8s/03.k8s之pod.md",key:"v-fdfd34bc",path:"/pages/2b547f/",headers:[{level:2,title:"什么是pod?",slug:"什么是pod",normalizedTitle:"什么是pod?",charIndex:2},{level:2,title:"为什么需要Pod?",slug:"为什么需要pod",normalizedTitle:"为什么需要pod?",charIndex:110},{level:2,title:"使用Pod",slug:"使用pod",normalizedTitle:"使用pod",charIndex:615},{level:2,title:"容器状态探针",slug:"容器状态探针",normalizedTitle:"容器状态探针",charIndex:1959},{level:2,title:"资源配置",slug:"资源配置",normalizedTitle:"资源配置",charIndex:2292}],headersStr:"什么是pod? 为什么需要Pod? 使用Pod 容器状态探针 资源配置",content:'# 什么是pod?\n\nPod是一组共享了某些资源的容器。\n\n容器的隔离是通过各种namespace来实现的，Pod 里的所有容器，可以通过Namespace来共享系统资源，像Network Namepsace。\n\n\n# 为什么需要Pod?\n\n众所周知所周知，容器是一个特殊的进程，但有些场景是，一个应用的运行，是需要多个进程结合使用，并有一定的依赖关系的。虽然我们也可以使用单独的容器来配置运行应用，但是都是独立的。而pod是k8s的原子调度，pod中的容器可以指定分配到同一个节点，统一按照资源调度。\n\n使用docker也可以实现A、B容器共享网络和Volume，但是容器B必须比容器A先启动，是一个拓扑结构，而不是平等关系\n\n$ docker run --net=B --volumes-from=B --name=A image-A ...\n\n\n1\n\n\n在Pod中，先创建启动的是Infra容器，该容器会处于一个禁止状态，而其他定义的容器，则通过Join Network Namespace与Infra容器连接在一起。\n\n\n\n在Pod中的容器处于同一个Network Namespace中，所以可以通过localhost直接进行通信，看到的网络设备是一致的。而Pod的生命周期和Infra容器一致，和容器A、B无关。\n\nPod，实际上是在扮演传统基础设施里“虚拟机”的角色；而容器，则是这个虚拟机里运行的用户程序。\n\n\n# 使用Pod\n\n使用yaml来描述一个Pod。\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-pod\n\nspec:\n  containers:\n  - name: nginx\n    image: nginx:laster\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n再使用kubectl apply来创建pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod.yaml -n zwf\npod/nginx-pod created\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf -o wide\nNAME        READY   STATUS    RESTARTS   AGE     IP              NODE          NOMINATED NODE   READINESS GATES\nnginx-pod   1/1     Running   0          2m51s   10.222.126.60   k8s-worker2   <none>           <none>\n\n\n1\n2\n3\n4\n5\n6\n\n\n我们可以使用curl访问到pod中的nginx的服务了\n\n[root@k8s-worker1 zwf]# curl 10.222.126.60:80\n<!DOCTYPE html>\n<html>\n<head>\n<title>Welcome to nginx!</title>\n<style>\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: Tahoma, Verdana, Arial, sans-serif; }\n</style>\n</head>\n<body>\n<h1>Welcome to nginx!</h1>\n<p>If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.</p>\n\n<p>For online documentation and support please refer to\n<a href="http://nginx.org/">nginx.org</a>.<br/>\nCommercial support is available at\n<a href="http://nginx.com/">nginx.com</a>.</p>\n\n<p><em>Thank you for using nginx.</em></p>\n</body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n一般我们不直接创建Pod，而是通过各种控制器来管理创建\n\n\n# 容器状态探针\n\n * ReadinessProbe\n\n就绪性探针，判断容器中的程序是否健康，不健康，则会将该pod从service可用端点列表移除。\n\n * livenessProbe\n\n存活性探针，判断容器是否健康，不健康，则会将容器重启。 注意：是将容器重启而不是pod\n\n * startupProbe\n\n在pod启动后按照配置执行一次，如果成功，则不再执行，如果失败，则会重启pod. 其他两个探针是在startupProbe运行成功之前都是暂停的。\n\n探测方式\n\n * exec，执行一个Linux命令，看返回值\n\n * tcpSocket，使用tcp尝试连接某个端口，看是否连接成功\n\n * httpGet，尝试使用http请求，看是否请求成功\n\n\n# 资源配置\n\n在配置中使用resources字段来设置限制容器的资源。\n\n * requests，系统必须预留的可用资源\n\n * limits，容器可申请使用的最大可用资源，超过则会被kill的可能性\n\n这里的cpu使用的是m(milli)的单位，1000m代表1个cpu，10m代表1%cpu\n\n而内存使用Mi代表MB。\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: ngx-pod-resources\n\nspec:\n  containers:\n  - image: nginx:alpine\n    name: ngx\n\n    resources:\n      requests:\n        cpu: 10m\n        memory: 100Mi\n      limits:\n        cpu: 20m\n        memory: 200Mi\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n我们再来看看是怎么使用cgroup来限制pod中容器的资源\n\n先找到pod中该容器的ID\n\n>>> kubectl describe pod -n zwf ngx-pod-resources\nName:         ngx-pod-resources\nNamespace:    zwf\nPriority:     0\nNode:         k8s-worker1/10.64.2.141\nStart Time:   Tue, 30 Aug 2022 16:11:45 +0800\nLabels:       <none>\nAnnotations:  cni.projectcalico.org/containerID: 4c8f23863e6589d44b96ded48a2abd857ca9e45637fb9dd6b106c3c217be0904\n              cni.projectcalico.org/podIP: 10.222.194.100/32\n              cni.projectcalico.org/podIPs: 10.222.194.100/32\nStatus:       Running\nIP:           10.222.194.100\nIPs:\n  IP:  10.222.194.100\nContainers:\n  ngx:\n    Container ID:   docker://c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859\n    Image:          nginx:alpine\n    Image ID:       docker-pullable://nginx@sha256:082f8c10bd47b6acc8ef15ae61ae45dd8fde0e9f389a8b5cb23c37408642bf5d\n    Port:           <none>\n    Host Port:      <none>\n    State:          Running\n      Started:      Tue, 30 Aug 2022 16:11:54 +0800\n    Ready:          True\n    Restart Count:  0\n    Limits:\n      cpu:     20m\n      memory:  200Mi\n    Requests:\n      cpu:        10m\n      memory:     100Mi\n    Environment:  <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jcccn (ro)\n\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n然后再通过docker inspect找到限制该容器的cgroup的路径\n\n>>> docker inspect c60e37 | grep Cgroup\n            "CgroupnsMode": "host",\n            "Cgroup": "",\n            "CgroupParent": "/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0",\n            "DeviceCgroupRules": null\n\n\n1\n2\n3\n4\n5\n\n\n我们再进入到/sys/fs/cgroup/cpu/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0，可以看到有两个容器ID的目录，因为除了我们nginx容器之外，还有一个infra容器。\n\n[root@k8s-worker1]# cd /sys/fs/cgroup/cpu/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0\n\n[root@k8s-worker1]# ls\n4c8f23863e6589d44b96ded48a2abd857ca9e45637fb9dd6b106c3c217be0904  cpuacct.usage              cpuacct.usage_sys   cpu.rt_runtime_us\nc60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859  cpuacct.usage_all          cpuacct.usage_user  cpu.shares\ncgroup.clone_children                                             cpuacct.usage_percpu       cpu.cfs_period_us   cpu.stat\ncgroup.procs                                                      cpuacct.usage_percpu_sys   cpu.cfs_quota_us    notify_on_release\ncpuacct.stat                                                      cpuacct.usage_percpu_user  cpu.rt_period_us    tasks\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n我们进入到nginx的容器ID目录下，查看tasks文件，发现有很多进程ID，为什么呢？\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# cat tasks\n2733304\n2733402\n2733403\n2733404\n2733405\n2733406\n2733407\n2733408\n2733409\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n容器就是一个隔离的进程，我们看下该容器的进程ID，再通过该ID找到该进程，确实是nginx没错，也在cgroup的tasks文件中，但是其他的进程ID是什么呢？\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# docker inspect c60e | grep Pid\n            "Pid": 2733304,\n            "PidMode": "",\n            "PidsLimit": null,\n            \n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# ps aux | grep 2733304\nroot     2733304  0.0  0.0   6304  4544 ?        Ss   16:11   0:00 nginx: master process nginx -g daemon off;\nroot     2787238  0.0  0.0  12132  1156 pts/3    S+   16:45   0:00 grep --color=auto 2733304\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n我通过ps aux来搜索一下nginx，容器ID为nginx master，而其他的进程ID都是nginx的worker进程。\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# ps aux | grep nginx\nroot     2733304  0.0  0.0   6304  4544 ?        Ss   16:11   0:00 nginx: master process nginx -g daemon off;\n101      2733402  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733403  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733404  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733405  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733406  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733407  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733408  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\n101      2733409  0.0  0.0   6760  1648 ?        S    16:11   0:00 nginx: worker process\nroot     2781594  0.0  0.0  12132  1164 pts/3    S+   16:41   0:00 grep --color=auto nginx\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n',normalizedContent:'# 什么是pod?\n\npod是一组共享了某些资源的容器。\n\n容器的隔离是通过各种namespace来实现的，pod 里的所有容器，可以通过namespace来共享系统资源，像network namepsace。\n\n\n# 为什么需要pod?\n\n众所周知所周知，容器是一个特殊的进程，但有些场景是，一个应用的运行，是需要多个进程结合使用，并有一定的依赖关系的。虽然我们也可以使用单独的容器来配置运行应用，但是都是独立的。而pod是k8s的原子调度，pod中的容器可以指定分配到同一个节点，统一按照资源调度。\n\n使用docker也可以实现a、b容器共享网络和volume，但是容器b必须比容器a先启动，是一个拓扑结构，而不是平等关系\n\n$ docker run --net=b --volumes-from=b --name=a image-a ...\n\n\n1\n\n\n在pod中，先创建启动的是infra容器，该容器会处于一个禁止状态，而其他定义的容器，则通过join network namespace与infra容器连接在一起。\n\n\n\n在pod中的容器处于同一个network namespace中，所以可以通过localhost直接进行通信，看到的网络设备是一致的。而pod的生命周期和infra容器一致，和容器a、b无关。\n\npod，实际上是在扮演传统基础设施里“虚拟机”的角色；而容器，则是这个虚拟机里运行的用户程序。\n\n\n# 使用pod\n\n使用yaml来描述一个pod。\n\napiversion: v1\nkind: pod\nmetadata:\n  name: nginx-pod\n\nspec:\n  containers:\n  - name: nginx\n    image: nginx:laster\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n再使用kubectl apply来创建pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod.yaml -n zwf\npod/nginx-pod created\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf -o wide\nname        ready   status    restarts   age     ip              node          nominated node   readiness gates\nnginx-pod   1/1     running   0          2m51s   10.222.126.60   k8s-worker2   <none>           <none>\n\n\n1\n2\n3\n4\n5\n6\n\n\n我们可以使用curl访问到pod中的nginx的服务了\n\n[root@k8s-worker1 zwf]# curl 10.222.126.60:80\n<!doctype html>\n<html>\n<head>\n<title>welcome to nginx!</title>\n<style>\nhtml { color-scheme: light dark; }\nbody { width: 35em; margin: 0 auto;\nfont-family: tahoma, verdana, arial, sans-serif; }\n</style>\n</head>\n<body>\n<h1>welcome to nginx!</h1>\n<p>if you see this page, the nginx web server is successfully installed and\nworking. further configuration is required.</p>\n\n<p>for online documentation and support please refer to\n<a href="http://nginx.org/">nginx.org</a>.<br/>\ncommercial support is available at\n<a href="http://nginx.com/">nginx.com</a>.</p>\n\n<p><em>thank you for using nginx.</em></p>\n</body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n一般我们不直接创建pod，而是通过各种控制器来管理创建\n\n\n# 容器状态探针\n\n * readinessprobe\n\n就绪性探针，判断容器中的程序是否健康，不健康，则会将该pod从service可用端点列表移除。\n\n * livenessprobe\n\n存活性探针，判断容器是否健康，不健康，则会将容器重启。 注意：是将容器重启而不是pod\n\n * startupprobe\n\n在pod启动后按照配置执行一次，如果成功，则不再执行，如果失败，则会重启pod. 其他两个探针是在startupprobe运行成功之前都是暂停的。\n\n探测方式\n\n * exec，执行一个linux命令，看返回值\n\n * tcpsocket，使用tcp尝试连接某个端口，看是否连接成功\n\n * httpget，尝试使用http请求，看是否请求成功\n\n\n# 资源配置\n\n在配置中使用resources字段来设置限制容器的资源。\n\n * requests，系统必须预留的可用资源\n\n * limits，容器可申请使用的最大可用资源，超过则会被kill的可能性\n\n这里的cpu使用的是m(milli)的单位，1000m代表1个cpu，10m代表1%cpu\n\n而内存使用mi代表mb。\n\napiversion: v1\nkind: pod\nmetadata:\n  name: ngx-pod-resources\n\nspec:\n  containers:\n  - image: nginx:alpine\n    name: ngx\n\n    resources:\n      requests:\n        cpu: 10m\n        memory: 100mi\n      limits:\n        cpu: 20m\n        memory: 200mi\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n我们再来看看是怎么使用cgroup来限制pod中容器的资源\n\n先找到pod中该容器的id\n\n>>> kubectl describe pod -n zwf ngx-pod-resources\nname:         ngx-pod-resources\nnamespace:    zwf\npriority:     0\nnode:         k8s-worker1/10.64.2.141\nstart time:   tue, 30 aug 2022 16:11:45 +0800\nlabels:       <none>\nannotations:  cni.projectcalico.org/containerid: 4c8f23863e6589d44b96ded48a2abd857ca9e45637fb9dd6b106c3c217be0904\n              cni.projectcalico.org/podip: 10.222.194.100/32\n              cni.projectcalico.org/podips: 10.222.194.100/32\nstatus:       running\nip:           10.222.194.100\nips:\n  ip:  10.222.194.100\ncontainers:\n  ngx:\n    container id:   docker://c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859\n    image:          nginx:alpine\n    image id:       docker-pullable://nginx@sha256:082f8c10bd47b6acc8ef15ae61ae45dd8fde0e9f389a8b5cb23c37408642bf5d\n    port:           <none>\n    host port:      <none>\n    state:          running\n      started:      tue, 30 aug 2022 16:11:54 +0800\n    ready:          true\n    restart count:  0\n    limits:\n      cpu:     20m\n      memory:  200mi\n    requests:\n      cpu:        10m\n      memory:     100mi\n    environment:  <none>\n    mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-jcccn (ro)\n\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n然后再通过docker inspect找到限制该容器的cgroup的路径\n\n>>> docker inspect c60e37 | grep cgroup\n            "cgroupnsmode": "host",\n            "cgroup": "",\n            "cgroupparent": "/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0",\n            "devicecgrouprules": null\n\n\n1\n2\n3\n4\n5\n\n\n我们再进入到/sys/fs/cgroup/cpu/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0，可以看到有两个容器id的目录，因为除了我们nginx容器之外，还有一个infra容器。\n\n[root@k8s-worker1]# cd /sys/fs/cgroup/cpu/kubepods/burstable/poda9ca2eed-ef7b-4564-b448-e35b06c7bdd0\n\n[root@k8s-worker1]# ls\n4c8f23863e6589d44b96ded48a2abd857ca9e45637fb9dd6b106c3c217be0904  cpuacct.usage              cpuacct.usage_sys   cpu.rt_runtime_us\nc60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859  cpuacct.usage_all          cpuacct.usage_user  cpu.shares\ncgroup.clone_children                                             cpuacct.usage_percpu       cpu.cfs_period_us   cpu.stat\ncgroup.procs                                                      cpuacct.usage_percpu_sys   cpu.cfs_quota_us    notify_on_release\ncpuacct.stat                                                      cpuacct.usage_percpu_user  cpu.rt_period_us    tasks\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n我们进入到nginx的容器id目录下，查看tasks文件，发现有很多进程id，为什么呢？\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# cat tasks\n2733304\n2733402\n2733403\n2733404\n2733405\n2733406\n2733407\n2733408\n2733409\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n容器就是一个隔离的进程，我们看下该容器的进程id，再通过该id找到该进程，确实是nginx没错，也在cgroup的tasks文件中，但是其他的进程id是什么呢？\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# docker inspect c60e | grep pid\n            "pid": 2733304,\n            "pidmode": "",\n            "pidslimit": null,\n            \n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# ps aux | grep 2733304\nroot     2733304  0.0  0.0   6304  4544 ?        ss   16:11   0:00 nginx: master process nginx -g daemon off;\nroot     2787238  0.0  0.0  12132  1156 pts/3    s+   16:45   0:00 grep --color=auto 2733304\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n我通过ps aux来搜索一下nginx，容器id为nginx master，而其他的进程id都是nginx的worker进程。\n\n[root@k8s-worker1 c60e370dd413f240164aec3f98cb35a8d09f6a3833c414a6c7a767d51977b859]# ps aux | grep nginx\nroot     2733304  0.0  0.0   6304  4544 ?        ss   16:11   0:00 nginx: master process nginx -g daemon off;\n101      2733402  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733403  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733404  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733405  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733406  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733407  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733408  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\n101      2733409  0.0  0.0   6760  1648 ?        s    16:11   0:00 nginx: worker process\nroot     2781594  0.0  0.0  12132  1164 pts/3    s+   16:41   0:00 grep --color=auto nginx\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"CompletableFuture学习",frontmatter:{title:"CompletableFuture学习",date:"2023-08-11T15:44:06.000Z",permalink:"/pages/f6a447/",author:{name:"陌上清风",link:"https://msqfx.github.io"},categories:["java","并发篇"],tags:[null],description:"我们异步执行一个任务时，一般是用线程池 Executor 去创建。",comment:!0,meta:[{name:"image",content:"https://cmty256.github.io/imgs-blog/Java/image.6ntc9cicslc0.webp"},{name:"twitter:title",content:"CompletableFuture学习"},{name:"twitter:description",content:"我们异步执行一个任务时，一般是用线程池 Executor 去创建。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://cmty256.github.io/imgs-blog/Java/image.6ntc9cicslc0.webp"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/05.CompletableFuture%E5%AD%A6%E4%B9%A0.html"},{property:"og:type",content:"article"},{property:"og:title",content:"CompletableFuture学习"},{property:"og:description",content:"我们异步执行一个任务时，一般是用线程池 Executor 去创建。"},{property:"og:image",content:"https://cmty256.github.io/imgs-blog/Java/image.6ntc9cicslc0.webp"},{property:"og:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/05.CompletableFuture%E5%AD%A6%E4%B9%A0.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-08-11T15:44:06.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"CompletableFuture学习"},{itemprop:"description",content:"我们异步执行一个任务时，一般是用线程池 Executor 去创建。"},{itemprop:"image",content:"https://cmty256.github.io/imgs-blog/Java/image.6ntc9cicslc0.webp"}],readingShow:"top"},regularPath:"/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/05.CompletableFuture%E5%AD%A6%E4%B9%A0.html",relativePath:"01.java/03.并发篇/05.CompletableFuture学习.md",key:"v-d51b20aa",path:"/pages/f6a447/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:29},{level:2,title:"源码解析",slug:"源码解析",normalizedTitle:"源码解析",charIndex:384},{level:2,title:"什么是 CompletableFuture？",slug:"什么是-completablefuture",normalizedTitle:"什么是 completablefuture？",charIndex:942},{level:2,title:"使用步骤",slug:"使用步骤",normalizedTitle:"使用步骤",charIndex:1102},{level:3,title:"创建 CompletableFuture",slug:"创建-completablefuture",normalizedTitle:"创建 completablefuture",charIndex:1111},{level:4,title:"new 关键字",slug:"new-关键字",normalizedTitle:"new 关键字",charIndex:1150},{level:4,title:"静态工厂方法",slug:"静态工厂方法",normalizedTitle:"静态工厂方法",charIndex:1186},{level:5,title:"supplyAsync 方法",slug:"supplyasync-方法",normalizedTitle:"supplyasync 方法",charIndex:2482},{level:5,title:"runAsync 方法",slug:"runasync-方法",normalizedTitle:"runasync 方法",charIndex:3329},{level:5,title:"实例代码",slug:"实例代码",normalizedTitle:"实例代码",charIndex:3737},{level:3,title:"简单任务异步回调",slug:"简单任务异步回调",normalizedTitle:"简单任务异步回调",charIndex:4614},{level:4,title:"处理异步结算结果",slug:"处理异步结算结果",normalizedTitle:"处理异步结算结果",charIndex:4628},{level:5,title:"thenRun/thenRunAsync",slug:"thenrun-thenrunasync",normalizedTitle:"thenrun/thenrunasync",charIndex:4748},{level:5,title:"thenAccept/thenAcceptAsync",slug:"thenaccept-thenacceptasync",normalizedTitle:"thenaccept/thenacceptasync",charIndex:6305},{level:5,title:"thenApply/thenApplyAsync",slug:"thenapply-thenapplyasync",normalizedTitle:"thenapply/thenapplyasync",charIndex:7147},{level:5,title:"whenComplete()",slug:"whencomplete",normalizedTitle:"whencomplete()",charIndex:4730},{level:4,title:"异常处理",slug:"异常处理",normalizedTitle:"异常处理",charIndex:9955},{level:3,title:"多个任务组合处理",slug:"多个任务组合处理",normalizedTitle:"多个任务组合处理",charIndex:11621},{level:4,title:"AND 组合关系",slug:"and-组合关系",normalizedTitle:"and 组合关系",charIndex:11633},{level:4,title:"allOf 全部执行完",slug:"allof-全部执行完",normalizedTitle:"allof 全部执行完",charIndex:12787},{level:4,title:"anyOf 任一执行完",slug:"anyof-任一执行完",normalizedTitle:"anyof 任一执行完",charIndex:13506},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:14616}],headersStr:"前言 源码解析 什么是 CompletableFuture？ 使用步骤 创建 CompletableFuture new 关键字 静态工厂方法 supplyAsync 方法 runAsync 方法 实例代码 简单任务异步回调 处理异步结算结果 thenRun/thenRunAsync thenAccept/thenAcceptAsync thenApply/thenApplyAsync whenComplete() 异常处理 多个任务组合处理 AND 组合关系 allOf 全部执行完 anyOf 任一执行完 参考",content:'# CompletableFuture 异步编程\n\n\n# 前言\n\n我们异步执行一个任务时，一般是用线程池 Executor 去创建。\n\n * 如果不需要有返回值，任务实现 Runnable 接口；\n * 如果需要有返回值，任务实现 Callable 接口，调用 Executor 的 submit 方法，再使用 Future 获取即可。\n\n如果多个线程存在依赖组合的话，我们怎么处理呢？\n\n * 可使用同步组件 CountDownLatch、CyclicBarrier 等，但是比较麻烦。\n * 其实有简单的方法，就是用 CompeletableFuture。\n\n在现代的软件开发中，处理并发和异步任务变得越来越重要。Java 中的 CompletableFuture 类为我们提供了一种强大的方式来处理异步编程，让我们能够更有效地利用多核处理器和并行执行。\n\n\n# 源码解析\n\n源码：\n\npublic class CompletableFuture<T> implements Future<T>, CompletionStage<T> {\n}\n\n\n1\n2\n\n\n从源码可以看出 CompletableFuture 同时实现了 Future 和 CompletionStage 接口。\n\nCompletableFuture 除了提供了更为好用和强大的 Future 特性之外，还提供了函数式编程的能力。\n\nFuture 接口有 5 个方法：\n\n 1. boolean cancel(boolean mayInterruptIfRunning)：尝试取消执行任务。\n 2. boolean isCancelled()：判断任务是否被取消。\n 3. boolean isDone()：判断任务是否已经被执行完成。\n 4. get()：等待任务执行完成并获取运算结果。\n 5. get(long timeout, TimeUnit unit)：多了一个超时时间。\n\nCompletionStage 接口\n\nCompletionStage 接口描述了一个异步计算的阶段。很多计算可以分成多个阶段或步骤，此时可以通过它将所有步骤组合起来，形成异步计算的流水线。（大量使用了函数式编程）\n\n\n# 什么是 CompletableFuture？\n\nCompletableFuture 是 Java 8 引入的一个类，用于支持异步编程和操作多个异步任务。它是 Future 的扩展，提供了更多的功能和灵活性。通过 CompletableFuture，我们可以将多个异步任务串行或并行执行，然后等待它们的完成结果。\n\n\n# 使用步骤\n\n\n# 创建 CompletableFuture\n\n常见的有两种方法\n\n 1. 通过 new 关键字\n 2. 基于 CompletableFuture 自带的静态工厂方法：runAsync()、supplyAsync()。\n\n# new 关键字\n\n通过 new 关键字创建 CompletableFuture 对象这种使用方式可以看作是将 CompletableFuture 当做 Future 来使用。\n\n举例：\n\n * 创建异步运算的载体\n\nCompletableFuture<RpcResponse<Object>> resultFuture = new CompletableFuture<>();\n\n\n1\n\n\n上面代码创建了一个结果值类型为 RpcResponse<Object> 的 CompletableFuture，你可以把 resultFuture 看作是异步运算结果的载体。\n\n * 传入运算结果\n\n// complete() 方法只能调用一次，后续调用将被忽略。\nresultFuture.complete(rpcResponse);\n\n\n1\n2\n\n\n假设在未来的某个时刻，我们得到了最终的结果。这时，我们可以调用 complete() 方法为其传入结果，这表示 resultFuture 已经被完成了。\n\n * 判断任务是否已经被完成\n\npublic boolean isDone() {\n    return result != null;\n}\n\n\n1\n2\n3\n\n\n可以通过 isDone() 方法来检查是否已经完成。（Future 接口的方法）\n\n * 等待任务执行完成并获取运算结果\n\nrpcResponse = completableFuture.get();\n\n\n1\n\n\n可以通过调用 get() 方法来获取异步计算结果。调用 get() 方法的线程会阻塞直到 CompletableFuture 完成运算。（阻塞等待）\n\n * 如果你已经知道计算的结果的话，可以使用静态方法 completedFuture() 来创建 CompletableFuture。\n\nCompletableFuture<String> future = CompletableFuture.completedFuture("hello!");\nassertEquals("hello!", future.get());\n\n\n1\n2\n\n\ncompletedFuture() 方法底层调用的是带参数的 new 方法，只不过，这个方法不对外暴露。\n\npublic static <U> CompletableFuture<U> completedFuture(U value) {\n    return new CompletableFuture<U>((value == null) ? NIL : value);\n}\n\n\n1\n2\n3\n\n\n# 静态工厂方法\n\n * supplyAsync 执行 CompletableFuture 任务，支持返回值\n * runAsync 执行 CompletableFuture 任务，没有返回值。因为 runAsync() 方法接受的参数是 Runnable ，这是一个函数式接口，不允许返回值。\n\n# supplyAsync 方法\n\n// 使用默认内置线程池ForkJoinPool.commonPool()，根据supplier构建执行任务\npublic static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier)\n// 使用自定义线程池，根据supplier构建执行任务（推荐）\npublic static <U> CompletableFuture<U> supplyAsync(Supplier<U> supplier, Executor executor)\n\n\n1\n2\n3\n4\n\n\nsupplyAsync() 方法接受的参数是 Supplier<U> ，是一个函数式接口，U 是返回结果值的类型。\n\n@FunctionalInterface\npublic interface Supplier<T> {\n\n    /**\n     * Gets a result.\n     *\n     * @return a result\n     */\n    T get();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n使用场景：当你需要异步操作且关心返回结果的时候,可以使用 supplyAsync() 方法。\n\nCompletableFuture<Void> future = CompletableFuture.runAsync(() -> System.out.println("hello!"));\nfuture.get();// 输出 "hello!"\nCompletableFuture<String> future2 = CompletableFuture.supplyAsync(() -> "hello!");\nassertEquals("hello!", future2.get()); // 进行断言，判断返回值是否为 "hello!"，不通过就会抛出异常\n\n\n1\n2\n3\n4\n\n\n# runAsync 方法\n\n// 使用默认内置线程池ForkJoinPool.commonPool()，根据runnable构建执行任务\npublic static CompletableFuture<Void> runAsync(Runnable runnable) \n// 使用自定义线程池，根据runnable构建执行任务（推荐）\npublic static CompletableFuture<Void> runAsync(Runnable runnable,  Executor executor)\n\n\n1\n2\n3\n4\n\n\n使用场景：当你需要异步操作且不关心返回结果的时候可以使用 runAsync() 方法。\n\n@FunctionalInterface\npublic interface Runnable {\n    public abstract void run();\n}\n\n\n1\n2\n3\n4\n\n\n# 实例代码\n\npublic class FutureTest {\n\n    public static void main(String[] args) {\n        //可以自定义线程池\n        ExecutorService executor = Executors.newCachedThreadPool();\n        //runAsync的使用\n        CompletableFuture<Void> runFuture = CompletableFuture.runAsync(() -> System.out.println("run,关注公众号:捡田螺的小男孩"), executor);\n        //supplyAsync的使用\n        CompletableFuture<String> supplyFuture = CompletableFuture.supplyAsync(() -> {\n                    System.out.print("supply,关注公众号:捡田螺的小男孩");\n                    return "捡田螺的小男孩"; }, executor);\n        //runAsync的future没有返回值，输出null\n        System.out.println(runFuture.join());\n        //supplyAsync的future，有返回值\n        System.out.println(supplyFuture.join());\n        executor.shutdown(); // 线程池需要关闭\n    }\n}\n//输出\nrun,关注公众号:捡田螺的小男孩\nnull\nsupply,关注公众号:捡田螺的小男孩捡田螺的小男孩\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n# 简单任务异步回调\n\n\n\n# 处理异步结算结果\n\n当我们获取到异步计算的结果之后，还可以对其进行进一步的处理，比较常用的方法有下面几个：\n\n * thenApply()\n * thenAccept()\n * thenRun()\n * whenComplete()\n\n# thenRun/thenRunAsync\n\npublic CompletableFuture<Void> thenRun(Runnable action);\npublic CompletableFuture<Void> thenRunAsync(Runnable action);\n\n\n1\n2\n\n\nCompletableFuture 的 thenRun 方法，通俗点讲就是，做完第一个任务后，再做第二个任务。\n\n某个任务执行完成后，执行回调方法；但是前后两个任务没有参数传递，第二个任务也没有返回值。\n\n代码示例：\n\npublic class FutureThenRunTest {\n\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n\n        CompletableFuture<String> orgFuture = CompletableFuture.supplyAsync(\n                ()->{\n                    System.out.println("先执行第一个CompletableFuture方法任务");\n                    return "捡田螺的小男孩";\n                }\n        );\n\n        CompletableFuture thenRunFuture = orgFuture.thenRun(() -> {\n            System.out.println("接着执行第二个任务");\n        });\n\n        System.out.println(thenRunFuture.get());\n    }\n}\n//输出\n先执行第一个CompletableFuture方法任务\n接着执行第二个任务\nnull\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\nthenRun 和 thenRunAsync 有什么区别？\n\n源码：\n\n    private static final Executor asyncPool = useCommonPool ? ForkJoinPool.commonPool() : new ThreadPerTaskExecutor();\n  \n    public CompletableFuture<Void> thenRun(Runnable action) {\n        return uniRunStage(null, action);\n    }\n\n    public CompletableFuture<Void> thenRunAsync(Runnable action) {\n        return uniRunStage(asyncPool, action);\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n如果你执行第一个任务的时候，传入了一个自定义线程池：\n\n * 调用 thenRun 方法执行第二个任务时，则第二个任务和第一个任务是共用同一个线程池。\n * 调用 thenRunAsync 执行第二个任务时，则第一个任务使用的是你自己传入的线程池，第二个任务使用的是 ForkJoin 线程池\n\n> tips: thenAccept 和 thenAcceptAsync，thenApply 和 thenApplyAsync 等，它们之间的区别也是这个\n\n# thenAccept/thenAcceptAsync\n\nCompletableFuture 的 thenAccept 方法表示，第一个任务执行完成后，执行第二个回调方法任务，会将该任务的执行结果，作为入参，传递到回调方法中，但是回调方法是没有返回值的。\n\npublic class FutureThenAcceptTest {\n\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n\n        CompletableFuture<String> orgFuture = CompletableFuture.supplyAsync(\n                ()->{\n                    System.out.println("原始CompletableFuture方法任务");\n                    return "捡田螺的小男孩";\n                }\n        );\n\n        CompletableFuture thenAcceptFuture = orgFuture.thenAccept((a) -> {\n            if ("捡田螺的小男孩".equals(a)) {\n                System.out.println("关注了");\n            }\n\n            System.out.println("先考虑考虑");\n        });\n\n        System.out.println(thenAcceptFuture.get());\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n# thenApply/thenApplyAsync\n\nthenApply() 方法接收一个 Function 实例，用它来处理结果。\n\n// 沿用上一个任务的线程池\npublic <U> CompletableFuture<U> thenApply(\n    Function<? super T,? extends U> fn) {\n    return uniApplyStage(null, fn);\n}\n\n//使用默认的 ForkJoinPool 线程池（不推荐）\npublic <U> CompletableFuture<U> thenApplyAsync(\n    Function<? super T,? extends U> fn) {\n    return uniApplyStage(defaultExecutor(), fn);\n}\n// 使用自定义线程池(推荐)\npublic <U> CompletableFuture<U> thenApplyAsync(\n    Function<? super T,? extends U> fn, Executor executor) {\n    return uniApplyStage(screenExecutor(executor), fn);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n使用示例：\n\nCompletableFuture 的 thenApply 方法表示，第一个任务执行完成后，执行第二个回调方法任务，会将该任务的执行结果，作为入参，传递到回调方法中，并且回调方法是有返回值的。\n\npublic class FutureThenApplyTest {\n\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n\n        CompletableFuture<String> orgFuture = CompletableFuture.supplyAsync(\n                ()->{\n                    System.out.println("原始CompletableFuture方法任务");\n                    return "捡田螺的小男孩";\n                }\n        );\n\n        CompletableFuture<String> thenApplyFuture = orgFuture.thenApply((a) -> {\n            if ("捡田螺的小男孩".equals(a)) {\n                return "关注了";\n            }\n\n            return "先考虑考虑";\n        });\n\n        System.out.println(thenApplyFuture.get());\n    }\n}\n//输出\n原始CompletableFuture方法任务\n关注了\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n# whenComplete()\n\nCompletableFuture 的 whenComplete 方法表示，某个任务执行完成后，执行的回调方法，无返回值；并且 whenComplete 方法返回的 CompletableFuture 的 result 是上个任务的结果。\n\npublic class FutureWhenTest {\n\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n\n        CompletableFuture<String> orgFuture = CompletableFuture.supplyAsync(\n                ()->{\n                    System.out.println("当前线程名称：" + Thread.currentThread().getName());\n                    try {\n                        Thread.sleep(2000L);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                    return "捡田螺的小男孩";\n                }\n        );\n\n        CompletableFuture<String> rstFuture = orgFuture.whenComplete((a, throwable) -> {\n            System.out.println("当前线程名称：" + Thread.currentThread().getName());\n            System.out.println("上个任务执行完啦，还把" + a + "传过来");\n            if ("捡田螺的小男孩".equals(a)) {\n                System.out.println("666");\n            }\n            System.out.println("233333");\n        });\n\n        System.out.println(rstFuture.get());\n    }\n}\n//输出\n当前线程名称：ForkJoinPool.commonPool-worker-1\n当前线程名称：ForkJoinPool.commonPool-worker-1\n上个任务执行完啦，还把捡田螺的小男孩传过来\n666\n233333\n捡田螺的小男孩\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n# 异常处理\n\n异步操作可能会失败，CompletableFuture 允许我们使用 exceptionally() 或 handle() 方法来处理异步操作的异常。\n\nhandle()\n\npublic <U> CompletableFuture<U> handle(\n    BiFunction<? super T, Throwable, ? extends U> fn) {\n    return uniHandleStage(null, fn);\n}\n\npublic <U> CompletableFuture<U> handleAsync(\n    BiFunction<? super T, Throwable, ? extends U> fn) {\n    return uniHandleStage(defaultExecutor(), fn);\n}\n\npublic <U> CompletableFuture<U> handleAsync(\n    BiFunction<? super T, Throwable, ? extends U> fn, Executor executor) {\n    return uniHandleStage(screenExecutor(executor), fn);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n示例代码：\n\nCompletableFuture<String> future\n        = CompletableFuture.supplyAsync(() -> {\n    if (true) {\n        throw new RuntimeException("Computation error!");\n    }\n    return "hello!";\n}).handle((res, ex) -> {\n    // res 代表返回的结果\n    // ex 的类型为 Throwable ，代表抛出的异常\n    return res != null ? res : "world!";\n});\nassertEquals("world!", future.get());\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nexceptionally()\n\nCompletableFuture<String> future\n        = CompletableFuture.supplyAsync(() -> {\n    if (true) {\n        throw new RuntimeException("Computation error!");\n    }\n    return "hello!";\n}).exceptionally(ex -> {\n    System.out.println(ex.toString());// CompletionException\n    return "world!";\n});\nassertEquals("world!", future.get());\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n设置 CompletableFuture 的结果就是异常\n\n可以使用 completeExceptionally() 方法为其赋值。\n\nCompletableFuture<String> completableFuture = new CompletableFuture<>();\n// ...\ncompletableFuture.completeExceptionally(\n  new RuntimeException("Calculation failed!"));\n// ...\ncompletableFuture.get(); // ExecutionException\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 多个任务组合处理\n\n# AND 组合关系\n\nthenCombine / thenAcceptBoth / runAfterBoth 都表示：将两个 CompletableFuture 组合起来，只有这两个都正常执行完了，才会执行某个任务。\n\n区别在于：\n\n * thenCombine：会将两个任务的执行结果作为方法入参，传递到指定方法中，且有返回值\n * thenAcceptBoth: 会将两个任务的执行结果作为方法入参，传递到指定方法中，且无返回值\n * runAfterBoth 不会把执行结果当做方法入参，且没有返回值。\n\n代码示例：\n\npublic class ThenCombineTest {\n\n    public static void main(String[] args) throws InterruptedException, ExecutionException, TimeoutException {\n\n        CompletableFuture<String> first = CompletableFuture.completedFuture("第一个异步任务");\n        ExecutorService executor = Executors.newFixedThreadPool(10);\n        CompletableFuture<String> future = CompletableFuture\n                //第二个异步任务\n                .supplyAsync(() -> "第二个异步任务", executor)\n                // (w, s) -> System.out.println(s) 是第三个任务\n                .thenCombineAsync(first, (s, w) -> {\n                    System.out.println(w);\n                    System.out.println(s);\n                    return "两个异步任务的组合";\n                }, executor);\n        System.out.println(future.join());\n        executor.shutdown();\n\n    }\n}\n//输出\n第一个异步任务\n第二个异步任务\n两个异步任务的组合\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n# allOf 全部执行完\n\n所有任务都执行完成后，才执行 allOf 返回的 CompletableFuture。如果任意一个任务异常，allOf 的 CompletableFuture，执行 get 方法，会抛出异常。\n\npublic class allOfFutureTest {\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n\n        CompletableFuture<Void> a = CompletableFuture.runAsync(()->{\n            System.out.println("我执行完了");\n        });\n        CompletableFuture<Void> b = CompletableFuture.runAsync(() -> {\n            System.out.println("我也执行完了");\n        });\n        CompletableFuture<Void> allOfFuture = CompletableFuture.allOf(a, b).whenComplete((m,k)->{\n            System.out.println("finish");\n        });\n    }\n}\n//输出\n我执行完了\n我也执行完了\nfinish\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n# anyOf 任一执行完\n\n任意一个任务执行完，就执行 anyOf 返回的 CompletableFuture。如果执行的任务异常，anyOf 的 CompletableFuture，执行 get 方法，会抛出异常。\n\npublic class AnyOfFutureTest {\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n\n        CompletableFuture<Void> a = CompletableFuture.runAsync(()->{\n            try {\n                Thread.sleep(3000L);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println("我执行完了");\n        });\n        CompletableFuture<Void> b = CompletableFuture.runAsync(() -> {\n            System.out.println("我也执行完了");\n        });\n        CompletableFuture<Object> anyOfFuture = CompletableFuture.anyOf(a, b).whenComplete((m,k)->{\n            System.out.println("finish");\n        });\n        anyOfFuture.join(); // 等待任意一个给定的 CompletableFuture 完成\n    }\n}\n// 输出\n我也执行完了\nfinish\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\njoin() 的含义是：等待一个异步操作（也就是 CompletableFuture）完成并获取其结果。\n\n具体来说，join 方法会阻塞当前线程，直到相应的 CompletableFuture 完成，并返回其计算结果（或异常）。如果在调用 join 时异步操作还未完成，那么当前线程将一直阻塞等待，直到操作完成或者抛出异常。\n\n\n# 参考\n\n * 异步编程利器：CompletableFuture详解 ｜Java 开发实战 - 掘金 (juejin.cn)\n * CompletableFuture 详解 | JavaGuide(Java面试 + 学习指南)',normalizedContent:'# completablefuture 异步编程\n\n\n# 前言\n\n我们异步执行一个任务时，一般是用线程池 executor 去创建。\n\n * 如果不需要有返回值，任务实现 runnable 接口；\n * 如果需要有返回值，任务实现 callable 接口，调用 executor 的 submit 方法，再使用 future 获取即可。\n\n如果多个线程存在依赖组合的话，我们怎么处理呢？\n\n * 可使用同步组件 countdownlatch、cyclicbarrier 等，但是比较麻烦。\n * 其实有简单的方法，就是用 compeletablefuture。\n\n在现代的软件开发中，处理并发和异步任务变得越来越重要。java 中的 completablefuture 类为我们提供了一种强大的方式来处理异步编程，让我们能够更有效地利用多核处理器和并行执行。\n\n\n# 源码解析\n\n源码：\n\npublic class completablefuture<t> implements future<t>, completionstage<t> {\n}\n\n\n1\n2\n\n\n从源码可以看出 completablefuture 同时实现了 future 和 completionstage 接口。\n\ncompletablefuture 除了提供了更为好用和强大的 future 特性之外，还提供了函数式编程的能力。\n\nfuture 接口有 5 个方法：\n\n 1. boolean cancel(boolean mayinterruptifrunning)：尝试取消执行任务。\n 2. boolean iscancelled()：判断任务是否被取消。\n 3. boolean isdone()：判断任务是否已经被执行完成。\n 4. get()：等待任务执行完成并获取运算结果。\n 5. get(long timeout, timeunit unit)：多了一个超时时间。\n\ncompletionstage 接口\n\ncompletionstage 接口描述了一个异步计算的阶段。很多计算可以分成多个阶段或步骤，此时可以通过它将所有步骤组合起来，形成异步计算的流水线。（大量使用了函数式编程）\n\n\n# 什么是 completablefuture？\n\ncompletablefuture 是 java 8 引入的一个类，用于支持异步编程和操作多个异步任务。它是 future 的扩展，提供了更多的功能和灵活性。通过 completablefuture，我们可以将多个异步任务串行或并行执行，然后等待它们的完成结果。\n\n\n# 使用步骤\n\n\n# 创建 completablefuture\n\n常见的有两种方法\n\n 1. 通过 new 关键字\n 2. 基于 completablefuture 自带的静态工厂方法：runasync()、supplyasync()。\n\n# new 关键字\n\n通过 new 关键字创建 completablefuture 对象这种使用方式可以看作是将 completablefuture 当做 future 来使用。\n\n举例：\n\n * 创建异步运算的载体\n\ncompletablefuture<rpcresponse<object>> resultfuture = new completablefuture<>();\n\n\n1\n\n\n上面代码创建了一个结果值类型为 rpcresponse<object> 的 completablefuture，你可以把 resultfuture 看作是异步运算结果的载体。\n\n * 传入运算结果\n\n// complete() 方法只能调用一次，后续调用将被忽略。\nresultfuture.complete(rpcresponse);\n\n\n1\n2\n\n\n假设在未来的某个时刻，我们得到了最终的结果。这时，我们可以调用 complete() 方法为其传入结果，这表示 resultfuture 已经被完成了。\n\n * 判断任务是否已经被完成\n\npublic boolean isdone() {\n    return result != null;\n}\n\n\n1\n2\n3\n\n\n可以通过 isdone() 方法来检查是否已经完成。（future 接口的方法）\n\n * 等待任务执行完成并获取运算结果\n\nrpcresponse = completablefuture.get();\n\n\n1\n\n\n可以通过调用 get() 方法来获取异步计算结果。调用 get() 方法的线程会阻塞直到 completablefuture 完成运算。（阻塞等待）\n\n * 如果你已经知道计算的结果的话，可以使用静态方法 completedfuture() 来创建 completablefuture。\n\ncompletablefuture<string> future = completablefuture.completedfuture("hello!");\nassertequals("hello!", future.get());\n\n\n1\n2\n\n\ncompletedfuture() 方法底层调用的是带参数的 new 方法，只不过，这个方法不对外暴露。\n\npublic static <u> completablefuture<u> completedfuture(u value) {\n    return new completablefuture<u>((value == null) ? nil : value);\n}\n\n\n1\n2\n3\n\n\n# 静态工厂方法\n\n * supplyasync 执行 completablefuture 任务，支持返回值\n * runasync 执行 completablefuture 任务，没有返回值。因为 runasync() 方法接受的参数是 runnable ，这是一个函数式接口，不允许返回值。\n\n# supplyasync 方法\n\n// 使用默认内置线程池forkjoinpool.commonpool()，根据supplier构建执行任务\npublic static <u> completablefuture<u> supplyasync(supplier<u> supplier)\n// 使用自定义线程池，根据supplier构建执行任务（推荐）\npublic static <u> completablefuture<u> supplyasync(supplier<u> supplier, executor executor)\n\n\n1\n2\n3\n4\n\n\nsupplyasync() 方法接受的参数是 supplier<u> ，是一个函数式接口，u 是返回结果值的类型。\n\n@functionalinterface\npublic interface supplier<t> {\n\n    /**\n     * gets a result.\n     *\n     * @return a result\n     */\n    t get();\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n使用场景：当你需要异步操作且关心返回结果的时候,可以使用 supplyasync() 方法。\n\ncompletablefuture<void> future = completablefuture.runasync(() -> system.out.println("hello!"));\nfuture.get();// 输出 "hello!"\ncompletablefuture<string> future2 = completablefuture.supplyasync(() -> "hello!");\nassertequals("hello!", future2.get()); // 进行断言，判断返回值是否为 "hello!"，不通过就会抛出异常\n\n\n1\n2\n3\n4\n\n\n# runasync 方法\n\n// 使用默认内置线程池forkjoinpool.commonpool()，根据runnable构建执行任务\npublic static completablefuture<void> runasync(runnable runnable) \n// 使用自定义线程池，根据runnable构建执行任务（推荐）\npublic static completablefuture<void> runasync(runnable runnable,  executor executor)\n\n\n1\n2\n3\n4\n\n\n使用场景：当你需要异步操作且不关心返回结果的时候可以使用 runasync() 方法。\n\n@functionalinterface\npublic interface runnable {\n    public abstract void run();\n}\n\n\n1\n2\n3\n4\n\n\n# 实例代码\n\npublic class futuretest {\n\n    public static void main(string[] args) {\n        //可以自定义线程池\n        executorservice executor = executors.newcachedthreadpool();\n        //runasync的使用\n        completablefuture<void> runfuture = completablefuture.runasync(() -> system.out.println("run,关注公众号:捡田螺的小男孩"), executor);\n        //supplyasync的使用\n        completablefuture<string> supplyfuture = completablefuture.supplyasync(() -> {\n                    system.out.print("supply,关注公众号:捡田螺的小男孩");\n                    return "捡田螺的小男孩"; }, executor);\n        //runasync的future没有返回值，输出null\n        system.out.println(runfuture.join());\n        //supplyasync的future，有返回值\n        system.out.println(supplyfuture.join());\n        executor.shutdown(); // 线程池需要关闭\n    }\n}\n//输出\nrun,关注公众号:捡田螺的小男孩\nnull\nsupply,关注公众号:捡田螺的小男孩捡田螺的小男孩\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n# 简单任务异步回调\n\n\n\n# 处理异步结算结果\n\n当我们获取到异步计算的结果之后，还可以对其进行进一步的处理，比较常用的方法有下面几个：\n\n * thenapply()\n * thenaccept()\n * thenrun()\n * whencomplete()\n\n# thenrun/thenrunasync\n\npublic completablefuture<void> thenrun(runnable action);\npublic completablefuture<void> thenrunasync(runnable action);\n\n\n1\n2\n\n\ncompletablefuture 的 thenrun 方法，通俗点讲就是，做完第一个任务后，再做第二个任务。\n\n某个任务执行完成后，执行回调方法；但是前后两个任务没有参数传递，第二个任务也没有返回值。\n\n代码示例：\n\npublic class futurethenruntest {\n\n    public static void main(string[] args) throws executionexception, interruptedexception {\n\n        completablefuture<string> orgfuture = completablefuture.supplyasync(\n                ()->{\n                    system.out.println("先执行第一个completablefuture方法任务");\n                    return "捡田螺的小男孩";\n                }\n        );\n\n        completablefuture thenrunfuture = orgfuture.thenrun(() -> {\n            system.out.println("接着执行第二个任务");\n        });\n\n        system.out.println(thenrunfuture.get());\n    }\n}\n//输出\n先执行第一个completablefuture方法任务\n接着执行第二个任务\nnull\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\nthenrun 和 thenrunasync 有什么区别？\n\n源码：\n\n    private static final executor asyncpool = usecommonpool ? forkjoinpool.commonpool() : new threadpertaskexecutor();\n  \n    public completablefuture<void> thenrun(runnable action) {\n        return unirunstage(null, action);\n    }\n\n    public completablefuture<void> thenrunasync(runnable action) {\n        return unirunstage(asyncpool, action);\n    }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n如果你执行第一个任务的时候，传入了一个自定义线程池：\n\n * 调用 thenrun 方法执行第二个任务时，则第二个任务和第一个任务是共用同一个线程池。\n * 调用 thenrunasync 执行第二个任务时，则第一个任务使用的是你自己传入的线程池，第二个任务使用的是 forkjoin 线程池\n\n> tips: thenaccept 和 thenacceptasync，thenapply 和 thenapplyasync 等，它们之间的区别也是这个\n\n# thenaccept/thenacceptasync\n\ncompletablefuture 的 thenaccept 方法表示，第一个任务执行完成后，执行第二个回调方法任务，会将该任务的执行结果，作为入参，传递到回调方法中，但是回调方法是没有返回值的。\n\npublic class futurethenaccepttest {\n\n    public static void main(string[] args) throws executionexception, interruptedexception {\n\n        completablefuture<string> orgfuture = completablefuture.supplyasync(\n                ()->{\n                    system.out.println("原始completablefuture方法任务");\n                    return "捡田螺的小男孩";\n                }\n        );\n\n        completablefuture thenacceptfuture = orgfuture.thenaccept((a) -> {\n            if ("捡田螺的小男孩".equals(a)) {\n                system.out.println("关注了");\n            }\n\n            system.out.println("先考虑考虑");\n        });\n\n        system.out.println(thenacceptfuture.get());\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n# thenapply/thenapplyasync\n\nthenapply() 方法接收一个 function 实例，用它来处理结果。\n\n// 沿用上一个任务的线程池\npublic <u> completablefuture<u> thenapply(\n    function<? super t,? extends u> fn) {\n    return uniapplystage(null, fn);\n}\n\n//使用默认的 forkjoinpool 线程池（不推荐）\npublic <u> completablefuture<u> thenapplyasync(\n    function<? super t,? extends u> fn) {\n    return uniapplystage(defaultexecutor(), fn);\n}\n// 使用自定义线程池(推荐)\npublic <u> completablefuture<u> thenapplyasync(\n    function<? super t,? extends u> fn, executor executor) {\n    return uniapplystage(screenexecutor(executor), fn);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n使用示例：\n\ncompletablefuture 的 thenapply 方法表示，第一个任务执行完成后，执行第二个回调方法任务，会将该任务的执行结果，作为入参，传递到回调方法中，并且回调方法是有返回值的。\n\npublic class futurethenapplytest {\n\n    public static void main(string[] args) throws executionexception, interruptedexception {\n\n        completablefuture<string> orgfuture = completablefuture.supplyasync(\n                ()->{\n                    system.out.println("原始completablefuture方法任务");\n                    return "捡田螺的小男孩";\n                }\n        );\n\n        completablefuture<string> thenapplyfuture = orgfuture.thenapply((a) -> {\n            if ("捡田螺的小男孩".equals(a)) {\n                return "关注了";\n            }\n\n            return "先考虑考虑";\n        });\n\n        system.out.println(thenapplyfuture.get());\n    }\n}\n//输出\n原始completablefuture方法任务\n关注了\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n# whencomplete()\n\ncompletablefuture 的 whencomplete 方法表示，某个任务执行完成后，执行的回调方法，无返回值；并且 whencomplete 方法返回的 completablefuture 的 result 是上个任务的结果。\n\npublic class futurewhentest {\n\n    public static void main(string[] args) throws executionexception, interruptedexception {\n\n        completablefuture<string> orgfuture = completablefuture.supplyasync(\n                ()->{\n                    system.out.println("当前线程名称：" + thread.currentthread().getname());\n                    try {\n                        thread.sleep(2000l);\n                    } catch (interruptedexception e) {\n                        e.printstacktrace();\n                    }\n                    return "捡田螺的小男孩";\n                }\n        );\n\n        completablefuture<string> rstfuture = orgfuture.whencomplete((a, throwable) -> {\n            system.out.println("当前线程名称：" + thread.currentthread().getname());\n            system.out.println("上个任务执行完啦，还把" + a + "传过来");\n            if ("捡田螺的小男孩".equals(a)) {\n                system.out.println("666");\n            }\n            system.out.println("233333");\n        });\n\n        system.out.println(rstfuture.get());\n    }\n}\n//输出\n当前线程名称：forkjoinpool.commonpool-worker-1\n当前线程名称：forkjoinpool.commonpool-worker-1\n上个任务执行完啦，还把捡田螺的小男孩传过来\n666\n233333\n捡田螺的小男孩\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n# 异常处理\n\n异步操作可能会失败，completablefuture 允许我们使用 exceptionally() 或 handle() 方法来处理异步操作的异常。\n\nhandle()\n\npublic <u> completablefuture<u> handle(\n    bifunction<? super t, throwable, ? extends u> fn) {\n    return unihandlestage(null, fn);\n}\n\npublic <u> completablefuture<u> handleasync(\n    bifunction<? super t, throwable, ? extends u> fn) {\n    return unihandlestage(defaultexecutor(), fn);\n}\n\npublic <u> completablefuture<u> handleasync(\n    bifunction<? super t, throwable, ? extends u> fn, executor executor) {\n    return unihandlestage(screenexecutor(executor), fn);\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n示例代码：\n\ncompletablefuture<string> future\n        = completablefuture.supplyasync(() -> {\n    if (true) {\n        throw new runtimeexception("computation error!");\n    }\n    return "hello!";\n}).handle((res, ex) -> {\n    // res 代表返回的结果\n    // ex 的类型为 throwable ，代表抛出的异常\n    return res != null ? res : "world!";\n});\nassertequals("world!", future.get());\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nexceptionally()\n\ncompletablefuture<string> future\n        = completablefuture.supplyasync(() -> {\n    if (true) {\n        throw new runtimeexception("computation error!");\n    }\n    return "hello!";\n}).exceptionally(ex -> {\n    system.out.println(ex.tostring());// completionexception\n    return "world!";\n});\nassertequals("world!", future.get());\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n设置 completablefuture 的结果就是异常\n\n可以使用 completeexceptionally() 方法为其赋值。\n\ncompletablefuture<string> completablefuture = new completablefuture<>();\n// ...\ncompletablefuture.completeexceptionally(\n  new runtimeexception("calculation failed!"));\n// ...\ncompletablefuture.get(); // executionexception\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 多个任务组合处理\n\n# and 组合关系\n\nthencombine / thenacceptboth / runafterboth 都表示：将两个 completablefuture 组合起来，只有这两个都正常执行完了，才会执行某个任务。\n\n区别在于：\n\n * thencombine：会将两个任务的执行结果作为方法入参，传递到指定方法中，且有返回值\n * thenacceptboth: 会将两个任务的执行结果作为方法入参，传递到指定方法中，且无返回值\n * runafterboth 不会把执行结果当做方法入参，且没有返回值。\n\n代码示例：\n\npublic class thencombinetest {\n\n    public static void main(string[] args) throws interruptedexception, executionexception, timeoutexception {\n\n        completablefuture<string> first = completablefuture.completedfuture("第一个异步任务");\n        executorservice executor = executors.newfixedthreadpool(10);\n        completablefuture<string> future = completablefuture\n                //第二个异步任务\n                .supplyasync(() -> "第二个异步任务", executor)\n                // (w, s) -> system.out.println(s) 是第三个任务\n                .thencombineasync(first, (s, w) -> {\n                    system.out.println(w);\n                    system.out.println(s);\n                    return "两个异步任务的组合";\n                }, executor);\n        system.out.println(future.join());\n        executor.shutdown();\n\n    }\n}\n//输出\n第一个异步任务\n第二个异步任务\n两个异步任务的组合\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n# allof 全部执行完\n\n所有任务都执行完成后，才执行 allof 返回的 completablefuture。如果任意一个任务异常，allof 的 completablefuture，执行 get 方法，会抛出异常。\n\npublic class alloffuturetest {\n    public static void main(string[] args) throws executionexception, interruptedexception {\n\n        completablefuture<void> a = completablefuture.runasync(()->{\n            system.out.println("我执行完了");\n        });\n        completablefuture<void> b = completablefuture.runasync(() -> {\n            system.out.println("我也执行完了");\n        });\n        completablefuture<void> alloffuture = completablefuture.allof(a, b).whencomplete((m,k)->{\n            system.out.println("finish");\n        });\n    }\n}\n//输出\n我执行完了\n我也执行完了\nfinish\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n# anyof 任一执行完\n\n任意一个任务执行完，就执行 anyof 返回的 completablefuture。如果执行的任务异常，anyof 的 completablefuture，执行 get 方法，会抛出异常。\n\npublic class anyoffuturetest {\n    public static void main(string[] args) throws executionexception, interruptedexception {\n\n        completablefuture<void> a = completablefuture.runasync(()->{\n            try {\n                thread.sleep(3000l);\n            } catch (interruptedexception e) {\n                e.printstacktrace();\n            }\n            system.out.println("我执行完了");\n        });\n        completablefuture<void> b = completablefuture.runasync(() -> {\n            system.out.println("我也执行完了");\n        });\n        completablefuture<object> anyoffuture = completablefuture.anyof(a, b).whencomplete((m,k)->{\n            system.out.println("finish");\n        });\n        anyoffuture.join(); // 等待任意一个给定的 completablefuture 完成\n    }\n}\n// 输出\n我也执行完了\nfinish\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\njoin() 的含义是：等待一个异步操作（也就是 completablefuture）完成并获取其结果。\n\n具体来说，join 方法会阻塞当前线程，直到相应的 completablefuture 完成，并返回其计算结果（或异常）。如果在调用 join 时异步操作还未完成，那么当前线程将一直阻塞等待，直到操作完成或者抛出异常。\n\n\n# 参考\n\n * 异步编程利器：completablefuture详解 ｜java 开发实战 - 掘金 (juejin.cn)\n * completablefuture 详解 | javaguide(java面试 + 学习指南)',charsets:{cjk:!0}},{title:"k8s之Deployment",frontmatter:{tags:["k8s","容器","云原生"],author:{name:"msqfx",link:"https://github.com/msqfx"},title:"k8s之Deployment",date:"2022-08-29T16:27:11.000Z",permalink:"/pages/d73c88/",description:"介绍k8s中的deployment资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220820143105.png"},{name:"twitter:title",content:"k8s之Deployment"},{name:"twitter:description",content:"介绍k8s中的deployment资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220820143105.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/04.k8s%E4%B9%8Bdeployment.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之Deployment"},{property:"og:description",content:"介绍k8s中的deployment资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220820143105.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/04.k8s%E4%B9%8Bdeployment.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-29T16:27:11.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之Deployment"},{itemprop:"description",content:"介绍k8s中的deployment资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220820143105.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/04.k8s%E4%B9%8Bdeployment.html",relativePath:"01.云原生/07.k8s/04.k8s之deployment.md",key:"v-74234f32",path:"/pages/d73c88/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"使用yaml描述Deployment",slug:"使用yaml描述deployment",normalizedTitle:"使用yaml描述deployment",charIndex:86},{level:2,title:"查看Deployment",slug:"查看deployment",normalizedTitle:"查看deployment",charIndex:730},{level:2,title:"ReplicaSet",slug:"replicaset",normalizedTitle:"replicaset",charIndex:1679},{level:2,title:"水平扩缩容",slug:"水平扩缩容",normalizedTitle:"水平扩缩容",charIndex:3501},{level:2,title:"滚动更新",slug:"滚动更新",normalizedTitle:"滚动更新",charIndex:4473}],headersStr:"简介 使用yaml描述Deployment 查看Deployment ReplicaSet 水平扩缩容 滚动更新",content:'# 简介\n\nDeployment是k8s用来管理部署无状态Pod的控制器。\n\n适用场景\n\n无状态应用，所有的pod无依赖关系，无指定节点运行、无特殊处理的方式部署\n\n\n# 使用yaml描述Deployment\n\n使用下面的yaml文件用来创建nginx的Deployment对象\n\nreplicas是用来定义创建pod的数量。template中的是所管理的Pod模板，Deployment就是根据该字段来创建pod资源对象。selector是用来筛选需要管理的pod对象，template下的labels的值需要与selector的值需要保持一致，这样Deployment才能找到需要控制的Pod。\n\n更多的字段说明可以看官网\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n  \nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ngx-dep\n      \n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: nginx:alpine\n        name: nginx\n        ports:\n        - containerPort: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 查看Deployment\n\n我们有了yaml来描述deployment之后，就可以使用kubectl apply来创建Deployment对象。\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments.yaml  -n zwf\ndeployment.apps/ngx-dep created\n\n\n1\n2\n\n\n我也也可以使用kubectl get来查看我们创建的deplotment对象的信息\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   2/2     2            2           19m\n\n\n1\n2\n3\n\n\n信息：\n\n * READY，就绪个数/期望个数\n * UP-TO-DATE，当前处于最新版本的pod数\n * AVAILABLE，当前可用的Pod数，也就是已经经过ready之后的Pod\n * age，存活时间\n\n我们将其中一个pod删除了，会发现不就后pod还会自动创建，因为k8s会根据yaml中replicas的值，让deployment的实际状态不断的向期望状态逼近，最终达到一个应用"永不宕机"\n\n[root@k8s-worker1 zwf]# kubectl delete pods ngx-dep-69b9455bcf-cfwgd -n zwf\npod "ngx-dep-69b9455bcf-cfwgd" deleted\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME                       READY   STATUS    RESTARTS   AGE\nngx-dep-69b9455bcf-ddjml   1/1     Running   0          13m\nngx-dep-69b9455bcf-fn6gw   1/1     Running   0          5s\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# ReplicaSet\n\nDeployment并不是直接管理Pod，而是通过ReplicaSet对象间接管理的，也就是说真正管理pod的其实是replicaSet对象.\n\n我们使用kubectl get rs可以查看到ReplicaSet对象，该对象是在创建Deployment时创建的，查看一下ReplicaSet对象的信息，其中的DESIRED和CURRENT对应在和Deployment的READY，READY和Deployment中的是一样的。\n\n[root@k8s-worker1 zwf]# kubectl get rs -n zwf\nNAME                 DESIRED   CURRENT   READY   AGE\nngx-dep-69b9455bcf   2         2         2       43s\n\n\n1\n2\n3\n\n\n通过kubectl describe查看deploment的详情，可以看到NewReplicaSet的值指向的是ReplicaSet对象，并间接管理Pod。\n\n[root@k8s-worker1 zwf]# kubectl describe deploy ngx-dep -n zwf \nName:                   ngx-dep\nNamespace:              zwf\nCreationTimestamp:      Tue, 30 Aug 2022 11:27:14 +0800\nLabels:                 app=ngx-dep\nAnnotations:            deployment.kubernetes.io/revision: 1\nSelector:               app=ngx-dep\nReplicas:               2 desired | 2 updated | 2 total | 2 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=ngx-dep\n  Containers:\n   nginx:\n    Image:        mirrors.sangfor.com/nginx:alpine\n    Port:         80/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Progressing    True    NewReplicaSetAvailable\n  Available      True    MinimumReplicasAvailable\nOldReplicaSets:  <none>\nNewReplicaSet:   ngx-dep-69b9455bcf (2/2 replicas created)\nEvents:\n  Type    Reason             Age   From                   Message\n  ----    ------             ----  ----                   -------\n  Normal  ScalingReplicaSet  13m   deployment-controller  Scaled up replica set ngx-dep-69b9455bcf to 2\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 水平扩缩容\n\n水平扩缩容是可以动态的改变Pod的数量，在高峰期可以扩大应用的数量提高并发，在低峰期缩减Pod减少资源的使用。\n\n我们使用kubectl scale动态改变Deployment的副本数，查看Deployment对象可以看到READY从2/4到4/4，并且AVALIABLE的值也是逐渐的从2到4\n\n[root@k8s-worker1 zwf]# kubectl scale deploy ngx-dep -n zwf --replicas=4\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   2/4     4            2           18m\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   3/4     4            3           18m\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   4/4     4            4           18m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n我们再看看ReplicaSet对象，可以看到当前正在运行Pod数量也发生了改变。因为水平扩缩容的实质是deplotment去修改ReplicaSet的Pod副本的数量。\n\n[root@k8s-worker1 zwf]# kubectl get replicaset  -n zwf\nNAME                 DESIRED   CURRENT   READY   AGE\nngx-dep-69b9455bcf   4         4         4       50m\n\n\n1\n2\n3\n\n\n\n\n\n# 滚动更新\n\n在更新的过程，是逐渐将旧的ReplicaSet所管理的Pod删除，新的ReplicaSet管理的Pod新增这么一个过程。\n\n我们修改Deployment的yaml文件，将containers的name修改为nginx2\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n  \nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ngx-dep\n      \n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: nginx:alpine\n        name: nginx2   # 修改\n        ports:\n        - containerPort: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再使用kubectl apply执行，更新Deployment，可以看到，UP-TO-DATE是逐渐的从1到2，旧的pod会逐渐的更新成最新的pod.\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments.yaml -n zwf\ndeployment.apps/ngx-dep configured\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   2/2     1            2           55m\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   2/2     2            2           55m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n我们再看下ReplicaSet对象，可以看到有两个对象。这是因为我们更新了Deployment中的pod template模板，也就是会更新pod，我们知道Deployment是通过ReplicaSet来管理对象的，所以会创建一个新版本的ReplicaSet对象用来创建新版本的Pod并逐渐增加，然后逐渐将旧版本的ReplicaSet对象管理的pod删除直至为0。\n\n[root@k8s-worker1 zwf]# kubectl get rs -n zwf\nNAME                 DESIRED   CURRENT   READY   AGE\nngx-dep-54d65f4d8c   2         2         2       2m54s\nngx-dep-69b9455bcf   0         0         0       58m\n\n\n1\n2\n3\n4\n\n\n我们再看Deployment的详情，Events字段是代表着Deployment中发生的事件，可以看到ngx-dep-69b9455bcf所管理的pod逐渐减少，而ngx-dep-69b9455bcf在逐渐增加pod的数量。这也就解释了上面为什么有两个ReplicaSet对象，因为一个是新对象，一个是旧对象，在更新Deployment时，都会保留下来。\n\n[root@k8s-worker1 zwf]# kubectl describe deploy ngx-dep -n zwf\nName:                   ngx-dep\nNamespace:              zwf\nCreationTimestamp:      Tue, 30 Aug 2022 11:27:14 +0800\nLabels:                 app=ngx-dep\nAnnotations:            deployment.kubernetes.io/revision: 2\nSelector:               app=ngx-dep\nReplicas:               2 desired | 2 updated | 2 total | 2 available | 0 unavailable\nStrategyType:           RollingUpdate\nMinReadySeconds:        0\nRollingUpdateStrategy:  25% max unavailable, 25% max surge\nPod Template:\n  Labels:  app=ngx-dep\n  Containers:\n   nginx2:\n    Image:        mirrors.sangfor.com/nginx:alpine\n    Port:         80/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  <none>\nNewReplicaSet:   ngx-dep-54d65f4d8c (2/2 replicas created)\nEvents:\n  Type    Reason             Age                  From                   Message\n  ----    ------             ----                 ----                   -------\n  Normal  ScalingReplicaSet  5m                   deployment-controller  Scaled up replica set ngx-dep-54d65f4d8c to 1\n  Normal  ScalingReplicaSet  4m58s                deployment-controller  Scaled down replica set ngx-dep-69b9455bcf to 1\n  Normal  ScalingReplicaSet  4m58s                deployment-controller  Scaled up replica set ngx-dep-54d65f4d8c to 2\n  Normal  ScalingReplicaSet  4m54s                deployment-controller  Scaled down replica set ngx-dep-69b9455bcf to 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n',normalizedContent:'# 简介\n\ndeployment是k8s用来管理部署无状态pod的控制器。\n\n适用场景\n\n无状态应用，所有的pod无依赖关系，无指定节点运行、无特殊处理的方式部署\n\n\n# 使用yaml描述deployment\n\n使用下面的yaml文件用来创建nginx的deployment对象\n\nreplicas是用来定义创建pod的数量。template中的是所管理的pod模板，deployment就是根据该字段来创建pod资源对象。selector是用来筛选需要管理的pod对象，template下的labels的值需要与selector的值需要保持一致，这样deployment才能找到需要控制的pod。\n\n更多的字段说明可以看官网\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n  \nspec:\n  replicas: 2\n  selector:\n    matchlabels:\n      app: ngx-dep\n      \n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: nginx:alpine\n        name: nginx\n        ports:\n        - containerport: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 查看deployment\n\n我们有了yaml来描述deployment之后，就可以使用kubectl apply来创建deployment对象。\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments.yaml  -n zwf\ndeployment.apps/ngx-dep created\n\n\n1\n2\n\n\n我也也可以使用kubectl get来查看我们创建的deplotment对象的信息\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nname      ready   up-to-date   available   age\nngx-dep   2/2     2            2           19m\n\n\n1\n2\n3\n\n\n信息：\n\n * ready，就绪个数/期望个数\n * up-to-date，当前处于最新版本的pod数\n * available，当前可用的pod数，也就是已经经过ready之后的pod\n * age，存活时间\n\n我们将其中一个pod删除了，会发现不就后pod还会自动创建，因为k8s会根据yaml中replicas的值，让deployment的实际状态不断的向期望状态逼近，最终达到一个应用"永不宕机"\n\n[root@k8s-worker1 zwf]# kubectl delete pods ngx-dep-69b9455bcf-cfwgd -n zwf\npod "ngx-dep-69b9455bcf-cfwgd" deleted\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname                       ready   status    restarts   age\nngx-dep-69b9455bcf-ddjml   1/1     running   0          13m\nngx-dep-69b9455bcf-fn6gw   1/1     running   0          5s\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# replicaset\n\ndeployment并不是直接管理pod，而是通过replicaset对象间接管理的，也就是说真正管理pod的其实是replicaset对象.\n\n我们使用kubectl get rs可以查看到replicaset对象，该对象是在创建deployment时创建的，查看一下replicaset对象的信息，其中的desired和current对应在和deployment的ready，ready和deployment中的是一样的。\n\n[root@k8s-worker1 zwf]# kubectl get rs -n zwf\nname                 desired   current   ready   age\nngx-dep-69b9455bcf   2         2         2       43s\n\n\n1\n2\n3\n\n\n通过kubectl describe查看deploment的详情，可以看到newreplicaset的值指向的是replicaset对象，并间接管理pod。\n\n[root@k8s-worker1 zwf]# kubectl describe deploy ngx-dep -n zwf \nname:                   ngx-dep\nnamespace:              zwf\ncreationtimestamp:      tue, 30 aug 2022 11:27:14 +0800\nlabels:                 app=ngx-dep\nannotations:            deployment.kubernetes.io/revision: 1\nselector:               app=ngx-dep\nreplicas:               2 desired | 2 updated | 2 total | 2 available | 0 unavailable\nstrategytype:           rollingupdate\nminreadyseconds:        0\nrollingupdatestrategy:  25% max unavailable, 25% max surge\npod template:\n  labels:  app=ngx-dep\n  containers:\n   nginx:\n    image:        mirrors.sangfor.com/nginx:alpine\n    port:         80/tcp\n    host port:    0/tcp\n    environment:  <none>\n    mounts:       <none>\n  volumes:        <none>\nconditions:\n  type           status  reason\n  ----           ------  ------\n  progressing    true    newreplicasetavailable\n  available      true    minimumreplicasavailable\noldreplicasets:  <none>\nnewreplicaset:   ngx-dep-69b9455bcf (2/2 replicas created)\nevents:\n  type    reason             age   from                   message\n  ----    ------             ----  ----                   -------\n  normal  scalingreplicaset  13m   deployment-controller  scaled up replica set ngx-dep-69b9455bcf to 2\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 水平扩缩容\n\n水平扩缩容是可以动态的改变pod的数量，在高峰期可以扩大应用的数量提高并发，在低峰期缩减pod减少资源的使用。\n\n我们使用kubectl scale动态改变deployment的副本数，查看deployment对象可以看到ready从2/4到4/4，并且avaliable的值也是逐渐的从2到4\n\n[root@k8s-worker1 zwf]# kubectl scale deploy ngx-dep -n zwf --replicas=4\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nname      ready   up-to-date   available   age\nngx-dep   2/4     4            2           18m\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nname      ready   up-to-date   available   age\nngx-dep   3/4     4            3           18m\n\n[root@k8s-worker1 zwf]# kubectl get deployment -n zwf\nname      ready   up-to-date   available   age\nngx-dep   4/4     4            4           18m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n我们再看看replicaset对象，可以看到当前正在运行pod数量也发生了改变。因为水平扩缩容的实质是deplotment去修改replicaset的pod副本的数量。\n\n[root@k8s-worker1 zwf]# kubectl get replicaset  -n zwf\nname                 desired   current   ready   age\nngx-dep-69b9455bcf   4         4         4       50m\n\n\n1\n2\n3\n\n\n\n\n\n# 滚动更新\n\n在更新的过程，是逐渐将旧的replicaset所管理的pod删除，新的replicaset管理的pod新增这么一个过程。\n\n我们修改deployment的yaml文件，将containers的name修改为nginx2\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n  \nspec:\n  replicas: 2\n  selector:\n    matchlabels:\n      app: ngx-dep\n      \n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: nginx:alpine\n        name: nginx2   # 修改\n        ports:\n        - containerport: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再使用kubectl apply执行，更新deployment，可以看到，up-to-date是逐渐的从1到2，旧的pod会逐渐的更新成最新的pod.\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments.yaml -n zwf\ndeployment.apps/ngx-dep configured\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nname      ready   up-to-date   available   age\nngx-dep   2/2     1            2           55m\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nname      ready   up-to-date   available   age\nngx-dep   2/2     2            2           55m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n我们再看下replicaset对象，可以看到有两个对象。这是因为我们更新了deployment中的pod template模板，也就是会更新pod，我们知道deployment是通过replicaset来管理对象的，所以会创建一个新版本的replicaset对象用来创建新版本的pod并逐渐增加，然后逐渐将旧版本的replicaset对象管理的pod删除直至为0。\n\n[root@k8s-worker1 zwf]# kubectl get rs -n zwf\nname                 desired   current   ready   age\nngx-dep-54d65f4d8c   2         2         2       2m54s\nngx-dep-69b9455bcf   0         0         0       58m\n\n\n1\n2\n3\n4\n\n\n我们再看deployment的详情，events字段是代表着deployment中发生的事件，可以看到ngx-dep-69b9455bcf所管理的pod逐渐减少，而ngx-dep-69b9455bcf在逐渐增加pod的数量。这也就解释了上面为什么有两个replicaset对象，因为一个是新对象，一个是旧对象，在更新deployment时，都会保留下来。\n\n[root@k8s-worker1 zwf]# kubectl describe deploy ngx-dep -n zwf\nname:                   ngx-dep\nnamespace:              zwf\ncreationtimestamp:      tue, 30 aug 2022 11:27:14 +0800\nlabels:                 app=ngx-dep\nannotations:            deployment.kubernetes.io/revision: 2\nselector:               app=ngx-dep\nreplicas:               2 desired | 2 updated | 2 total | 2 available | 0 unavailable\nstrategytype:           rollingupdate\nminreadyseconds:        0\nrollingupdatestrategy:  25% max unavailable, 25% max surge\npod template:\n  labels:  app=ngx-dep\n  containers:\n   nginx2:\n    image:        mirrors.sangfor.com/nginx:alpine\n    port:         80/tcp\n    host port:    0/tcp\n    environment:  <none>\n    mounts:       <none>\n  volumes:        <none>\nconditions:\n  type           status  reason\n  ----           ------  ------\n  available      true    minimumreplicasavailable\n  progressing    true    newreplicasetavailable\noldreplicasets:  <none>\nnewreplicaset:   ngx-dep-54d65f4d8c (2/2 replicas created)\nevents:\n  type    reason             age                  from                   message\n  ----    ------             ----                 ----                   -------\n  normal  scalingreplicaset  5m                   deployment-controller  scaled up replica set ngx-dep-54d65f4d8c to 1\n  normal  scalingreplicaset  4m58s                deployment-controller  scaled down replica set ngx-dep-69b9455bcf to 1\n  normal  scalingreplicaset  4m58s                deployment-controller  scaled up replica set ngx-dep-54d65f4d8c to 2\n  normal  scalingreplicaset  4m54s                deployment-controller  scaled down replica set ngx-dep-69b9455bcf to 0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之Service",frontmatter:{tags:["k8s","容器","云原生"],author:{name:"msqfx",link:"https://github.com/msqfx"},title:"k8s之Service",date:"2022-08-30T16:59:37.000Z",permalink:"/pages/1f860b/",description:"介绍k8s中的service资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220808185926.png"},{name:"twitter:title",content:"k8s之Service"},{name:"twitter:description",content:"介绍k8s中的service资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220808185926.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/05.k8s%E4%B9%8Bservice.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之Service"},{property:"og:description",content:"介绍k8s中的service资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220808185926.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/05.k8s%E4%B9%8Bservice.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-30T16:59:37.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之Service"},{itemprop:"description",content:"介绍k8s中的service资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220808185926.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/05.k8s%E4%B9%8Bservice.html",relativePath:"01.云原生/07.k8s/05.k8s之service.md",key:"v-0fd7c93e",path:"/pages/1f860b/",headers:[{level:2,title:"什么是service？",slug:"什么是service",normalizedTitle:"什么是service？",charIndex:2},{level:2,title:"使用ClusterIP Service",slug:"使用clusterip-service",normalizedTitle:"使用clusterip service",charIndex:372},{level:2,title:"使用NodePort Service",slug:"使用nodeport-service",normalizedTitle:"使用nodeport service",charIndex:5163},{level:2,title:"如何实现的代理？",slug:"如何实现的代理",normalizedTitle:"如何实现的代理？",charIndex:6453}],headersStr:"什么是service？ 使用ClusterIP Service 使用NodePort Service 如何实现的代理？",content:"# 什么是service？\n\n将运行在一组 Pods 上的应用程序公开为网络服务的抽象方法。\n\n为什么需要service?\n\n 1. pod的数量、IP都是动态变化的，service可以给该集合的Pod一个固定的IP，无论pod的集合如何改变，都可以通过service的固定IP来访问到应用。\n\n 2. 可以给pod集合提供负载均衡的功能。\n\nService类型\n\n * LoadBalance，使用云提供商的负载均衡器向外部暴露服务。\n * ExternalName，将服务映射到指定的域名，这个域名可以集群内部也可以是外部的。\n * NodePort，提供的服务既可对外部服务通过NodeIp:NodePort访问，也可以对集群内部通过ClusterIp访问\n * ClusterIP，service提供的访问IP仅在集群内部可达\n\n\n# 使用ClusterIP Service\n\n我们定义service如下，其中selector是用来筛选需要代理的pod，targetPort是目标pod的端口，port是指该service的端口。\n\nkind: Service \napiVersion: v1 \nmetadata: \n  name: demoapp-svc \nspec: \n  selector: \n    app: demoapp \n  ports: \n  - name: http \n    protocol: TCP    \n    port: 80\n    targetPort: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n使用上面定义的yaml创建service对象，并可以看到SELECTOR的值是app=demoapp，我们需要创建带有该标签的pod，才能够进行代理。\n\n[root@k8s-worker1 zwf]# kubectl apply -f service.yaml -n zwf\nservice/demoapp-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf -o wide\nNAME          TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR\ndemoapp-svc   ClusterIP   10.0.0.74    <none>        80/TCP    18s   app=demoapp\n\n\n1\n2\n3\n4\n5\n6\n\n\n定义deployment，会创建带有app=demoapp的Pod\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: demoapp\n  name: demo-deploy\n\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: demoapp\n\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/ikubernetes/demoapp:v1.0\n        name: demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建Deployment对象，并且可以看到创建了2个Pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_service.yaml -n zwf\ndeployment.apps/demo-deploy created\n\n[root@k8s-worker1 zwf]# kubectl get deploy -o wide -n zwf\nNAME          READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS   IMAGES                                         SELECTOR\ndemo-deploy   2/2     2            2           2m37s   demoapp      mirrors.sangfor.com/ikubernetes/demoapp:v1.0   app=demoapp\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n查看pod的详情，可以看到Labels有一个app=demoapp的标签\n\n[root@k8s-worker1 zwf]# kubectl get pods -o wide -n zwf\nNAME                           READY   STATUS    RESTARTS   AGE   IP               NODE          NOMINATED NODE   READINESS GATES\ndemo-deploy-6c6d588789-h9gmd   1/1     Running   0          32s   10.222.126.1     k8s-worker2   <none>           <none>\ndemo-deploy-6c6d588789-nhzhl   1/1     Running   0          32s   10.222.194.104   k8s-worker1   <none>           <none>\n\n[root@k8s-worker1 zwf]# kubectl describe demo-deploy-6c6d588789-h9gmd -n zwf\nName:         demo-deploy-6c6d588789-h9gmd\nNamespace:    zwf\nPriority:     0\nNode:         k8s-worker2/10.64.2.153\nStart Time:   Tue, 30 Aug 2022 19:23:22 +0800\nLabels:       app=demoapp\n              pod-template-hash=6c6d588789\n\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n通过查看service的详情，我们可以看到Endpoints的值是上面创建的两个Pod的IP。\n\n[root@k8s-worker1 zwf]# kubectl describe svc -n zwf\nName:              demoapp-svc\nNamespace:         zwf\nLabels:            <none>\nAnnotations:       <none>\nSelector:          app=demoapp\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.0.0.74\nIPs:               10.0.0.74\nPort:              http  80/TCP\nTargetPort:        80/TCP\nEndpoints:         10.222.126.1:80,10.222.194.104:80\nSession Affinity:  None\nEvents:            <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\nEndpoints也是一个资源对象，Service通过筛选标签到的Pod会添加到Endpints中保存\n\n[root@k8s-worker1 zwf]# kubectl get endpoints -n zwf\nNAME          ENDPOINTS                           AGE\ndemoapp-svc   10.222.126.1:80,10.222.194.104:80   15m\n\n\n1\n2\n3\n\n\n这个时候，我们访问service的80端口，会访问到轮询访问到这两个pod中，我们就可以通过访问service来访问pod集合。\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-nhzhl, ServerIP: 10.222.194.104!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-h9gmd, ServerIP: 10.222.126.1!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-nhzhl, ServerIP: 10.222.194.104!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-h9gmd, ServerIP: 10.222.126.1!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n除了通过ClusterIP访问，在集群中也能通过域名进行访问，访问方式：<serviceName>.<namespace>.svc.cluster.local\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- nslookup demoapp-svc.zwf.svc.cluster.local\nServer:         10.0.0.2\nAddress:        10.0.0.2#53\n\nName:   demoapp-svc.zwf.svc.cluster.local\nAddress: 10.0.0.74\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- curl demoapp-svc.zwf.svc.cluster.local\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.153, ServerName: demo-deploy-6c6d588789-h9gmd, ServerIP: 10.222.126.1!\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- curl demoapp-svc.zwf.svc.cluster.local\niKubernetes demoapp v1.0 !! ClientIP: 10.222.126.1, ServerName: demo-deploy-6c6d588789-nhzhl, ServerIP: 10.222.194.104!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 使用NodePort Service\n\n定义NodePort Service如下，和ClusterIP Service比较，新增type: NodePort代表该Service的类型是NodePort，然后nodePort是节点的端口，在每一台Node上都会创建这么一个端口给集群外调用。\n\nkind: Service\napiVersion: v1\nmetadata:\n  name: demoapp-nodeport-svc\nspec:\n  selector:\n    app: demoapp\n  ports:\n  - name: http\n    protocol: TCP\n    port: 80\n    targetPort: 80\n    nodePort: 31999\n  type: NodePort\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建该Service，可以看到TYPE是NodePort，PORT是80:31999代表着将80端口映射到节点的31999端口\n\n[root@k8s-worker1 zwf]# kubectl apply -f service_nodeport.yaml -n zwf\nservice/demoapp-nodeport-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf -o wide\nNAME                   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE   SELECTOR\ndemoapp-nodeport-svc   NodePort    10.0.0.144   <none>        80:31999/TCP   10s   app=demoapp\ndemoapp-svc            ClusterIP   10.0.0.74    <none>        80/TCP         47m   app=demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们可以在集群外通过节点的IP:31999端口一样可以访问Pod服务。\n\nC:\\Users\\User>curl 10.64.2.141:31999\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-nhzhl, ServerIP: 10.222.194.104!\n\nC:\\Users\\User>curl 10.64.2.141:31999\niKubernetes demoapp v1.0 !! ClientIP: 10.64.2.141, ServerName: demo-deploy-6c6d588789-h9gmd, ServerIP: 10.222.126.1!\n\n\n1\n2\n3\n4\n5\n\n\n\n# 如何实现的代理？\n\n每个Node都会有一个kube-proxy进程，该进程会监控Service的创建与EndPoints列表的添加与删除，配置iptables规则，当客户端请求Service的ClusterIP和端口时，会根据规则轮询转发到后端的Pod中。\n\n",normalizedContent:"# 什么是service？\n\n将运行在一组 pods 上的应用程序公开为网络服务的抽象方法。\n\n为什么需要service?\n\n 1. pod的数量、ip都是动态变化的，service可以给该集合的pod一个固定的ip，无论pod的集合如何改变，都可以通过service的固定ip来访问到应用。\n\n 2. 可以给pod集合提供负载均衡的功能。\n\nservice类型\n\n * loadbalance，使用云提供商的负载均衡器向外部暴露服务。\n * externalname，将服务映射到指定的域名，这个域名可以集群内部也可以是外部的。\n * nodeport，提供的服务既可对外部服务通过nodeip:nodeport访问，也可以对集群内部通过clusterip访问\n * clusterip，service提供的访问ip仅在集群内部可达\n\n\n# 使用clusterip service\n\n我们定义service如下，其中selector是用来筛选需要代理的pod，targetport是目标pod的端口，port是指该service的端口。\n\nkind: service \napiversion: v1 \nmetadata: \n  name: demoapp-svc \nspec: \n  selector: \n    app: demoapp \n  ports: \n  - name: http \n    protocol: tcp    \n    port: 80\n    targetport: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n使用上面定义的yaml创建service对象，并可以看到selector的值是app=demoapp，我们需要创建带有该标签的pod，才能够进行代理。\n\n[root@k8s-worker1 zwf]# kubectl apply -f service.yaml -n zwf\nservice/demoapp-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf -o wide\nname          type        cluster-ip   external-ip   port(s)   age   selector\ndemoapp-svc   clusterip   10.0.0.74    <none>        80/tcp    18s   app=demoapp\n\n\n1\n2\n3\n4\n5\n6\n\n\n定义deployment，会创建带有app=demoapp的pod\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: demoapp\n  name: demo-deploy\n\nspec:\n  replicas: 2\n  selector:\n    matchlabels:\n      app: demoapp\n\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/ikubernetes/demoapp:v1.0\n        name: demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建deployment对象，并且可以看到创建了2个pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_service.yaml -n zwf\ndeployment.apps/demo-deploy created\n\n[root@k8s-worker1 zwf]# kubectl get deploy -o wide -n zwf\nname          ready   up-to-date   available   age     containers   images                                         selector\ndemo-deploy   2/2     2            2           2m37s   demoapp      mirrors.sangfor.com/ikubernetes/demoapp:v1.0   app=demoapp\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n查看pod的详情，可以看到labels有一个app=demoapp的标签\n\n[root@k8s-worker1 zwf]# kubectl get pods -o wide -n zwf\nname                           ready   status    restarts   age   ip               node          nominated node   readiness gates\ndemo-deploy-6c6d588789-h9gmd   1/1     running   0          32s   10.222.126.1     k8s-worker2   <none>           <none>\ndemo-deploy-6c6d588789-nhzhl   1/1     running   0          32s   10.222.194.104   k8s-worker1   <none>           <none>\n\n[root@k8s-worker1 zwf]# kubectl describe demo-deploy-6c6d588789-h9gmd -n zwf\nname:         demo-deploy-6c6d588789-h9gmd\nnamespace:    zwf\npriority:     0\nnode:         k8s-worker2/10.64.2.153\nstart time:   tue, 30 aug 2022 19:23:22 +0800\nlabels:       app=demoapp\n              pod-template-hash=6c6d588789\n\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n通过查看service的详情，我们可以看到endpoints的值是上面创建的两个pod的ip。\n\n[root@k8s-worker1 zwf]# kubectl describe svc -n zwf\nname:              demoapp-svc\nnamespace:         zwf\nlabels:            <none>\nannotations:       <none>\nselector:          app=demoapp\ntype:              clusterip\nip family policy:  singlestack\nip families:       ipv4\nip:                10.0.0.74\nips:               10.0.0.74\nport:              http  80/tcp\ntargetport:        80/tcp\nendpoints:         10.222.126.1:80,10.222.194.104:80\nsession affinity:  none\nevents:            <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\nendpoints也是一个资源对象，service通过筛选标签到的pod会添加到endpints中保存\n\n[root@k8s-worker1 zwf]# kubectl get endpoints -n zwf\nname          endpoints                           age\ndemoapp-svc   10.222.126.1:80,10.222.194.104:80   15m\n\n\n1\n2\n3\n\n\n这个时候，我们访问service的80端口，会访问到轮询访问到这两个pod中，我们就可以通过访问service来访问pod集合。\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-nhzhl, serverip: 10.222.194.104!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-h9gmd, serverip: 10.222.126.1!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-nhzhl, serverip: 10.222.194.104!\n\n[root@k8s-worker1 zwf]# curl 10.0.0.74\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-h9gmd, serverip: 10.222.126.1!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n除了通过clusterip访问，在集群中也能通过域名进行访问，访问方式：<servicename>.<namespace>.svc.cluster.local\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- nslookup demoapp-svc.zwf.svc.cluster.local\nserver:         10.0.0.2\naddress:        10.0.0.2#53\n\nname:   demoapp-svc.zwf.svc.cluster.local\naddress: 10.0.0.74\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- curl demoapp-svc.zwf.svc.cluster.local\nikubernetes demoapp v1.0 !! clientip: 10.64.2.153, servername: demo-deploy-6c6d588789-h9gmd, serverip: 10.222.126.1!\n\n[root@k8s-worker1 zwf]# kubectl exec -it demo-deploy-6c6d588789-h9gmd -n zwf  -- curl demoapp-svc.zwf.svc.cluster.local\nikubernetes demoapp v1.0 !! clientip: 10.222.126.1, servername: demo-deploy-6c6d588789-nhzhl, serverip: 10.222.194.104!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 使用nodeport service\n\n定义nodeport service如下，和clusterip service比较，新增type: nodeport代表该service的类型是nodeport，然后nodeport是节点的端口，在每一台node上都会创建这么一个端口给集群外调用。\n\nkind: service\napiversion: v1\nmetadata:\n  name: demoapp-nodeport-svc\nspec:\n  selector:\n    app: demoapp\n  ports:\n  - name: http\n    protocol: tcp\n    port: 80\n    targetport: 80\n    nodeport: 31999\n  type: nodeport\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建该service，可以看到type是nodeport，port是80:31999代表着将80端口映射到节点的31999端口\n\n[root@k8s-worker1 zwf]# kubectl apply -f service_nodeport.yaml -n zwf\nservice/demoapp-nodeport-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf -o wide\nname                   type        cluster-ip   external-ip   port(s)        age   selector\ndemoapp-nodeport-svc   nodeport    10.0.0.144   <none>        80:31999/tcp   10s   app=demoapp\ndemoapp-svc            clusterip   10.0.0.74    <none>        80/tcp         47m   app=demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们可以在集群外通过节点的ip:31999端口一样可以访问pod服务。\n\nc:\\users\\user>curl 10.64.2.141:31999\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-nhzhl, serverip: 10.222.194.104!\n\nc:\\users\\user>curl 10.64.2.141:31999\nikubernetes demoapp v1.0 !! clientip: 10.64.2.141, servername: demo-deploy-6c6d588789-h9gmd, serverip: 10.222.126.1!\n\n\n1\n2\n3\n4\n5\n\n\n\n# 如何实现的代理？\n\n每个node都会有一个kube-proxy进程，该进程会监控service的创建与endpoints列表的添加与删除，配置iptables规则，当客户端请求service的clusterip和端口时，会根据规则轮询转发到后端的pod中。\n\n",charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之ConfigMap和Secret",frontmatter:{tags:["k8s","容器","云原生"],title:"k8s之ConfigMap和Secret",date:"2022-08-30T21:16:09.000Z",permalink:"/pages/ff8188/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍k8s中的configmap和secret资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"twitter:title",content:"k8s之ConfigMap和Secret"},{name:"twitter:description",content:"介绍k8s中的configmap和secret资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/06.k8s%E4%B9%8BConfigMap%E5%92%8CSecret.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之ConfigMap和Secret"},{property:"og:description",content:"介绍k8s中的configmap和secret资源对象，及其使用方法和案例"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/06.k8s%E4%B9%8BConfigMap%E5%92%8CSecret.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-30T21:16:09.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之ConfigMap和Secret"},{itemprop:"description",content:"介绍k8s中的configmap和secret资源对象，及其使用方法和案例"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/06.k8s%E4%B9%8BConfigMap%E5%92%8CSecret.html",relativePath:"01.云原生/07.k8s/06.k8s之ConfigMap和Secret.md",key:"v-064e6b52",path:"/pages/ff8188/",headers:[{level:2,title:"ConfigMap",slug:"configmap",normalizedTitle:"configmap",charIndex:2},{level:3,title:"什么是ConfigMap?",slug:"什么是configmap",normalizedTitle:"什么是configmap?",charIndex:16},{level:3,title:"创建ConifgMap",slug:"创建conifgmap",normalizedTitle:"创建conifgmap",charIndex:54},{level:2,title:"Secret",slug:"secret",normalizedTitle:"secret",charIndex:526},{level:3,title:"什么是Secret?",slug:"什么是secret",normalizedTitle:"什么是secret?",charIndex:537},{level:3,title:"创建Secret",slug:"创建secret",normalizedTitle:"创建secret",charIndex:650},{level:2,title:"如何使用ConfigMap/Secret",slug:"如何使用configmap-secret",normalizedTitle:"如何使用configmap/secret",charIndex:2439},{level:3,title:"注入环境变量",slug:"注入环境变量",normalizedTitle:"注入环境变量",charIndex:2544},{level:3,title:"注入配置文件",slug:"注入配置文件",normalizedTitle:"注入配置文件",charIndex:4200}],headersStr:"ConfigMap 什么是ConfigMap? 创建ConifgMap Secret 什么是Secret? 创建Secret 如何使用ConfigMap/Secret 注入环境变量 注入配置文件",content:'# ConfigMap\n\n\n# 什么是ConfigMap?\n\n用来存储应用所需要的明文配置数据的。\n\n\n# 创建ConifgMap\n\n使用yaml定义ConfigMap对象，在data字段中定义配置数据。\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: info\n\ndata:\n  count: \'10\'\n  debug: \'on\'\n  path: \'/etc/systemd\'\n  greeting: |\n    say hello to kubernetes.\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n使用定义的yaml文件创建ConfigMap对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f config.yaml  -n zwf\nconfigmap/info created\n\n[root@k8s-worker1 zwf]# kubectl get cm -n zwf\nNAME               DATA   AGE\ninfo               4      9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# Secret\n\n\n# 什么是Secret?\n\n和ConfigMap基本相同，差异在于存储的是密文的配置数据。\n\n具体的体现在于，使用kubectl describe时，ConfigMap可以看到配置信息，而Secret是看不到具体内容的。\n\n\n# 创建Secret\n\n使用yaml描述文件创建Secret对象，其中的数据必须得是base64编码的密文，否则会创建失败。\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: user\n\ndata:\n  name: cm9vdA==  # root\n  pwd: MTIzNDU2   # 123456\n  db: bXlzcWw=    # mysql\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n使用上面的yaml文件创建Secret对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f secret.yaml -n zwf\nsecret/user created\n\n[root@k8s-worker1 zwf]# kubectl get secret -n zwf\nNAME                                 TYPE                                  DATA   AGE\nuser                                 Opaque                                3      9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n通过查看Secret详情，会发现都是密文的，无法查看\n\n[root@k8s-worker1 zwf]# kubectl describe secret user -n zwf\nName:         user\nNamespace:    zwf\nLabels:       <none>\nAnnotations:  <none>\n\nType:  Opaque\n\nData\n====\ndb:    5 bytes\nname:  4 bytes\npwd:   6 bytes\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n但是还是可以通过自己通过base64解码来获取\n\n[root@k8s-worker1 zwf]# kubectl get secret user -n zwf -o json\n{\n    "apiVersion": "v1",\n    "data": {\n        "db": "bXlzcWw=",\n        "name": "cm9vdA==",\n        "pwd": "MTIzNDU2"\n    },\n    "kind": "Secret",\n    "metadata": {\n        "annotations": {\n            "kubectl.kubernetes.io/last-applied-configuration": "{\\"apiVersion\\":\\"v1\\",\\"data\\":{\\"db\\":\\"bXlzcWw=\\",\\"name\\":\\"cm9vdA==\\",\\"pwd\\":\\"MTIzNDU2\\"},\\"kind\\":\\"Secret\\",\\"metadata\\":{\\"annotations\\":{},\\"name\\":\\"user\\",\\"namespace\\":\\"zwf\\"}}\\n"\n        },\n        "creationTimestamp": "2022-08-31T01:43:30Z",\n        "name": "user",\n        "namespace": "zwf",\n        "resourceVersion": "17208325",\n        "uid": "c5082495-1b85-42ef-a202-596d65e2449c"\n    },\n    "type": "Opaque"\n}\n\n[root@k8s-worker1 zwf]#  kubectl get secret user -n zwf -o jsonpath="{.data.name}" | base64 --decode\nroot\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 如何使用ConfigMap/Secret\n\n使用的方式\n\n * 将配置以环境变量的方式注入到容器中，应用程序从环境变量中获取配置\n\n * 将配置以文件的方式放在容器的目录中，应用程序从文件中获取配置。\n\n\n# 注入环境变量\n\n定义Deployment的yaml文件，在containers下的env中使用configMapKeyRef来使用ConfigMap中的值作为环境变量。\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ngx-dep\n\n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/nginx:alpine\n        name: nginx2\n        ports:\n        - containerPort: 80\n        env:\n        - name: count\n          valueFrom:\n            configMapKeyRef:\n              name: info\n              key: count\n        - name: debug\n          valueFrom:\n            configMapKeyRef:\n              name: info\n              key: debug\n        - name: pwd\n          valueFrom:\n            secretKeyRef:\n              name: user\n              key: pwd\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n使用上面定义的yaml创建Deployment对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_cm.yaml -n zwf\ndeployment.apps/ngx-dep created\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nNAME      READY   UP-TO-DATE   AVAILABLE   AGE\nngx-dep   2/2     2            2           1h\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME                       READY   STATUS    RESTARTS   AGE\nngx-dep-6c659bcc45-nnkgz   1/1     Running   0          8s\nngx-dep-6c659bcc45-rgfxx   1/1     Running   0          6s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n进入到容器中，可以查看到我们设置debug、count、pwd的值\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-6c659bcc45-nnkgz -n zwf -- /bin/sh\n/ # echo $debug\non\n/ # echo $count\n10\n/ # echo $pwd\n123456\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 注入配置文件\n\n编写描述Deployment文件，在sepc下定义两个volume，然后在containers下进行使用volumeMounts字段进行挂载。\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: ngx-dep\n\n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/nginx:alpine\n        name: nginx2\n        ports:\n        - containerPort: 80\n      - volumeMounts：\n        - mountPath: /tmp/cm-items\n          name: cm-vol\n        - mountPath: /tmp/sec-items\n          name: sec-vol\n\n      volumes:\n      - name: cm-vol\n        configMap:\n          name: info\n\t  - name: sec-vol \n\t    secret: \n\t    secretName: user\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n创建该Deployment对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_cm_file.yaml -n zwf\ndeployment.apps/ngx-dep configured\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME                       READY   STATUS    RESTARTS   AGE\nngx-dep-798f6f6c4f-cg6lv   1/1     Running   0          9s\nngx-dep-798f6f6c4f-s8wws   1/1     Running   0          6s\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们可以看到在容器内部在tmp目录下创建了cm-items和sec-items目录\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/\ncm-items   sec-items\n\n\n1\n2\n\n\n再看到这两个目录下的文件，都是以ConfigMap和Secret中定义的key为文件名，value为文件中的内容\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/cm-items\ncount     debug     greeting  path\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- cat /tmp/cm-items/debug\non\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/sec-items\ndb    name  pwd\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- cat /tmp/sec-items/pwd\n123456\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n',normalizedContent:'# configmap\n\n\n# 什么是configmap?\n\n用来存储应用所需要的明文配置数据的。\n\n\n# 创建conifgmap\n\n使用yaml定义configmap对象，在data字段中定义配置数据。\n\napiversion: v1\nkind: configmap\nmetadata:\n  name: info\n\ndata:\n  count: \'10\'\n  debug: \'on\'\n  path: \'/etc/systemd\'\n  greeting: |\n    say hello to kubernetes.\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n使用定义的yaml文件创建configmap对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f config.yaml  -n zwf\nconfigmap/info created\n\n[root@k8s-worker1 zwf]# kubectl get cm -n zwf\nname               data   age\ninfo               4      9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# secret\n\n\n# 什么是secret?\n\n和configmap基本相同，差异在于存储的是密文的配置数据。\n\n具体的体现在于，使用kubectl describe时，configmap可以看到配置信息，而secret是看不到具体内容的。\n\n\n# 创建secret\n\n使用yaml描述文件创建secret对象，其中的数据必须得是base64编码的密文，否则会创建失败。\n\napiversion: v1\nkind: secret\nmetadata:\n  name: user\n\ndata:\n  name: cm9vda==  # root\n  pwd: mtizndu2   # 123456\n  db: bxlzcww=    # mysql\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n使用上面的yaml文件创建secret对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f secret.yaml -n zwf\nsecret/user created\n\n[root@k8s-worker1 zwf]# kubectl get secret -n zwf\nname                                 type                                  data   age\nuser                                 opaque                                3      9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n通过查看secret详情，会发现都是密文的，无法查看\n\n[root@k8s-worker1 zwf]# kubectl describe secret user -n zwf\nname:         user\nnamespace:    zwf\nlabels:       <none>\nannotations:  <none>\n\ntype:  opaque\n\ndata\n====\ndb:    5 bytes\nname:  4 bytes\npwd:   6 bytes\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n但是还是可以通过自己通过base64解码来获取\n\n[root@k8s-worker1 zwf]# kubectl get secret user -n zwf -o json\n{\n    "apiversion": "v1",\n    "data": {\n        "db": "bxlzcww=",\n        "name": "cm9vda==",\n        "pwd": "mtizndu2"\n    },\n    "kind": "secret",\n    "metadata": {\n        "annotations": {\n            "kubectl.kubernetes.io/last-applied-configuration": "{\\"apiversion\\":\\"v1\\",\\"data\\":{\\"db\\":\\"bxlzcww=\\",\\"name\\":\\"cm9vda==\\",\\"pwd\\":\\"mtizndu2\\"},\\"kind\\":\\"secret\\",\\"metadata\\":{\\"annotations\\":{},\\"name\\":\\"user\\",\\"namespace\\":\\"zwf\\"}}\\n"\n        },\n        "creationtimestamp": "2022-08-31t01:43:30z",\n        "name": "user",\n        "namespace": "zwf",\n        "resourceversion": "17208325",\n        "uid": "c5082495-1b85-42ef-a202-596d65e2449c"\n    },\n    "type": "opaque"\n}\n\n[root@k8s-worker1 zwf]#  kubectl get secret user -n zwf -o jsonpath="{.data.name}" | base64 --decode\nroot\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 如何使用configmap/secret\n\n使用的方式\n\n * 将配置以环境变量的方式注入到容器中，应用程序从环境变量中获取配置\n\n * 将配置以文件的方式放在容器的目录中，应用程序从文件中获取配置。\n\n\n# 注入环境变量\n\n定义deployment的yaml文件，在containers下的env中使用configmapkeyref来使用configmap中的值作为环境变量。\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n\nspec:\n  replicas: 2\n  selector:\n    matchlabels:\n      app: ngx-dep\n\n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/nginx:alpine\n        name: nginx2\n        ports:\n        - containerport: 80\n        env:\n        - name: count\n          valuefrom:\n            configmapkeyref:\n              name: info\n              key: count\n        - name: debug\n          valuefrom:\n            configmapkeyref:\n              name: info\n              key: debug\n        - name: pwd\n          valuefrom:\n            secretkeyref:\n              name: user\n              key: pwd\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n使用上面定义的yaml创建deployment对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_cm.yaml -n zwf\ndeployment.apps/ngx-dep created\n\n[root@k8s-worker1 zwf]# kubectl get deploy -n zwf\nname      ready   up-to-date   available   age\nngx-dep   2/2     2            2           1h\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname                       ready   status    restarts   age\nngx-dep-6c659bcc45-nnkgz   1/1     running   0          8s\nngx-dep-6c659bcc45-rgfxx   1/1     running   0          6s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n进入到容器中，可以查看到我们设置debug、count、pwd的值\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-6c659bcc45-nnkgz -n zwf -- /bin/sh\n/ # echo $debug\non\n/ # echo $count\n10\n/ # echo $pwd\n123456\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 注入配置文件\n\n编写描述deployment文件，在sepc下定义两个volume，然后在containers下进行使用volumemounts字段进行挂载。\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: ngx-dep\n  name: ngx-dep\n\nspec:\n  replicas: 2\n  selector:\n    matchlabels:\n      app: ngx-dep\n\n  template:\n    metadata:\n      labels:\n        app: ngx-dep\n    spec:\n      containers:\n      - image: mirrors.sangfor.com/nginx:alpine\n        name: nginx2\n        ports:\n        - containerport: 80\n      - volumemounts：\n        - mountpath: /tmp/cm-items\n          name: cm-vol\n        - mountpath: /tmp/sec-items\n          name: sec-vol\n\n      volumes:\n      - name: cm-vol\n        configmap:\n          name: info\n\t  - name: sec-vol \n\t    secret: \n\t    secretname: user\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n创建该deployment对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f deployments_cm_file.yaml -n zwf\ndeployment.apps/ngx-dep configured\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname                       ready   status    restarts   age\nngx-dep-798f6f6c4f-cg6lv   1/1     running   0          9s\nngx-dep-798f6f6c4f-s8wws   1/1     running   0          6s\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们可以看到在容器内部在tmp目录下创建了cm-items和sec-items目录\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/\ncm-items   sec-items\n\n\n1\n2\n\n\n再看到这两个目录下的文件，都是以configmap和secret中定义的key为文件名，value为文件中的内容\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/cm-items\ncount     debug     greeting  path\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- cat /tmp/cm-items/debug\non\n\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- ls /tmp/sec-items\ndb    name  pwd\n[root@k8s-worker1 zwf]# kubectl exec -it ngx-dep-798f6f6c4f-cg6lv -n zwf -- cat /tmp/sec-items/pwd\n123456\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之Job和CronJob",frontmatter:{tags:["k8s","容器","云原生"],title:"k8s之Job和CronJob",date:"2022-08-31T10:34:54.000Z",permalink:"/pages/c96905/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍k8s中的job资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220721102314.png"},{name:"twitter:title",content:"k8s之Job和CronJob"},{name:"twitter:description",content:"介绍k8s中的job资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220721102314.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/07.k8s%E4%B9%8BJob%E5%92%8CCronJob.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之Job和CronJob"},{property:"og:description",content:"介绍k8s中的job资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220721102314.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/07.k8s%E4%B9%8BJob%E5%92%8CCronJob.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-31T10:34:54.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之Job和CronJob"},{itemprop:"description",content:"介绍k8s中的job资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220721102314.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/07.k8s%E4%B9%8BJob%E5%92%8CCronJob.html",relativePath:"01.云原生/07.k8s/07.k8s之Job和CronJob.md",key:"v-86796282",path:"/pages/c96905/",headers:[{level:2,title:"Job",slug:"job",normalizedTitle:"job",charIndex:2},{level:3,title:"什么是Job?",slug:"什么是job",normalizedTitle:"什么是job?",charIndex:10},{level:3,title:"使用Job",slug:"使用job",normalizedTitle:"使用job",charIndex:46},{level:2,title:"CronJob",slug:"cronjob",normalizedTitle:"cronjob",charIndex:1082},{level:3,title:"什么是ConJob？",slug:"什么是conjob",normalizedTitle:"什么是conjob？",charIndex:1094},{level:3,title:"使用CronJob",slug:"使用cronjob",normalizedTitle:"使用cronjob",charIndex:1121}],headersStr:"Job 什么是Job? 使用Job CronJob 什么是ConJob？ 使用CronJob",content:'# Job\n\n\n# 什么是Job?\n\n该对象是用来执行运行一段时间后会退出的任务。\n\n\n# 使用Job\n\n使用yaml描述Job对象，其中restartPolicy是重启策略，需要设定为OnFailure，代表着如果失败则重启，如果是正常执行完成退出，则不需要再次启动。默认的值是Always，会保持着该Pod总是运行的。\n\ntemplate下的Pod模板，Job通过该模板来创建Pod。\n\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: echo-job\n\nspec:\n  template:\n    spec:\n      restartPolicy: OnFailure\n      containers:\n      - image: busybox\n        name: echo-job\n        command: ["/bin/echo"]\n        args: ["hello", "world"]\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\n使用yaml文件创建Job，然后查看job的pod对象，会发现它的STATUS状态为Completed，因为该job正常完成结束退出了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f job.yaml -n zwf\njob.batch/echo-job created\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME                       READY   STATUS      RESTARTS   AGE\necho-job-45pmc             0/1     Completed   0          5s\n\n\n1\n2\n3\n4\n5\n6\n\n\n再来看下该Completed的log，会发现已经输出了hello world\n\n[root@k8s-worker1 zwf]# kubectl logs echo-job-45pmc  -n zwf\nhello world\n\n\n1\n2\n\n\nJob的参数\n\n * activeDeadlineSeconds，设置 Pod 运行的超时时间。\n\n * backoffLimit，设置 Pod 的失败重试次数。\n\n为什么不直接在Pod上实现，而要新创建对象Job?\n\n保持单一原则，将业务特性与容器管理分开。\n\n\n# CronJob\n\n\n# 什么是ConJob？\n\n该对象用于定时任务。\n\n\n# 使用CronJob\n\n使用Yaml描述CronJob对象，会发现该对象多了一个schedule字段，这个是用来描述定时任务周期的规则，jobTemplate是Job对象的模板，也就是在定时周期内不断创建Job对象来达到定时任务的目的，也是一种组合的方式。\n\n\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: echo-cj\n\nspec:\n  schedule: \'*/1 * * * *\'\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          restartPolicy: OnFailure\n          containers:\n          - image: busybox\n            name: echo-cj\n            imagePullPolicy: IfNotPresent\n            command: ["/bin/echo"]\n            args: ["hello", "world"]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n\n\n使用定义的Yaml创建CronJob\n\n[root@k8s-worker1 zwf]# kubectl apply -f cronjob.yaml -n zwf\ncronjob.batch/echo-cj created\n\n[root@k8s-worker1 zwf]# kubectl get cronjob -n zwf\nNAME      SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE\necho-cj   */1 * * * *   False     1        1s              2m24s\n\n\n1\n2\n3\n4\n5\n6\n\n\n等待3分钟后，创建了3个CronJob的Pod，并且通过AGE可以发现是每分钟创建一个。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME                       READY   STATUS      RESTARTS   AGE\necho-cj-27698578-jtfxm     0/1     Completed   0          2m23s\necho-cj-27698579-cdzxg     0/1     Completed   0          83s\necho-cj-27698580-rfp72     0/1     Completed   0          23s\n\n\n1\n2\n3\n4\n5\n',normalizedContent:'# job\n\n\n# 什么是job?\n\n该对象是用来执行运行一段时间后会退出的任务。\n\n\n# 使用job\n\n使用yaml描述job对象，其中restartpolicy是重启策略，需要设定为onfailure，代表着如果失败则重启，如果是正常执行完成退出，则不需要再次启动。默认的值是always，会保持着该pod总是运行的。\n\ntemplate下的pod模板，job通过该模板来创建pod。\n\napiversion: batch/v1\nkind: job\nmetadata:\n  name: echo-job\n\nspec:\n  template:\n    spec:\n      restartpolicy: onfailure\n      containers:\n      - image: busybox\n        name: echo-job\n        command: ["/bin/echo"]\n        args: ["hello", "world"]\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n\n使用yaml文件创建job，然后查看job的pod对象，会发现它的status状态为completed，因为该job正常完成结束退出了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f job.yaml -n zwf\njob.batch/echo-job created\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname                       ready   status      restarts   age\necho-job-45pmc             0/1     completed   0          5s\n\n\n1\n2\n3\n4\n5\n6\n\n\n再来看下该completed的log，会发现已经输出了hello world\n\n[root@k8s-worker1 zwf]# kubectl logs echo-job-45pmc  -n zwf\nhello world\n\n\n1\n2\n\n\njob的参数\n\n * activedeadlineseconds，设置 pod 运行的超时时间。\n\n * backofflimit，设置 pod 的失败重试次数。\n\n为什么不直接在pod上实现，而要新创建对象job?\n\n保持单一原则，将业务特性与容器管理分开。\n\n\n# cronjob\n\n\n# 什么是conjob？\n\n该对象用于定时任务。\n\n\n# 使用cronjob\n\n使用yaml描述cronjob对象，会发现该对象多了一个schedule字段，这个是用来描述定时任务周期的规则，jobtemplate是job对象的模板，也就是在定时周期内不断创建job对象来达到定时任务的目的，也是一种组合的方式。\n\n\napiversion: batch/v1\nkind: cronjob\nmetadata:\n  name: echo-cj\n\nspec:\n  schedule: \'*/1 * * * *\'\n  jobtemplate:\n    spec:\n      template:\n        spec:\n          restartpolicy: onfailure\n          containers:\n          - image: busybox\n            name: echo-cj\n            imagepullpolicy: ifnotpresent\n            command: ["/bin/echo"]\n            args: ["hello", "world"]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n\n\n使用定义的yaml创建cronjob\n\n[root@k8s-worker1 zwf]# kubectl apply -f cronjob.yaml -n zwf\ncronjob.batch/echo-cj created\n\n[root@k8s-worker1 zwf]# kubectl get cronjob -n zwf\nname      schedule      suspend   active   last schedule   age\necho-cj   */1 * * * *   false     1        1s              2m24s\n\n\n1\n2\n3\n4\n5\n6\n\n\n等待3分钟后，创建了3个cronjob的pod，并且通过age可以发现是每分钟创建一个。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname                       ready   status      restarts   age\necho-cj-27698578-jtfxm     0/1     completed   0          2m23s\necho-cj-27698579-cdzxg     0/1     completed   0          83s\necho-cj-27698580-rfp72     0/1     completed   0          23s\n\n\n1\n2\n3\n4\n5\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"手动实现docker容器bridge网络模型",frontmatter:{title:"手动实现docker容器bridge网络模型",date:"2023-01-08T10:52:18.000Z",permalink:"/pages/d3768c/",tags:["docker","云原生","容器"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文主要是通过使用Network Namespace来模式docker的bridge模式来深入的理解其原理。",feed:{enable:!0},categories:["云原生","docker"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16731830378711673183036984.png"},{name:"twitter:title",content:"手动实现docker容器bridge网络模型"},{name:"twitter:description",content:"本文主要是通过使用Network Namespace来模式docker的bridge模式来深入的理解其原理。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16731830378711673183036984.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/03.%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0docker%E5%AE%B9%E5%99%A8bridge%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"手动实现docker容器bridge网络模型"},{property:"og:description",content:"本文主要是通过使用Network Namespace来模式docker的bridge模式来深入的理解其原理。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16731830378711673183036984.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/03.%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0docker%E5%AE%B9%E5%99%A8bridge%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-01-08T10:52:18.000Z"},{property:"article:tag",content:"docker"},{property:"article:tag",content:"云原生"},{property:"article:tag",content:"容器"},{itemprop:"name",content:"手动实现docker容器bridge网络模型"},{itemprop:"description",content:"本文主要是通过使用Network Namespace来模式docker的bridge模式来深入的理解其原理。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16731830378711673183036984.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/03.%E6%89%8B%E5%8A%A8%E5%AE%9E%E7%8E%B0docker%E5%AE%B9%E5%99%A8bridge%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B.html",relativePath:"01.云原生/06.docker/03.手动实现docker容器bridge网络模型.md",key:"v-1a0f65c8",path:"/pages/d3768c/",headers:[{level:2,title:"Network Namespace",slug:"network-namespace",normalizedTitle:"network namespace",charIndex:2},{level:2,title:"容器间网络互通",slug:"容器间网络互通",normalizedTitle:"容器间网络互通",charIndex:202},{level:3,title:"veth pair",slug:"veth-pair",normalizedTitle:"veth pair",charIndex:491},{level:3,title:"实践",slug:"实践",normalizedTitle:"实践",charIndex:635},{level:3,title:"测试",slug:"测试",normalizedTitle:"测试",charIndex:3971},{level:2,title:"宿主机访问容器",slug:"宿主机访问容器",normalizedTitle:"宿主机访问容器",charIndex:6151},{level:2,title:"容器内访问外部",slug:"容器内访问外部",normalizedTitle:"容器内访问外部",charIndex:7551},{level:2,title:"外部访问容器暴露的服务",slug:"外部访问容器暴露的服务",normalizedTitle:"外部访问容器暴露的服务",charIndex:10201}],headersStr:"Network Namespace 容器间网络互通 veth pair 实践 测试 宿主机访问容器 容器内访问外部 外部访问容器暴露的服务",content:"# Network Namespace\n\nNamespace 技术是容器虚拟化的重要技术，可以将进程隔离在自己的 Namespace 中。而 Network Namespace 技术是将进程隔离在自己的网络空间中，拥有独立的网络栈，仿佛自己处于独立的网络中。\n\n> 网络栈是指网卡、回环设备、路由表和 iptables 规则等等。网络栈是指网卡、回环设备、路由表和 iptables 规则等等。\n\n\n# 容器间网络互通\n\n容器的 bridge 网络模式会创建属于自己的 Network Namespace 来隔离自己与宿主机，拥有属于自己的网络栈。可以理解为不同的 Network Namespace 是不同的主机，那么它们想要网络通信，该如何实现？\n\n首先想到的当然是交换机和路由器了，因为它们是处于同一个网络中，所以使用交换机即可，而 Linux 提供了 bridge 来充当虚拟交换机的角色，将多个 Network Namespace 接入到 bridge 中，它们就能网络互通了。\n\n那么如何将容器的 Network Namespace 接入到 bridge 呢？\n\n\n# veth pair\n\nveth pair 是成对出现的虚拟网卡，可以把它看做成一个管道，或者一根网线，从一段输入的数据包会从另一端输出，可以通过它来连接容器的 Network Namespace 和 bridge。\n\n使用 veth pair + bridge 的网络模型如下：\n\n\n# 实践\n\n我们不用安装 docker，直接用 Network Namespace 来模拟容器的网络环境。\n\n 1. 创建 bridge 设备\n\n这里使用 ip 命令来对 bridge 进行操作，也可以使用 brctl 命令，该命令是在 bridge-utils 包中。\n\n[root@localhost ~]# ip link add br0 type bridge\n[root@localhost ~]# ip link set dev br0 up\n[root@localhost ~]# ip addr add 10.0.0.3/24 dev br0\n\n[root@localhost ~]# ip link\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n2: ens18: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP mode DEFAULT group default qlen 1000\n    link/ether fe:fc:fe:af:4b:ea brd ff:ff:ff:ff:ff:ff\n60: br0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000\n    link/ether 7e:b5:12:2d:fd:d4 brd ff:ff:ff:ff:ff:ff\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 2. 创建 3 个 Network Namespace\n\n使用 ip netns 命令可以对 Network Namesapce 进行操作，所以使用该命令创建 net0、net1 两个 Network Namespace\n\n[root@localhost ~]# ip netns add net0\n[root@localhost ~]# ip netns add net1\n\n\n1\n2\n\n 3. 创建两对 veth pair\n\n首先创建两对 veth pair 虚拟网卡，它们是一一对应的，veth0 和 veth1，veth2 和 veth3\n\n[root@localhost ~]# ip link add veth0 type veth peer name veth1\n[root@localhost ~]# ip link add veth2 type veth peer name veth3\n\n\n1\n2\n\n\n查看创建出来的 4 个虚拟网卡，@前面的是该网卡的名称，后面的是该网卡的另一端。\n\n[root@localhost ~]# ip a\n...\n67: veth1@veth0: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 7e:b5:12:2d:fd:d4 brd ff:ff:ff:ff:ff:ff\n68: veth0@veth1: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether 26:22:ef:1a:b3:33 brd ff:ff:ff:ff:ff:ff\n69: veth3@veth2: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether c6:f2:d1:2d:c7:95 brd ff:ff:ff:ff:ff:ff\n70: veth2@veth3: <BROADCAST,MULTICAST,M-DOWN> mtu 1500 qdisc noop state DOWN group default qlen 1000\n    link/ether ee:4b:0d:17:60:b1 brd ff:ff:ff:ff:ff:ff\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n 4. 将 veth pair 的一端接入到 Network Namespace 中，并设置好其 IP 地址\n\n[root@localhost ~]# ip link set dev veth0 netns net0\n[root@localhost ~]# ip netns exec net0 ip addr add 10.0.0.1/24 dev veth0\n[root@localhost ~]# ip netns exec net0 ip link set dev veth0 up\n\n\n[root@localhost ~]# ip link set dev veth2 netns net1\n[root@localhost ~]# ip netns exec net1 ip addr add 10.0.0.2/24 dev veth2\n[root@localhost ~]# ip netns exec net1 ip link set dev veth2 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n> ip netns exec 命令可以进入到指定的 Network Namespace 中执行命令\n\n 5. 将 veth pair 的另一端设置到 bridge 中\n\n[root@localhost ~]# ip link set dev veth1 master br0\n[root@localhost ~]# ip link set dev veth3 master br0\n\n[root@localhost ~]# ip link set dev veth1 up\n[root@localhost ~]# ip link set dev veth3 up\n\n\n1\n2\n3\n4\n5\n\n\n可以通过命令 bridge link 查看到 veth1、veth3都插入到 br0 中了。\n\n[root@localhost ~]# bridge link\n67: veth1 state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master br0 state forwarding priority 32 cost 2 \n69: veth3 state UP @(null): <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 master br0 state forwarding priority 32 cost 2\n\n\n1\n2\n3\n\n\n也可以通过 brctl 命令查看\n\n[root@localhost ~]# brctl show\n[root@localhost ~]# brctl show\nbridge name     bridge id               STP enabled     interfaces\nbr0             8000.7eb5122dfdd4       no              veth1\n                                                        veth3\n\n\n1\n2\n3\n4\n5\n\n\n\n# 测试\n\n 1. 首先监听 br0 网卡\n\n[root@localhost ~]# tcpdump -i br0\n\n\n1\n\n 2. 在 net0 中 ping net1 的 ip\n\nip netns exec net0 ping -c 3 10.0.0.2\n\n\n1\n\n 3. 会发现监听 br0 网卡是有流量的：\n\n[root@localhost ~]# tcpdump -i br0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type EN10MB (Ethernet), capture size 262144 bytes\n02:39:41.251428 ARP, Request who-has 10.0.0.2 tell 10.0.0.1, length 28\n02:39:41.251495 ARP, Reply 10.0.0.2 is-at ee:4b:0d:17:60:b1 (oui Unknown), length 28\n02:39:41.251502 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15665, seq 1, length 64\n02:39:41.251702 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15665, seq 1, length 64\n02:39:42.251435 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15665, seq 2, length 64\n02:39:42.251554 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15665, seq 2, length 64\n02:39:43.251414 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15665, seq 3, length 64\n02:39:43.251512 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15665, seq 3, length 64\n02:39:46.261377 ARP, Request who-has 10.0.0.1 tell 10.0.0.2, length 28\n02:39:46.261400 ARP, Reply 10.0.0.1 is-at 26:22:ef:1a:b3:33 (oui Unknown), length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到先是 10.0.0.1 发送的 ARP 获取 10.0.0.2 的 MAC 地址，然后再发送 ICMP 的请求和响应，最后 10.0.0.2 也发送 ARP 获取 10.0.0.1 的 MAC 地址。\n\n因为 bridge 是二层网络设备，所以它是需要通过识别 MAC 地址来进行通信的局域网。\n\n后面我又通过 net0 ping net1 的 ip，发现它没有发送 ARP 了，这个是因为第一次 bridge 已经将 MAC 地址和端口的映射关系已经记录了下来，后面可以直接通过查表，而不用再发送 ARP 了。\n\n[root@localhost ~]# tcpdump -i br0 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type EN10MB (Ethernet), capture size 262144 bytes\n02:40:01.267689 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15991, seq 1, length 64\n02:40:01.267948 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15991, seq 1, length 64\n02:40:02.267509 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15991, seq 2, length 64\n02:40:02.267641 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15991, seq 2, length 64\n02:40:03.267458 IP 10.0.0.1 > 10.0.0.2: ICMP echo request, id 15991, seq 3, length 64\n02:40:03.267582 IP 10.0.0.2 > 10.0.0.1: ICMP echo reply, id 15991, seq 3, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 宿主机访问容器\n\n 1. 再次监听 br0 网卡\n\ntcpdump -i br0\n\n\n1\n\n 2. 在宿主机上 ping 容器内部 ip，是可以 ping 通的\n\nping 10.0.0.1 -n 3\n\n\n1\n\n 3. 查看监听的 br0 网卡流量：\n\n[root@localhost ~]# tcpdump -i br0 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type EN10MB (Ethernet), capture size 262144 bytes\n02:56:03.232293 ARP, Request who-has 10.0.0.1 tell 10.0.0.3, length 28\n02:56:03.232342 ARP, Reply 10.0.0.1 is-at 26:22:ef:1a:b3:33, length 28\n02:56:03.232379 IP 10.0.0.3 > 10.0.0.1: ICMP echo request, id 3964, seq 1, length 64\n02:56:03.232402 IP 10.0.0.1 > 10.0.0.3: ICMP echo reply, id 3964, seq 1, length 64\n02:56:04.232494 IP 10.0.0.3 > 10.0.0.1: ICMP echo request, id 3964, seq 2, length 64\n02:56:04.232554 IP 10.0.0.1 > 10.0.0.3: ICMP echo reply, id 3964, seq 2, length 64\n02:56:05.232517 IP 10.0.0.3 > 10.0.0.1: ICMP echo request, id 3964, seq 3, length 64\n02:56:05.232607 IP 10.0.0.1 > 10.0.0.3: ICMP echo reply, id 3964, seq 3, length 64\n02:56:08.245354 ARP, Request who-has 10.0.0.3 tell 10.0.0.1, length 28\n02:56:08.245412 ARP, Reply 10.0.0.3 is-at 7e:b5:12:2d:fd:d4, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到是 10.0.0.3 访问通了 10.0.0.1 ，我们是通过宿主机访问的容器内部，为什么源 ip 变成 10.0.0.3？\n\n 4. 通过查看宿主机的路由表，可以看到当我们 ping 10.0.0.1 时，是匹配上了该条路由，然后走 br0 网卡，使用的源 ip 是 br0 的 ip 10.0.0.3\n\n[root@localhost ~]# ip r\n...\n10.0.0.0/24 dev br0 proto kernel scope link src 10.0.0.3 \n...\n\n\n1\n2\n3\n4\n\n\n\n# 容器内访问外部\n\n 1. 配置 Network Namespace 中将 bridge 作为默认网关\n\n当我们在 net0 内部访问外部 ip 时，会发现网络不可达。\n\n[root@localhost ~]# ip netns exec net0 ping 10.65.132.187\nconnect: Network is unreachable\n\n\n1\n2\n\n\n这个是因为没有匹配上路由表上的原因\n\n[root@localhost ~]# ip netns exec net0 ip r\n10.0.0.0/24 dev veth0 proto kernel scope link src 10.0.0.1\n\n\n1\n2\n\n\n我们加上默认网关，也就是在没有匹配上其他路由时，走该网关\n\n[root@localhost ~]# ip netns exec net0 ip r add default via 10.0.0.3 dev veth0\n\n[root@localhost ~]# ip netns exec net0 ip r \ndefault via 10.0.0.3 dev veth0 \n10.0.0.0/24 dev veth0 proto kernel scope link src 10.0.0.1 \n\n\n1\n2\n3\n4\n5\n\n 2. 配置宿主机 iptables 的 SNAT 规则\n\n我们再次在容器中访问外部 ip 时，发现网络还不可达，但是我们监听 br0 网卡发现是有数据包的，也就是路由配的没问题\n\n[root@localhost ~]# tcpdump -i br0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type EN10MB (Ethernet), capture size 262144 bytes\n03:23:23.738010 IP 10.0.0.1 > 10.65.132.187: ICMP echo request, id 11228, seq 1, length 64\n03:23:24.737415 IP 10.0.0.1 > 10.65.132.187: ICMP echo request, id 11228, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n我们再看宿主机上的路由，是有配置默认路由的。\n\n[root@localhost ~]# ip r\ndefault via 10.61.74.1 dev ens18 proto static metric 100\n\n\n1\n2\n\n\n所以我再监听一下宿主机的网卡 ens18 看看：\n\n[root@localhost ~]# tcpdump -i ens18 dst host 10.65.132.187\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n03:24:47.162152 IP 10.0.0.1 > 10.65.132.187: ICMP echo request, id 13281, seq 1, length 64\n03:24:48.161585 IP 10.0.0.1 > 10.65.132.187: ICMP echo request, id 13281, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n发现也是有数据包的，但是原地址是 net0 的 ip 地址 10.0.0.1，外部是不认识的，所以需要配置 iptables，将源 IP 改为宿主机的 IP。\n\n# 创建规则\n[root@localhost ~]# iptables -t nat -A POSTROUTING -s 10.0.0.0/24 ! -o br0 -j MASQUERADE\n\n# 查看规则\n[root@localhost ~]# iptables -L POSTROUTING -t nat\n...\nMASQUERADE  all  --  10.0.0.0/24          anywhere\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n上面设置 ipatbels 的命令的含义是，在 POSTROUTING 链的 nat 表中添加一条规则，当数据包的源 IP 网段为 10.0.0.0/24 时，并且不是网卡 br0 发送的，就执行 MASQUERADE 动作，该动作就是源地址改为宿主机地址的转换动作。\n\n现在就可以 ping 通外部 IP 了，查看 ens18 网卡的数据包，源地址已经修改成宿主机网卡 ens18 的地址了。\n\n[root@localhost ~]# tcpdump -i ens18 dst host 10.65.132.187 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n03:41:51.157483 IP 10.61.74.37 > 10.65.132.187: ICMP echo request, id 3972, seq 1, length 64\n03:41:52.158483 IP 10.61.74.37 > 10.65.132.187: ICMP echo request, id 3972, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n那外部 IP 回包时，只有宿主机的 IP，并没有容器的 IP，那宿主机怎么知道发送容器中呢？\n\n这个是因为内核 netfilter 会追踪记录连接，我们在增加了 SNAT 规则时，系统会自动增加一个隐式的反向规则，这样返回的包会自动将宿主机的 IP 替换为容器 IP。\n\n\n# 外部访问容器暴露的服务\n\ndocker 容器可以通过-p 的方式将容器内部的端口暴露到宿主机中，给外部访问，这个是怎么实现的呢？\n\n 1. 这个是通过 iptables 的 DNAT 规则实现的\n\n# 创建规则\n[root@localhost ~]# iptables -t nat -A PREROUTING  ! -i br0 -p tcp -m tcp --dport 80 -j DNAT --to-destination 10.0.0.1:80\n\n# 查看规则\n[root@localhost ~]# iptables -L PREROUTING -t nat\nDNAT       tcp  --  anywhere             anywhere             tcp dpt:http to:10.0.0.1:80\n\n\n1\n2\n3\n4\n5\n6\n\n\n创建规则的命令的意思是，在 PREROUTING 链的 nat 表中添加一条规则，数据包的来源网卡不是 br0，数据包协议是 tcp，目的端口是 80，则进行 DNAT，将目的 IP 从宿主机 IP 改为容器 IP。\n\n 2. 在 net0 中开启 80 端口\n\n[root@localhost ~]# nc -lp 80\n\n\n1\n\n 3. 在外部主机上访问宿主机的 80 端口，是可以访问成功的\n\n[root@k8s-master-07rf9 ~]# telnet 10.61.74.37 80\n\n\n1\n",normalizedContent:"# network namespace\n\nnamespace 技术是容器虚拟化的重要技术，可以将进程隔离在自己的 namespace 中。而 network namespace 技术是将进程隔离在自己的网络空间中，拥有独立的网络栈，仿佛自己处于独立的网络中。\n\n> 网络栈是指网卡、回环设备、路由表和 iptables 规则等等。网络栈是指网卡、回环设备、路由表和 iptables 规则等等。\n\n\n# 容器间网络互通\n\n容器的 bridge 网络模式会创建属于自己的 network namespace 来隔离自己与宿主机，拥有属于自己的网络栈。可以理解为不同的 network namespace 是不同的主机，那么它们想要网络通信，该如何实现？\n\n首先想到的当然是交换机和路由器了，因为它们是处于同一个网络中，所以使用交换机即可，而 linux 提供了 bridge 来充当虚拟交换机的角色，将多个 network namespace 接入到 bridge 中，它们就能网络互通了。\n\n那么如何将容器的 network namespace 接入到 bridge 呢？\n\n\n# veth pair\n\nveth pair 是成对出现的虚拟网卡，可以把它看做成一个管道，或者一根网线，从一段输入的数据包会从另一端输出，可以通过它来连接容器的 network namespace 和 bridge。\n\n使用 veth pair + bridge 的网络模型如下：\n\n\n# 实践\n\n我们不用安装 docker，直接用 network namespace 来模拟容器的网络环境。\n\n 1. 创建 bridge 设备\n\n这里使用 ip 命令来对 bridge 进行操作，也可以使用 brctl 命令，该命令是在 bridge-utils 包中。\n\n[root@localhost ~]# ip link add br0 type bridge\n[root@localhost ~]# ip link set dev br0 up\n[root@localhost ~]# ip addr add 10.0.0.3/24 dev br0\n\n[root@localhost ~]# ip link\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown mode default group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n2: ens18: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state up mode default group default qlen 1000\n    link/ether fe:fc:fe:af:4b:ea brd ff:ff:ff:ff:ff:ff\n60: br0: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up mode default group default qlen 1000\n    link/ether 7e:b5:12:2d:fd:d4 brd ff:ff:ff:ff:ff:ff\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 2. 创建 3 个 network namespace\n\n使用 ip netns 命令可以对 network namesapce 进行操作，所以使用该命令创建 net0、net1 两个 network namespace\n\n[root@localhost ~]# ip netns add net0\n[root@localhost ~]# ip netns add net1\n\n\n1\n2\n\n 3. 创建两对 veth pair\n\n首先创建两对 veth pair 虚拟网卡，它们是一一对应的，veth0 和 veth1，veth2 和 veth3\n\n[root@localhost ~]# ip link add veth0 type veth peer name veth1\n[root@localhost ~]# ip link add veth2 type veth peer name veth3\n\n\n1\n2\n\n\n查看创建出来的 4 个虚拟网卡，@前面的是该网卡的名称，后面的是该网卡的另一端。\n\n[root@localhost ~]# ip a\n...\n67: veth1@veth0: <broadcast,multicast,m-down> mtu 1500 qdisc noop state down group default qlen 1000\n    link/ether 7e:b5:12:2d:fd:d4 brd ff:ff:ff:ff:ff:ff\n68: veth0@veth1: <broadcast,multicast,m-down> mtu 1500 qdisc noop state down group default qlen 1000\n    link/ether 26:22:ef:1a:b3:33 brd ff:ff:ff:ff:ff:ff\n69: veth3@veth2: <broadcast,multicast,m-down> mtu 1500 qdisc noop state down group default qlen 1000\n    link/ether c6:f2:d1:2d:c7:95 brd ff:ff:ff:ff:ff:ff\n70: veth2@veth3: <broadcast,multicast,m-down> mtu 1500 qdisc noop state down group default qlen 1000\n    link/ether ee:4b:0d:17:60:b1 brd ff:ff:ff:ff:ff:ff\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n 4. 将 veth pair 的一端接入到 network namespace 中，并设置好其 ip 地址\n\n[root@localhost ~]# ip link set dev veth0 netns net0\n[root@localhost ~]# ip netns exec net0 ip addr add 10.0.0.1/24 dev veth0\n[root@localhost ~]# ip netns exec net0 ip link set dev veth0 up\n\n\n[root@localhost ~]# ip link set dev veth2 netns net1\n[root@localhost ~]# ip netns exec net1 ip addr add 10.0.0.2/24 dev veth2\n[root@localhost ~]# ip netns exec net1 ip link set dev veth2 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n> ip netns exec 命令可以进入到指定的 network namespace 中执行命令\n\n 5. 将 veth pair 的另一端设置到 bridge 中\n\n[root@localhost ~]# ip link set dev veth1 master br0\n[root@localhost ~]# ip link set dev veth3 master br0\n\n[root@localhost ~]# ip link set dev veth1 up\n[root@localhost ~]# ip link set dev veth3 up\n\n\n1\n2\n3\n4\n5\n\n\n可以通过命令 bridge link 查看到 veth1、veth3都插入到 br0 中了。\n\n[root@localhost ~]# bridge link\n67: veth1 state up @(null): <broadcast,multicast,up,lower_up> mtu 1500 master br0 state forwarding priority 32 cost 2 \n69: veth3 state up @(null): <broadcast,multicast,up,lower_up> mtu 1500 master br0 state forwarding priority 32 cost 2\n\n\n1\n2\n3\n\n\n也可以通过 brctl 命令查看\n\n[root@localhost ~]# brctl show\n[root@localhost ~]# brctl show\nbridge name     bridge id               stp enabled     interfaces\nbr0             8000.7eb5122dfdd4       no              veth1\n                                                        veth3\n\n\n1\n2\n3\n4\n5\n\n\n\n# 测试\n\n 1. 首先监听 br0 网卡\n\n[root@localhost ~]# tcpdump -i br0\n\n\n1\n\n 2. 在 net0 中 ping net1 的 ip\n\nip netns exec net0 ping -c 3 10.0.0.2\n\n\n1\n\n 3. 会发现监听 br0 网卡是有流量的：\n\n[root@localhost ~]# tcpdump -i br0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type en10mb (ethernet), capture size 262144 bytes\n02:39:41.251428 arp, request who-has 10.0.0.2 tell 10.0.0.1, length 28\n02:39:41.251495 arp, reply 10.0.0.2 is-at ee:4b:0d:17:60:b1 (oui unknown), length 28\n02:39:41.251502 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15665, seq 1, length 64\n02:39:41.251702 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15665, seq 1, length 64\n02:39:42.251435 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15665, seq 2, length 64\n02:39:42.251554 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15665, seq 2, length 64\n02:39:43.251414 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15665, seq 3, length 64\n02:39:43.251512 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15665, seq 3, length 64\n02:39:46.261377 arp, request who-has 10.0.0.1 tell 10.0.0.2, length 28\n02:39:46.261400 arp, reply 10.0.0.1 is-at 26:22:ef:1a:b3:33 (oui unknown), length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到先是 10.0.0.1 发送的 arp 获取 10.0.0.2 的 mac 地址，然后再发送 icmp 的请求和响应，最后 10.0.0.2 也发送 arp 获取 10.0.0.1 的 mac 地址。\n\n因为 bridge 是二层网络设备，所以它是需要通过识别 mac 地址来进行通信的局域网。\n\n后面我又通过 net0 ping net1 的 ip，发现它没有发送 arp 了，这个是因为第一次 bridge 已经将 mac 地址和端口的映射关系已经记录了下来，后面可以直接通过查表，而不用再发送 arp 了。\n\n[root@localhost ~]# tcpdump -i br0 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type en10mb (ethernet), capture size 262144 bytes\n02:40:01.267689 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15991, seq 1, length 64\n02:40:01.267948 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15991, seq 1, length 64\n02:40:02.267509 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15991, seq 2, length 64\n02:40:02.267641 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15991, seq 2, length 64\n02:40:03.267458 ip 10.0.0.1 > 10.0.0.2: icmp echo request, id 15991, seq 3, length 64\n02:40:03.267582 ip 10.0.0.2 > 10.0.0.1: icmp echo reply, id 15991, seq 3, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 宿主机访问容器\n\n 1. 再次监听 br0 网卡\n\ntcpdump -i br0\n\n\n1\n\n 2. 在宿主机上 ping 容器内部 ip，是可以 ping 通的\n\nping 10.0.0.1 -n 3\n\n\n1\n\n 3. 查看监听的 br0 网卡流量：\n\n[root@localhost ~]# tcpdump -i br0 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type en10mb (ethernet), capture size 262144 bytes\n02:56:03.232293 arp, request who-has 10.0.0.1 tell 10.0.0.3, length 28\n02:56:03.232342 arp, reply 10.0.0.1 is-at 26:22:ef:1a:b3:33, length 28\n02:56:03.232379 ip 10.0.0.3 > 10.0.0.1: icmp echo request, id 3964, seq 1, length 64\n02:56:03.232402 ip 10.0.0.1 > 10.0.0.3: icmp echo reply, id 3964, seq 1, length 64\n02:56:04.232494 ip 10.0.0.3 > 10.0.0.1: icmp echo request, id 3964, seq 2, length 64\n02:56:04.232554 ip 10.0.0.1 > 10.0.0.3: icmp echo reply, id 3964, seq 2, length 64\n02:56:05.232517 ip 10.0.0.3 > 10.0.0.1: icmp echo request, id 3964, seq 3, length 64\n02:56:05.232607 ip 10.0.0.1 > 10.0.0.3: icmp echo reply, id 3964, seq 3, length 64\n02:56:08.245354 arp, request who-has 10.0.0.3 tell 10.0.0.1, length 28\n02:56:08.245412 arp, reply 10.0.0.3 is-at 7e:b5:12:2d:fd:d4, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到是 10.0.0.3 访问通了 10.0.0.1 ，我们是通过宿主机访问的容器内部，为什么源 ip 变成 10.0.0.3？\n\n 4. 通过查看宿主机的路由表，可以看到当我们 ping 10.0.0.1 时，是匹配上了该条路由，然后走 br0 网卡，使用的源 ip 是 br0 的 ip 10.0.0.3\n\n[root@localhost ~]# ip r\n...\n10.0.0.0/24 dev br0 proto kernel scope link src 10.0.0.3 \n...\n\n\n1\n2\n3\n4\n\n\n\n# 容器内访问外部\n\n 1. 配置 network namespace 中将 bridge 作为默认网关\n\n当我们在 net0 内部访问外部 ip 时，会发现网络不可达。\n\n[root@localhost ~]# ip netns exec net0 ping 10.65.132.187\nconnect: network is unreachable\n\n\n1\n2\n\n\n这个是因为没有匹配上路由表上的原因\n\n[root@localhost ~]# ip netns exec net0 ip r\n10.0.0.0/24 dev veth0 proto kernel scope link src 10.0.0.1\n\n\n1\n2\n\n\n我们加上默认网关，也就是在没有匹配上其他路由时，走该网关\n\n[root@localhost ~]# ip netns exec net0 ip r add default via 10.0.0.3 dev veth0\n\n[root@localhost ~]# ip netns exec net0 ip r \ndefault via 10.0.0.3 dev veth0 \n10.0.0.0/24 dev veth0 proto kernel scope link src 10.0.0.1 \n\n\n1\n2\n3\n4\n5\n\n 2. 配置宿主机 iptables 的 snat 规则\n\n我们再次在容器中访问外部 ip 时，发现网络还不可达，但是我们监听 br0 网卡发现是有数据包的，也就是路由配的没问题\n\n[root@localhost ~]# tcpdump -i br0\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on br0, link-type en10mb (ethernet), capture size 262144 bytes\n03:23:23.738010 ip 10.0.0.1 > 10.65.132.187: icmp echo request, id 11228, seq 1, length 64\n03:23:24.737415 ip 10.0.0.1 > 10.65.132.187: icmp echo request, id 11228, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n我们再看宿主机上的路由，是有配置默认路由的。\n\n[root@localhost ~]# ip r\ndefault via 10.61.74.1 dev ens18 proto static metric 100\n\n\n1\n2\n\n\n所以我再监听一下宿主机的网卡 ens18 看看：\n\n[root@localhost ~]# tcpdump -i ens18 dst host 10.65.132.187\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n03:24:47.162152 ip 10.0.0.1 > 10.65.132.187: icmp echo request, id 13281, seq 1, length 64\n03:24:48.161585 ip 10.0.0.1 > 10.65.132.187: icmp echo request, id 13281, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n发现也是有数据包的，但是原地址是 net0 的 ip 地址 10.0.0.1，外部是不认识的，所以需要配置 iptables，将源 ip 改为宿主机的 ip。\n\n# 创建规则\n[root@localhost ~]# iptables -t nat -a postrouting -s 10.0.0.0/24 ! -o br0 -j masquerade\n\n# 查看规则\n[root@localhost ~]# iptables -l postrouting -t nat\n...\nmasquerade  all  --  10.0.0.0/24          anywhere\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n上面设置 ipatbels 的命令的含义是，在 postrouting 链的 nat 表中添加一条规则，当数据包的源 ip 网段为 10.0.0.0/24 时，并且不是网卡 br0 发送的，就执行 masquerade 动作，该动作就是源地址改为宿主机地址的转换动作。\n\n现在就可以 ping 通外部 ip 了，查看 ens18 网卡的数据包，源地址已经修改成宿主机网卡 ens18 的地址了。\n\n[root@localhost ~]# tcpdump -i ens18 dst host 10.65.132.187 -n \ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n03:41:51.157483 ip 10.61.74.37 > 10.65.132.187: icmp echo request, id 3972, seq 1, length 64\n03:41:52.158483 ip 10.61.74.37 > 10.65.132.187: icmp echo request, id 3972, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n\n\n那外部 ip 回包时，只有宿主机的 ip，并没有容器的 ip，那宿主机怎么知道发送容器中呢？\n\n这个是因为内核 netfilter 会追踪记录连接，我们在增加了 snat 规则时，系统会自动增加一个隐式的反向规则，这样返回的包会自动将宿主机的 ip 替换为容器 ip。\n\n\n# 外部访问容器暴露的服务\n\ndocker 容器可以通过-p 的方式将容器内部的端口暴露到宿主机中，给外部访问，这个是怎么实现的呢？\n\n 1. 这个是通过 iptables 的 dnat 规则实现的\n\n# 创建规则\n[root@localhost ~]# iptables -t nat -a prerouting  ! -i br0 -p tcp -m tcp --dport 80 -j dnat --to-destination 10.0.0.1:80\n\n# 查看规则\n[root@localhost ~]# iptables -l prerouting -t nat\ndnat       tcp  --  anywhere             anywhere             tcp dpt:http to:10.0.0.1:80\n\n\n1\n2\n3\n4\n5\n6\n\n\n创建规则的命令的意思是，在 prerouting 链的 nat 表中添加一条规则，数据包的来源网卡不是 br0，数据包协议是 tcp，目的端口是 80，则进行 dnat，将目的 ip 从宿主机 ip 改为容器 ip。\n\n 2. 在 net0 中开启 80 端口\n\n[root@localhost ~]# nc -lp 80\n\n\n1\n\n 3. 在外部主机上访问宿主机的 80 端口，是可以访问成功的\n\n[root@k8s-master-07rf9 ~]# telnet 10.61.74.37 80\n\n\n1\n",charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之DaemonSet",frontmatter:{tags:["k8s","容器","云原生"],title:"k8s之DaemonSet",date:"2022-08-31T11:06:48.000Z",permalink:"/pages/92bee4/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍k8s中的daemonset资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"twitter:title",content:"k8s之DaemonSet"},{name:"twitter:description",content:"介绍k8s中的daemonset资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/08.k8s%E4%B9%8BDaemonSet.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之DaemonSet"},{property:"og:description",content:"介绍k8s中的daemonset资源对象，及其使用方法和案例"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/08.k8s%E4%B9%8BDaemonSet.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-31T11:06:48.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之DaemonSet"},{itemprop:"description",content:"介绍k8s中的daemonset资源对象，及其使用方法和案例"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/08.k8s%E4%B9%8BDaemonSet.html",relativePath:"01.云原生/07.k8s/08.k8s之DaemonSet.md",key:"v-642acf34",path:"/pages/92bee4/",headers:[{level:2,title:"什么是DaemonSet？",slug:"什么是daemonset",normalizedTitle:"什么是daemonset？",charIndex:2},{level:2,title:"使用DaemonSet",slug:"使用daemonset",normalizedTitle:"使用daemonset",charIndex:153}],headersStr:"什么是DaemonSet？ 使用DaemonSet",content:"# 什么是DaemonSet？\n\n在K8s集群中的每一个Node中都会运行一个Pod的控制器。\n\n使用场景是？\n\n * 日志收集，每个节点运行一个Pod用于收集容器产生的日志\n * 监控管理，每个节点运行一个pod用于监控节点的状态\n * 网络应用，每个节点运行一个Pod用于将节点加入k8s网络\n\n\n# 使用DaemonSet\n\n使用yaml描述DaemonSet对象\n\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: nginx-ds\n  labels:\n    k8s-app: nginx-ds\nspec:\n  selector:\n    matchLabels:\n      name: nginx-ds\n  template:\n    metadata:\n      labels:\n        name: nginx-ds\n    spec:\n      containers:\n      - name: nginx-ds\n        image: nginx\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n创建DaemonSet对象，会看到自动的每一个节点中都创建了一个pod。\n\n[root@k8s-worker1 zwf]# kubectl apply -f daemonset.yaml -n zwf\ndaemonset.apps/nginx-ds configured\n\n[root@k8s-worker1 zwf]# kubectl get nodes\nNAME          STATUS   ROLES    AGE    VERSION\nk8s-master    Ready    <none>   32d    v1.23.4\nk8s-worker1   Ready    <none>   152d   v1.23.4\nk8s-worker2   Ready    <none>   152d   v1.23.4\n\n[root@k8s-worker1 zwf]# kubectl get ds -n zwf\nNAME       DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE\nnginx-ds   3         3         3       3            3           <none>          4m2s\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf -o wide\nNAME             READY   STATUS    RESTARTS   AGE   IP               NODE          NOMINATED NODE   READINESS GATES\nnginx-ds-7w2kx   1/1     Running   0          81s   10.222.194.73    k8s-worker1   <none>           <none>\nnginx-ds-l5lmx   1/1     Running   0          46s   10.222.126.38    k8s-worker2   <none>           <none>\nnginx-ds-zdfgl   1/1     Running   0          82s   10.222.235.217   k8s-master    <none>           <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n",normalizedContent:"# 什么是daemonset？\n\n在k8s集群中的每一个node中都会运行一个pod的控制器。\n\n使用场景是？\n\n * 日志收集，每个节点运行一个pod用于收集容器产生的日志\n * 监控管理，每个节点运行一个pod用于监控节点的状态\n * 网络应用，每个节点运行一个pod用于将节点加入k8s网络\n\n\n# 使用daemonset\n\n使用yaml描述daemonset对象\n\napiversion: apps/v1\nkind: daemonset\nmetadata:\n  name: nginx-ds\n  labels:\n    k8s-app: nginx-ds\nspec:\n  selector:\n    matchlabels:\n      name: nginx-ds\n  template:\n    metadata:\n      labels:\n        name: nginx-ds\n    spec:\n      containers:\n      - name: nginx-ds\n        image: nginx\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n创建daemonset对象，会看到自动的每一个节点中都创建了一个pod。\n\n[root@k8s-worker1 zwf]# kubectl apply -f daemonset.yaml -n zwf\ndaemonset.apps/nginx-ds configured\n\n[root@k8s-worker1 zwf]# kubectl get nodes\nname          status   roles    age    version\nk8s-master    ready    <none>   32d    v1.23.4\nk8s-worker1   ready    <none>   152d   v1.23.4\nk8s-worker2   ready    <none>   152d   v1.23.4\n\n[root@k8s-worker1 zwf]# kubectl get ds -n zwf\nname       desired   current   ready   up-to-date   available   node selector   age\nnginx-ds   3         3         3       3            3           <none>          4m2s\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf -o wide\nname             ready   status    restarts   age   ip               node          nominated node   readiness gates\nnginx-ds-7w2kx   1/1     running   0          81s   10.222.194.73    k8s-worker1   <none>           <none>\nnginx-ds-l5lmx   1/1     running   0          46s   10.222.126.38    k8s-worker2   <none>           <none>\nnginx-ds-zdfgl   1/1     running   0          82s   10.222.235.217   k8s-master    <none>           <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n",charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之PV、PVC和StorageClass",frontmatter:{tags:["k8s","容器","云原生"],title:"k8s之PV、PVC和StorageClass",date:"2022-08-31T15:03:37.000Z",permalink:"/pages/095c75/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍k8s中的pv、pvc和storageclass资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220831163136.png"},{name:"twitter:title",content:"k8s之PV、PVC和StorageClass"},{name:"twitter:description",content:"介绍k8s中的pv、pvc和storageclass资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220831163136.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/09.k8s%E4%B9%8BPV%E3%80%81PVC%E5%92%8CStorageClass.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之PV、PVC和StorageClass"},{property:"og:description",content:"介绍k8s中的pv、pvc和storageclass资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220831163136.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/09.k8s%E4%B9%8BPV%E3%80%81PVC%E5%92%8CStorageClass.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-31T15:03:37.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之PV、PVC和StorageClass"},{itemprop:"description",content:"介绍k8s中的pv、pvc和storageclass资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220831163136.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/09.k8s%E4%B9%8BPV%E3%80%81PVC%E5%92%8CStorageClass.html",relativePath:"01.云原生/07.k8s/09.k8s之PV、PVC和StorageClass.md",key:"v-86799138",path:"/pages/095c75/",headers:[{level:2,title:"PV",slug:"pv",normalizedTitle:"pv",charIndex:2},{level:3,title:"什么是PV？",slug:"什么是pv",normalizedTitle:"什么是pv？",charIndex:9},{level:3,title:"创建PV",slug:"创建pv",normalizedTitle:"创建pv",charIndex:78},{level:2,title:"PVC",slug:"pvc",normalizedTitle:"pvc",charIndex:918},{level:3,title:"什么是PVC？",slug:"什么是pvc",normalizedTitle:"什么是pvc？",charIndex:926},{level:3,title:"创建PVC",slug:"创建pvc",normalizedTitle:"创建pvc",charIndex:1095},{level:2,title:"在Pod中申请PVC",slug:"在pod中申请pvc",normalizedTitle:"在pod中申请pvc",charIndex:1861},{level:2,title:"StorageClass",slug:"storageclass",normalizedTitle:"storageclass",charIndex:2832},{level:3,title:"通过StorageClass配置NFS Provisioner",slug:"通过storageclass配置nfs-provisioner",normalizedTitle:"通过storageclass配置nfs provisioner",charIndex:3020},{level:3,title:"使用NFS动态存储卷",slug:"使用nfs动态存储卷",normalizedTitle:"使用nfs动态存储卷",charIndex:4499}],headersStr:"PV 什么是PV？ 创建PV PVC 什么是PVC？ 创建PVC 在Pod中申请PVC StorageClass 通过StorageClass配置NFS Provisioner 使用NFS动态存储卷",content:'# PV\n\n\n# 什么是PV？\n\nPV 描述的，则是一个具体的 Volume 的属性，比如 Volume 的类型、挂载目录、远程存储服务器地址等。\n\n\n# 创建PV\n\n使用yaml来定义PV\n\n\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: nfs-1g-pv\n\nspec:\n  storageClassName: nfs\n  accessModes:\n    - ReadWriteMany\n  capacity:\n    storage: 1Gi\n\n  nfs:\n    path: /root/zwf/share\n    server: 10.64.2.153\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n参数说明：\n\n * storageClassName的值为nfs，使用了NFS网络文件系统作为存储卷，\n * accessModes的值为ReadWriteMany，支持多个节点同时读写该共享目录\n * storage的值为1Gi，分配了1G的存储空间\n\n使用yaml定义的描述文件来创建PV对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f pv.yaml -n zwf\npersistentvolume/nfs-1g-pv created\n[root@k8s-worker1 zwf]# kubectl get pv -n zwf\nNAME        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                           STORAGECLASS   REASON   AGE\nnfs-1g-pv   1Gi        RWX            Retain           Available                                   nfs                     12s\n\n\n1\n2\n3\n4\n5\n\n\n\n# PVC\n\n\n# 什么是PVC？\n\n提供给应用开发获取存储资源的对象，开发将pod与PVC进行绑定可以达到持久化的存储状态，而PVC会与相对应的PV相绑定，提供具体的存储空间。\n\nPV和PVC有什么区别？\n\n实际上类似于“接口”和“实现”的思想。开发者只要知道并会使用“接口”，即：PVC；而运维人员则负责给“接口”绑定具体的实现，即：PV。\n\n\n\n\n# 创建PVC\n\n有了pv之后，创建申请存储的PVC对象，yaml定义如下，定义的内容和PV基本相同，但是不包含NFS的存储细节。\n\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nfs-static-pvc\n\nspec:\n  storageClassName: nfs\n  accessModes:\n    - ReadWriteMany\n\n  resources:\n    requests:\n      storage: 1Gi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n创建pvc对象，并且可以看到VOLUME的值是上面创建的pv对象，这样两者就进行绑定了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f pvc.yaml -n zwf\npersistentvolumeclaim/nfs-static-pvc created\n[root@k8s-worker1 zwf]# \n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nNAME             STATUS   VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nnfs-static-pvc   Bound    nfs-1g-pv   1Gi        RWX            nfs            9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n我们再pvc文件中并没有填写pv的任何信息，它是如何知道该绑定那个pv对象的呢？这是因为pvc会根据自身需要的容量去找到对应的pv进行匹配绑定。\n\n\n# 在Pod中申请PVC\n\nPod的yaml定义如下，使用volumes定义了存储卷使用上面创建的pvc对象nfs-static-pvc，在containers中使用vlumeMounts在pod中挂载了/tmp目录在该存储卷中。\n\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nfs-static-pod\n\nspec:\n  volumes:\n  - name: nfs-pvc-vol\n    persistentVolumeClaim:\n      claimName: nfs-static-pvc\n\n  containers:\n    - name: nfs-pvc-test\n      image: nginx:alpine\n      ports:\n      - containerPort: 80\n\n      volumeMounts:\n        - name: nfs-pvc-vol\n          mountPath: /tmp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建pod后，我们进入pod中在/tmp写入数据\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod_pvc.yaml -n zwf\npod/nfs-static-pod created\n\n[root@k8s-worker1 zwf]# kubectl exec -it nfs-static-pod -n zwf -- /bin/sh\n/ # cd /tmp\n/tmp # echo 222 > 2.txt\n\n\n1\n2\n3\n4\n5\n6\n\n\n在nfs服务器中的/root/zwf/share中，我们也可以看到上面写的数据\n\n[root@k8s-worker2 share]# pwd\n/root/zwf/share\n[root@k8s-worker2 share]# ls\n2.txt\n[root@k8s-worker2 share]# cat 2.txt\n222\n\n\n1\n2\n3\n4\n5\n6\n\n\nPod、PVC、PV 和 NFS 存储的关系可以用下图来形象地表示：\n\n\n\n\n# StorageClass\n\n上面的PV是需要管理员手动创建的，每一次的开发都需要根据需求逐个创建PV，并且还需要精确创建空间大小，导致工作量巨大。所以我们需要在开发中可以动态的创建PV。\n\nStoreageClass可以用来绑定Provisioner对象，而这个Provisioner就是一个能够自动管理存储、创建 PV 的应用，代替了原来系统管理员的手工劳动。\n\n\n\n\n# 通过StorageClass配置NFS Provisioner\n\nk8s中每一类的存储设备都有相应的Provisioner，这里我们使用的是NFS Provisioner(https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner)\n\n在 GitHub 的 deploy 目录里是部署它所需的 YAML 文件，一共有三个，分别是 rbac.yaml、class.yaml和 deployment.yaml。\n\n 1. 首先将rbac.yaml的namespace改成kube-system\n 2. 在修改deployment.yaml的namespace也改为kube-system，再修改其中的volumes 和 env 里的 IP 地址和共享目录名，与NFS服务器保持一致.\n\n\nspec:\n  template:\n    spec:\n      serviceAccountName: nfs-client-provisioner\n      containers:\n      ...\n          env:\n            - name: PROVISIONER_NAME\n              value: k8s-sigs.io/nfs-subdir-external-provisioner\n            - name: NFS_SERVER\n              value: 192.168.10.208        #改IP地址\n            - name: NFS_PATH\n              value: /tmp/nfs              #改共享目录名\n      volumes:\n        - name: nfs-client-root\n          nfs:\n            server: 192.168.10.208         #改IP地址\n            Path: /tmp/nfs                 #改共享目录名\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n再将k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2改成chronolaw/nfs-subdir-external-provisioner:v4.0.2\n\n 3. 最后创建NFS Provisioner\n\nkubectl apply -f rbac.yaml\nkubectl apply -f class.yaml\nkubectl apply -f deployment.yaml\n\n\n1\n2\n3\n\n\n查看kube-system的pod可以看到nfs的provisioner。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n kube-system\nNAME                                      READY   STATUS    RESTARTS      AGE\nnfs-client-provisioner-57789d96b7-42q67   1/1     Running   0             22h\n\n\n1\n2\n3\n\n\n\n# 使用NFS动态存储卷\n\n创建StrogeClass对象，onDelete: "remain"代表着即使Pod被删除，也会保留分配的存储，之后再手动删除。\n\n\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: nfs-client\n\nprovisioner: k8s-sigs.io/nfs-subdir-external-provisioner \nparameters:\n  onDelete: "remain"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n创建StrageClass对象，并可以看到PROVISIONER已经绑定了我们上面创建的nfs-provisioner了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f pvc_dyn.yaml -n zwf\nstorageclass.storage.k8s.io/nfs-client-retained created\n\n[root@k8s-worker1 zwf]# kubectl get sc -n zwf\nNAME                  PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\nnfs-client   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  21h\n\n\n1\n2\n3\n4\n5\n6\n\n\n定义PVC，配置storageClassName:nfs-client与上面的StrageClass对象相绑定。\n\n\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: nfs-dyn-10m-pvc\n\nspec:\n  storageClassName: nfs-client\n  accessModes:\n    - ReadWriteMany\n\n  resources:\n    requests:\n      storage: 10Mi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建PVC，然后你会发现STATUS的状态为Bound，已经自动的创建了PV，并且已经相互绑定。\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nNAME              STATUS    VOLUME      CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nnfs-dyn-10m-pvc   Pending                                         nfs-client     25s\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nNAME              STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nnfs-dyn-10m-pvc   Bound    pvc-292cfed3-bec8-4425-aeac-697e3740c76c   10Mi       RWX            nfs-client     9s\n\n[root@k8s-worker1 zwf]# kubectl get pv -n zwf\nNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                           STORAGECLASS   REASON   AGE\npvc-292cfed3-bec8-4425-aeac-697e3740c76c   10Mi       RWX            Delete           Bound    zwf/nfs-dyn-10m-pvc             nfs-client              47s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n去NFS文件服务器的共享目录中查看，可以看到多出来了一个目录，目录名称为命名空间-pvc名称-pvc名称\n\n[root@k8s-worker2 share]# pwd\n/root/zwf/share\n[root@k8s-worker2 share]# ls\nzwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c\n\n\n1\n2\n3\n4\n\n\n定义Pod，挂载上面创建的PVC到容器的/tmp目录中\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: nfs-dyn-pod\n\nspec:\n  volumes:\n  - name: nfs-dyn-10m-vol\n    persistentVolumeClaim:\n      claimName: nfs-dyn-10m-pvc\n\n  containers:\n    - name: nfs-dyn-test\n      image: nginx:alpine\n\n      volumeMounts:\n        - name: nfs-dyn-10m-vol\n          mountPath: /tmp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n创建Pod成功\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod_strageclass.yaml -n zwf\npod/nfs-dyn-pod created\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME          READY   STATUS    RESTARTS   AGE\nnfs-dyn-pod   1/1     Running   0          10s\n\n\n1\n2\n3\n4\n5\n\n\n进入到挂载了pvc的pod，然后在/tmp目录下写一个文件\n\nkubectl exec -it nfs-dyn-pod -n zwf -- /bin/sh\n/ # cd /tmp\n/tmp # echo 111 > 3.txt\n\n\n1\n2\n3\n\n\n再到NFS服务器上的共享目录对应的pv目录下，能看到之前写的文件。\n\n[root@k8s-worker2 zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c]# pwd\n/root/zwf/share/zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c\n\n[root@k8s-worker2 zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c]# cat 3.txt \n111\n\n\n1\n2\n3\n4\n5\n\n\n关系图如下：\n\n',normalizedContent:'# pv\n\n\n# 什么是pv？\n\npv 描述的，则是一个具体的 volume 的属性，比如 volume 的类型、挂载目录、远程存储服务器地址等。\n\n\n# 创建pv\n\n使用yaml来定义pv\n\n\napiversion: v1\nkind: persistentvolume\nmetadata:\n  name: nfs-1g-pv\n\nspec:\n  storageclassname: nfs\n  accessmodes:\n    - readwritemany\n  capacity:\n    storage: 1gi\n\n  nfs:\n    path: /root/zwf/share\n    server: 10.64.2.153\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n参数说明：\n\n * storageclassname的值为nfs，使用了nfs网络文件系统作为存储卷，\n * accessmodes的值为readwritemany，支持多个节点同时读写该共享目录\n * storage的值为1gi，分配了1g的存储空间\n\n使用yaml定义的描述文件来创建pv对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f pv.yaml -n zwf\npersistentvolume/nfs-1g-pv created\n[root@k8s-worker1 zwf]# kubectl get pv -n zwf\nname        capacity   access modes   reclaim policy   status      claim                           storageclass   reason   age\nnfs-1g-pv   1gi        rwx            retain           available                                   nfs                     12s\n\n\n1\n2\n3\n4\n5\n\n\n\n# pvc\n\n\n# 什么是pvc？\n\n提供给应用开发获取存储资源的对象，开发将pod与pvc进行绑定可以达到持久化的存储状态，而pvc会与相对应的pv相绑定，提供具体的存储空间。\n\npv和pvc有什么区别？\n\n实际上类似于“接口”和“实现”的思想。开发者只要知道并会使用“接口”，即：pvc；而运维人员则负责给“接口”绑定具体的实现，即：pv。\n\n\n\n\n# 创建pvc\n\n有了pv之后，创建申请存储的pvc对象，yaml定义如下，定义的内容和pv基本相同，但是不包含nfs的存储细节。\n\napiversion: v1\nkind: persistentvolumeclaim\nmetadata:\n  name: nfs-static-pvc\n\nspec:\n  storageclassname: nfs\n  accessmodes:\n    - readwritemany\n\n  resources:\n    requests:\n      storage: 1gi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n创建pvc对象，并且可以看到volume的值是上面创建的pv对象，这样两者就进行绑定了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f pvc.yaml -n zwf\npersistentvolumeclaim/nfs-static-pvc created\n[root@k8s-worker1 zwf]# \n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nname             status   volume      capacity   access modes   storageclass   age\nnfs-static-pvc   bound    nfs-1g-pv   1gi        rwx            nfs            9s\n\n\n1\n2\n3\n4\n5\n6\n\n\n我们再pvc文件中并没有填写pv的任何信息，它是如何知道该绑定那个pv对象的呢？这是因为pvc会根据自身需要的容量去找到对应的pv进行匹配绑定。\n\n\n# 在pod中申请pvc\n\npod的yaml定义如下，使用volumes定义了存储卷使用上面创建的pvc对象nfs-static-pvc，在containers中使用vlumemounts在pod中挂载了/tmp目录在该存储卷中。\n\n\napiversion: v1\nkind: pod\nmetadata:\n  name: nfs-static-pod\n\nspec:\n  volumes:\n  - name: nfs-pvc-vol\n    persistentvolumeclaim:\n      claimname: nfs-static-pvc\n\n  containers:\n    - name: nfs-pvc-test\n      image: nginx:alpine\n      ports:\n      - containerport: 80\n\n      volumemounts:\n        - name: nfs-pvc-vol\n          mountpath: /tmp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建pod后，我们进入pod中在/tmp写入数据\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod_pvc.yaml -n zwf\npod/nfs-static-pod created\n\n[root@k8s-worker1 zwf]# kubectl exec -it nfs-static-pod -n zwf -- /bin/sh\n/ # cd /tmp\n/tmp # echo 222 > 2.txt\n\n\n1\n2\n3\n4\n5\n6\n\n\n在nfs服务器中的/root/zwf/share中，我们也可以看到上面写的数据\n\n[root@k8s-worker2 share]# pwd\n/root/zwf/share\n[root@k8s-worker2 share]# ls\n2.txt\n[root@k8s-worker2 share]# cat 2.txt\n222\n\n\n1\n2\n3\n4\n5\n6\n\n\npod、pvc、pv 和 nfs 存储的关系可以用下图来形象地表示：\n\n\n\n\n# storageclass\n\n上面的pv是需要管理员手动创建的，每一次的开发都需要根据需求逐个创建pv，并且还需要精确创建空间大小，导致工作量巨大。所以我们需要在开发中可以动态的创建pv。\n\nstoreageclass可以用来绑定provisioner对象，而这个provisioner就是一个能够自动管理存储、创建 pv 的应用，代替了原来系统管理员的手工劳动。\n\n\n\n\n# 通过storageclass配置nfs provisioner\n\nk8s中每一类的存储设备都有相应的provisioner，这里我们使用的是nfs provisioner(https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner)\n\n在 github 的 deploy 目录里是部署它所需的 yaml 文件，一共有三个，分别是 rbac.yaml、class.yaml和 deployment.yaml。\n\n 1. 首先将rbac.yaml的namespace改成kube-system\n 2. 在修改deployment.yaml的namespace也改为kube-system，再修改其中的volumes 和 env 里的 ip 地址和共享目录名，与nfs服务器保持一致.\n\n\nspec:\n  template:\n    spec:\n      serviceaccountname: nfs-client-provisioner\n      containers:\n      ...\n          env:\n            - name: provisioner_name\n              value: k8s-sigs.io/nfs-subdir-external-provisioner\n            - name: nfs_server\n              value: 192.168.10.208        #改ip地址\n            - name: nfs_path\n              value: /tmp/nfs              #改共享目录名\n      volumes:\n        - name: nfs-client-root\n          nfs:\n            server: 192.168.10.208         #改ip地址\n            path: /tmp/nfs                 #改共享目录名\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n再将k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2改成chronolaw/nfs-subdir-external-provisioner:v4.0.2\n\n 3. 最后创建nfs provisioner\n\nkubectl apply -f rbac.yaml\nkubectl apply -f class.yaml\nkubectl apply -f deployment.yaml\n\n\n1\n2\n3\n\n\n查看kube-system的pod可以看到nfs的provisioner。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n kube-system\nname                                      ready   status    restarts      age\nnfs-client-provisioner-57789d96b7-42q67   1/1     running   0             22h\n\n\n1\n2\n3\n\n\n\n# 使用nfs动态存储卷\n\n创建strogeclass对象，ondelete: "remain"代表着即使pod被删除，也会保留分配的存储，之后再手动删除。\n\n\napiversion: storage.k8s.io/v1\nkind: storageclass\nmetadata:\n  name: nfs-client\n\nprovisioner: k8s-sigs.io/nfs-subdir-external-provisioner \nparameters:\n  ondelete: "remain"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n创建strageclass对象，并可以看到provisioner已经绑定了我们上面创建的nfs-provisioner了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f pvc_dyn.yaml -n zwf\nstorageclass.storage.k8s.io/nfs-client-retained created\n\n[root@k8s-worker1 zwf]# kubectl get sc -n zwf\nname                  provisioner                                   reclaimpolicy   volumebindingmode   allowvolumeexpansion   age\nnfs-client   k8s-sigs.io/nfs-subdir-external-provisioner   delete          immediate           false                  21h\n\n\n1\n2\n3\n4\n5\n6\n\n\n定义pvc，配置storageclassname:nfs-client与上面的strageclass对象相绑定。\n\n\napiversion: v1\nkind: persistentvolumeclaim\nmetadata:\n  name: nfs-dyn-10m-pvc\n\nspec:\n  storageclassname: nfs-client\n  accessmodes:\n    - readwritemany\n\n  resources:\n    requests:\n      storage: 10mi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建pvc，然后你会发现status的状态为bound，已经自动的创建了pv，并且已经相互绑定。\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nname              status    volume      capacity   access modes   storageclass   age\nnfs-dyn-10m-pvc   pending                                         nfs-client     25s\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nname              status   volume                                     capacity   access modes   storageclass   age\nnfs-dyn-10m-pvc   bound    pvc-292cfed3-bec8-4425-aeac-697e3740c76c   10mi       rwx            nfs-client     9s\n\n[root@k8s-worker1 zwf]# kubectl get pv -n zwf\nname                                       capacity   access modes   reclaim policy   status   claim                           storageclass   reason   age\npvc-292cfed3-bec8-4425-aeac-697e3740c76c   10mi       rwx            delete           bound    zwf/nfs-dyn-10m-pvc             nfs-client              47s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n去nfs文件服务器的共享目录中查看，可以看到多出来了一个目录，目录名称为命名空间-pvc名称-pvc名称\n\n[root@k8s-worker2 share]# pwd\n/root/zwf/share\n[root@k8s-worker2 share]# ls\nzwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c\n\n\n1\n2\n3\n4\n\n\n定义pod，挂载上面创建的pvc到容器的/tmp目录中\n\napiversion: v1\nkind: pod\nmetadata:\n  name: nfs-dyn-pod\n\nspec:\n  volumes:\n  - name: nfs-dyn-10m-vol\n    persistentvolumeclaim:\n      claimname: nfs-dyn-10m-pvc\n\n  containers:\n    - name: nfs-dyn-test\n      image: nginx:alpine\n\n      volumemounts:\n        - name: nfs-dyn-10m-vol\n          mountpath: /tmp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n创建pod成功\n\n[root@k8s-worker1 zwf]# kubectl apply -f pod_strageclass.yaml -n zwf\npod/nfs-dyn-pod created\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname          ready   status    restarts   age\nnfs-dyn-pod   1/1     running   0          10s\n\n\n1\n2\n3\n4\n5\n\n\n进入到挂载了pvc的pod，然后在/tmp目录下写一个文件\n\nkubectl exec -it nfs-dyn-pod -n zwf -- /bin/sh\n/ # cd /tmp\n/tmp # echo 111 > 3.txt\n\n\n1\n2\n3\n\n\n再到nfs服务器上的共享目录对应的pv目录下，能看到之前写的文件。\n\n[root@k8s-worker2 zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c]# pwd\n/root/zwf/share/zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c\n\n[root@k8s-worker2 zwf-nfs-dyn-10m-pvc-pvc-292cfed3-bec8-4425-aeac-697e3740c76c]# cat 3.txt \n111\n\n\n1\n2\n3\n4\n5\n\n\n关系图如下：\n\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"k8s之StatefulSet",frontmatter:{tags:["k8s","容器","云原生"],author:{name:"msqfx",link:"https://github.com/msqfx"},title:"k8s之StatefulSet",date:"2022-08-31T14:55:02.000Z",permalink:"/pages/d178a2/",description:"介绍k8s中的statefulset资源对象，及其使用方法和案例",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220831173844.png"},{name:"twitter:title",content:"k8s之StatefulSet"},{name:"twitter:description",content:"介绍k8s中的statefulset资源对象，及其使用方法和案例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220831173844.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/10.k8s%E4%B9%8BStatefulSet.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s之StatefulSet"},{property:"og:description",content:"介绍k8s中的statefulset资源对象，及其使用方法和案例"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220831173844.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/10.k8s%E4%B9%8BStatefulSet.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-31T14:55:02.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"k8s之StatefulSet"},{itemprop:"description",content:"介绍k8s中的statefulset资源对象，及其使用方法和案例"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220831173844.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/10.k8s%E4%B9%8BStatefulSet.html",relativePath:"01.云原生/07.k8s/10.k8s之StatefulSet.md",key:"v-1eacf608",path:"/pages/d178a2/",headers:[{level:2,title:"什么是StatefulSet?",slug:"什么是statefulset",normalizedTitle:"什么是statefulset?",charIndex:2},{level:2,title:"使用StatefulSet",slug:"使用statefulset",normalizedTitle:"使用statefulset",charIndex:227},{level:3,title:"创建StatefulSet",slug:"创建statefulset",normalizedTitle:"创建statefulset",charIndex:245},{level:3,title:"Service配置",slug:"service配置",normalizedTitle:"service配置",charIndex:1436},{level:3,title:"持久化配置",slug:"持久化配置",normalizedTitle:"持久化配置",charIndex:4150}],headersStr:"什么是StatefulSet? 使用StatefulSet 创建StatefulSet Service配置 持久化配置",content:'# 什么是StatefulSet?\n\n是用来创建有状态应用，可以通过过某种方式记录这些状态，然后在 Pod 被重新创建时，能够为新 Pod 恢复这些状态。\n\n什么是有状态应用？\n\n首先是需要有数据的持久化，即使Pod被重启后，也能恢复，与重启前保持一致。然后是应用创建的所有pod有依赖关系，顺序的创建、需要运行在指定的宿主机上，并且都有对应的网络标志。\n\n应用场景？\n\n分布式应用，它的多个实例之间，往往有依赖关系，比如：主从关系、主备关系。\n\n\n# 使用StatefulSet\n\n\n# 创建StatefulSet\n\n创建yaml文件定义StatefulSet对象如下，与Deployment比较，多了一个serviceName字段，这个是用来指定StatefulSet所管理的pod是用域名访问是通过该service所设定的。\n\n\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis-sts\n\nspec:\n  serviceName: redis-svc\n  replicas: 2\n  selector:\n    matchLabels:\n      app: redis-sts\n\n  template:\n    metadata:\n      labels:\n        app: redis-sts\n    spec:\n      containers:\n      - image: redis\n        name: redis\n        ports:\n        - containerPort: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n创建StatefulSet对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f statefulset.yaml  -n zwf\nstatefulset.apps/redis-sts created\n\n[root@k8s-worker1 zwf]# kubectl get sts -n zwf\nNAME        READY   AGE\nredis-sts   2/2     54s\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看创建的Pod会发现，命名不再是随机创建的名字，而是有了顺序号，从0开始，而k8s也会按照这个顺序一次创建。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME          READY   STATUS    RESTARTS   AGE\nredis-sts-0   1/1     Running   0          61s\nredis-sts-1   1/1     Running   0          54s\n\n\n1\n2\n3\n4\n\n\n输出pod中的hostname发现与pod的名称也保持一致，也就是应用可以自行决定依赖关系，比如该例子中可以使用0号pod作为主实例，而1号pod作为从实例。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-sts-0 -n zwf -- hostname\nredis-sts-0\n\n\n1\n2\n\n\n\n# Service配置\n\n定义匹配上面的创建StatefulSet对象所有管理的Service，也就是标签筛选需要和pod的标签保持一致，并且这里的metadata.name也要与StatefulSet中的serviceName一样。\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-svc\n\nspec:\n  selector:\n    app: redis-sts\n\n  ports:\n  - port: 6379\n    protocol: TCP\n    targetPort: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建Service对象，我们可以看到已经将StatefulSet所创建的pod加入到端点列表了，也就是可以稳定的通过Service来访问到Pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f service_statefulset.yaml -n zwf\nkservice/redis-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf\nNAME                   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE\nredis-svc              ClusterIP   10.0.0.246   <none>        6379/TCP       5s\n\n[root@k8s-worker1 zwf]# kubectl describe svc redis-svc -n zwf\nName:              redis-svc\nNamespace:         zwf\nLabels:            <none>\nAnnotations:       <none>\nSelector:          app=redis-sts\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.0.0.246\nIPs:               10.0.0.246\nPort:              <unset>  6379/TCP\nTargetPort:        6379/TCP\nEndpoints:         10.222.126.51:6379,10.222.194.84:6379\nSession Affinity:  None\nEvents:            <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n但是我们的Pod不是一般的的应用，是有状态的应用，需要有稳定的网络标识，所以会为每一个Pod也创建一个域名，格式是：<podName>.<serviceName>.<namesapce>.svc.cluster.local。\n\n我们进入pod中验证一下，通过ping redis-sts-1.redis-svc.zwf.svc.cluster.local发现是可以ping通的，虽然Pod的IP会变化，但是通过固定的域名就能访问到指定Pod了。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-sts-0 -n zwf -- ping redis-sts-1.redis-svc.zwf.svc.cluster.local\nPING redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51) 56(84) bytes of data.\n64 bytes from redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51): icmp_seq=1 ttl=62 time=0.964 ms\n64 bytes from redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51): icmp_seq=2 ttl=62 time=0.932 ms\n\n\n1\n2\n3\n4\n\n\n既然我们的pod有了稳定的网络标识，Service也就不需要再分配ClusterIP了，这个时候，只需要添加字段clusterIP: None，这样就不会再分配IP了，这样的Service称为Headless Service\n\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: redis-svc\n\nspec:\n  clusterIP: None\n  selector:\n    app: redis-sts\n\n  ports:\n  - port: 6379\n    protocol: TCP\n    targetPort: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n创建Headless Service，可以看到CLUSTER-IP为None\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf\nNAME                   TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE\ndemoapp-nodeport-svc   NodePort    10.0.0.144   <none>        80:31999/TCP   21h\ndemoapp-svc            ClusterIP   10.0.0.74    <none>        80/TCP         22h\nredis-svc              ClusterIP   None         <none>        6379/TCP       4s\n\n\n1\n2\n3\n4\n5\n\n\nService和StatefulSet配置图如下：\n\n\n\n\n# 持久化配置\n\n接下来是给StatefulSet对象添加持久化配置。\n\n定义StatefulSet描述如下：\n\n\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: redis-pv-sts\n\nspec:\n  serviceName: redis-pv-svc\n\n  volumeClaimTemplates:\n  - metadata:\n      name: redis-100m-pvc\n    spec:\n      storageClassName: nfs-client\n      accessModes:\n        - ReadWriteMany\n      resources:\n        requests:\n          storage: 100Mi\n\n  replicas: 2\n  selector:\n    matchLabels:\n      app: redis-pv-sts\n\n  template:\n    metadata:\n      labels:\n        app: redis-pv-sts\n    spec:\n      containers:\n      - image: redis:5-alpine\n        name: redis\n\n        volumeMounts:\n        - name: redis-100m-pvc\n          mountPath: /data\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n\n\n参数：\n\n * volumeClaimTemplates，用来将PVC的定义嵌入到StatefulSet中的字段，是创建PVC的模板，可以让每一个Pod都能自动创建PVC\n * voulumeMounts，是用来选择上面的PVC挂载在容器的/data目录中\n\n创建StatefulSet对象，可以看到pod已经创建起来了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f statefulset_pvc.yaml -n zwf\nstatefulset.apps/redis-pv-sts created\n\n[root@k8s-worker1 zwf]# kubectl get sts -n zwf\nNAME           READY   AGE\nredis-pv-sts   2/2     25\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nNAME             READY   STATUS    RESTARTS   AGE\nredis-pv-sts-0   1/1     Running   0          63s\nredis-pv-sts-1   1/1     Running   0          54s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n我们查看pvc，会发现创建了2个对象 ，以PVC名称-pod名称命名。\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nNAME                            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\nredis-100m-pvc-redis-pv-sts-0   Bound    pvc-2712daa4-36b4-4a63-ac2f-7d3b31e2a887   100Mi      RWX            nfs-client     109s\nredis-100m-pvc-redis-pv-sts-1   Bound    pvc-a3781354-e182-42f7-b6f6-983999603653   100Mi      RWX            nfs-client     100s\n\n\n1\n2\n3\n4\n\n\n进入到pod中，使用redis-cli运行redis客户端，添加一些数据\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-pv-sts-0 -n zwf /bin/bash\n[ root@redis-pv-sts-0:/data ]$ redis-cli  \n127.0.0.1:6379> set name zhangsan\nOK\n127.0.0.1:6379> set age 18\nOK\n127.0.0.1:6379> keys *\n1) "name"\n2) "age"\n127.0.0.1:6379> quit\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n将pod删除，然后再重新进入Pod中，查询之前创建的redis的key，还是能够查询到。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-pv-sts-0  -n zwf -- /bin/bash\n[ root@redis-pv-sts-0:/data ]$ redis-cli  \n127.0.0.1:6379> keys *\n1) "name"\n2) "age"\n127.0.0.1:6379> get name\n"zhangsan"\n127.0.0.1:6379> get age\n"18"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n配置的关系图如下：\n\n',normalizedContent:'# 什么是statefulset?\n\n是用来创建有状态应用，可以通过过某种方式记录这些状态，然后在 pod 被重新创建时，能够为新 pod 恢复这些状态。\n\n什么是有状态应用？\n\n首先是需要有数据的持久化，即使pod被重启后，也能恢复，与重启前保持一致。然后是应用创建的所有pod有依赖关系，顺序的创建、需要运行在指定的宿主机上，并且都有对应的网络标志。\n\n应用场景？\n\n分布式应用，它的多个实例之间，往往有依赖关系，比如：主从关系、主备关系。\n\n\n# 使用statefulset\n\n\n# 创建statefulset\n\n创建yaml文件定义statefulset对象如下，与deployment比较，多了一个servicename字段，这个是用来指定statefulset所管理的pod是用域名访问是通过该service所设定的。\n\n\napiversion: apps/v1\nkind: statefulset\nmetadata:\n  name: redis-sts\n\nspec:\n  servicename: redis-svc\n  replicas: 2\n  selector:\n    matchlabels:\n      app: redis-sts\n\n  template:\n    metadata:\n      labels:\n        app: redis-sts\n    spec:\n      containers:\n      - image: redis\n        name: redis\n        ports:\n        - containerport: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n创建statefulset对象\n\n[root@k8s-worker1 zwf]# kubectl apply -f statefulset.yaml  -n zwf\nstatefulset.apps/redis-sts created\n\n[root@k8s-worker1 zwf]# kubectl get sts -n zwf\nname        ready   age\nredis-sts   2/2     54s\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看创建的pod会发现，命名不再是随机创建的名字，而是有了顺序号，从0开始，而k8s也会按照这个顺序一次创建。\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname          ready   status    restarts   age\nredis-sts-0   1/1     running   0          61s\nredis-sts-1   1/1     running   0          54s\n\n\n1\n2\n3\n4\n\n\n输出pod中的hostname发现与pod的名称也保持一致，也就是应用可以自行决定依赖关系，比如该例子中可以使用0号pod作为主实例，而1号pod作为从实例。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-sts-0 -n zwf -- hostname\nredis-sts-0\n\n\n1\n2\n\n\n\n# service配置\n\n定义匹配上面的创建statefulset对象所有管理的service，也就是标签筛选需要和pod的标签保持一致，并且这里的metadata.name也要与statefulset中的servicename一样。\n\n\napiversion: v1\nkind: service\nmetadata:\n  name: redis-svc\n\nspec:\n  selector:\n    app: redis-sts\n\n  ports:\n  - port: 6379\n    protocol: tcp\n    targetport: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n创建service对象，我们可以看到已经将statefulset所创建的pod加入到端点列表了，也就是可以稳定的通过service来访问到pod\n\n[root@k8s-worker1 zwf]# kubectl apply -f service_statefulset.yaml -n zwf\nkservice/redis-svc created\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf\nname                   type        cluster-ip   external-ip   port(s)        age\nredis-svc              clusterip   10.0.0.246   <none>        6379/tcp       5s\n\n[root@k8s-worker1 zwf]# kubectl describe svc redis-svc -n zwf\nname:              redis-svc\nnamespace:         zwf\nlabels:            <none>\nannotations:       <none>\nselector:          app=redis-sts\ntype:              clusterip\nip family policy:  singlestack\nip families:       ipv4\nip:                10.0.0.246\nips:               10.0.0.246\nport:              <unset>  6379/tcp\ntargetport:        6379/tcp\nendpoints:         10.222.126.51:6379,10.222.194.84:6379\nsession affinity:  none\nevents:            <none>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n但是我们的pod不是一般的的应用，是有状态的应用，需要有稳定的网络标识，所以会为每一个pod也创建一个域名，格式是：<podname>.<servicename>.<namesapce>.svc.cluster.local。\n\n我们进入pod中验证一下，通过ping redis-sts-1.redis-svc.zwf.svc.cluster.local发现是可以ping通的，虽然pod的ip会变化，但是通过固定的域名就能访问到指定pod了。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-sts-0 -n zwf -- ping redis-sts-1.redis-svc.zwf.svc.cluster.local\nping redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51) 56(84) bytes of data.\n64 bytes from redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51): icmp_seq=1 ttl=62 time=0.964 ms\n64 bytes from redis-sts-1.redis-svc.zwf.svc.cluster.local (10.222.126.51): icmp_seq=2 ttl=62 time=0.932 ms\n\n\n1\n2\n3\n4\n\n\n既然我们的pod有了稳定的网络标识，service也就不需要再分配clusterip了，这个时候，只需要添加字段clusterip: none，这样就不会再分配ip了，这样的service称为headless service\n\n\napiversion: v1\nkind: service\nmetadata:\n  name: redis-svc\n\nspec:\n  clusterip: none\n  selector:\n    app: redis-sts\n\n  ports:\n  - port: 6379\n    protocol: tcp\n    targetport: 6379\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n创建headless service，可以看到cluster-ip为none\n\n[root@k8s-worker1 zwf]# kubectl get svc -n zwf\nname                   type        cluster-ip   external-ip   port(s)        age\ndemoapp-nodeport-svc   nodeport    10.0.0.144   <none>        80:31999/tcp   21h\ndemoapp-svc            clusterip   10.0.0.74    <none>        80/tcp         22h\nredis-svc              clusterip   none         <none>        6379/tcp       4s\n\n\n1\n2\n3\n4\n5\n\n\nservice和statefulset配置图如下：\n\n\n\n\n# 持久化配置\n\n接下来是给statefulset对象添加持久化配置。\n\n定义statefulset描述如下：\n\n\napiversion: apps/v1\nkind: statefulset\nmetadata:\n  name: redis-pv-sts\n\nspec:\n  servicename: redis-pv-svc\n\n  volumeclaimtemplates:\n  - metadata:\n      name: redis-100m-pvc\n    spec:\n      storageclassname: nfs-client\n      accessmodes:\n        - readwritemany\n      resources:\n        requests:\n          storage: 100mi\n\n  replicas: 2\n  selector:\n    matchlabels:\n      app: redis-pv-sts\n\n  template:\n    metadata:\n      labels:\n        app: redis-pv-sts\n    spec:\n      containers:\n      - image: redis:5-alpine\n        name: redis\n\n        volumemounts:\n        - name: redis-100m-pvc\n          mountpath: /data\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n\n\n参数：\n\n * volumeclaimtemplates，用来将pvc的定义嵌入到statefulset中的字段，是创建pvc的模板，可以让每一个pod都能自动创建pvc\n * voulumemounts，是用来选择上面的pvc挂载在容器的/data目录中\n\n创建statefulset对象，可以看到pod已经创建起来了。\n\n[root@k8s-worker1 zwf]# kubectl apply -f statefulset_pvc.yaml -n zwf\nstatefulset.apps/redis-pv-sts created\n\n[root@k8s-worker1 zwf]# kubectl get sts -n zwf\nname           ready   age\nredis-pv-sts   2/2     25\n\n[root@k8s-worker1 zwf]# kubectl get pods -n zwf\nname             ready   status    restarts   age\nredis-pv-sts-0   1/1     running   0          63s\nredis-pv-sts-1   1/1     running   0          54s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n我们查看pvc，会发现创建了2个对象 ，以pvc名称-pod名称命名。\n\n[root@k8s-worker1 zwf]# kubectl get pvc -n zwf\nname                            status   volume                                     capacity   access modes   storageclass   age\nredis-100m-pvc-redis-pv-sts-0   bound    pvc-2712daa4-36b4-4a63-ac2f-7d3b31e2a887   100mi      rwx            nfs-client     109s\nredis-100m-pvc-redis-pv-sts-1   bound    pvc-a3781354-e182-42f7-b6f6-983999603653   100mi      rwx            nfs-client     100s\n\n\n1\n2\n3\n4\n\n\n进入到pod中，使用redis-cli运行redis客户端，添加一些数据\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-pv-sts-0 -n zwf /bin/bash\n[ root@redis-pv-sts-0:/data ]$ redis-cli  \n127.0.0.1:6379> set name zhangsan\nok\n127.0.0.1:6379> set age 18\nok\n127.0.0.1:6379> keys *\n1) "name"\n2) "age"\n127.0.0.1:6379> quit\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n将pod删除，然后再重新进入pod中，查询之前创建的redis的key，还是能够查询到。\n\n[root@k8s-worker1 zwf]# kubectl exec -it redis-pv-sts-0  -n zwf -- /bin/bash\n[ root@redis-pv-sts-0:/data ]$ redis-cli  \n127.0.0.1:6379> keys *\n1) "name"\n2) "age"\n127.0.0.1:6379> get name\n"zhangsan"\n127.0.0.1:6379> get age\n"18"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n配置的关系图如下：\n\n',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"docker容器",frontmatter:{title:"docker容器",date:"2022-08-10T00:11:29.000Z",permalink:"/pages/39f36e/",tags:["docker","云原生","容器"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"简介docker及其使用方法",feed:{enable:!0},categories:["云原生","docker"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220705193057.png"},{name:"twitter:title",content:"docker容器"},{name:"twitter:description",content:"简介docker及其使用方法"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220705193057.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/02.docker%E5%AE%B9%E5%99%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"docker容器"},{property:"og:description",content:"简介docker及其使用方法"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220705193057.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/02.docker%E5%AE%B9%E5%99%A8.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:11:29.000Z"},{property:"article:tag",content:"docker"},{property:"article:tag",content:"云原生"},{property:"article:tag",content:"容器"},{itemprop:"name",content:"docker容器"},{itemprop:"description",content:"简介docker及其使用方法"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220705193057.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/06.docker/02.docker%E5%AE%B9%E5%99%A8.html",relativePath:"01.云原生/06.docker/02.docker容器.md",key:"v-77369d13",path:"/pages/39f36e/",headers:[{level:2,title:"容器是什么？",slug:"容器是什么",normalizedTitle:"容器是什么？",charIndex:15},{level:2,title:"为什么要隔离?",slug:"为什么要隔离",normalizedTitle:"为什么要隔离?",charIndex:42},{level:2,title:"和虚拟机的区别是什么?",slug:"和虚拟机的区别是什么",normalizedTitle:"和虚拟机的区别是什么?",charIndex:100},{level:2,title:"什么是容器化应用？",slug:"什么是容器化应用",normalizedTitle:"什么是容器化应用？",charIndex:606},{level:2,title:"docker架构",slug:"docker架构",normalizedTitle:"docker架构",charIndex:840},{level:2,title:"常用镜像操作",slug:"常用镜像操作",normalizedTitle:"常用镜像操作",charIndex:1054},{level:2,title:"常用容器操作",slug:"常用容器操作",normalizedTitle:"常用容器操作",charIndex:1164},{level:2,title:"容器镜像",slug:"容器镜像",normalizedTitle:"容器镜像",charIndex:2093},{level:3,title:"镜像内部机制",slug:"镜像内部机制",normalizedTitle:"镜像内部机制",charIndex:2102},{level:2,title:"Dockerfile",slug:"dockerfile",normalizedTitle:"dockerfile",charIndex:5229},{level:2,title:"容器与外部的交互",slug:"容器与外部的交互",normalizedTitle:"容器与外部的交互",charIndex:5781},{level:2,title:"关于k8s与docker的关系",slug:"关于k8s与docker的关系",normalizedTitle:"关于k8s与docker的关系",charIndex:6584}],headersStr:"容器是什么？ 为什么要隔离? 和虚拟机的区别是什么? 什么是容器化应用？ docker架构 常用镜像操作 常用容器操作 容器镜像 镜像内部机制 Dockerfile 容器与外部的交互 关于k8s与docker的关系",content:'# docker容器\n\n\n# 容器是什么？\n\n容器，就是一个被隔离的进程。\n\n\n# 为什么要隔离?\n\n 1. 将应用程序与外界系统隔离，保证容器外系统安全\n 2. 资源隔离，只能使用指定配额\n\n\n# 和虚拟机的区别是什么?\n\n虚拟机：虚拟的是硬件，需要在上面安装操作系统才能运行应用程序。\n\n容器：共享下层的硬件和操作系统。\n\n下图是官方的图\n\n\n\n其实上图关于容器的部分并不准确，APP也就是容器并不是运行在Docker上的，Docker只是在帮助用户创建进程时添加了各种Namespace参数，容器是特殊的进程，还是运行在操作系统上的。\n\n      实现方式             优势             劣势\n虚拟机   虚拟化硬件            隔离程度非常高        资源消耗大，启动慢\n容器    直接利用下层的硬件和操作系统   资源利用率高，运行速度快   隔离程度低, 安全性低\n\n 1. 虚拟机是硬件级别的隔离，而容器化是进程间的隔离。\n\n 2. 虚拟化需要模拟硬件占用部分内存，并且对宿主机操作的系统调用需要经过虚拟化软件的拦截与转换，造成资源的开销。而容器就是一个普通的进程，基本无额外的计算资源的开销。\n\n 3. 在Linux内核中有部分的资源和对象无法namespace化，如时间。\n\n 4. 因为容器是共享宿主机内核，所以对外暴露的供给面非常的大。\n\n\n# 什么是容器化应用？\n\n镜像，就是将容器的初始化环境固化下来，将运行进程所需要的文件系统、依赖库、环境变量、启动参数等打包整合到一起，保存成一个静态的文件。\n\n容器化环境可以通过镜像快速重建容器，应用程序看到的就是一致的运行环境。\n\n容器化应用，也就是应用程序不直接与操作系统去打交道，而是将应用程序打包成镜像，再交给容器环境去运行\n\n镜像与容器的关系还可以用"序列化"和"反序列化"来理解，镜像就是序列化到磁盘的数据，而容器是反序列化后内存中的对象。\n\n\n\n\n\n\n# docker架构\n\n创建容器时，我们通过docker命令请求Docker Daemon服务，然后该服务再通过RPC请求Containerd进程，该进程会创建Containerd-shim进程，该进程会再创建RunC进程，该进程是真正创建容器的是进程，等容器创建好后，RunC会退出，容器的父进程会变成Containerd-shim，当容器结束时，Conatinerd-shim会回收容器进程的资源，以防止僵尸进程。\n\n\n\n\n# 常用镜像操作\n\n命令              作用\ndocker pull     从远端仓库拉取镜像\ndocker images   列出当前本地已有镜像\ndocker rmi      删除不再使用的镜像\n\n\n# 常用容器操作\n\n命令              作用            例子\ndocker run      使用镜像启动容器      \ndocker ps       列出正在运行的容器     \ndocker exec     在容器内执行另一个程序   \ndocker stop     停止容器          \ndocker start    将停止的容器再次启动    \ndocker rm       删除容器          \ndocker export   将容器内的文件系统导出   docker export -o rootfs.tar 容器ID\n\n容器被停止后，docker ps命令就看不到该容器了，需要使用docker ps -a来查看所有容器，包括已经停止的容器。\n\n可能会导致非常多已经停止的容器占用系统资源，所以建议docker run时添加--rm参数，在容器运行完毕时自动清除\n\ndocker exec是如何进入到容器中的?\n\n该命令会创建一个新的进程加入到容器的namepsace中。\n\n/proc/{进程ID}/ns/下的虚拟文件会链接到真实的Namespace文件上。通过查看exec创建的进程ns文件可以看出和容器的Namespace文件一致\n\n[root@k8s-master proc]# ll /proc/288948/ns/pid\nlrwxrwxrwx 1 root root 0 Jul  8 11:27 /proc/288948/ns/pid -> \'pid:[4026532247]\'\n\n[root@k8s-master proc]# ll /proc/289220/ns/pid\nlrwxrwxrwx 1 root root 0 Jul  8 11:27 /proc/289220/ns/pid -> \'pid:[4026532247]\'\n\n\n1\n2\n3\n4\n5\n\n\ndocker run和docker exec的区别是什么?\n\nrun是将镜像运行成容器并执行命令，该命令为1号进程。\n\nexec是在容器中执行一个命令，该命令是另一个进程，加入到了容器的namespace中。\n\n\n# 容器镜像\n\n\n# 镜像内部机制\n\n容器镜像内部是由许多的镜像层(Layer)组成的，每层都是只读不可修改的一组文件，相同的层可以在镜像中共享，然后多个层像搭积木叠加起来，使用**联合文件系统（UnionFS)**将它们合并起来，最终形成容器看到的文件系统。\n\n镜像中的层级是只读层，而容器所在的层级是可读写层。\n\n\n\n镜像的分层信息可以通过命令docker inspect 镜像名称获取，其中RootFs是对应的信息\n\n>>> docker inspect b3log/siyuan\n\n.....\n"RootFS": {\n            "Type": "layers",\n            "Layers": [\n                "sha256:24302eb7d9085da80f016e7e4ae55417e412fb7e0a8021e95e3b60c67cde557d",\n                "sha256:e7356c89d8c31fc628769b331f73d6e036e1d5900d2d2a3990c89ef91bce707a",\n                "sha256:90358380b9ea63cfb8832ae627455faf85596e822ff8abe9e1d7c8bbd93804ad",\n                "sha256:c6d8ffacc07d179562cd70114402e549d9fce92b12a019d3f4003eb94944d089"\n            ]\n        }\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n好处是，如果多个镜像使用了相同的层，可以直接共享，减少磁盘空间的占用。比如nginx镜像和Tomcat镜像都是用了基础镜像centos，那么该基础镜像可以共享。\n\n\n\nOverlayFS\n\n镜像层和容器是如何合并的呢？\n\n\n\nlowerdir是镜像层，upperdir是容器层，如果双方有相同文件则展示容器层的文件。\n\n在容器写文件时，会先从镜像层拷贝一份文件到容器层，然后再写入，使用的是**写时复制(copy on write)**策略\n\n例子\n\noverlay2\n├── lowerdirA\n│   ├── a     内容：AA\n│   └── b     内容：AA\n├── lowerdirB\n│   └── a     内容: BB\n├── merge\n├── upper\n└── work\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n执行以下命令使用overlay进行合并层\n\nmount -t overlay overlay -o lowerdir=lowerdirA:lowerdirB,upperdir=upper,workdir=work merge\n\n\n1\n\n\nlowerdir为镜像层，upperdir为容器层，merge目录为最终展示层。\n\n可以看到merge目录中的a文件内容lowerdirA镜像层的内容\n\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# cat merge/a \nAA\n\n\n1\n2\n\n\n当我们修改megre目录中的a文件时，可以看到upperdir目录的会生成a文件并且内容修改后的内容\n\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# ls upper/\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# echo upper > merge/a\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# ls upper/\na\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# cat upper/a\nupper\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# cat merge/a\nupper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n当删除文件merge/a时，会出现什么情况呢?\n\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# rm merge/a\nrm: remove regular file ‘merge/a’? y\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# ll lowerdirA/\ntotal 8\n-rw-r--r-- 1 root root 3 Jul 12 19:11 a\n-rw-r--r-- 1 root root 3 Jul 12 19:10 b\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]# ll upper/\ntotal 0\nc--------- 1 root root 0, 0 Jul 12 19:31 a\n[root@iZwz93q4afq8ck02cesqh4Z k8s_learn]#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n可以看出镜像层lowerdirA的文件a是不变的，而在容器层upper中的a文件类型变成了c，该文件类型，最终在展示层看不到该文件了。\n\n可以使用命令docker inspect来查看layer的路径\n\n>>> docker inspect xxx\n\n....\n"GraphDriver": {\n            "Data": {\n                "LowerDir": "/var/lib/docker/overlay2/641e486c54d15d2a8d807fd8964f4a4b8687cbcf95c176cd9a46553b1e80341d/diff:/var/lib/docker/overlay2/ed9ad4fb9d0f9bf3aea553c634e54fef89448cf43c5b662468d79f01cf41d0c3/diff:/var/lib/docker/overlay2/9db169e1ad2165f688e652ef06dfe9a3e465c31299f3c357a37a6919747efbc8/diff",\n                "MergedDir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/merged",\n                "UpperDir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/diff",\n                "WorkDir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/work"\n            },\n            "Name": "overlay2"\n        },\n....\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# Dockerfile\n\nDockerfile是一个用来创建镜像的文本文件，该文件中的每一条命令都会成生成一个layer。\n\n例子：\n\n最简单的Dockerfile的例子\n\nFROM busybox                  # 选择基础镜像\nCMD echo "hello world"        # 启动容器时默认运行的命令\n\n\n1\n2\n\n\nFROM指令是构建使用的基础镜像\n\nCMD指令是用于启动容器时默认运行的命令\n\n使用docker build 即可执行创建镜像\n\ndocker build -f Dockerfile .\n\nSending build context to Docker daemon   7.68kB\nStep 1/2 : FROM busybox\n ---\x3e d38589532d97\nStep 2/2 : CMD echo "hello world"\n ---\x3e Running in c5a762edd1c8\nRemoving intermediate container c5a762edd1c8\n ---\x3e b61882f42db7\nSuccessfully built b61882f42db7\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 容器与外部的交互\n\n如何拷贝宿主机的文件到容器内\n\n可以使用docker cp命令将宿主机的文件拷贝到容器中。\n\ndocker cp a.txt 062:/tmp\n\n\n1\n\n\n其中的062为容器ID，如果想将容器中的文件拷贝到宿主机中，反过来即可。\n\ndocker cp 062:/tmp/a.txt /tmp\n\n\n1\n\n\n注意，这里的拷贝是临时的，拷贝进容器中的文件只存在于容器中，不存在与镜像中，如果想要将文件拷贝到镜像中，在写Dockerfile时使用copy命令拷贝即可。\n\n宿主机与容器共享文件夹\n\n在使用镜像运行容器时，使用参数-v可以将宿主机中的文件夹映射到容器中，双方修改该文件夹中的内容，都可以及时看到。\n\ndocker run -d --rm -v /tmp:/tmp redis\n\n\n1\n\n\n如何实现网络互通？\n\ndocker提供三种网络模式：\n\n * null，无网络\n * host，直接使用宿主机网络，在创建容器时，使用--net=host参数。\n\n其实就是创建新的namespace，而是直接加入到宿主机的namesapce\n\ndocker run -d --rm --net=host nginx:alpine\n\n\n1\n\n * bridge，桥接模式，由软件虚拟网卡与网桥，容器和宿主机都接入该网桥，即可正常发送数据包。可以使用参数--net=bridge创建容器，但这个是默认参数。\n\ndocker run -d --rm nginx:alpine\n\n\n1\n\n\n\n\n网络模式     优点                        缺点\nhost     因为是直接使用宿主机的网络，效率更高        运行太多的容器，会导致端口发生冲突\nbridge   因为有了网桥可以设置更多的策略，比如流量控制等   需要软件模拟虚拟网卡与网桥，效率更低\n\n\n\n\n\n\n# 关于k8s与docker的关系\n\n在2014年的时候,Docker如日中天，那么k8s自然选择基于docker上运行。\n\n在2016年k8s加入了CNCF，一个开源的云原生计算基金会。\n\n并且引入了一个接口标准：CRI，Container Runtime Interface。也就是规定kubelet该如何调用Container Runtime去管理容器和镜像，但这是一套全新的接口，和之前的Docker完全不兼容。目的很明显，不想绑定Docker，可以随时将Docker踢掉。\n\n因为docker已经非常成熟，各大厂商不可能将Docker全部替换。所以k8s在kubelet和Docker中间加一个"适配器"，把Docker的接口转换成符合CRI标准的接口。\n\n\n\n什么是containerd？\n\n不过 Docker 也没有“坐以待毙”，而是采取了“断臂求生”的策略，推动自身的重构，把原本单体架构的 Docker Engine 拆分成了多个模块，其中的 Docker daemon 部分就捐献给了 CNCF，形成了 containerd。\n\ncontainerd 作为 CNCF 的托管项目，自然是要符合 CRI 标准的。但 Docker 出于自己诸多原因的考虑，它只是在 Docker Engine 里调用了 containerd，外部的接口仍然保持不变，也就是说还不与 CRI 兼容。\n\n由于 Docker 的“固执己见”，这时 Kubernetes 里就出现了两种调用链：第一种是用 CRI 接口调用 dockershim，然后 dockershim 调用 Docker，Docker 再走 containerd 去操作容器。第二种是用 CRI 接口直接调用 containerd 去操作容器。\n\n\n\n显而易见，使用第二种省去了dockershim和Docker Engine两个环节，损耗更少，性能也提升了。\n\n正式"弃用Docker"\n\n在2020年K8s弃用Docker支持，但该弃用支持弃用了"dockershim"的这个组件，也就是把dockershim移出kubelete，只是绕过Docker，直接调用了Docker内部的containerd而已。\n\n并且对docker也无影响，因为docker内部也是使用开源的containerd。\n\n\n\n唯一影响的是，k8s是直接操作containerd操作容器，那么它和docker是独立的工作环境，彼此都不能访问对方的容器和镜像，也就是docker ps看不到k8s运行的容器。改用crictl命令。\n\nDocker 重构自身，分离出 containerd，这是否算是一种“自掘坟墓”的行为呢？如果没有 containerd，那现在的情形会是怎么样的呢？\n\nDocker 是一个完整的软件产品线，不止是 containerd，它还包括了镜像构建、分发、测试等许多服务，甚至在 Docker Desktop 里还内置了 Kubernetes。\n\n> docker分离containerd是一个很聪明的举动！与其将来被人分离或者抛弃不用，不如我主动革新，把Kubernates绑在我的战车上，这样cri的第一选择仍然是docker的自己人。\n> 一时的退让是为了更好的将来。',normalizedContent:'# docker容器\n\n\n# 容器是什么？\n\n容器，就是一个被隔离的进程。\n\n\n# 为什么要隔离?\n\n 1. 将应用程序与外界系统隔离，保证容器外系统安全\n 2. 资源隔离，只能使用指定配额\n\n\n# 和虚拟机的区别是什么?\n\n虚拟机：虚拟的是硬件，需要在上面安装操作系统才能运行应用程序。\n\n容器：共享下层的硬件和操作系统。\n\n下图是官方的图\n\n\n\n其实上图关于容器的部分并不准确，app也就是容器并不是运行在docker上的，docker只是在帮助用户创建进程时添加了各种namespace参数，容器是特殊的进程，还是运行在操作系统上的。\n\n      实现方式             优势             劣势\n虚拟机   虚拟化硬件            隔离程度非常高        资源消耗大，启动慢\n容器    直接利用下层的硬件和操作系统   资源利用率高，运行速度快   隔离程度低, 安全性低\n\n 1. 虚拟机是硬件级别的隔离，而容器化是进程间的隔离。\n\n 2. 虚拟化需要模拟硬件占用部分内存，并且对宿主机操作的系统调用需要经过虚拟化软件的拦截与转换，造成资源的开销。而容器就是一个普通的进程，基本无额外的计算资源的开销。\n\n 3. 在linux内核中有部分的资源和对象无法namespace化，如时间。\n\n 4. 因为容器是共享宿主机内核，所以对外暴露的供给面非常的大。\n\n\n# 什么是容器化应用？\n\n镜像，就是将容器的初始化环境固化下来，将运行进程所需要的文件系统、依赖库、环境变量、启动参数等打包整合到一起，保存成一个静态的文件。\n\n容器化环境可以通过镜像快速重建容器，应用程序看到的就是一致的运行环境。\n\n容器化应用，也就是应用程序不直接与操作系统去打交道，而是将应用程序打包成镜像，再交给容器环境去运行\n\n镜像与容器的关系还可以用"序列化"和"反序列化"来理解，镜像就是序列化到磁盘的数据，而容器是反序列化后内存中的对象。\n\n\n\n\n\n\n# docker架构\n\n创建容器时，我们通过docker命令请求docker daemon服务，然后该服务再通过rpc请求containerd进程，该进程会创建containerd-shim进程，该进程会再创建runc进程，该进程是真正创建容器的是进程，等容器创建好后，runc会退出，容器的父进程会变成containerd-shim，当容器结束时，conatinerd-shim会回收容器进程的资源，以防止僵尸进程。\n\n\n\n\n# 常用镜像操作\n\n命令              作用\ndocker pull     从远端仓库拉取镜像\ndocker images   列出当前本地已有镜像\ndocker rmi      删除不再使用的镜像\n\n\n# 常用容器操作\n\n命令              作用            例子\ndocker run      使用镜像启动容器      \ndocker ps       列出正在运行的容器     \ndocker exec     在容器内执行另一个程序   \ndocker stop     停止容器          \ndocker start    将停止的容器再次启动    \ndocker rm       删除容器          \ndocker export   将容器内的文件系统导出   docker export -o rootfs.tar 容器id\n\n容器被停止后，docker ps命令就看不到该容器了，需要使用docker ps -a来查看所有容器，包括已经停止的容器。\n\n可能会导致非常多已经停止的容器占用系统资源，所以建议docker run时添加--rm参数，在容器运行完毕时自动清除\n\ndocker exec是如何进入到容器中的?\n\n该命令会创建一个新的进程加入到容器的namepsace中。\n\n/proc/{进程id}/ns/下的虚拟文件会链接到真实的namespace文件上。通过查看exec创建的进程ns文件可以看出和容器的namespace文件一致\n\n[root@k8s-master proc]# ll /proc/288948/ns/pid\nlrwxrwxrwx 1 root root 0 jul  8 11:27 /proc/288948/ns/pid -> \'pid:[4026532247]\'\n\n[root@k8s-master proc]# ll /proc/289220/ns/pid\nlrwxrwxrwx 1 root root 0 jul  8 11:27 /proc/289220/ns/pid -> \'pid:[4026532247]\'\n\n\n1\n2\n3\n4\n5\n\n\ndocker run和docker exec的区别是什么?\n\nrun是将镜像运行成容器并执行命令，该命令为1号进程。\n\nexec是在容器中执行一个命令，该命令是另一个进程，加入到了容器的namespace中。\n\n\n# 容器镜像\n\n\n# 镜像内部机制\n\n容器镜像内部是由许多的镜像层(layer)组成的，每层都是只读不可修改的一组文件，相同的层可以在镜像中共享，然后多个层像搭积木叠加起来，使用**联合文件系统（unionfs)**将它们合并起来，最终形成容器看到的文件系统。\n\n镜像中的层级是只读层，而容器所在的层级是可读写层。\n\n\n\n镜像的分层信息可以通过命令docker inspect 镜像名称获取，其中rootfs是对应的信息\n\n>>> docker inspect b3log/siyuan\n\n.....\n"rootfs": {\n            "type": "layers",\n            "layers": [\n                "sha256:24302eb7d9085da80f016e7e4ae55417e412fb7e0a8021e95e3b60c67cde557d",\n                "sha256:e7356c89d8c31fc628769b331f73d6e036e1d5900d2d2a3990c89ef91bce707a",\n                "sha256:90358380b9ea63cfb8832ae627455faf85596e822ff8abe9e1d7c8bbd93804ad",\n                "sha256:c6d8ffacc07d179562cd70114402e549d9fce92b12a019d3f4003eb94944d089"\n            ]\n        }\n....\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n好处是，如果多个镜像使用了相同的层，可以直接共享，减少磁盘空间的占用。比如nginx镜像和tomcat镜像都是用了基础镜像centos，那么该基础镜像可以共享。\n\n\n\noverlayfs\n\n镜像层和容器是如何合并的呢？\n\n\n\nlowerdir是镜像层，upperdir是容器层，如果双方有相同文件则展示容器层的文件。\n\n在容器写文件时，会先从镜像层拷贝一份文件到容器层，然后再写入，使用的是**写时复制(copy on write)**策略\n\n例子\n\noverlay2\n├── lowerdira\n│   ├── a     内容：aa\n│   └── b     内容：aa\n├── lowerdirb\n│   └── a     内容: bb\n├── merge\n├── upper\n└── work\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n执行以下命令使用overlay进行合并层\n\nmount -t overlay overlay -o lowerdir=lowerdira:lowerdirb,upperdir=upper,workdir=work merge\n\n\n1\n\n\nlowerdir为镜像层，upperdir为容器层，merge目录为最终展示层。\n\n可以看到merge目录中的a文件内容lowerdira镜像层的内容\n\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# cat merge/a \naa\n\n\n1\n2\n\n\n当我们修改megre目录中的a文件时，可以看到upperdir目录的会生成a文件并且内容修改后的内容\n\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# ls upper/\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# echo upper > merge/a\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# ls upper/\na\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# cat upper/a\nupper\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# cat merge/a\nupper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n当删除文件merge/a时，会出现什么情况呢?\n\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# rm merge/a\nrm: remove regular file ‘merge/a’? y\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# ll lowerdira/\ntotal 8\n-rw-r--r-- 1 root root 3 jul 12 19:11 a\n-rw-r--r-- 1 root root 3 jul 12 19:10 b\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]# ll upper/\ntotal 0\nc--------- 1 root root 0, 0 jul 12 19:31 a\n[root@izwz93q4afq8ck02cesqh4z k8s_learn]#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n可以看出镜像层lowerdira的文件a是不变的，而在容器层upper中的a文件类型变成了c，该文件类型，最终在展示层看不到该文件了。\n\n可以使用命令docker inspect来查看layer的路径\n\n>>> docker inspect xxx\n\n....\n"graphdriver": {\n            "data": {\n                "lowerdir": "/var/lib/docker/overlay2/641e486c54d15d2a8d807fd8964f4a4b8687cbcf95c176cd9a46553b1e80341d/diff:/var/lib/docker/overlay2/ed9ad4fb9d0f9bf3aea553c634e54fef89448cf43c5b662468d79f01cf41d0c3/diff:/var/lib/docker/overlay2/9db169e1ad2165f688e652ef06dfe9a3e465c31299f3c357a37a6919747efbc8/diff",\n                "mergeddir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/merged",\n                "upperdir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/diff",\n                "workdir": "/var/lib/docker/overlay2/fa3166e545a2d1811dbeecb6f1fdda96b9f97b3cd629f32a8ea378aa79b1c780/work"\n            },\n            "name": "overlay2"\n        },\n....\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# dockerfile\n\ndockerfile是一个用来创建镜像的文本文件，该文件中的每一条命令都会成生成一个layer。\n\n例子：\n\n最简单的dockerfile的例子\n\nfrom busybox                  # 选择基础镜像\ncmd echo "hello world"        # 启动容器时默认运行的命令\n\n\n1\n2\n\n\nfrom指令是构建使用的基础镜像\n\ncmd指令是用于启动容器时默认运行的命令\n\n使用docker build 即可执行创建镜像\n\ndocker build -f dockerfile .\n\nsending build context to docker daemon   7.68kb\nstep 1/2 : from busybox\n ---\x3e d38589532d97\nstep 2/2 : cmd echo "hello world"\n ---\x3e running in c5a762edd1c8\nremoving intermediate container c5a762edd1c8\n ---\x3e b61882f42db7\nsuccessfully built b61882f42db7\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 容器与外部的交互\n\n如何拷贝宿主机的文件到容器内\n\n可以使用docker cp命令将宿主机的文件拷贝到容器中。\n\ndocker cp a.txt 062:/tmp\n\n\n1\n\n\n其中的062为容器id，如果想将容器中的文件拷贝到宿主机中，反过来即可。\n\ndocker cp 062:/tmp/a.txt /tmp\n\n\n1\n\n\n注意，这里的拷贝是临时的，拷贝进容器中的文件只存在于容器中，不存在与镜像中，如果想要将文件拷贝到镜像中，在写dockerfile时使用copy命令拷贝即可。\n\n宿主机与容器共享文件夹\n\n在使用镜像运行容器时，使用参数-v可以将宿主机中的文件夹映射到容器中，双方修改该文件夹中的内容，都可以及时看到。\n\ndocker run -d --rm -v /tmp:/tmp redis\n\n\n1\n\n\n如何实现网络互通？\n\ndocker提供三种网络模式：\n\n * null，无网络\n * host，直接使用宿主机网络，在创建容器时，使用--net=host参数。\n\n其实就是创建新的namespace，而是直接加入到宿主机的namesapce\n\ndocker run -d --rm --net=host nginx:alpine\n\n\n1\n\n * bridge，桥接模式，由软件虚拟网卡与网桥，容器和宿主机都接入该网桥，即可正常发送数据包。可以使用参数--net=bridge创建容器，但这个是默认参数。\n\ndocker run -d --rm nginx:alpine\n\n\n1\n\n\n\n\n网络模式     优点                        缺点\nhost     因为是直接使用宿主机的网络，效率更高        运行太多的容器，会导致端口发生冲突\nbridge   因为有了网桥可以设置更多的策略，比如流量控制等   需要软件模拟虚拟网卡与网桥，效率更低\n\n\n\n\n\n\n# 关于k8s与docker的关系\n\n在2014年的时候,docker如日中天，那么k8s自然选择基于docker上运行。\n\n在2016年k8s加入了cncf，一个开源的云原生计算基金会。\n\n并且引入了一个接口标准：cri，container runtime interface。也就是规定kubelet该如何调用container runtime去管理容器和镜像，但这是一套全新的接口，和之前的docker完全不兼容。目的很明显，不想绑定docker，可以随时将docker踢掉。\n\n因为docker已经非常成熟，各大厂商不可能将docker全部替换。所以k8s在kubelet和docker中间加一个"适配器"，把docker的接口转换成符合cri标准的接口。\n\n\n\n什么是containerd？\n\n不过 docker 也没有“坐以待毙”，而是采取了“断臂求生”的策略，推动自身的重构，把原本单体架构的 docker engine 拆分成了多个模块，其中的 docker daemon 部分就捐献给了 cncf，形成了 containerd。\n\ncontainerd 作为 cncf 的托管项目，自然是要符合 cri 标准的。但 docker 出于自己诸多原因的考虑，它只是在 docker engine 里调用了 containerd，外部的接口仍然保持不变，也就是说还不与 cri 兼容。\n\n由于 docker 的“固执己见”，这时 kubernetes 里就出现了两种调用链：第一种是用 cri 接口调用 dockershim，然后 dockershim 调用 docker，docker 再走 containerd 去操作容器。第二种是用 cri 接口直接调用 containerd 去操作容器。\n\n\n\n显而易见，使用第二种省去了dockershim和docker engine两个环节，损耗更少，性能也提升了。\n\n正式"弃用docker"\n\n在2020年k8s弃用docker支持，但该弃用支持弃用了"dockershim"的这个组件，也就是把dockershim移出kubelete，只是绕过docker，直接调用了docker内部的containerd而已。\n\n并且对docker也无影响，因为docker内部也是使用开源的containerd。\n\n\n\n唯一影响的是，k8s是直接操作containerd操作容器，那么它和docker是独立的工作环境，彼此都不能访问对方的容器和镜像，也就是docker ps看不到k8s运行的容器。改用crictl命令。\n\ndocker 重构自身，分离出 containerd，这是否算是一种“自掘坟墓”的行为呢？如果没有 containerd，那现在的情形会是怎么样的呢？\n\ndocker 是一个完整的软件产品线，不止是 containerd，它还包括了镜像构建、分发、测试等许多服务，甚至在 docker desktop 里还内置了 kubernetes。\n\n> docker分离containerd是一个很聪明的举动！与其将来被人分离或者抛弃不用，不如我主动革新，把kubernates绑在我的战车上，这样cri的第一选择仍然是docker的自己人。\n> 一时的退让是为了更好的将来。',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"使用kubeadm安装k8s",frontmatter:{tags:["k8s","容器","云原生"],title:"使用kubeadm安装k8s",date:"2022-09-13T20:14:37.000Z",permalink:"/pages/9e17c8/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍如何使用kubeadm来搭建一个小型的k8s集群",feed:{enable:!0},categories:["云原生","k8s"],comment:!0,meta:[{name:"twitter:title",content:"使用kubeadm安装k8s"},{name:"twitter:description",content:"介绍如何使用kubeadm来搭建一个小型的k8s集群"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/11.%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85k8s.html"},{property:"og:type",content:"article"},{property:"og:title",content:"使用kubeadm安装k8s"},{property:"og:description",content:"介绍如何使用kubeadm来搭建一个小型的k8s集群"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/11.%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85k8s.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-09-13T20:14:37.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"使用kubeadm安装k8s"},{itemprop:"description",content:"介绍如何使用kubeadm来搭建一个小型的k8s集群"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/11.%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85k8s.html",relativePath:"01.云原生/07.k8s/11.使用kubeadm安装k8s.md",key:"v-8f1b0f62",path:"/pages/9e17c8/",headers:[{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:2},{level:2,title:"安装配置",slug:"安装配置",normalizedTitle:"安装配置",charIndex:44},{level:2,title:"主节点执行",slug:"主节点执行",normalizedTitle:"主节点执行",charIndex:1557},{level:2,title:"子节点加入集群",slug:"子节点加入集群",normalizedTitle:"子节点加入集群",charIndex:2189},{level:2,title:"测试",slug:"测试",normalizedTitle:"测试",charIndex:2648},{level:2,title:"常见错误",slug:"常见错误",normalizedTitle:"常见错误",charIndex:4155}],headersStr:"相关链接 安装配置 主节点执行 子节点加入集群 测试 常见错误",content:'# 相关链接\n\nkubeadm安装官网\n\nkubeadm安装k8s完整教程 ‍\n\n\n# 安装配置\n\n以下操作是每个节点都要执行的步骤\n\n 1. 配置hosts\n\n将主节点与子节点分别配置hostname如下：\n\nhostnamectl set-hostname master  # 主节点\nhostnamectl set-hostname node1   # 子节点\nhostnamectl set-hostname node2   # 子节点\n\n\n1\n2\n3\n\n\n在/etc/hosts中添加本机hostname与ip的映射关系\n\n1.1.1.1 master\n1.1.1.2 node1\n1.1.1.3 node2\n\n\n1\n2\n3\n\n 2. 关闭防火墙\n\n需要将主节点与子节点都关闭防火墙\n\nsystemctl stop firewalld\n\n\n1\n\n 3. 配置yum源\n\n在安装kubeadm之前，都需要配置yum源，创建文件/etc/yum.repos.d/kubernetes.repo\n\n[kubernetes]\nname=Kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=0\n\n\n1\n2\n3\n4\n5\n\n 4. 将 SELinux 设置为 permissive 模式（相当于将其禁用）\n\nsudo setenforce 0\nsudo sed -i \'s/^SELINUX=enforcing$/SELINUX=permissive/\' /etc/selinux/config\n\n\n1\n2\n\n 5. 安装kubeadm、kubelet、kubectl\n\nsudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n\n1\n\n 6. 安装docker并开启\n\ncurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun\nsystemctl enable --now docker\n\n\n1\n2\n\n 7. 开启kubelet\n\nsudo systemctl enable --now kubelet\n\n\n1\n\n 8. 手动配置containerd的配置\n\n自动生成的文件会使用k8s.gcr.io/pause:3.6镜像，国内无法下载，导致kubeadm初始化失败。\n\n生成 containerd 的配置文件\n\nmkdir -p /etc/containerd\ncontainerd config default > /etc/containerd/config.toml\n\n\n1\n2\n\n\n修改 SystemdCgroup 为 true\n\n# 编辑文件\nvi /etc/containerd/config.toml\n\n#更改SystemdCgroup值为true\nSystemdCgroup = true\n\n\n1\n2\n3\n4\n5\n\n\n修改 sandbox_image 值\n\n# 更改k8s.gcr.io/pause:3.6为registry.aliyuncs.com/google_containers/pause:3.7\nsandbox_image = "registry.aliyuncs.com/google_containers/pause:3.7"\n\n\n1\n2\n\n\n重启containerd\n\nsystemctl restart containerd\n\n\n1\n\n\n\n# 主节点执行\n\n 1. 使用kubedam init初始化\n\nkubeadm init --image-repository registry.aliyuncs.com/google_containers --v=5 --pod-network-cidr 10.244.0.0/16\n\n\n1\n\n 2. kubectl读取k8s授权认证文件\n\n将安全配置文件放在指定目录中，该文件时kubectl需要读取的授权文件，放在指定目录下，kubectl才能读取到并访问到k8s\n\n  mkdir -p $HOME/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config\n  sudo chown $(id -u):$(id -g) $HOME/.kube/config\n\n\n1\n2\n3\n\n\n或者放在环境变量中，kubectl会读取该环境变量中的文件\n\nvim /etc/profile\nexport KUBECONFIG=/etc/kubernetes/admin.conf\nsource /etc/profile\n\n\n1\n2\n3\n\n 3. 创建网络flannel\n\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n\n\n1\n\n\n‍\n\n\n# 子节点加入集群\n\n 1. 使用kubeadm join加入集群\n\n先在主节点使用kubeadm token create --print-join-command来获取到子节点加入主节点的命令\n\n[root@master ~]# kubeadm token create --print-join-command\nkubeadm join 172.16.16.16:6443 --token vnu6yz.4zk8f7hdorb8fpl0 --discovery-token-ca-cert-hash sha256:ca4e1e3e2afe16f592c3623f17a6b0dc9cfebd4ec459755e02f4b8db779e21d4\n\n\n1\n2\n\n\n再在子节点上执行该命令，即可加入集群\n\n 2. 将主节点的config移动到子节点\n\n子节点也需要主节点的config文件，才能通过kubectl访问集群\n\nscp ~/.kube/config node1:~/.kube/config\n\n\n1\n\n\n\n# 测试\n\n在主节点创建deployment.yaml文件如下\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app: demoapp\n  name: demo-deploy\n\nspec:\n  replicas: 10\n  selector:\n    matchLabels:\n      app: demoapp\n\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - image: ikubernetes/demoapp:v1.0\n        name: demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建控制器\n\n[root@master ~]# kubectl apply -f deployment.yaml \ndeployment.apps/demo-deploy created\n\n\n1\n2\n\n\n可以看到创建成功，并且所有的pod已经READY\n\n[root@master ~]# kubectl get deploy -n zwf\nNAME          READY   UP-TO-DATE   AVAILABLE   AGE\ndemo-deploy   10/10   10           10          3m15s\n\n\n1\n2\n3\n\n\n可以看到pod都已经创建成功。\n\n[root@master ~]# kubectl get pods -n zwf \nNAME                           READY   STATUS    RESTARTS   AGE\ndemo-deploy-55c5f88dcb-2nzbf   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-5kwc9   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-8jd9k   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-b7zjp   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-bs7tm   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-jrbzw   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-lsfff   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-mgqpq   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-wfzzb   1/1     Running   0          4m38s\ndemo-deploy-55c5f88dcb-wkbv2   1/1     Running   0          4m38s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 常见错误\n\n * kubeadm init 报错 ”unknown service runtime.v1alpha2.RuntimeService”\n\n解决：\n\nrm /etc/containerd/config.toml -f\nsystemctl restart containerd\n\n\n1\n2\n\n\n * 如果在kubeadm init中出现了失败，在解决问题后，需要执行kubeadm reset，否则会报错\n\n * Failed to create pod sandbox: rpc error: code = Unknown desc = failed to get sandbox image "k8s.gcr.io/pause:3.6": failed to pull image "k8s.gcr.io/pause:3.6": failed to pull and unpack image "k8s.gcr.io/pause:3.6": failed to resolve reference "k8s.gcr.io/pause:3.6": failed to do request: Head "https://k8s.gcr.io/v2/pause/manifests/3.6": dial tcp 74.125.23.82:443: connect: connection refused\n\n是因为拉不到k8s官方的k8s.gcr.io/pause:3.6镜像，使用主节点container配置可以解决。\n\n * kube-flannel报错：\n   \n   running-error-CrashLoopBackOff。node“k8s-master-1“podcidr not assigned\n\nhttps://blog.csdn.net/shm19990131/article/details/107115750/\n\nhttps://blog.csdn.net/anqixiang/article/details/107715591\n\n * plugin type="flannel" failed (add): failed to delegate add: failed to set bridge addr: "cni0" already has an IP address different from\n\n解决办法:\n\nsudo ifconfig cni0 down  \nsudo ip link delete cni0\n\n\n1\n2\n\n\n相关资料：\n\nhttps://blog.csdn.net/ibless/article/details/107899009',normalizedContent:'# 相关链接\n\nkubeadm安装官网\n\nkubeadm安装k8s完整教程 ‍\n\n\n# 安装配置\n\n以下操作是每个节点都要执行的步骤\n\n 1. 配置hosts\n\n将主节点与子节点分别配置hostname如下：\n\nhostnamectl set-hostname master  # 主节点\nhostnamectl set-hostname node1   # 子节点\nhostnamectl set-hostname node2   # 子节点\n\n\n1\n2\n3\n\n\n在/etc/hosts中添加本机hostname与ip的映射关系\n\n1.1.1.1 master\n1.1.1.2 node1\n1.1.1.3 node2\n\n\n1\n2\n3\n\n 2. 关闭防火墙\n\n需要将主节点与子节点都关闭防火墙\n\nsystemctl stop firewalld\n\n\n1\n\n 3. 配置yum源\n\n在安装kubeadm之前，都需要配置yum源，创建文件/etc/yum.repos.d/kubernetes.repo\n\n[kubernetes]\nname=kubernetes\nbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/\nenabled=1\ngpgcheck=0\n\n\n1\n2\n3\n4\n5\n\n 4. 将 selinux 设置为 permissive 模式（相当于将其禁用）\n\nsudo setenforce 0\nsudo sed -i \'s/^selinux=enforcing$/selinux=permissive/\' /etc/selinux/config\n\n\n1\n2\n\n 5. 安装kubeadm、kubelet、kubectl\n\nsudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes\n\n\n1\n\n 6. 安装docker并开启\n\ncurl -fssl https://get.docker.com | bash -s docker --mirror aliyun\nsystemctl enable --now docker\n\n\n1\n2\n\n 7. 开启kubelet\n\nsudo systemctl enable --now kubelet\n\n\n1\n\n 8. 手动配置containerd的配置\n\n自动生成的文件会使用k8s.gcr.io/pause:3.6镜像，国内无法下载，导致kubeadm初始化失败。\n\n生成 containerd 的配置文件\n\nmkdir -p /etc/containerd\ncontainerd config default > /etc/containerd/config.toml\n\n\n1\n2\n\n\n修改 systemdcgroup 为 true\n\n# 编辑文件\nvi /etc/containerd/config.toml\n\n#更改systemdcgroup值为true\nsystemdcgroup = true\n\n\n1\n2\n3\n4\n5\n\n\n修改 sandbox_image 值\n\n# 更改k8s.gcr.io/pause:3.6为registry.aliyuncs.com/google_containers/pause:3.7\nsandbox_image = "registry.aliyuncs.com/google_containers/pause:3.7"\n\n\n1\n2\n\n\n重启containerd\n\nsystemctl restart containerd\n\n\n1\n\n\n\n# 主节点执行\n\n 1. 使用kubedam init初始化\n\nkubeadm init --image-repository registry.aliyuncs.com/google_containers --v=5 --pod-network-cidr 10.244.0.0/16\n\n\n1\n\n 2. kubectl读取k8s授权认证文件\n\n将安全配置文件放在指定目录中，该文件时kubectl需要读取的授权文件，放在指定目录下，kubectl才能读取到并访问到k8s\n\n  mkdir -p $home/.kube\n  sudo cp -i /etc/kubernetes/admin.conf $home/.kube/config\n  sudo chown $(id -u):$(id -g) $home/.kube/config\n\n\n1\n2\n3\n\n\n或者放在环境变量中，kubectl会读取该环境变量中的文件\n\nvim /etc/profile\nexport kubeconfig=/etc/kubernetes/admin.conf\nsource /etc/profile\n\n\n1\n2\n3\n\n 3. 创建网络flannel\n\nkubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/documentation/kube-flannel.yml\n\n\n1\n\n\n‍\n\n\n# 子节点加入集群\n\n 1. 使用kubeadm join加入集群\n\n先在主节点使用kubeadm token create --print-join-command来获取到子节点加入主节点的命令\n\n[root@master ~]# kubeadm token create --print-join-command\nkubeadm join 172.16.16.16:6443 --token vnu6yz.4zk8f7hdorb8fpl0 --discovery-token-ca-cert-hash sha256:ca4e1e3e2afe16f592c3623f17a6b0dc9cfebd4ec459755e02f4b8db779e21d4\n\n\n1\n2\n\n\n再在子节点上执行该命令，即可加入集群\n\n 2. 将主节点的config移动到子节点\n\n子节点也需要主节点的config文件，才能通过kubectl访问集群\n\nscp ~/.kube/config node1:~/.kube/config\n\n\n1\n\n\n\n# 测试\n\n在主节点创建deployment.yaml文件如下\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  labels:\n    app: demoapp\n  name: demo-deploy\n\nspec:\n  replicas: 10\n  selector:\n    matchlabels:\n      app: demoapp\n\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n      - image: ikubernetes/demoapp:v1.0\n        name: demoapp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n创建控制器\n\n[root@master ~]# kubectl apply -f deployment.yaml \ndeployment.apps/demo-deploy created\n\n\n1\n2\n\n\n可以看到创建成功，并且所有的pod已经ready\n\n[root@master ~]# kubectl get deploy -n zwf\nname          ready   up-to-date   available   age\ndemo-deploy   10/10   10           10          3m15s\n\n\n1\n2\n3\n\n\n可以看到pod都已经创建成功。\n\n[root@master ~]# kubectl get pods -n zwf \nname                           ready   status    restarts   age\ndemo-deploy-55c5f88dcb-2nzbf   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-5kwc9   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-8jd9k   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-b7zjp   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-bs7tm   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-jrbzw   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-lsfff   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-mgqpq   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-wfzzb   1/1     running   0          4m38s\ndemo-deploy-55c5f88dcb-wkbv2   1/1     running   0          4m38s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 常见错误\n\n * kubeadm init 报错 ”unknown service runtime.v1alpha2.runtimeservice”\n\n解决：\n\nrm /etc/containerd/config.toml -f\nsystemctl restart containerd\n\n\n1\n2\n\n\n * 如果在kubeadm init中出现了失败，在解决问题后，需要执行kubeadm reset，否则会报错\n\n * failed to create pod sandbox: rpc error: code = unknown desc = failed to get sandbox image "k8s.gcr.io/pause:3.6": failed to pull image "k8s.gcr.io/pause:3.6": failed to pull and unpack image "k8s.gcr.io/pause:3.6": failed to resolve reference "k8s.gcr.io/pause:3.6": failed to do request: head "https://k8s.gcr.io/v2/pause/manifests/3.6": dial tcp 74.125.23.82:443: connect: connection refused\n\n是因为拉不到k8s官方的k8s.gcr.io/pause:3.6镜像，使用主节点container配置可以解决。\n\n * kube-flannel报错：\n   \n   running-error-crashloopbackoff。node“k8s-master-1“podcidr not assigned\n\nhttps://blog.csdn.net/shm19990131/article/details/107115750/\n\nhttps://blog.csdn.net/anqixiang/article/details/107715591\n\n * plugin type="flannel" failed (add): failed to delegate add: failed to set bridge addr: "cni0" already has an ip address different from\n\n解决办法:\n\nsudo ifconfig cni0 down  \nsudo ip link delete cni0\n\n\n1\n2\n\n\n相关资料：\n\nhttps://blog.csdn.net/ibless/article/details/107899009',charsets:{cjk:!0},lastUpdated:"2023/01/15, 20:17:10",lastUpdatedTimestamp:167378503e4},{title:"pod中将代码与运行环境分离",frontmatter:{title:"pod中将代码与运行环境分离",date:"2022-11-14T09:56:31.000Z",permalink:"/pages/27987d/",tags:["k8s","容器","云原生"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。",categories:["云原生","k8s"],comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20221114095752.png"},{name:"twitter:title",content:"pod中将代码与运行环境分离"},{name:"twitter:description",content:"我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20221114095752.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/12.pod%E4%B8%AD%E5%B0%86%E4%BB%A3%E7%A0%81%E4%B8%8E%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E5%88%86%E7%A6%BB.html"},{property:"og:type",content:"article"},{property:"og:title",content:"pod中将代码与运行环境分离"},{property:"og:description",content:"我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20221114095752.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/12.pod%E4%B8%AD%E5%B0%86%E4%BB%A3%E7%A0%81%E4%B8%8E%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E5%88%86%E7%A6%BB.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-11-14T09:56:31.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{itemprop:"name",content:"pod中将代码与运行环境分离"},{itemprop:"description",content:"我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20221114095752.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/12.pod%E4%B8%AD%E5%B0%86%E4%BB%A3%E7%A0%81%E4%B8%8E%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83%E5%88%86%E7%A6%BB.html",relativePath:"01.云原生/07.k8s/12.pod中将代码与运行环境分离.md",key:"v-f08b0a92",path:"/pages/27987d/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 思路",slug:"_1-思路",normalizedTitle:"1. 思路",charIndex:171},{level:2,title:"2. 案例",slug:"_2-案例",normalizedTitle:"2. 案例",charIndex:337},{level:3,title:"2.1 创建代码镜像",slug:"_2-1-创建代码镜像",normalizedTitle:"2.1 创建代码镜像",charIndex:347},{level:3,title:"2.2 创建 python 运行环境",slug:"_2-2-创建-python-运行环境",normalizedTitle:"2.2 创建 python 运行环境",charIndex:802},{level:3,title:"2.3 容器编排",slug:"_2-3-容器编排",normalizedTitle:"2.3 容器编排",charIndex:1078},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:2797}],headersStr:"0. 前言 1. 思路 2. 案例 2.1 创建代码镜像 2.2 创建 python 运行环境 2.3 容器编排 3. 总结",content:'# 0. 前言\n\n我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。\n\n现在有个需求就是将 python 环境和代码分别构造成两个镜像，让他们进行解耦，并且将他们编排在一个 pod 中。\n\n本文介绍如何将 pod 中的代码与运行的环境进行拆分。\n\n\n# 1. 思路\n\n首先我们将代码打包成镜像 A，再将 python 运行环境打包成镜像 B，通过编排在 Pod 中的 InitContainer 设置为镜像 A，并将其内的代码拷贝到挂载的 emptyDir 存储卷中，然后在镜像 B 中挂载相同的存储卷，在使用运行环境中的 python 去执行存储卷中拷贝过来的代码即可。\n\n\n\n\n# 2. 案例\n\n\n# 2.1 创建代码镜像\n\n先创建一个简单的 python web 程序 main.py\n\nfrom flask import Flask\n\napp = Flask(__name__)\n\n\n@app.route("/")\ndef hello_world():\n    return "Hello, World!"\n\napp.run(host="0.0.0.0")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n我们再创建包含代码镜像的 Dockerfile，做的事情是将 main.py 文件拷贝到镜像的根目录下，文件命名为Dockerfile_code\n\nFROM busybox:latest\nCOPY main.py /\n\n\n1\n2\n\n\n我们通过 docker build 开始创建镜像，镜像名称为 demo_code，默认 tag为 latest\n\ndocker build . -t "demo_code" -f Dockerfile_code\n\n\n1\n\n\n这个时候我们的代码镜像创建好了。\n\n\n# 2.2 创建 python 运行环境\n\n我们开始创建 python 运行环境镜像的 Dockerfile，以 python3 的镜像为基础，并安装 flask 库，文件名为 Dockerfile_runtime\n\nFROM python:3\nRUN pip install flask\n\n\n1\n2\n\n\n再构建一下这个镜像，镜像名为 demo_runtime，默认 tag 是 latest\n\ndocker build . -t "demo_runtime" -f Dockerfile_runtime\n\n\n1\n\n\n这个时候，两个镜像都已准备好\n\n\n# 2.3 容器编排\n\n创建 deployments.yaml 文件，在 Pod 中的 initContainers 中配置代码镜像, 然后挂载临时存储卷，将代码复制到存储卷中。\n\n然后再配置应用容器 python 运行环境，挂载上面相同的临时存储卷，然后再使用 python 将代码运行。\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demo\n  labels:\n    app: demo\nspec:\n  selector:\n    matchLabels:\n      app: demo\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      initContainers:\n        - image: demo_code:latest\n          name: code\n          imagePullPolicy: IfNotPresent\n          volumeMounts:\n          - mountPath: /opt/demo\n            name: app-volume\n          command: ["cp", "/main.py", "/opt/demo/"]\n      containers:\n        - name: runtime\n          image: demo_runtime:latest\n          imagePullPolicy: IfNotPresent\n          ports:\n            - containerPort: 5000\n              hostPort: 5000\n              protocol: TCP\n              name: http\n          volumeMounts:\n            - mountPath: /opt/demo\n              name: app-volume\n          command: ["python", "/opt/demo/main.py"]\n      volumes:\n      - name: app-volume\n        emptyDir: { }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n我们通过 kubectl apply 创建 deployments\n\nkubectl apply -f deployments.yaml\n\n\n1\n\n\n我们通过 kubectl get pods 可以看到 pod 已经创建成功，然后找到 pod 所在的节点。通过节点 ip+端口即可访问到容器的中接口。\n\n[root@k8s-master-07rf9 test]# kubectl get pods -o wide\nNAME                    READY   STATUS    RESTARTS   AGE     IP               NODE               NOMINATED NODE   READINESS GATES\ndemo-6f49db5d6c-25vss   1/1     Running   0          4m58s   10.244.132.130   k8s-master-07rf9   <none>           <none>\n\n\n[root@k8s-master-07rf9 test]# curl 10.65.132.187:5000\nHello, World!\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 3. 总结\n\n本文的编排方式只是 pod 的设计模式的一种。有兴趣的可以了解更多。\n\n通过这种方式可以让代码与运行环境解耦，当我们更新代码时，并不会影响到运行环境。',normalizedContent:'# 0. 前言\n\n我们在创建一个 python 的 web 服务的镜像时，一般的做法是，将 python 环境与代码打包成一个镜像，然后将这个镜像进行发布。\n\n现在有个需求就是将 python 环境和代码分别构造成两个镜像，让他们进行解耦，并且将他们编排在一个 pod 中。\n\n本文介绍如何将 pod 中的代码与运行的环境进行拆分。\n\n\n# 1. 思路\n\n首先我们将代码打包成镜像 a，再将 python 运行环境打包成镜像 b，通过编排在 pod 中的 initcontainer 设置为镜像 a，并将其内的代码拷贝到挂载的 emptydir 存储卷中，然后在镜像 b 中挂载相同的存储卷，在使用运行环境中的 python 去执行存储卷中拷贝过来的代码即可。\n\n\n\n\n# 2. 案例\n\n\n# 2.1 创建代码镜像\n\n先创建一个简单的 python web 程序 main.py\n\nfrom flask import flask\n\napp = flask(__name__)\n\n\n@app.route("/")\ndef hello_world():\n    return "hello, world!"\n\napp.run(host="0.0.0.0")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n我们再创建包含代码镜像的 dockerfile，做的事情是将 main.py 文件拷贝到镜像的根目录下，文件命名为dockerfile_code\n\nfrom busybox:latest\ncopy main.py /\n\n\n1\n2\n\n\n我们通过 docker build 开始创建镜像，镜像名称为 demo_code，默认 tag为 latest\n\ndocker build . -t "demo_code" -f dockerfile_code\n\n\n1\n\n\n这个时候我们的代码镜像创建好了。\n\n\n# 2.2 创建 python 运行环境\n\n我们开始创建 python 运行环境镜像的 dockerfile，以 python3 的镜像为基础，并安装 flask 库，文件名为 dockerfile_runtime\n\nfrom python:3\nrun pip install flask\n\n\n1\n2\n\n\n再构建一下这个镜像，镜像名为 demo_runtime，默认 tag 是 latest\n\ndocker build . -t "demo_runtime" -f dockerfile_runtime\n\n\n1\n\n\n这个时候，两个镜像都已准备好\n\n\n# 2.3 容器编排\n\n创建 deployments.yaml 文件，在 pod 中的 initcontainers 中配置代码镜像, 然后挂载临时存储卷，将代码复制到存储卷中。\n\n然后再配置应用容器 python 运行环境，挂载上面相同的临时存储卷，然后再使用 python 将代码运行。\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  name: demo\n  labels:\n    app: demo\nspec:\n  selector:\n    matchlabels:\n      app: demo\n  template:\n    metadata:\n      labels:\n        app: demo\n    spec:\n      initcontainers:\n        - image: demo_code:latest\n          name: code\n          imagepullpolicy: ifnotpresent\n          volumemounts:\n          - mountpath: /opt/demo\n            name: app-volume\n          command: ["cp", "/main.py", "/opt/demo/"]\n      containers:\n        - name: runtime\n          image: demo_runtime:latest\n          imagepullpolicy: ifnotpresent\n          ports:\n            - containerport: 5000\n              hostport: 5000\n              protocol: tcp\n              name: http\n          volumemounts:\n            - mountpath: /opt/demo\n              name: app-volume\n          command: ["python", "/opt/demo/main.py"]\n      volumes:\n      - name: app-volume\n        emptydir: { }\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n我们通过 kubectl apply 创建 deployments\n\nkubectl apply -f deployments.yaml\n\n\n1\n\n\n我们通过 kubectl get pods 可以看到 pod 已经创建成功，然后找到 pod 所在的节点。通过节点 ip+端口即可访问到容器的中接口。\n\n[root@k8s-master-07rf9 test]# kubectl get pods -o wide\nname                    ready   status    restarts   age     ip               node               nominated node   readiness gates\ndemo-6f49db5d6c-25vss   1/1     running   0          4m58s   10.244.132.130   k8s-master-07rf9   <none>           <none>\n\n\n[root@k8s-master-07rf9 test]# curl 10.65.132.187:5000\nhello, world!\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 3. 总结\n\n本文的编排方式只是 pod 的设计模式的一种。有兴趣的可以了解更多。\n\n通过这种方式可以让代码与运行环境解耦，当我们更新代码时，并不会影响到运行环境。',charsets:{cjk:!0},lastUpdated:"2023/02/07, 09:44:40",lastUpdatedTimestamp:167573428e4},{title:"django后端服务、logstash和flink接入VictoriaMetrics指标监控",frontmatter:{title:"django后端服务、logstash和flink接入VictoriaMetrics指标监控",date:"2023-02-21T11:05:03.000Z",permalink:"/pages/b1b4a3/",categories:["云原生","k8s"],tags:[null],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230221110733.png"},{name:"twitter:title",content:"django后端服务、logstash和flink接入VictoriaMetrics指标监控"},{name:"twitter:description",content:"通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230221110733.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/13.django%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%E3%80%81logstash%E5%92%8Cflink%E6%8E%A5%E5%85%A5VictoriaMetrics%E6%8C%87%E6%A0%87%E7%9B%91%E6%8E%A7.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django后端服务、logstash和flink接入VictoriaMetrics指标监控"},{property:"og:description",content:"通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230221110733.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/13.django%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%E3%80%81logstash%E5%92%8Cflink%E6%8E%A5%E5%85%A5VictoriaMetrics%E6%8C%87%E6%A0%87%E7%9B%91%E6%8E%A7.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-02-21T11:05:03.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"django后端服务、logstash和flink接入VictoriaMetrics指标监控"},{itemprop:"description",content:"通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230221110733.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/13.django%E5%90%8E%E7%AB%AF%E6%9C%8D%E5%8A%A1%E3%80%81logstash%E5%92%8Cflink%E6%8E%A5%E5%85%A5VictoriaMetrics%E6%8C%87%E6%A0%87%E7%9B%91%E6%8E%A7.html",relativePath:"01.云原生/07.k8s/13.django后端服务、logstash和flink接入VictoriaMetrics指标监控.md",key:"v-0fd01db7",path:"/pages/b1b4a3/",headers:[{level:2,title:"0.简介",slug:"_0-简介",normalizedTitle:"0.简介",charIndex:2},{level:2,title:"1.VictoriaMetrics",slug:"_1-victoriametrics",normalizedTitle:"1.victoriametrics",charIndex:172},{level:2,title:"2.django 服务接入",slug:"_2-django-服务接入",normalizedTitle:"2.django 服务接入",charIndex:376},{level:2,title:"3.logstash 接入",slug:"_3-logstash-接入",normalizedTitle:"3.logstash 接入",charIndex:799},{level:2,title:"4.flink 接入监控",slug:"_4-flink-接入监控",normalizedTitle:"4.flink 接入监控",charIndex:1515},{level:2,title:"5.VMPodScrape",slug:"_5-vmpodscrape",normalizedTitle:"5.vmpodscrape",charIndex:1844}],headersStr:"0.简介 1.VictoriaMetrics 2.django 服务接入 3.logstash 接入 4.flink 接入监控 5.VMPodScrape",content:'# 0.简介\n\n通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。\n\n背景：使用的 VictoriaMetrics(简称 VM) 作为监控的解决方案，需要将 django 服务、logstash 和 flink 引擎接入进来，VM 可以实时的获取它们的指标存储并进行监控告警，以上的服务都是部署在 k8s 中的。\n\n\n# 1.VictoriaMetrics\n\nVictoriaMetrics，是一个快速高效、经济并且可扩展的监控解决方案和时序数据库。比较出名的监控方案有 Promethues，而 VM 是兼容 Promethues 的各种规范、配置等，可以快速的融入 Promethues 生态甚至是取代它。\n\nVM 获取服务指标的方式也是通过主动拉取的方式，每个服务都会暴露一个端口供 VM 来拉取服务的指标信息\n\n\n\n\n# 2.django 服务接入\n\n可以通过使用第三方库 prometheus-client 来收集服务的指标信息，并暴露端口给 VM 拉取。\n\n * 安装\n\npip install prometheus-client\n\n\n1\n\n * 使用\n\n因为该服务使用的是 wsgi 协议的，所以在 wsgi.py 文件中添加以下代码，会开启一个新的线程监听 9300 端口，请求该端口可以获取当前服务的参数指标。\n\nfrom prometheus_client import start_wsgi_server\nstart_wsgi_server(9300)\n\n\n1\n2\n\n\n如果想要上报业务指标，可以通过该库在业务中进行埋点和收集。\n\n还需要在 pod 中添加 ports 属性提供给 VM 使用，这个在后面讲解。\n\n- containerPort: 9300\n  name: exportport\n  protocol: TCP\n\n\n1\n2\n3\n\n\n\n# 3.logstash 接入\n\nlogstash 是有自己的指标监控服务，需要在配置文件 logstash.yaml 中将其端口暴露。\n\nhttp.port: 9600\n\n\n1\n\n\n但是其指标格式和 prometheus 的指标格式是不同的，所以需要通过另一个程序 exporter 来将 logstash 指标转换成 prometheus 指标格式。\n\n该 logstash 是部署在 k8s 中的，使用到容器设计模式 sidecar，就是在 pod 中新增一个容器来辅助主容器 logstash 来做监控指标的转换并提供给 VM 调用。\n\n\n\nlogstash 的 exporter 可以使用 prometheus-logstash-exporter 来完成，可以去 docker hub 中找到对应的镜像，并将其下载下来使用。\n\n在 logstash 的 pod 中添加以下配置来设置 exporter，将暴露 9300 端口作为 logstash 的指标监控端口给 VM 拉取。这里需要配置 ports，在 VM 中需要使用该参数。\n\n- name: logstash-exporter\nimage: alxrem/prometheus-logstash-exporter:0.7.0\nargs:\n- -logstash.host\n- 127.0.0.1\n- -logstash.port\n- 9600\n- -web.listen-address\n- 9300\nports:\n- name: exportport\n  containerPort: 9300\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 4.flink 接入监控\n\nflink 本身是支持 prometheus 的指标监控，只需要通过添加配置 flink 的参数即可开启。\n\n  metrics.reporters: prom\n  metrics.reporter.prom.class: org.apache.flink.metrics.prometheus.PrometheusReporter\n  metrics.reporter.prom.port: "9300"\n\n\n1\n2\n3\n\n\n除了上面的配置外，还需要在 Pod 中设置 ports 来供 VM 使用。\n\nports:\n  - name: exportport\n\tcontainerPort: 9300\n\n\n1\n2\n3\n\n\n\n# 5.VMPodScrape\n\n虽然上面的服务都暴露了指标端口，VM 如何找到它们呢？需要通过创建 VMPodScrape 的资源对象来帮助 VM 来找到它们。\n\n配置如下：\n\napiVersion: operator.victoriametrics.com/v1beta1\nkind: VMPodScrape\nmetadata:\n  labels:\n    prometheus: k8s\n  name: demo-pod-monitor          \n  namespace: monitor\nspec:\n  namespaceSelector:\n    any: true                   \n  podMetricsEndpoints:\n    - path: /metrics            \n      port: exportport          \n  selector:\n    matchLabels:\n      app: django\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n * spec.podMetricsEndpoints.port，这个就是在每个 pod 中添加的 ports 中对应的 name，VM 会去找到对应 name 的端口获取指标\n * spec.selector.matchLabels，通过标签过滤找到指定的 pod\n\n通过 kubectl apply -f 创建该资源对象，VM 就能找到指标提供的服务。',normalizedContent:'# 0.简介\n\n通过指标监控可以设置对应的告警，快速发现问题，并通过相应的指标定位问题。\n\n背景：使用的 victoriametrics(简称 vm) 作为监控的解决方案，需要将 django 服务、logstash 和 flink 引擎接入进来，vm 可以实时的获取它们的指标存储并进行监控告警，以上的服务都是部署在 k8s 中的。\n\n\n# 1.victoriametrics\n\nvictoriametrics，是一个快速高效、经济并且可扩展的监控解决方案和时序数据库。比较出名的监控方案有 promethues，而 vm 是兼容 promethues 的各种规范、配置等，可以快速的融入 promethues 生态甚至是取代它。\n\nvm 获取服务指标的方式也是通过主动拉取的方式，每个服务都会暴露一个端口供 vm 来拉取服务的指标信息\n\n\n\n\n# 2.django 服务接入\n\n可以通过使用第三方库 prometheus-client 来收集服务的指标信息，并暴露端口给 vm 拉取。\n\n * 安装\n\npip install prometheus-client\n\n\n1\n\n * 使用\n\n因为该服务使用的是 wsgi 协议的，所以在 wsgi.py 文件中添加以下代码，会开启一个新的线程监听 9300 端口，请求该端口可以获取当前服务的参数指标。\n\nfrom prometheus_client import start_wsgi_server\nstart_wsgi_server(9300)\n\n\n1\n2\n\n\n如果想要上报业务指标，可以通过该库在业务中进行埋点和收集。\n\n还需要在 pod 中添加 ports 属性提供给 vm 使用，这个在后面讲解。\n\n- containerport: 9300\n  name: exportport\n  protocol: tcp\n\n\n1\n2\n3\n\n\n\n# 3.logstash 接入\n\nlogstash 是有自己的指标监控服务，需要在配置文件 logstash.yaml 中将其端口暴露。\n\nhttp.port: 9600\n\n\n1\n\n\n但是其指标格式和 prometheus 的指标格式是不同的，所以需要通过另一个程序 exporter 来将 logstash 指标转换成 prometheus 指标格式。\n\n该 logstash 是部署在 k8s 中的，使用到容器设计模式 sidecar，就是在 pod 中新增一个容器来辅助主容器 logstash 来做监控指标的转换并提供给 vm 调用。\n\n\n\nlogstash 的 exporter 可以使用 prometheus-logstash-exporter 来完成，可以去 docker hub 中找到对应的镜像，并将其下载下来使用。\n\n在 logstash 的 pod 中添加以下配置来设置 exporter，将暴露 9300 端口作为 logstash 的指标监控端口给 vm 拉取。这里需要配置 ports，在 vm 中需要使用该参数。\n\n- name: logstash-exporter\nimage: alxrem/prometheus-logstash-exporter:0.7.0\nargs:\n- -logstash.host\n- 127.0.0.1\n- -logstash.port\n- 9600\n- -web.listen-address\n- 9300\nports:\n- name: exportport\n  containerport: 9300\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 4.flink 接入监控\n\nflink 本身是支持 prometheus 的指标监控，只需要通过添加配置 flink 的参数即可开启。\n\n  metrics.reporters: prom\n  metrics.reporter.prom.class: org.apache.flink.metrics.prometheus.prometheusreporter\n  metrics.reporter.prom.port: "9300"\n\n\n1\n2\n3\n\n\n除了上面的配置外，还需要在 pod 中设置 ports 来供 vm 使用。\n\nports:\n  - name: exportport\n\tcontainerport: 9300\n\n\n1\n2\n3\n\n\n\n# 5.vmpodscrape\n\n虽然上面的服务都暴露了指标端口，vm 如何找到它们呢？需要通过创建 vmpodscrape 的资源对象来帮助 vm 来找到它们。\n\n配置如下：\n\napiversion: operator.victoriametrics.com/v1beta1\nkind: vmpodscrape\nmetadata:\n  labels:\n    prometheus: k8s\n  name: demo-pod-monitor          \n  namespace: monitor\nspec:\n  namespaceselector:\n    any: true                   \n  podmetricsendpoints:\n    - path: /metrics            \n      port: exportport          \n  selector:\n    matchlabels:\n      app: django\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n * spec.podmetricsendpoints.port，这个就是在每个 pod 中添加的 ports 中对应的 name，vm 会去找到对应 name 的端口获取指标\n * spec.selector.matchlabels，通过标签过滤找到指定的 pod\n\n通过 kubectl apply -f 创建该资源对象，vm 就能找到指标提供的服务。',charsets:{cjk:!0},lastUpdated:"2023/02/21, 11:15:06",lastUpdatedTimestamp:1676949306e3},{title:"理解calico容器网络通信方案原理",frontmatter:{title:"理解calico容器网络通信方案原理",date:"2023-06-03T11:04:25.000Z",permalink:"/pages/f0f725/",categories:["云原生","k8s"],tags:["k8s","容器","云原生","计算机网络","Linux网络虚拟化"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"Calico是k8s中常用的容器解决方案的插件，本文主要介绍BGP模式和IPIP模式是如何解决的，并详细了解其原理，并通过实验加深理解。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_calico.png"},{name:"twitter:title",content:"理解calico容器网络通信方案原理"},{name:"twitter:description",content:"Calico是k8s中常用的容器解决方案的插件，本文主要介绍BGP模式和IPIP模式是如何解决的，并详细了解其原理，并通过实验加深理解。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_calico.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/15.%E7%90%86%E8%A7%A3calico%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"理解calico容器网络通信方案原理"},{property:"og:description",content:"Calico是k8s中常用的容器解决方案的插件，本文主要介绍BGP模式和IPIP模式是如何解决的，并详细了解其原理，并通过实验加深理解。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_calico.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/15.%E7%90%86%E8%A7%A3calico%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-06-03T11:04:25.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"Linux网络虚拟化"},{itemprop:"name",content:"理解calico容器网络通信方案原理"},{itemprop:"description",content:"Calico是k8s中常用的容器解决方案的插件，本文主要介绍BGP模式和IPIP模式是如何解决的，并详细了解其原理，并通过实验加深理解。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_calico.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/15.%E7%90%86%E8%A7%A3calico%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html",relativePath:"01.云原生/07.k8s/15.理解calico容器网络通信方案原理.md",key:"v-11e81284",path:"/pages/f0f725/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 介绍Calico",slug:"_1-介绍calico",normalizedTitle:"1. 介绍calico",charIndex:82},{level:2,title:"2. Calio架构",slug:"_2-calio架构",normalizedTitle:"2. calio架构",charIndex:585},{level:2,title:"3. BGP模式",slug:"_3-bgp模式",normalizedTitle:"3. bgp模式",charIndex:1154},{level:2,title:"4. 手动模拟BGP模式实验",slug:"_4-手动模拟bgp模式实验",normalizedTitle:"4. 手动模拟bgp模式实验",charIndex:1397},{level:3,title:"4.1 操作",slug:"_4-1-操作",normalizedTitle:"4.1 操作",charIndex:1418},{level:3,title:"4.2 分析",slug:"_4-2-分析",normalizedTitle:"4.2 分析",charIndex:3211},{level:2,title:"5. IPIP隧道模式",slug:"_5-ipip隧道模式",normalizedTitle:"5. ipip隧道模式",charIndex:5636}],headersStr:"0. 前言 1. 介绍Calico 2. Calio架构 3. BGP模式 4. 手动模拟BGP模式实验 4.1 操作 4.2 分析 5. IPIP隧道模式",content:"# 0. 前言\n\nCalico是k8s中常用的容器解决方案的插件，本文主要介绍BGP模式和IPIP模式是如何解决的，并详细了解其原理，并通过实验加深理解。\n\n\n# 1. 介绍Calico\n\nCalico是属于纯3层的网络模型，每个容器都通过IP直接通信，中间通过路由转发找到对方。容器所在的节点类似于传统的路由器，提供了路由查找的功能。每个容器所在的主机节点扮演了虚拟路由器 （vRouter）的功能，vRouter必须有某种方法，能够知道整个集群的路由信息。\n\n之前提到的FlannelHost Gateway模式方案是不能跨二层网络，是因为它只能修改主机路由，Calico把改路由表的做法换成了标准的BGP路由协议。相当于在每个节点上模拟出一个额外的路由器，由于采用的是标准协议，Calico模拟路由器的路由表信息可以被传播到网络的其他路由设备中，这样就实现了在三层网络上的高速跨节点网络。\n\n> BGP（Border Gateway Protocol）是一种用于在互联网中交换路由信息的协议。它是一种自治系统（AS）之间的路由协议，用于在不同的自治系统之间交换路由信息。BGP协议的主要作用是将路由信息从一个自治系统传递到另一个自治系统，以便实现互联网的全球路由。\n\n但现实中的网络并不一定支持BGP路由，在这种情况下可以使用IPIP隧道模式来传输数据。\n\n\n# 2. Calio架构\n\n\n\nFelix\n\nFelix是一个守护程序，作为agent运行在托管容器或虚拟机的Calico节点上。Felix负责刷新主机路由和ACL规则等，以便为该主机上的Endpoint正常运行提供所需的网络连接和管理。进出容器、虚拟机和物理主机的所有流量都会遍历Calico，利用Linux内核原生的路由和iptables生成的规则。\n\nBGP Client\n\nCalico在每个运行Felix服务的节点上都部署一个BGP Client（BGP客户端）。BGP客户端的作用是读取Felix编写到内核中的路由信息，由BGP客户端对这些路由信息进行分发。当Felix将路由插入Linux内核时，BGP客户端将接收它们，并将它们分发到集群中的其他工作节点。\n\nNode-to-Node Mesh\n\n该模式为默认模式，在BGP下，集群中的每一个节点的BGP Client都需要和其他所有节点的BGP Client进行通信来交换路由。\n但随着节点数量增加，连接数会以N^2规模增加，给集群网络带来巨大的压力。\n\nBGP Route Reflector\n\nCalico会指定几个节点负责专门跟其他所有节点进行连接并交换路由信息，从而学习到全局的路由信息。而其他节点也只需要跟这几个节点进行通信来获取到整个集群的规则信息。\n\n\n\n\n# 3. BGP模式\n\n\n\n每个容器都会创建一对veth pair网卡，一端放在容器内部，另一端放在宿主机中，容器中发送的IP包通过veth pair网卡可以达到宿主机的网络协议栈中。\n\nFelix会通过监听etcd来获取其他节点的相关信息，然后添加本地路由：\n\n 1. 通往其他节点容器的IP包下一条到其节点物理网卡中。\n 2. 通过本机节点容器的IP包到calixxx网卡中，然后进入到容器中。\n\nBGP Client会读取Felix写入到本地的路由，再通过进行分发到网络中。\n\n\n# 4. 手动模拟BGP模式实验\n\n\n\n\n# 4.1 操作\n\n首先在Node1中创建Network Namespace命名为net1\n\nip netns add net1\n\n\n1\n\n\n然后创建一对veth pair设备veth0和veth1，将veth0放到net1中，拉起并设置好ip地址172.19.1.2/24，veth1也拉取但不用设置IP地址，但需要设置默认的MAC地址为ee:ee:ee:ee:ee:ee\n\nip link add veth0 type veth peer name veth1\nip link set dev veth0 netns net1\nip netns exec net1 ip link set veth0 up\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\n\nip link set dev veth1 up\nip link set dev veth1 address ee:ee:ee:ee:ee:ee\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\nnet1配置的路由有点意思，和一般配置的路由不同，所有的报文都需要通过veth0设备发送到下一跳的地址为169.254.1.1，而这个地址在整个平台找是不存在的，这是一个默认的网关，那如何达到该地址呢？\n\nip netns exec net1 ip r a 169.254.1.1 dev veth0 \nip netns exec net1 ip r a default via 169.254.1.1 dev veth0 \n\n\n1\n2\n\n\n通过设置veth1设备proxy_arp，可以对于任何ARP请求到达veth1时，都响应自己的Mac地址，也就是ee:ee:ee:ee:ee:ee\n\n当访问网关的时候，首先是需要进行ARP请求，请求通过veth0设备达到了veth1中，因为设置proxy_arp，会将自身的mac地址ee:ee:ee:ee:ee:ee作为arp回复。\n\n而容器的后续报文目的IP地址是目的容器的IP地址，而mac地址变成了网关MAC地址ee:ee:ee:ee:ee:ee，而网关的IP地址并不会出现在任何的数据包中，也没人关心这个具体的地址是什么，只要能找到arp就行。\n\necho 1 > /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n\n\n数据包已经从net1中通过veth1作为网关达到宿主机的网络协议栈中，再通过设置宿主机路由表，将目的地址为Node2容器网段的数据包通过Node2 ens18网卡地址作为下一跳地址。\n\nip r add 172.19.2.0/24 via 10.65.132.188 dev ens18\n\n\n1\n\n\n目的地址为Node1的net1时，需要配置通过路由表到达veth1网卡，然后再进入到net1中。\n\nip r add 172.19.1.2 dev veth1\n\n\n1\n\n\n再在Node2中重复Node1的操作创建Network Namespace net2，并初始化网络配置。\n\nip netns add net2\nip link add veth0 type veth peer name veth1\nip link set dev veth0 netns net2\nip netns exec net2 ip addr add 172.19.2.2/24 dev veth0 \nip netns exec net2 ip link set veth0 up\n\nip link set dev veth1 up\nip link set dev veth1 address ee:ee:ee:ee:ee:ee\n\nip netns exec net2 ip r a 169.254.1.1 dev veth0 \nip netns exec net2 ip r a default via 169.254.1.1 dev veth0 \nip r add 172.19.1.0/24 via 10.65.132.187 dev ens18\nip r add 172.19.2.2/32 dev veth1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 4.2 分析\n\n在Node1 net1中ping Node2 net2，然后使用tcpdump监听Node1的veth1，结果如下：\n\n# tcpdump -i veth1 -ne\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes\n10:38:29.713322 02:1c:9c:83:87:f2 > Broadcast, ethertype ARP (0x0806), length 42: Request who-has 169.254.1.1 tell 172.19.1.2, length 28\n10:38:30.205862 ee:ee:ee:ee:ee:ee > 02:1c:9c:83:87:f2, ethertype ARP (0x0806), length 42: Reply 169.254.1.1 is-at ee:ee:ee:ee:ee:ee, length 28\n10:38:30.205922 02:1c:9c:83:87:f2 > ee:ee:ee:ee:ee:ee, ethertype IPv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: ICMP echo request, id 37475, seq 1, length 64\n10:38:30.206393 ee:ee:ee:ee:ee:ee > 02:1c:9c:83:87:f2, ethertype IPv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: ICMP echo reply, id 37475, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n可以看到，先是发送arp请求获取172.19.1.2的mac地址，因为设置了proxy_arp，所以会将自身的Mac地址进行回复，在后面的ICMP包中，目的IP地址为目的容器IP地址172.19.2.2，而目的Mac地址为veth1的Mac地址ee:ee:ee:ee:ee:ee\n\n再使用tcpdump监听Node2的ens18网卡，结果如下：\n\n# tcpdump -i ens18 host 172.19.2.2 -en\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n10:52:43.993140 fa:16:3e:d3:f6:3a > fa:16:3e:b1:9a:65, ethertype IPv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: ICMP echo request, id 4349, seq 1, length 64\n10:52:43.993291 fa:16:3e:b1:9a:65 > fa:16:3e:d3:f6:3a, ethertype IPv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: ICMP echo reply, id 4349, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n数据包从Node1中到达了Node2 ens18网卡，源IP和目的IP分别为net1和net2的IP地址，而mac地址是Node1和Node2的物理网卡ens18 Mac地址.\n\n使用tcpdump监听veth1网卡，结果如下：\n\n# tcpdump -i veth1 -en\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on veth1, link-type EN10MB (Ethernet), capture size 262144 bytes\n10:58:13.780247 ee:ee:ee:ee:ee:ee > fa:63:d4:dc:25:01, ethertype IPv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: ICMP echo request, id 41971, seq 1, length 64\n10:58:13.780288 fa:63:d4:dc:25:01 > ee:ee:ee:ee:ee:ee, ethertype IPv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: ICMP echo reply, id 41971, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看Node2的路由\n\n# ip r\n...\n172.19.2.2 dev veth1 scope link \n...\n\n\n1\n2\n3\n4\n\n\n数据包达到Node2 ens18网卡后，解开mac头，到达网络协议栈中，通过路由，将目的地址为172.19.2.2的数据包都进入到veth1网卡中，最终进入到net2中\n\n\n# 5. IPIP隧道模式\n\n该模式的解决方式是在物理机A和物理机B之间打一个隧道，这个隧道有两个端点，在端点上进行封装，将容器的IP作为乘客协议放在隧道里面，而物理主机的IP放在外面作为承载协议。这样不管外层的IP通过传统的物理网络，走多少跳到达目标物理机，从隧道两端看起来，物理机A的下一跳就是物理机B。",normalizedContent:"# 0. 前言\n\ncalico是k8s中常用的容器解决方案的插件，本文主要介绍bgp模式和ipip模式是如何解决的，并详细了解其原理，并通过实验加深理解。\n\n\n# 1. 介绍calico\n\ncalico是属于纯3层的网络模型，每个容器都通过ip直接通信，中间通过路由转发找到对方。容器所在的节点类似于传统的路由器，提供了路由查找的功能。每个容器所在的主机节点扮演了虚拟路由器 （vrouter）的功能，vrouter必须有某种方法，能够知道整个集群的路由信息。\n\n之前提到的flannelhost gateway模式方案是不能跨二层网络，是因为它只能修改主机路由，calico把改路由表的做法换成了标准的bgp路由协议。相当于在每个节点上模拟出一个额外的路由器，由于采用的是标准协议，calico模拟路由器的路由表信息可以被传播到网络的其他路由设备中，这样就实现了在三层网络上的高速跨节点网络。\n\n> bgp（border gateway protocol）是一种用于在互联网中交换路由信息的协议。它是一种自治系统（as）之间的路由协议，用于在不同的自治系统之间交换路由信息。bgp协议的主要作用是将路由信息从一个自治系统传递到另一个自治系统，以便实现互联网的全球路由。\n\n但现实中的网络并不一定支持bgp路由，在这种情况下可以使用ipip隧道模式来传输数据。\n\n\n# 2. calio架构\n\n\n\nfelix\n\nfelix是一个守护程序，作为agent运行在托管容器或虚拟机的calico节点上。felix负责刷新主机路由和acl规则等，以便为该主机上的endpoint正常运行提供所需的网络连接和管理。进出容器、虚拟机和物理主机的所有流量都会遍历calico，利用linux内核原生的路由和iptables生成的规则。\n\nbgp client\n\ncalico在每个运行felix服务的节点上都部署一个bgp client（bgp客户端）。bgp客户端的作用是读取felix编写到内核中的路由信息，由bgp客户端对这些路由信息进行分发。当felix将路由插入linux内核时，bgp客户端将接收它们，并将它们分发到集群中的其他工作节点。\n\nnode-to-node mesh\n\n该模式为默认模式，在bgp下，集群中的每一个节点的bgp client都需要和其他所有节点的bgp client进行通信来交换路由。\n但随着节点数量增加，连接数会以n^2规模增加，给集群网络带来巨大的压力。\n\nbgp route reflector\n\ncalico会指定几个节点负责专门跟其他所有节点进行连接并交换路由信息，从而学习到全局的路由信息。而其他节点也只需要跟这几个节点进行通信来获取到整个集群的规则信息。\n\n\n\n\n# 3. bgp模式\n\n\n\n每个容器都会创建一对veth pair网卡，一端放在容器内部，另一端放在宿主机中，容器中发送的ip包通过veth pair网卡可以达到宿主机的网络协议栈中。\n\nfelix会通过监听etcd来获取其他节点的相关信息，然后添加本地路由：\n\n 1. 通往其他节点容器的ip包下一条到其节点物理网卡中。\n 2. 通过本机节点容器的ip包到calixxx网卡中，然后进入到容器中。\n\nbgp client会读取felix写入到本地的路由，再通过进行分发到网络中。\n\n\n# 4. 手动模拟bgp模式实验\n\n\n\n\n# 4.1 操作\n\n首先在node1中创建network namespace命名为net1\n\nip netns add net1\n\n\n1\n\n\n然后创建一对veth pair设备veth0和veth1，将veth0放到net1中，拉起并设置好ip地址172.19.1.2/24，veth1也拉取但不用设置ip地址，但需要设置默认的mac地址为ee:ee:ee:ee:ee:ee\n\nip link add veth0 type veth peer name veth1\nip link set dev veth0 netns net1\nip netns exec net1 ip link set veth0 up\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\n\nip link set dev veth1 up\nip link set dev veth1 address ee:ee:ee:ee:ee:ee\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\nnet1配置的路由有点意思，和一般配置的路由不同，所有的报文都需要通过veth0设备发送到下一跳的地址为169.254.1.1，而这个地址在整个平台找是不存在的，这是一个默认的网关，那如何达到该地址呢？\n\nip netns exec net1 ip r a 169.254.1.1 dev veth0 \nip netns exec net1 ip r a default via 169.254.1.1 dev veth0 \n\n\n1\n2\n\n\n通过设置veth1设备proxy_arp，可以对于任何arp请求到达veth1时，都响应自己的mac地址，也就是ee:ee:ee:ee:ee:ee\n\n当访问网关的时候，首先是需要进行arp请求，请求通过veth0设备达到了veth1中，因为设置proxy_arp，会将自身的mac地址ee:ee:ee:ee:ee:ee作为arp回复。\n\n而容器的后续报文目的ip地址是目的容器的ip地址，而mac地址变成了网关mac地址ee:ee:ee:ee:ee:ee，而网关的ip地址并不会出现在任何的数据包中，也没人关心这个具体的地址是什么，只要能找到arp就行。\n\necho 1 > /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n\n\n数据包已经从net1中通过veth1作为网关达到宿主机的网络协议栈中，再通过设置宿主机路由表，将目的地址为node2容器网段的数据包通过node2 ens18网卡地址作为下一跳地址。\n\nip r add 172.19.2.0/24 via 10.65.132.188 dev ens18\n\n\n1\n\n\n目的地址为node1的net1时，需要配置通过路由表到达veth1网卡，然后再进入到net1中。\n\nip r add 172.19.1.2 dev veth1\n\n\n1\n\n\n再在node2中重复node1的操作创建network namespace net2，并初始化网络配置。\n\nip netns add net2\nip link add veth0 type veth peer name veth1\nip link set dev veth0 netns net2\nip netns exec net2 ip addr add 172.19.2.2/24 dev veth0 \nip netns exec net2 ip link set veth0 up\n\nip link set dev veth1 up\nip link set dev veth1 address ee:ee:ee:ee:ee:ee\n\nip netns exec net2 ip r a 169.254.1.1 dev veth0 \nip netns exec net2 ip r a default via 169.254.1.1 dev veth0 \nip r add 172.19.1.0/24 via 10.65.132.187 dev ens18\nip r add 172.19.2.2/32 dev veth1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 4.2 分析\n\n在node1 net1中ping node2 net2，然后使用tcpdump监听node1的veth1，结果如下：\n\n# tcpdump -i veth1 -ne\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on veth1, link-type en10mb (ethernet), capture size 262144 bytes\n10:38:29.713322 02:1c:9c:83:87:f2 > broadcast, ethertype arp (0x0806), length 42: request who-has 169.254.1.1 tell 172.19.1.2, length 28\n10:38:30.205862 ee:ee:ee:ee:ee:ee > 02:1c:9c:83:87:f2, ethertype arp (0x0806), length 42: reply 169.254.1.1 is-at ee:ee:ee:ee:ee:ee, length 28\n10:38:30.205922 02:1c:9c:83:87:f2 > ee:ee:ee:ee:ee:ee, ethertype ipv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: icmp echo request, id 37475, seq 1, length 64\n10:38:30.206393 ee:ee:ee:ee:ee:ee > 02:1c:9c:83:87:f2, ethertype ipv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: icmp echo reply, id 37475, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n可以看到，先是发送arp请求获取172.19.1.2的mac地址，因为设置了proxy_arp，所以会将自身的mac地址进行回复，在后面的icmp包中，目的ip地址为目的容器ip地址172.19.2.2，而目的mac地址为veth1的mac地址ee:ee:ee:ee:ee:ee\n\n再使用tcpdump监听node2的ens18网卡，结果如下：\n\n# tcpdump -i ens18 host 172.19.2.2 -en\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n10:52:43.993140 fa:16:3e:d3:f6:3a > fa:16:3e:b1:9a:65, ethertype ipv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: icmp echo request, id 4349, seq 1, length 64\n10:52:43.993291 fa:16:3e:b1:9a:65 > fa:16:3e:d3:f6:3a, ethertype ipv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: icmp echo reply, id 4349, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n数据包从node1中到达了node2 ens18网卡，源ip和目的ip分别为net1和net2的ip地址，而mac地址是node1和node2的物理网卡ens18 mac地址.\n\n使用tcpdump监听veth1网卡，结果如下：\n\n# tcpdump -i veth1 -en\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on veth1, link-type en10mb (ethernet), capture size 262144 bytes\n10:58:13.780247 ee:ee:ee:ee:ee:ee > fa:63:d4:dc:25:01, ethertype ipv4 (0x0800), length 98: 172.19.1.2 > 172.19.2.2: icmp echo request, id 41971, seq 1, length 64\n10:58:13.780288 fa:63:d4:dc:25:01 > ee:ee:ee:ee:ee:ee, ethertype ipv4 (0x0800), length 98: 172.19.2.2 > 172.19.1.2: icmp echo reply, id 41971, seq 1, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看node2的路由\n\n# ip r\n...\n172.19.2.2 dev veth1 scope link \n...\n\n\n1\n2\n3\n4\n\n\n数据包达到node2 ens18网卡后，解开mac头，到达网络协议栈中，通过路由，将目的地址为172.19.2.2的数据包都进入到veth1网卡中，最终进入到net2中\n\n\n# 5. ipip隧道模式\n\n该模式的解决方式是在物理机a和物理机b之间打一个隧道，这个隧道有两个端点，在端点上进行封装，将容器的ip作为乘客协议放在隧道里面，而物理主机的ip放在外面作为承载协议。这样不管外层的ip通过传统的物理网络，走多少跳到达目标物理机，从隧道两端看起来，物理机a的下一跳就是物理机b。",charsets:{cjk:!0},lastUpdated:"2023/07/07, 08:56:29",lastUpdatedTimestamp:1688691389e3},{title:"理解flannel的三种容器网络方案原理",frontmatter:{title:"理解flannel的三种容器网络方案原理",date:"2023-06-01T12:56:36.000Z",permalink:"/pages/d9d0ce/",categories:["云原生","k8s"],tags:["k8s","容器","云原生","计算机网络","Linux网络虚拟化"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文主要介绍flannel在k8s网络中作为网络插件通过UDP、VXLAN、HOST-GATEWAY三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230603100424.png"},{name:"twitter:title",content:"理解flannel的三种容器网络方案原理"},{name:"twitter:description",content:"本文主要介绍flannel在k8s网络中作为网络插件通过UDP、VXLAN、HOST-GATEWAY三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230603100424.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/14.%E7%90%86%E8%A7%A3flannel%E7%9A%84%E4%B8%89%E7%A7%8D%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"理解flannel的三种容器网络方案原理"},{property:"og:description",content:"本文主要介绍flannel在k8s网络中作为网络插件通过UDP、VXLAN、HOST-GATEWAY三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230603100424.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/14.%E7%90%86%E8%A7%A3flannel%E7%9A%84%E4%B8%89%E7%A7%8D%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-06-01T12:56:36.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"容器"},{property:"article:tag",content:"云原生"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"Linux网络虚拟化"},{itemprop:"name",content:"理解flannel的三种容器网络方案原理"},{itemprop:"description",content:"本文主要介绍flannel在k8s网络中作为网络插件通过UDP、VXLAN、HOST-GATEWAY三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230603100424.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/14.%E7%90%86%E8%A7%A3flannel%E7%9A%84%E4%B8%89%E7%A7%8D%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E6%96%B9%E6%A1%88%E5%8E%9F%E7%90%86.html",relativePath:"01.云原生/07.k8s/14.理解flannel的三种容器网络方案原理.md",key:"v-be038f46",path:"/pages/d9d0ce/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. flannel全局网络地址分配机制",slug:"_1-flannel全局网络地址分配机制",normalizedTitle:"1. flannel全局网络地址分配机制",charIndex:102},{level:2,title:"2. UDP模式",slug:"_2-udp模式",normalizedTitle:"2. udp模式",charIndex:353},{level:3,title:"2.1 简介",slug:"_2-1-简介",normalizedTitle:"2.1 简介",charIndex:366},{level:3,title:"2.2 flannel实现UDP流程",slug:"_2-2-flannel实现udp流程",normalizedTitle:"2.2 flannel实现udp流程",charIndex:542},{level:3,title:"2.3 手动模拟flannel实现udp实验",slug:"_2-3-手动模拟flannel实现udp实验",normalizedTitle:"2.3 手动模拟flannel实现udp实验",charIndex:975},{level:3,title:"2.4 分析",slug:"_2-4-分析",normalizedTitle:"2.4 分析",charIndex:4474},{level:2,title:"3. VXLAN模式",slug:"_3-vxlan模式",normalizedTitle:"3. vxlan模式",charIndex:5076},{level:3,title:"3.1 简介",slug:"_3-1-简介",normalizedTitle:"3.1 简介",charIndex:5091},{level:3,title:"3.3 flannel实现vxlan模式流程",slug:"_3-3-flannel实现vxlan模式流程",normalizedTitle:"3.3 flannel实现vxlan模式流程",charIndex:5396},{level:3,title:"3.4 手动模拟flanneld维护VTEP组实践",slug:"_3-4-手动模拟flanneld维护vtep组实践",normalizedTitle:"3.4 手动模拟flanneld维护vtep组实践",charIndex:5837},{level:2,title:"4. Host Gateway模式",slug:"_4-host-gateway模式",normalizedTitle:"4. host gateway模式",charIndex:8588},{level:3,title:"4.1 简介",slug:"_4-1-简介",normalizedTitle:"4.1 简介",charIndex:8610},{level:3,title:"4.3 flannel实现Host Gateway模式流程",slug:"_4-3-flannel实现host-gateway模式流程",normalizedTitle:"4.3 flannel实现host gateway模式流程",charIndex:8879},{level:3,title:"4.4 手动模拟flannel实现Host Gateway模式实验",slug:"_4-4-手动模拟flannel实现host-gateway模式实验",normalizedTitle:"4.4 手动模拟flannel实现host gateway模式实验",charIndex:9078},{level:2,title:"5. 巨人的肩膀",slug:"_5-巨人的肩膀",normalizedTitle:"5. 巨人的肩膀",charIndex:10926}],headersStr:"0. 前言 1. flannel全局网络地址分配机制 2. UDP模式 2.1 简介 2.2 flannel实现UDP流程 2.3 手动模拟flannel实现udp实验 2.4 分析 3. VXLAN模式 3.1 简介 3.3 flannel实现vxlan模式流程 3.4 手动模拟flanneld维护VTEP组实践 4. Host Gateway模式 4.1 简介 4.3 flannel实现Host Gateway模式流程 4.4 手动模拟flannel实现Host Gateway模式实验 5. 巨人的肩膀",content:'# 0. 前言\n\n本文主要介绍flannel在k8s网络中作为网络插件通过UDP、VXLAN、HOST-GATEWAY三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。\n\n\n# 1. flannel全局网络地址分配机制\n\n每台节点上容器的IP地址是由所属节点自动分配的，那么会存在一个问题是，不同节点上的容器所分配的IP地址则可能会有重复的情况。\n\nflannel设计了一种全局的网络地址分配机制，flannel会为每台节点申请一个独一无二的网段，并存储在etcd中，flannel会将该网段配置到各个节点上的Docker(或者其他容器工具)，当前节点上的容器 只从分配的网段里中获取IP地址。\n\n> 修改docker启动参数--bip来限制节点容器获得的IP范围。\n\n\n\n\n# 2. UDP模式\n\n\n# 2.1 简介\n\n在Flannel的UDP模式中，每个节点都会启动一个UDP服务器，用于监听来自其他节点的数据包。当一个容器向另一个容器发送数据包时，它会将数据包发送到目标容器的IP地址和端口号。Flannel会将该数据包封装在一个UDP数据包中，并将其发送到目标节点的UDP服务器。目标节点的UDP服务器会解析该数据包，并将其传递给目标容器。\n\n\n# 2.2 flannel实现UDP流程\n\n\n\nflanneld启动后会通过打开/dev/net/tun的方式创建tun设备，名称为flannel0，该设备是用户空间与内核空间的数据包交互的通道。然后再将从tun设备获取的IP数据包封装到UDP数据包中通过物理网卡发送到其他节点中，内核通过UDP端口转发给flanneld然后解包，得到其中的IP数据包，然后再通过tun设备进入内核空间中，通过路由到达网桥，然后再到目的容器中。\n\nflanneld在其中主要做了：\n\n 1. 开启了udp服务，并对udp数据包封包和解包\n 2. 节点上路由表的动态更新，也就是从网桥出来的数据包目的IP为其他节点容器IP时，需要路由到flanneld中进行封包，并且在flanneld接收UDP包后解封出来的IP包需要通过路由到网桥docker0中\n\n缺点很明显，仅一次网络传输的数据包经历了2次用户态与内核态的切换，而切换的效率是不高的，每一次的切换都是一次数据的复制。\n\n\n\n\n# 2.3 手动模拟flannel实现udp实验\n\n首先创建Network Namesapce net1用来模拟容器\n\nip netns add net1\n\n\n1\n\n\n然后创建一对veth pair网卡veth0和veth1，并将veth0放到net1中，拉起并设置veth0的ip地址为172.19.1.2/24\n\nip link add veth0 type veth peer name veth1\n\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n\n\n创建网桥设备，拉起并设置ip地址为172.19.1.1/24，将veth1拉起并绑定到网桥bridge0中\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n在net1中添加默认路由，设置下一条地址为网桥bridge0的IP地址，从网桥进入到宿主机的网络协议栈中。\n\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n\n1\n\n\n再运行以下代码，该代码是用来模拟flanneld程序，主要作用是创建了tun设备flannel0，开启了UDP服务收发UDP包，然后就是对容器IP包的封装与解封。\n\nimport os\nimport socket\nimport struct\nimport threading\nfrom fcntl import ioctl\nimport click\n\nBIND_ADDRESS = (\'0.0.0.0\', 8285)\nBUFFER_SIZE = 4096\n\nTUNSETIFF = 0x400454ca\nIFF_TUN = 0x0001\nIFF_TAP = 0x0002\n\n\ndef create_tunnel(tun_name=\'flannel%d\', tun_mode=IFF_TUN):\n    tun_fd = os.open("/dev/net/tun", os.O_RDWR)\n    ifn = ioctl(tun_fd, TUNSETIFF, struct.pack(b"16sH", tun_name.encode(), tun_mode))\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef start_tunnel(tun_name):\n    os.popen(f"ip link set {tun_name} up")\n\n\ndef udp_server(udp_socket, tun_fd):\n    while True:\n        data, addr = udp_socket.recvfrom(2048)\n        print("get data from udp.")\n        if not data:\n            break\n\n        os.write(tun_fd, data)\n\n\n@click.command()\n@click.option("--peer_node_ip", "-p", required=True, help="对端节点IP")\ndef main(peer_node_ip):\n    peer_node_addr = (peer_node_ip, 7000)\n\n    tun_fd, tun_name = create_tunnel()\n    start_tunnel(tun_name)\n\n    udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    udp_socket.bind(BIND_ADDRESS)\n\n    t = threading.Thread(target=udp_server, args=(udp_socket, tun_fd))\n    t.daemon = True\n    t.start()\n\n    while True:\n        data = os.read(tun_fd, BUFFER_SIZE)\n        print(f"get data from tun. data size = {len(data)}")\n        udp_socket.sendto(data, peer_node_addr)\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n在Node1中运行该程序，设置Node2 IP\n\npython3 tun_app.py -p 10.65.132.188\n\n\n1\n\n\n可以看到已经创建了tun设备\n\n# ip link show flannel0\n...\n109: tun0: <POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 500\n    link/none \n    inet6 fe80::8e98:91a4:6537:d77a/64 scope link flags 800 \n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在设置宿主机的路由，将所有到Node2容器的IP包，都转发到flannel0设备中。\n\nip r add 172.19.2.0/24 dev flannel0\n\n\n1\n\n\n最后重复Node1的操作配置Node2\n\n# 创建net3\nip netns add net3\n\n# 创建veth pair\nip link add veth0 type veth peer name veth1\n\n# 设置net1网络\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.2.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 配置net3路由\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 创建flannel0\npython3 flanneld.py -p 10.65.132.187\n\n# 配置到flannel0的路由\nip r add 172.19.1.0/24 dev flannel0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 2.4 分析\n\n在Node1的net1中ping Node2的net2的ip 172.19.2.2，可以看到是可以ping通的\n\n# ping 172.19.2.2 -c 1\nPING 172.19.2.2 (172.19.2.2) 56(84) bytes of data.\n64 bytes from 172.19.2.2: icmp_seq=1 ttl=63 time=0.641 ms\n\n--- 172.19.2.2 ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\nrtt min/avg/max/mdev = 0.641/0.641/0.641/0.000 ms\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在Node1的flanneld.py中看到日志，从tun中收到了来自容器的IP数据包\n\n# python3 flanneld.py -p 10.65.132.188\nget data from tun. data size = 88\n\n\n1\n2\n\n\n在Node2的flanneld.py中看到日志，接收到了Node1发送过来的udp数据包。\n\n# python3 flanneld.py -p 10.65.132.187\nget data from udp.\n\n\n1\n2\n\n\n\n# 3. VXLAN模式\n\n\n# 3.1 简介\n\n在Flannel的VXLAN模式中，每个节点都会启动一个VXLAN隧道，用于将容器之间的数据包封装在VXLAN协议中进行传输。当一个容器向另一个容器发送数据包时，它会将数据包发送到目标容器的IP地址和虚拟网络ID。Flannel会将该数据包封装在一个VXLAN数据包中，并将其发送到目标节点的VXLAN隧道。目标节点的VXLAN隧道会解析该数据包，并将其传递给目标容器。\n\nvxlan模式也是通过封包与解包的形式来实现隧道达到容器的跨主机访问，那和UDP模式有什么区别呢？ 区别在于，VXLAN的封包与解包都是在内核态完成的，对比UDP模式用户态与内核态的切换来说，效率大大的提升了。\n\n\n# 3.3 flannel实现vxlan模式流程\n\n\n\n在Node1的net1中ping Node2的net3，数据流如下：\n\n 1. bridge作为net1的下一跳网关，所以会先发送ARP获取bridge的mac地址\n 2. 获取到后，然后发送ICMP数据包通过bridge进入到宿主机的网络协议栈中，通过路由表，会进入到flannel.1中，下一跳地址为Node2的flannel.1的地址\n 3. 本来是要发送ARP来获取Node2的flannel.1的地址，因为已经手动配置了ARP表，可以直接获取到到MAC地址，然后将其填充内层二层头中。\n 4. 再通过查询FDB表，找到外层UDP包中目的IP地址，也就是Node2的IP地址，填充到外部IP头中。最终通过物理网卡ens18走外部网络达到Node2中。\n 5. 达到Node2后，通过端口8472，将包转发给VTEP设备flannel.1进行解包，解封后的IP包经过路由表达到bridge中，最终转发到net3中。\n\n\n# 3.4 手动模拟flanneld维护VTEP组实践\n\n创建VTEP设备命名为flannel.1，然后flannel.1配置ip地址为172.19.1.0/32\n\n# 添加VTEP设备\nip link add flannel.1 type vxlan id 42 dstport 8472 local 10.65.132.187 dev ens18 nolearning proxy\n\n# 配置flannel.1\nip link set flannel.1 up\nip a add 172.19.1.0/32 dev flannel.1\n\n\n1\n2\n3\n4\n5\n6\n\n * 只需要填写local地址\n * nolearning，VTEP不要通过收到的报文学习FDB表项的内容，减少广播风暴，提高效率。\n * proxy，VTEP承担ARP代理功能，收到ARP请求时，如果有缓存则直接应答，减少广播风暴，提高效率。\n\n添加network namespace net1，创建veth pair，将其中一端放进net1中，并配置好ip地址，再添加默认路由都走veth0\n\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n# 默认路由\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n创建网桥设备命名为bridge0，并将veth1插到其上\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n到达net3的数据包下一跳为Node2的VTEP设备IP通过flannel.1设备，需要添加onlink，因为下一跳网关不和本地地址在同一网段，路由添加时输出路由不可达的错误，onlink的意义在于协议栈虽然找不到链路层直连路由，但是还是会发布针对via网关的arp请求的.\n\nip r add 172.19.2.0/24 via 172.19.2.0 dev flannel.1 onlink\n\n\n1\n\n\n在Node2节点中重复上面操作创建VETP设备和相关网络配置\n\n# 添加VTEP设备\nip link add flannel.1 type vxlan id 42 dstport 8472 local 10.65.132.188 dev ens18\nip link set flannel.1 up\nip a add 172.19.2.0/32 dev flannel.1\nip r add 172.19.1.0/24 via 172.19.1.0 dev flannel.1 onlink\n\n\n# 添加net3模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 设置net3中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\nip netns exec net3 ip r add default dev veth0\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip a add 172.19.2.1/24 dev bridge0\nip link set bridge0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n在Node1节点中需要再新增ARP缓存，Node1中添加路由的下一跳地址是Node2的VTEP设备，所以需要在arp添加VTEP IP和MAC地址的缓存。\n\narp -s 172.19.2.0 8a:8b:4d:10:82:56 dev flannel.1\n\n\n1\n\n\n再在节点FDB表中添加对端VETP MAC地址和对外IP（物理网卡IP）的映射关系表项\n\nbridge fdb add 8a:8b:4d:10:82:56 dev flannel.1 dst 10.65.132.188\n\n\n1\n\n\n重复Node1操作，配置Node2的ARP缓存和FDB表。\n\narp -s 172.19.1.0 1e:b7:5e:19:ab:90 dev flannel.1\nbridge fdb add 1e:b7:5e:19:ab:90 dev flannel.1 dst 10.65.132.187\n\n\n1\n2\n\n\n通过以上操作完成了环境的搭建，接下来，我们在Node1的net1中进行ping Node2的net3，可以发现是可以ping通的\n\n# ip netns exec net1 ping 172.19.2.2 -c 2\nPING 172.19.2.2 (172.19.2.2) 56(84) bytes of data.\n64 bytes from 172.19.2.2: icmp_seq=1 ttl=62 time=0.547 ms\n64 bytes from 172.19.2.2: icmp_seq=2 ttl=62 time=0.560 ms\n\n\n1\n2\n3\n4\n\n\n\n# 4. Host Gateway模式\n\n\n# 4.1 简介\n\n通过把主机当作网关实现跨节点网络通信的。因此通信双方的宿主机要求能够直接路由，必须在同一个网络，这个限制使得host-gw模式无法适用于集群规模较大且需要对节点进行网段划分的场景。host-gw的另外一个限制则是随着集群中节点规模的增大，flanneld维护主机上成千上万条路由表的动态更新也是一个不小的压力。\n\nflanneld的唯一作用就是负责主机上路由表的动态，但因为只能修改主机的路由，所以各个主机必须二层网络互通。\n\n跟VXLAN模式和UDP模式比较，优点主要是没有封包与解包的操作，大大的提高了性能。\n\n\n# 4.3 flannel实现Host Gateway模式流程\n\n\n\n在Node1的net1中ping Node2的net3，数据流如下：\n\n 1. 数据包从容器进入到宿主机网络协议栈逻辑与VXLAN模式一致\n 2. 通过路由表可知，该数据包通过ens18网卡到达下一跳网关Node2的ens18\n 3. 通过物理网络，达到Node2并进入网络协议栈，通过路由达到bridge进入到net3中\n\n\n# 4.4 手动模拟flannel实现Host Gateway模式实验\n\n在Node1中创建Network Namesapce net1、vethpair和网桥，并配置好其网络。\n\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n# 默认路由\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n再添加路由，将Node2所分配到的容器网段为目的数据包都将Node2作为下一跳网关。\n\nip r add 172.19.2.0/24 via 10.65.132.188 dev ens18\n\n\n1\n\n\n重复Node1的配置，并添加将Node1所分配到的容器网段为目的数据包都将Node1作为下一跳网关。\n\n# 添加net3模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 设置net3中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip a add 172.19.2.1/24 dev bridge0\nip link set bridge0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 路由\nip r add 172.19.1.0/24 via 10.65.132.187 dev ens18\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n在Node1的net1中ping Node2的net2，是可以ping通的，说明网络互通了。\n\n在通过tcpdump抓取Node2 ens18网卡的包，可以看到ICMP数据包到了Node2节点。\n\n# tcpdump -i ens18 host 172.19.2.2\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n15:07:00.072677 IP 172.19.1.2 > 172.19.2.2: ICMP echo request, id 52240, seq 8, length 64\n15:07:00.072782 IP 172.19.2.2 > 172.19.1.2: ICMP echo reply, id 52240, seq 8, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 5. 巨人的肩膀\n\n * Flannel Vxlan封包原理剖析\n * 《kubernetes网络权威指南》\n * 《极客时间-深入剖析Kubernetes》',normalizedContent:'# 0. 前言\n\n本文主要介绍flannel在k8s网络中作为网络插件通过udp、vxlan、host-gateway三种模式来解决容器跨主机网络通信的，并通过手动实现这三种模式深入理解其原理。\n\n\n# 1. flannel全局网络地址分配机制\n\n每台节点上容器的ip地址是由所属节点自动分配的，那么会存在一个问题是，不同节点上的容器所分配的ip地址则可能会有重复的情况。\n\nflannel设计了一种全局的网络地址分配机制，flannel会为每台节点申请一个独一无二的网段，并存储在etcd中，flannel会将该网段配置到各个节点上的docker(或者其他容器工具)，当前节点上的容器 只从分配的网段里中获取ip地址。\n\n> 修改docker启动参数--bip来限制节点容器获得的ip范围。\n\n\n\n\n# 2. udp模式\n\n\n# 2.1 简介\n\n在flannel的udp模式中，每个节点都会启动一个udp服务器，用于监听来自其他节点的数据包。当一个容器向另一个容器发送数据包时，它会将数据包发送到目标容器的ip地址和端口号。flannel会将该数据包封装在一个udp数据包中，并将其发送到目标节点的udp服务器。目标节点的udp服务器会解析该数据包，并将其传递给目标容器。\n\n\n# 2.2 flannel实现udp流程\n\n\n\nflanneld启动后会通过打开/dev/net/tun的方式创建tun设备，名称为flannel0，该设备是用户空间与内核空间的数据包交互的通道。然后再将从tun设备获取的ip数据包封装到udp数据包中通过物理网卡发送到其他节点中，内核通过udp端口转发给flanneld然后解包，得到其中的ip数据包，然后再通过tun设备进入内核空间中，通过路由到达网桥，然后再到目的容器中。\n\nflanneld在其中主要做了：\n\n 1. 开启了udp服务，并对udp数据包封包和解包\n 2. 节点上路由表的动态更新，也就是从网桥出来的数据包目的ip为其他节点容器ip时，需要路由到flanneld中进行封包，并且在flanneld接收udp包后解封出来的ip包需要通过路由到网桥docker0中\n\n缺点很明显，仅一次网络传输的数据包经历了2次用户态与内核态的切换，而切换的效率是不高的，每一次的切换都是一次数据的复制。\n\n\n\n\n# 2.3 手动模拟flannel实现udp实验\n\n首先创建network namesapce net1用来模拟容器\n\nip netns add net1\n\n\n1\n\n\n然后创建一对veth pair网卡veth0和veth1，并将veth0放到net1中，拉起并设置veth0的ip地址为172.19.1.2/24\n\nip link add veth0 type veth peer name veth1\n\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n\n\n创建网桥设备，拉起并设置ip地址为172.19.1.1/24，将veth1拉起并绑定到网桥bridge0中\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n在net1中添加默认路由，设置下一条地址为网桥bridge0的ip地址，从网桥进入到宿主机的网络协议栈中。\n\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n\n1\n\n\n再运行以下代码，该代码是用来模拟flanneld程序，主要作用是创建了tun设备flannel0，开启了udp服务收发udp包，然后就是对容器ip包的封装与解封。\n\nimport os\nimport socket\nimport struct\nimport threading\nfrom fcntl import ioctl\nimport click\n\nbind_address = (\'0.0.0.0\', 8285)\nbuffer_size = 4096\n\ntunsetiff = 0x400454ca\niff_tun = 0x0001\niff_tap = 0x0002\n\n\ndef create_tunnel(tun_name=\'flannel%d\', tun_mode=iff_tun):\n    tun_fd = os.open("/dev/net/tun", os.o_rdwr)\n    ifn = ioctl(tun_fd, tunsetiff, struct.pack(b"16sh", tun_name.encode(), tun_mode))\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef start_tunnel(tun_name):\n    os.popen(f"ip link set {tun_name} up")\n\n\ndef udp_server(udp_socket, tun_fd):\n    while true:\n        data, addr = udp_socket.recvfrom(2048)\n        print("get data from udp.")\n        if not data:\n            break\n\n        os.write(tun_fd, data)\n\n\n@click.command()\n@click.option("--peer_node_ip", "-p", required=true, help="对端节点ip")\ndef main(peer_node_ip):\n    peer_node_addr = (peer_node_ip, 7000)\n\n    tun_fd, tun_name = create_tunnel()\n    start_tunnel(tun_name)\n\n    udp_socket = socket.socket(socket.af_inet, socket.sock_dgram)\n    udp_socket.bind(bind_address)\n\n    t = threading.thread(target=udp_server, args=(udp_socket, tun_fd))\n    t.daemon = true\n    t.start()\n\n    while true:\n        data = os.read(tun_fd, buffer_size)\n        print(f"get data from tun. data size = {len(data)}")\n        udp_socket.sendto(data, peer_node_addr)\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n在node1中运行该程序，设置node2 ip\n\npython3 tun_app.py -p 10.65.132.188\n\n\n1\n\n\n可以看到已经创建了tun设备\n\n# ip link show flannel0\n...\n109: tun0: <pointopoint,multicast,noarp,up,lower_up> mtu 1500 qdisc pfifo_fast state unknown group default qlen 500\n    link/none \n    inet6 fe80::8e98:91a4:6537:d77a/64 scope link flags 800 \n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在设置宿主机的路由，将所有到node2容器的ip包，都转发到flannel0设备中。\n\nip r add 172.19.2.0/24 dev flannel0\n\n\n1\n\n\n最后重复node1的操作配置node2\n\n# 创建net3\nip netns add net3\n\n# 创建veth pair\nip link add veth0 type veth peer name veth1\n\n# 设置net1网络\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.2.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 配置net3路由\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 创建flannel0\npython3 flanneld.py -p 10.65.132.187\n\n# 配置到flannel0的路由\nip r add 172.19.1.0/24 dev flannel0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 2.4 分析\n\n在node1的net1中ping node2的net2的ip 172.19.2.2，可以看到是可以ping通的\n\n# ping 172.19.2.2 -c 1\nping 172.19.2.2 (172.19.2.2) 56(84) bytes of data.\n64 bytes from 172.19.2.2: icmp_seq=1 ttl=63 time=0.641 ms\n\n--- 172.19.2.2 ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\nrtt min/avg/max/mdev = 0.641/0.641/0.641/0.000 ms\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在node1的flanneld.py中看到日志，从tun中收到了来自容器的ip数据包\n\n# python3 flanneld.py -p 10.65.132.188\nget data from tun. data size = 88\n\n\n1\n2\n\n\n在node2的flanneld.py中看到日志，接收到了node1发送过来的udp数据包。\n\n# python3 flanneld.py -p 10.65.132.187\nget data from udp.\n\n\n1\n2\n\n\n\n# 3. vxlan模式\n\n\n# 3.1 简介\n\n在flannel的vxlan模式中，每个节点都会启动一个vxlan隧道，用于将容器之间的数据包封装在vxlan协议中进行传输。当一个容器向另一个容器发送数据包时，它会将数据包发送到目标容器的ip地址和虚拟网络id。flannel会将该数据包封装在一个vxlan数据包中，并将其发送到目标节点的vxlan隧道。目标节点的vxlan隧道会解析该数据包，并将其传递给目标容器。\n\nvxlan模式也是通过封包与解包的形式来实现隧道达到容器的跨主机访问，那和udp模式有什么区别呢？ 区别在于，vxlan的封包与解包都是在内核态完成的，对比udp模式用户态与内核态的切换来说，效率大大的提升了。\n\n\n# 3.3 flannel实现vxlan模式流程\n\n\n\n在node1的net1中ping node2的net3，数据流如下：\n\n 1. bridge作为net1的下一跳网关，所以会先发送arp获取bridge的mac地址\n 2. 获取到后，然后发送icmp数据包通过bridge进入到宿主机的网络协议栈中，通过路由表，会进入到flannel.1中，下一跳地址为node2的flannel.1的地址\n 3. 本来是要发送arp来获取node2的flannel.1的地址，因为已经手动配置了arp表，可以直接获取到到mac地址，然后将其填充内层二层头中。\n 4. 再通过查询fdb表，找到外层udp包中目的ip地址，也就是node2的ip地址，填充到外部ip头中。最终通过物理网卡ens18走外部网络达到node2中。\n 5. 达到node2后，通过端口8472，将包转发给vtep设备flannel.1进行解包，解封后的ip包经过路由表达到bridge中，最终转发到net3中。\n\n\n# 3.4 手动模拟flanneld维护vtep组实践\n\n创建vtep设备命名为flannel.1，然后flannel.1配置ip地址为172.19.1.0/32\n\n# 添加vtep设备\nip link add flannel.1 type vxlan id 42 dstport 8472 local 10.65.132.187 dev ens18 nolearning proxy\n\n# 配置flannel.1\nip link set flannel.1 up\nip a add 172.19.1.0/32 dev flannel.1\n\n\n1\n2\n3\n4\n5\n6\n\n * 只需要填写local地址\n * nolearning，vtep不要通过收到的报文学习fdb表项的内容，减少广播风暴，提高效率。\n * proxy，vtep承担arp代理功能，收到arp请求时，如果有缓存则直接应答，减少广播风暴，提高效率。\n\n添加network namespace net1，创建veth pair，将其中一端放进net1中，并配置好ip地址，再添加默认路由都走veth0\n\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n# 默认路由\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n创建网桥设备命名为bridge0，并将veth1插到其上\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n到达net3的数据包下一跳为node2的vtep设备ip通过flannel.1设备，需要添加onlink，因为下一跳网关不和本地地址在同一网段，路由添加时输出路由不可达的错误，onlink的意义在于协议栈虽然找不到链路层直连路由，但是还是会发布针对via网关的arp请求的.\n\nip r add 172.19.2.0/24 via 172.19.2.0 dev flannel.1 onlink\n\n\n1\n\n\n在node2节点中重复上面操作创建vetp设备和相关网络配置\n\n# 添加vtep设备\nip link add flannel.1 type vxlan id 42 dstport 8472 local 10.65.132.188 dev ens18\nip link set flannel.1 up\nip a add 172.19.2.0/32 dev flannel.1\nip r add 172.19.1.0/24 via 172.19.1.0 dev flannel.1 onlink\n\n\n# 添加net3模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 设置net3中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\nip netns exec net3 ip r add default dev veth0\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip a add 172.19.2.1/24 dev bridge0\nip link set bridge0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n在node1节点中需要再新增arp缓存，node1中添加路由的下一跳地址是node2的vtep设备，所以需要在arp添加vtep ip和mac地址的缓存。\n\narp -s 172.19.2.0 8a:8b:4d:10:82:56 dev flannel.1\n\n\n1\n\n\n再在节点fdb表中添加对端vetp mac地址和对外ip（物理网卡ip）的映射关系表项\n\nbridge fdb add 8a:8b:4d:10:82:56 dev flannel.1 dst 10.65.132.188\n\n\n1\n\n\n重复node1操作，配置node2的arp缓存和fdb表。\n\narp -s 172.19.1.0 1e:b7:5e:19:ab:90 dev flannel.1\nbridge fdb add 1e:b7:5e:19:ab:90 dev flannel.1 dst 10.65.132.187\n\n\n1\n2\n\n\n通过以上操作完成了环境的搭建，接下来，我们在node1的net1中进行ping node2的net3，可以发现是可以ping通的\n\n# ip netns exec net1 ping 172.19.2.2 -c 2\nping 172.19.2.2 (172.19.2.2) 56(84) bytes of data.\n64 bytes from 172.19.2.2: icmp_seq=1 ttl=62 time=0.547 ms\n64 bytes from 172.19.2.2: icmp_seq=2 ttl=62 time=0.560 ms\n\n\n1\n2\n3\n4\n\n\n\n# 4. host gateway模式\n\n\n# 4.1 简介\n\n通过把主机当作网关实现跨节点网络通信的。因此通信双方的宿主机要求能够直接路由，必须在同一个网络，这个限制使得host-gw模式无法适用于集群规模较大且需要对节点进行网段划分的场景。host-gw的另外一个限制则是随着集群中节点规模的增大，flanneld维护主机上成千上万条路由表的动态更新也是一个不小的压力。\n\nflanneld的唯一作用就是负责主机上路由表的动态，但因为只能修改主机的路由，所以各个主机必须二层网络互通。\n\n跟vxlan模式和udp模式比较，优点主要是没有封包与解包的操作，大大的提高了性能。\n\n\n# 4.3 flannel实现host gateway模式流程\n\n\n\n在node1的net1中ping node2的net3，数据流如下：\n\n 1. 数据包从容器进入到宿主机网络协议栈逻辑与vxlan模式一致\n 2. 通过路由表可知，该数据包通过ens18网卡到达下一跳网关node2的ens18\n 3. 通过物理网络，达到node2并进入网络协议栈，通过路由达到bridge进入到net3中\n\n\n# 4.4 手动模拟flannel实现host gateway模式实验\n\n在node1中创建network namesapce net1、vethpair和网桥，并配置好其网络。\n\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n# 默认路由\nip netns exec net1 ip r add default via 172.19.1.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set bridge0 up\nip a add 172.19.1.1/24 dev bridge0\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n再添加路由，将node2所分配到的容器网段为目的数据包都将node2作为下一跳网关。\n\nip r add 172.19.2.0/24 via 10.65.132.188 dev ens18\n\n\n1\n\n\n重复node1的配置，并添加将node1所分配到的容器网段为目的数据包都将node1作为下一跳网关。\n\n# 添加net3模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 设置net3中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.2.2/24 dev veth0\nip netns exec net3 ip link set veth0 up\nip netns exec net3 ip r add default via 172.19.2.1 dev veth0\n\n# 添加网桥\nip link add bridge0 type bridge\nip a add 172.19.2.1/24 dev bridge0\nip link set bridge0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 路由\nip r add 172.19.1.0/24 via 10.65.132.187 dev ens18\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n在node1的net1中ping node2的net2，是可以ping通的，说明网络互通了。\n\n在通过tcpdump抓取node2 ens18网卡的包，可以看到icmp数据包到了node2节点。\n\n# tcpdump -i ens18 host 172.19.2.2\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n15:07:00.072677 ip 172.19.1.2 > 172.19.2.2: icmp echo request, id 52240, seq 8, length 64\n15:07:00.072782 ip 172.19.2.2 > 172.19.1.2: icmp echo reply, id 52240, seq 8, length 64\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 5. 巨人的肩膀\n\n * flannel vxlan封包原理剖析\n * 《kubernetes网络权威指南》\n * 《极客时间-深入剖析kubernetes》',charsets:{cjk:!0},lastUpdated:"2023/06/06, 18:33:56",lastUpdatedTimestamp:1686047636e3},{title:"kubernetes service如何通过iptables转发",frontmatter:{title:"kubernetes service如何通过iptables转发",date:"2024-01-18T16:40:30.000Z",permalink:"/pages/b3955c/",categories:["云原生","k8s"],tags:["k8s","计算机网络"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。",comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/image-20240110142336-wl40wxw.png"},{name:"twitter:title",content:"kubernetes service如何通过iptables转发"},{name:"twitter:description",content:"本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/image-20240110142336-wl40wxw.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/16.kubernetes%20service%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87iptables%E8%BD%AC%E5%8F%91.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kubernetes service如何通过iptables转发"},{property:"og:description",content:"本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/image-20240110142336-wl40wxw.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/16.kubernetes%20service%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87iptables%E8%BD%AC%E5%8F%91.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2024-01-18T16:40:30.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"计算机网络"},{itemprop:"name",content:"kubernetes service如何通过iptables转发"},{itemprop:"description",content:"本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/image-20240110142336-wl40wxw.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/16.kubernetes%20service%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87iptables%E8%BD%AC%E5%8F%91.html",relativePath:"01.云原生/07.k8s/16.kubernetes service如何通过iptables转发.md",key:"v-6cbb1851",path:"/pages/b3955c/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:39},{level:2,title:"环境搭建",slug:"环境搭建",normalizedTitle:"环境搭建",charIndex:126},{level:2,title:"KUBE-SERVICES",slug:"kube-services",normalizedTitle:"kube-services",charIndex:2150},{level:2,title:"POSTROUTING",slug:"postrouting",normalizedTitle:"postrouting",charIndex:5322},{level:2,title:"SNAT",slug:"snat",normalizedTitle:"snat",charIndex:5941},{level:3,title:"为什么集群外部访问该service需要被SNAT？",slug:"为什么集群外部访问该service需要被snat",normalizedTitle:"为什么集群外部访问该service需要被snat？",charIndex:6449},{level:3,title:"conntrack",slug:"conntrack",normalizedTitle:"conntrack",charIndex:6624},{level:2,title:"源和目的IP相同",slug:"源和目的ip相同",normalizedTitle:"源和目的ip相同",charIndex:7440},{level:2,title:"NodePort",slug:"nodeport",normalizedTitle:"nodeport",charIndex:7954},{level:3,title:"搭建环境",slug:"搭建环境",normalizedTitle:"搭建环境",charIndex:132},{level:3,title:"请求clusterip",slug:"请求clusterip",normalizedTitle:"请求clusterip",charIndex:8672},{level:3,title:"请求节点IP",slug:"请求节点ip",normalizedTitle:"请求节点ip",charIndex:10190},{level:2,title:"参考链接",slug:"参考链接",normalizedTitle:"参考链接",charIndex:10887}],headersStr:"前言 环境搭建 KUBE-SERVICES POSTROUTING SNAT 为什么集群外部访问该service需要被SNAT？ conntrack 源和目的IP相同 NodePort 搭建环境 请求clusterip 请求节点IP 参考链接",content:"# kubernetes service如何通过iptables转发\n\n\n# 前言\n\n本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。\n\n\n# 环境搭建\n\n搭建环境如下图所示：\n\n\n\n 1. 创建一个deploy，设置其副本数为3\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: demoapp-deployment\n  labels:\n    app: demoapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: demoapp\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n        - name: ubuntu\n          image: ikubernetes/demoapp:v1.0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n 2. 创建service，为上面deployment的3个pod进行负载均衡访问\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: demoapp-service\nspec:\n  selector:\n    app: demoapp\n  clusterIP: 192.44.140.73\n  ports:\n    - name: http\n      protocol: TCP\n      port: 80\n      targetPort: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n 3. 验证\n\n创建完后，环境如下：\n\n# kubectl get pods -n zwf -o wide\nNAME                                  READY   STATUS    RESTARTS   AGE     IP\ndemoapp-deployment-64bdcb8666-4prbk   1/1     Running   0          7d17h   192.33.229.12   dmoc-fa163eee1e30\ndemoapp-deployment-64bdcb8666-cxmmz   1/1     Running   0          7d17h   192.33.73.139   dmoc-fa163e7188d6\ndemoapp-deployment-64bdcb8666-kkzsg   1/1     Running   0          7d17h   192.33.206.93   dmoc-fa163ee6bbe1\ndemoapp-pod                           1/1     Running   0          4d17h   192.33.73.172   dmoc-fa163e7188d6\n\n# kubectl get svc -n zwf\nNAME                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\ndemoapp-service            ClusterIP   192.44.140.73    <none>        80/TCP         7s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n可以直接在环境中请求service的clusterip地址，会随机访问到三个pod，输出的信息包含了请求IP和目的IP。\n\n# curl 192.44.140.73\niKubernetes demoapp v1.0 !! ClientIP: 10.10.10.16, ServerName: demoapp-deployment-64bdcb8666-kkzsg, ServerIP: 192.33.206.93!\n\n# curl 192.44.140.73\niKubernetes demoapp v1.0 !! ClientIP: 10.65.196.41, ServerName: demoapp-deployment-64bdcb8666-cxmmz, ServerIP: 192.33.73.139!\n\n# curl 192.44.140.73\niKubernetes demoapp v1.0 !! ClientIP: 10.10.10.16, ServerName: demoapp-deployment-64bdcb8666-4prbk, ServerIP: 192.33.229.12!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# KUBE-SERVICES\n\n在PREROUTING 和OUTPUT 链的nat表中，都包含了KUBE-SERVICES 子链，该子链中就包含了serivce的iptables规则的配置。\n\n# iptables -L PREROUTING -t nat\nChain PREROUTING (policy ACCEPT)\ntarget     prot opt source               destination       \nKUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-PREROUTING  all  --  anywhere             anywhere             /* cali:6gwbT8clXdHdC1b1 */\n\n# iptables -L OUTPUT -t nat\nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination       \nKUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-OUTPUT  all  --  anywhere             anywhere             /* cali:tVnHkvAo15HuiPy0 */\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n为什么在PREROUTING和OUTPUT链中添加service规则？\n\nservice的作用是负载均衡，也就是需要将IP包进行DNAT操作，而这个操作需要在最靠近发送的位置。网卡收到的包进入到网络协议栈时，最先进入的就是PREROUTING链，也就是节点外部的流量进入的入口。OUTPUT是本地进程发出的包最先进入的链。所以需要在这两条链中添加KUBE-SERVICES，详情可参考快速了解iptables\n\n为什么nat表？\n\n因为要做DNAT操作，所以在nat表。\n\nKUBE-SERVICES下面有许多KUBE-SVC-XXX的子链，每一条子链都是一个集群中一个service的配置，筛选一下\n\n通过筛选demoapp-service 得到下面的子链，只有访问目的地址为192.44.140.73才能进入到该子链中。\n\n# iptables -L KUBE-SERVICES -t nat | grep demoapp-service\nKUBE-SVC-FIHIHDNRZEG5VQEQ  tcp  --  anywhere             192.44.140.73        /* zwf/demoapp-service:http cluster IP */ tcp dpt:http\n\n\n1\n2\n\n\n查看UBE-SVC-FIHIHDNRZEG5VQEQ 链中内容，其中包含了四条子链。\n\n# iptables -L KUBE-SVC-FIHIHDNRZEG5VQEQ -t nat -n\nChain KUBE-SVC-FIHIHDNRZEG5VQEQ (1 references)\ntarget     prot opt source               destination       \nKUBE-MARK-MASQ  tcp  -- !192.33.0.0/16        192.44.140.73        /* zwf/demoapp-service:http cluster IP */ tcp dpt:80\nKUBE-SEP-FO7YK2K5DAKTCVSE  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */ statistic mode random probability 0.33333333349\nKUBE-SEP-IPKL7NSNTVGKI4T5  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */ statistic mode random probability 0.50000000000\nKUBE-SEP-BPER562ISF3UFYOQ  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n第一条链是，源IP不在192.33.0.0/16段、目的IP为192.44.140.73并且目的端口是80的数据包会匹配到该条子链进行跳转。其中192.33.0.0/16是pod的网段，如果不是集群内的流量，则会匹配上该条子链，会打上0x4000的标记。\n\n# iptables -L KUBE-MARK-MASQ -t nat -n\nChain KUBE-MARK-MASQ (548 references)\ntarget     prot opt source               destination       \nMARK       all  --  0.0.0.0/0            0.0.0.0/0            MARK or 0x4000\n\n\n1\n2\n3\n4\n\n\n后面的三条链是为了将流量随机的分配到任意一个pod中。第二条链代表着有1/3的概率会匹配到该链，而第三条链代表着1/2，最后一条链代表着百分百。\n\n看第二条链中的规则，第一条规则是跳转到子链KUBE-MARK-MASQ ，源IP为192.33.206.93的数据包打上了0x4000标记，再将目的IP DNAT成192.33.206.93，说明如果自己访问自己，也会被打上标记。\n\n这里的192.33.206.93是本身service所匹配上的pod IP地址，如果调用自己的service则会匹配上该链，打上0x4000标记。\n\n而第二条规则是一个DNAT操作，会将目标地址改为192.33.206.93:80，也就是pod的地址。\n\n # iptables -L KUBE-SEP-FO7YK2K5DAKTCVSE -t nat\nChain KUBE-SEP-FO7YK2K5DAKTCVSE (1 references)\ntarget     prot opt source               destination   \nKUBE-MARK-MASQ  all  --  192.33.206.93        anywhere             /* zwf/demoapp-service:http */\nDNAT       tcp  --  anywhere             anywhere             /* zwf/demoapp-service:http */ tcp to:192.33.206.93:80\n\n\n1\n2\n3\n4\n5\n\n\n剩下的第3、4条规则也是一样的操作，会将流量DNAT到对应的pod中。\n\n\n# POSTROUTING\n\nPOSTROUTING中包含了一条KUBE-POSTROUTING子链，子链也是由kube-porxy来写入的。\n\n# iptables -L POSTROUTING -t nat\nChain POSTROUTING (policy ACCEPT)\ntarget     prot opt source               destination       \nKUBE-POSTROUTING  all  --  anywhere             anywhere             /* kubernetes postrouting rules */\ncali-POSTROUTING  all  --  anywhere             anywhere             /* cali:O3lYWMrLQYEMJtB5 */\n\n\n1\n2\n3\n4\n5\n\n\n查看子链KUBE-POSTROUTING 内容：\n\n 1. 第一条规则是没有标记为0x400的数据包会return，不执行下面的子链。还记得在KUBE-PREROUTING 中有两次打上0x4000标记，代表着访问是集群外部访问该service或者是源和目的一样，都会往下走。\n 2. 第二条规则是对数据包的标记值进行异或，而这里是0x4000与0x4000进行异或，也就是0\n 3. 第三条规则时对该数据包进行SNAT，random-fully是对源端口进行随机获取。\n\n# iptables -L KUBE-POSTROUTING -t nat\nChain KUBE-POSTROUTING (1 references)\ntarget     prot opt source               destination       \nRETURN     all  --  anywhere             anywhere             mark match ! 0x4000/0x4000\nMARK       all  --  anywhere             anywhere             MARK xor 0x4000\nMASQUERADE  all  --  anywhere             anywhere             /* kubernetes service traffic requiring SNAT */ random-fully\n\n\n1\n2\n3\n4\n5\n6\n\n\n这里有两种情况会被SNAT，说说为什么。\n\n\n# SNAT\n\n\n# 为什么集群外部访问该service需要被SNAT？\n\n数据包需要回包，如果没有SNAT，那么回包的目的IP是客户端的IP，而源IP是Pod的IP，而客户端并不认该数据包，则会被丢弃。\n\n‍\n\n如果有发生SNAT，那么回包的时候可以回到Node1的节点，再回到client。\n\n‍\n\n但问题又来了，是怎么从Node1再回包到client的呢？\n\n\n# conntrack\n\nconntrack是一个追踪表，在每一个数据包进入到netfilter的时候，都会记录一条记录，当我们进行SNAT和DNAT的时候也都会更新该表中的记录。\n\n所以在Node1回包给client时候，可以通过查询这个表中的记录，然后再次SNAT和DNAT恢复回去就可以进行正常的回包了。\n\n\n\n可以看下conntrack里面的记录长什么样子。\n\n先在某一台节点上curl service的ip，上图的client其实也是在Node1上的，因为Node1上有两张网卡，Node1和Node2的通信使用的网卡eth2 ip为10.10.10.16，因为转发到其他节点，所以会被SNAT。\n\n# curl 192.44.140.73\niKubernetes demoapp v1.0 !! ClientIP: 10.10.10.16, ServerName: demoapp-deployment-64bdcb8666-4prbk, ServerIP: 192.33.229.12!\n\n\n1\n2\n\n\n这里主要是看src和dst分别是client请求service的目的IP，然后后面又有一个src和dst它是由Node2回包给Node1的源和目的IP，也就是源是pod的IP，dst是Node1节点IP。\n\n前面是发送包的方向，后面是回包的方向。通过查询该表，即可以从Node1回包给client\n\n# conntrack -L | grep 192.33.229.12\ntcp      6 107 TIME_WAIT src=10.65.196.41 dst=192.44.140.73 sport=33468 dport=80 src=192.33.229.12 dst=10.10.10.16 sport=80 dport=18623 [ASSURED] mark=0 use=1\n\n\n1\n2\n\n\n‍\n\n\n# 源和目的IP相同\n\n当pod访问service时，正好DNAT成自己的IP，那么就存在源和目的IP一样的情况。\n\n\n\n这种数据包是很特殊的存在，网络设备可能会将这种数据包视为无效或者异常的包被丢弃，最好不要一样，所以会将源IP SNAT为主机的IP，解决该问题。\n\n实验\n\n\n\n当前节点的IP为：10.65.196.41，然后进入在当前节点的Pod内，当前pod的ip为：192.33.73.139\n\nkubectl exec -it -n zwf demoapp-deployment-64bdcb8666-cxmmz -- sh\n\n\n\n1\n2\n\n\n进行多次curl service ip，当某一次请求到本POD的IP时，查看其ClientIP，发现其源IP是：10.65.196.41，这个当前节点的IP\n\n# curl 192.44.140.73\niKubernetes demoapp v1.0 !! ClientIP: 10.65.196.41, ServerName: demoapp-deployment-64bdcb8666-cxmmz, ServerIP: 192.33.73.139!\n\n\n1\n2\n\n\n\n# NodePort\n\n上面介绍的是serivi type=ClusterIP方式的，那么NodePort有什么区别呢？\n\n\n# 搭建环境\n\n先将clusterIP的service删了，防止干扰。\n\nkubectl delete svc -n zwf demoapp-service\n\n\n1\n\n\n创建NodePort的service文件demo_service_nodeport.yaml\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: demoapp-nodeport-service\nspec:\n  selector:\n    app: demoapp\n  ports:\n    - name: http\n      protocol: TCP\n      port: 80\n      targetPort: 80\n  type: NodePort\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n创建Service\n\n# kubectl apply -n zwf -f demo_service_nodeport.yaml \n\n# kubectl get svc -n zwf\nNAME                       TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\ndemoapp-nodeport-service   NodePort   192.44.152.223   <none>        80:30337/TCP   64s\n\n\n1\n2\n3\n4\n5\n\n\n\n# 请求clusterip\n\n通过clusterip+端口的方式请求service，原理和上面将是一样的。\n\n在POSTROUTING和OUTPUT中添加了KUBE-SERVICES链，其中包含了新增的service对应的KUBE-SVC-XXX子链，当访问的是其clusterip时，则匹配上该链。在其中包含了从多个pod中随机选择一个进行DNAT操作，打上标记，在POSTROUTING中再SNAT。\n\n# iptables -L PREROUTING -t nat\nChain PREROUTING (policy ACCEPT)\ntarget     prot opt source               destination       \nKUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-PREROUTING  all  --  anywhere             anywhere             /* cali:6gwbT8clXdHdC1b1 */\n\n\n# iptables -L KUBE-SERVICES -t nat | grep zwf\nKUBE-SVC-YSWRJGOK5VEB6HOG  tcp  --  anywhere             192.44.152.223       /* zwf/demoapp-nodeport-service:http cluster IP */ tcp dpt:http\n\n# iptables -L KUBE-SVC-YSWRJGOK5VEB6HOG -t nat |grep zwf\nKUBE-MARK-MASQ  tcp  -- !192.33.0.0/16        192.44.152.223       /* zwf/demoapp-nodeport-service:http cluster IP */ tcp dpt:http\nKUBE-MARK-MASQ  tcp  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ tcp dpt:30337\nKUBE-SEP-NMMBRSZXI4OIWDPB  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ statistic mode random probability 0.33333333349\nKUBE-SEP-PXDORKZI3GD2RUMC  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ statistic mode random probability 0.50000000000\nKUBE-SEP-YLPOR67MTHPHIZAB  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 请求节点IP\n\n但是如果不是通过ClusterIP而是通过节点IP请求service呢，它是怎么做的？\n\n因为是节点IP，所以无法匹配上该service的KUBE-SVC-XXX子链，但是有一条KUBE-NODEPORTS\n\n# iptables -L KUBE-SERVICES  -t nat | grep KUBE-NODEPORTS\nKUBE-NODEPORTS  all  --  anywhere             anywhere             /* kubernetes service nodeports; NOTE: this must be the last rule in this chain */ ADDRTYPE match dst-type LOCAL\n\n\n1\n2\n\n\n在其中包含了一条子链KUBE-SVC-YSWRJGOK5VEB6HOG ，只要目的端口为30337就能匹配上，而这个端口正好就是demoapp-nodeport-service 的NodePort端口。\n\n这条子链和上面匹配clusterIP时是同一个链，都是进行一个DNAT操作。\n\n# # iptables -L KUBE-NODEPORTS -t nat | grep zwf\nKUBE-SVC-YSWRJGOK5VEB6HOG  tcp  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ tcp dpt:30337\n\n\n1\n2\n\n\n‍\n\n\n# 参考链接\n\n * netfilter 链接跟踪机制与NAT原理\n * k8s 之 service ip\n * 连接跟踪 conntrack",normalizedContent:"# kubernetes service如何通过iptables转发\n\n\n# 前言\n\n本文主要是介绍kubernetes的service是如何利用iptables来进行流量的转发达到流量的负载均衡的，并会通过实践操作来更好的理解与验证其原理。\n\n\n# 环境搭建\n\n搭建环境如下图所示：\n\n\n\n 1. 创建一个deploy，设置其副本数为3\n\napiversion: apps/v1\nkind: deployment\nmetadata:\n  name: demoapp-deployment\n  labels:\n    app: demoapp\nspec:\n  replicas: 3\n  selector:\n    matchlabels:\n      app: demoapp\n  template:\n    metadata:\n      labels:\n        app: demoapp\n    spec:\n      containers:\n        - name: ubuntu\n          image: ikubernetes/demoapp:v1.0\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n 2. 创建service，为上面deployment的3个pod进行负载均衡访问\n\napiversion: v1\nkind: service\nmetadata:\n  name: demoapp-service\nspec:\n  selector:\n    app: demoapp\n  clusterip: 192.44.140.73\n  ports:\n    - name: http\n      protocol: tcp\n      port: 80\n      targetport: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n 3. 验证\n\n创建完后，环境如下：\n\n# kubectl get pods -n zwf -o wide\nname                                  ready   status    restarts   age     ip\ndemoapp-deployment-64bdcb8666-4prbk   1/1     running   0          7d17h   192.33.229.12   dmoc-fa163eee1e30\ndemoapp-deployment-64bdcb8666-cxmmz   1/1     running   0          7d17h   192.33.73.139   dmoc-fa163e7188d6\ndemoapp-deployment-64bdcb8666-kkzsg   1/1     running   0          7d17h   192.33.206.93   dmoc-fa163ee6bbe1\ndemoapp-pod                           1/1     running   0          4d17h   192.33.73.172   dmoc-fa163e7188d6\n\n# kubectl get svc -n zwf\nname                       type        cluster-ip       external-ip   port(s)        age\ndemoapp-service            clusterip   192.44.140.73    <none>        80/tcp         7s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n可以直接在环境中请求service的clusterip地址，会随机访问到三个pod，输出的信息包含了请求ip和目的ip。\n\n# curl 192.44.140.73\nikubernetes demoapp v1.0 !! clientip: 10.10.10.16, servername: demoapp-deployment-64bdcb8666-kkzsg, serverip: 192.33.206.93!\n\n# curl 192.44.140.73\nikubernetes demoapp v1.0 !! clientip: 10.65.196.41, servername: demoapp-deployment-64bdcb8666-cxmmz, serverip: 192.33.73.139!\n\n# curl 192.44.140.73\nikubernetes demoapp v1.0 !! clientip: 10.10.10.16, servername: demoapp-deployment-64bdcb8666-4prbk, serverip: 192.33.229.12!\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# kube-services\n\n在prerouting 和output 链的nat表中，都包含了kube-services 子链，该子链中就包含了serivce的iptables规则的配置。\n\n# iptables -l prerouting -t nat\nchain prerouting (policy accept)\ntarget     prot opt source               destination       \nkube-services  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-prerouting  all  --  anywhere             anywhere             /* cali:6gwbt8clxdhdc1b1 */\n\n# iptables -l output -t nat\nchain output (policy accept)\ntarget     prot opt source               destination       \nkube-services  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-output  all  --  anywhere             anywhere             /* cali:tvnhkvao15huipy0 */\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n为什么在prerouting和output链中添加service规则？\n\nservice的作用是负载均衡，也就是需要将ip包进行dnat操作，而这个操作需要在最靠近发送的位置。网卡收到的包进入到网络协议栈时，最先进入的就是prerouting链，也就是节点外部的流量进入的入口。output是本地进程发出的包最先进入的链。所以需要在这两条链中添加kube-services，详情可参考快速了解iptables\n\n为什么nat表？\n\n因为要做dnat操作，所以在nat表。\n\nkube-services下面有许多kube-svc-xxx的子链，每一条子链都是一个集群中一个service的配置，筛选一下\n\n通过筛选demoapp-service 得到下面的子链，只有访问目的地址为192.44.140.73才能进入到该子链中。\n\n# iptables -l kube-services -t nat | grep demoapp-service\nkube-svc-fihihdnrzeg5vqeq  tcp  --  anywhere             192.44.140.73        /* zwf/demoapp-service:http cluster ip */ tcp dpt:http\n\n\n1\n2\n\n\n查看ube-svc-fihihdnrzeg5vqeq 链中内容，其中包含了四条子链。\n\n# iptables -l kube-svc-fihihdnrzeg5vqeq -t nat -n\nchain kube-svc-fihihdnrzeg5vqeq (1 references)\ntarget     prot opt source               destination       \nkube-mark-masq  tcp  -- !192.33.0.0/16        192.44.140.73        /* zwf/demoapp-service:http cluster ip */ tcp dpt:80\nkube-sep-fo7yk2k5daktcvse  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */ statistic mode random probability 0.33333333349\nkube-sep-ipkl7nsntvgki4t5  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */ statistic mode random probability 0.50000000000\nkube-sep-bper562isf3ufyoq  all  --  0.0.0.0/0            0.0.0.0/0            /* zwf/demoapp-service:http */\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n第一条链是，源ip不在192.33.0.0/16段、目的ip为192.44.140.73并且目的端口是80的数据包会匹配到该条子链进行跳转。其中192.33.0.0/16是pod的网段，如果不是集群内的流量，则会匹配上该条子链，会打上0x4000的标记。\n\n# iptables -l kube-mark-masq -t nat -n\nchain kube-mark-masq (548 references)\ntarget     prot opt source               destination       \nmark       all  --  0.0.0.0/0            0.0.0.0/0            mark or 0x4000\n\n\n1\n2\n3\n4\n\n\n后面的三条链是为了将流量随机的分配到任意一个pod中。第二条链代表着有1/3的概率会匹配到该链，而第三条链代表着1/2，最后一条链代表着百分百。\n\n看第二条链中的规则，第一条规则是跳转到子链kube-mark-masq ，源ip为192.33.206.93的数据包打上了0x4000标记，再将目的ip dnat成192.33.206.93，说明如果自己访问自己，也会被打上标记。\n\n这里的192.33.206.93是本身service所匹配上的pod ip地址，如果调用自己的service则会匹配上该链，打上0x4000标记。\n\n而第二条规则是一个dnat操作，会将目标地址改为192.33.206.93:80，也就是pod的地址。\n\n # iptables -l kube-sep-fo7yk2k5daktcvse -t nat\nchain kube-sep-fo7yk2k5daktcvse (1 references)\ntarget     prot opt source               destination   \nkube-mark-masq  all  --  192.33.206.93        anywhere             /* zwf/demoapp-service:http */\ndnat       tcp  --  anywhere             anywhere             /* zwf/demoapp-service:http */ tcp to:192.33.206.93:80\n\n\n1\n2\n3\n4\n5\n\n\n剩下的第3、4条规则也是一样的操作，会将流量dnat到对应的pod中。\n\n\n# postrouting\n\npostrouting中包含了一条kube-postrouting子链，子链也是由kube-porxy来写入的。\n\n# iptables -l postrouting -t nat\nchain postrouting (policy accept)\ntarget     prot opt source               destination       \nkube-postrouting  all  --  anywhere             anywhere             /* kubernetes postrouting rules */\ncali-postrouting  all  --  anywhere             anywhere             /* cali:o3lywmrlqyemjtb5 */\n\n\n1\n2\n3\n4\n5\n\n\n查看子链kube-postrouting 内容：\n\n 1. 第一条规则是没有标记为0x400的数据包会return，不执行下面的子链。还记得在kube-prerouting 中有两次打上0x4000标记，代表着访问是集群外部访问该service或者是源和目的一样，都会往下走。\n 2. 第二条规则是对数据包的标记值进行异或，而这里是0x4000与0x4000进行异或，也就是0\n 3. 第三条规则时对该数据包进行snat，random-fully是对源端口进行随机获取。\n\n# iptables -l kube-postrouting -t nat\nchain kube-postrouting (1 references)\ntarget     prot opt source               destination       \nreturn     all  --  anywhere             anywhere             mark match ! 0x4000/0x4000\nmark       all  --  anywhere             anywhere             mark xor 0x4000\nmasquerade  all  --  anywhere             anywhere             /* kubernetes service traffic requiring snat */ random-fully\n\n\n1\n2\n3\n4\n5\n6\n\n\n这里有两种情况会被snat，说说为什么。\n\n\n# snat\n\n\n# 为什么集群外部访问该service需要被snat？\n\n数据包需要回包，如果没有snat，那么回包的目的ip是客户端的ip，而源ip是pod的ip，而客户端并不认该数据包，则会被丢弃。\n\n‍\n\n如果有发生snat，那么回包的时候可以回到node1的节点，再回到client。\n\n‍\n\n但问题又来了，是怎么从node1再回包到client的呢？\n\n\n# conntrack\n\nconntrack是一个追踪表，在每一个数据包进入到netfilter的时候，都会记录一条记录，当我们进行snat和dnat的时候也都会更新该表中的记录。\n\n所以在node1回包给client时候，可以通过查询这个表中的记录，然后再次snat和dnat恢复回去就可以进行正常的回包了。\n\n\n\n可以看下conntrack里面的记录长什么样子。\n\n先在某一台节点上curl service的ip，上图的client其实也是在node1上的，因为node1上有两张网卡，node1和node2的通信使用的网卡eth2 ip为10.10.10.16，因为转发到其他节点，所以会被snat。\n\n# curl 192.44.140.73\nikubernetes demoapp v1.0 !! clientip: 10.10.10.16, servername: demoapp-deployment-64bdcb8666-4prbk, serverip: 192.33.229.12!\n\n\n1\n2\n\n\n这里主要是看src和dst分别是client请求service的目的ip，然后后面又有一个src和dst它是由node2回包给node1的源和目的ip，也就是源是pod的ip，dst是node1节点ip。\n\n前面是发送包的方向，后面是回包的方向。通过查询该表，即可以从node1回包给client\n\n# conntrack -l | grep 192.33.229.12\ntcp      6 107 time_wait src=10.65.196.41 dst=192.44.140.73 sport=33468 dport=80 src=192.33.229.12 dst=10.10.10.16 sport=80 dport=18623 [assured] mark=0 use=1\n\n\n1\n2\n\n\n‍\n\n\n# 源和目的ip相同\n\n当pod访问service时，正好dnat成自己的ip，那么就存在源和目的ip一样的情况。\n\n\n\n这种数据包是很特殊的存在，网络设备可能会将这种数据包视为无效或者异常的包被丢弃，最好不要一样，所以会将源ip snat为主机的ip，解决该问题。\n\n实验\n\n\n\n当前节点的ip为：10.65.196.41，然后进入在当前节点的pod内，当前pod的ip为：192.33.73.139\n\nkubectl exec -it -n zwf demoapp-deployment-64bdcb8666-cxmmz -- sh\n\n\n\n1\n2\n\n\n进行多次curl service ip，当某一次请求到本pod的ip时，查看其clientip，发现其源ip是：10.65.196.41，这个当前节点的ip\n\n# curl 192.44.140.73\nikubernetes demoapp v1.0 !! clientip: 10.65.196.41, servername: demoapp-deployment-64bdcb8666-cxmmz, serverip: 192.33.73.139!\n\n\n1\n2\n\n\n\n# nodeport\n\n上面介绍的是serivi type=clusterip方式的，那么nodeport有什么区别呢？\n\n\n# 搭建环境\n\n先将clusterip的service删了，防止干扰。\n\nkubectl delete svc -n zwf demoapp-service\n\n\n1\n\n\n创建nodeport的service文件demo_service_nodeport.yaml\n\napiversion: v1\nkind: service\nmetadata:\n  name: demoapp-nodeport-service\nspec:\n  selector:\n    app: demoapp\n  ports:\n    - name: http\n      protocol: tcp\n      port: 80\n      targetport: 80\n  type: nodeport\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n创建service\n\n# kubectl apply -n zwf -f demo_service_nodeport.yaml \n\n# kubectl get svc -n zwf\nname                       type       cluster-ip       external-ip   port(s)        age\ndemoapp-nodeport-service   nodeport   192.44.152.223   <none>        80:30337/tcp   64s\n\n\n1\n2\n3\n4\n5\n\n\n\n# 请求clusterip\n\n通过clusterip+端口的方式请求service，原理和上面将是一样的。\n\n在postrouting和output中添加了kube-services链，其中包含了新增的service对应的kube-svc-xxx子链，当访问的是其clusterip时，则匹配上该链。在其中包含了从多个pod中随机选择一个进行dnat操作，打上标记，在postrouting中再snat。\n\n# iptables -l prerouting -t nat\nchain prerouting (policy accept)\ntarget     prot opt source               destination       \nkube-services  all  --  anywhere             anywhere             /* kubernetes service portals */\ncali-prerouting  all  --  anywhere             anywhere             /* cali:6gwbt8clxdhdc1b1 */\n\n\n# iptables -l kube-services -t nat | grep zwf\nkube-svc-yswrjgok5veb6hog  tcp  --  anywhere             192.44.152.223       /* zwf/demoapp-nodeport-service:http cluster ip */ tcp dpt:http\n\n# iptables -l kube-svc-yswrjgok5veb6hog -t nat |grep zwf\nkube-mark-masq  tcp  -- !192.33.0.0/16        192.44.152.223       /* zwf/demoapp-nodeport-service:http cluster ip */ tcp dpt:http\nkube-mark-masq  tcp  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ tcp dpt:30337\nkube-sep-nmmbrszxi4oiwdpb  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ statistic mode random probability 0.33333333349\nkube-sep-pxdorkzi3gd2rumc  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ statistic mode random probability 0.50000000000\nkube-sep-ylpor67mthphizab  all  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 请求节点ip\n\n但是如果不是通过clusterip而是通过节点ip请求service呢，它是怎么做的？\n\n因为是节点ip，所以无法匹配上该service的kube-svc-xxx子链，但是有一条kube-nodeports\n\n# iptables -l kube-services  -t nat | grep kube-nodeports\nkube-nodeports  all  --  anywhere             anywhere             /* kubernetes service nodeports; note: this must be the last rule in this chain */ addrtype match dst-type local\n\n\n1\n2\n\n\n在其中包含了一条子链kube-svc-yswrjgok5veb6hog ，只要目的端口为30337就能匹配上，而这个端口正好就是demoapp-nodeport-service 的nodeport端口。\n\n这条子链和上面匹配clusterip时是同一个链，都是进行一个dnat操作。\n\n# # iptables -l kube-nodeports -t nat | grep zwf\nkube-svc-yswrjgok5veb6hog  tcp  --  anywhere             anywhere             /* zwf/demoapp-nodeport-service:http */ tcp dpt:30337\n\n\n1\n2\n\n\n‍\n\n\n# 参考链接\n\n * netfilter 链接跟踪机制与nat原理\n * k8s 之 service ip\n * 连接跟踪 conntrack",charsets:{cjk:!0},lastUpdated:"2024/01/18, 19:21:39",lastUpdatedTimestamp:1705576899e3},{title:"kafka中listener和advertised.listeners的作用",frontmatter:{title:"kafka中listener和advertised.listeners的作用",date:"2023-05-01T17:41:02.000Z",permalink:"/pages/fa114f/",categories:["中间件","kafka"],tags:["kafka","中间件"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"如下配置：",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"kafka中listener和advertised.listeners的作用"},{name:"twitter:description",content:"如下配置："},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.kafka/01.listener%E5%92%8Cadvertised.listeners%E7%9A%84%E4%BD%9C%E7%94%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kafka中listener和advertised.listeners的作用"},{property:"og:description",content:"如下配置："},{property:"og:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.kafka/01.listener%E5%92%8Cadvertised.listeners%E7%9A%84%E4%BD%9C%E7%94%A8.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-05-01T17:41:02.000Z"},{property:"article:tag",content:"kafka"},{property:"article:tag",content:"中间件"},{itemprop:"name",content:"kafka中listener和advertised.listeners的作用"},{itemprop:"description",content:"如下配置："}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/01.kafka/01.listener%E5%92%8Cadvertised.listeners%E7%9A%84%E4%BD%9C%E7%94%A8.html",relativePath:"03.中间件/01.kafka/01.listener和advertised.listeners的作用.md",key:"v-67c4fe98",path:"/pages/fa114f/",headers:[{level:2,title:"listener",slug:"listener",normalizedTitle:"listener",charIndex:2},{level:2,title:"advertised.listeners",slug:"advertised-listeners",normalizedTitle:"advertised.listeners",charIndex:630},{level:2,title:"内外网分流",slug:"内外网分流",normalizedTitle:"内外网分流",charIndex:1647},{level:2,title:"参考链接",slug:"参考链接",normalizedTitle:"参考链接",charIndex:2246}],headersStr:"listener advertised.listeners 内外网分流 参考链接",content:'# listener\n\nlistener配置是用来绑定BrokerIP+端口地址 的，也就是只有通过绑定的地址才能够访问到该Broker。除了绑定地址之外，还可以配置该监听地址的认证协议，也就是使用该地址连接Broker时需要指定使用何种协议方式进行连接。\n\n如下配置：\n\nlisteners: INTERNAL://172.17.0.10:9092,EXTERNAL://172.17.0.10:9094\nkafka_listener_security_protocol_map: "INTERNAL:SASL_PLAINTEXT,EXTERNAL:SASL_PLAINTEXT"\n\n\n1\n2\n\n\n连接该Broker的客户端只能通过172.17.0.10:9092 和172.17.0.10:9094 这两个地址访问kafka，并给前一个地址设置listener名称为INTERNAL ，后一个为EXTERNAL\n\n在kafka_listener_security_protocol_map 配置中设置listener所使用的通信协议，INTERNAL设置的是SASL_PLAINTEXT ，这也是常见的用户名和密码认证协议，EXTERNAL 设置也是该协议。\n\n最终，kafka 客户端连接该kafka broker，需要通过172.17.0.10:9092 或172.17.0.10:9094 地址进行连接，并且都需要使用用户名和密码进行认证。\n\n\n# advertised.listeners\n\n该配置指定Kafka Broker对外公开的网络IP和端口，用于告知客户端如何连接到Kafka Broker。公开的方式是通过存储在zookeeper中进行共享数据的。\n\n如下配置：\n\nlisteners: INTERNAL://172.17.0.10:9092,EXTERNAL://172.17.0.10:9094\nadvertised_listeners: INTERNAL://172.17.0.10:9092,EXTERNAL://公网IP:端口\nkafka_listener_security_protocol_map: "INTERNAL:SASL_PLAINTEXT,EXTERNAL:SASL_PLAINTEXT"\n\n\n1\n2\n3\n\n\nlisteners 和kafka_listener_security_protocol_map 的配置和上面讲的一样，而advertised_listeners 的配置和listeners 配置含义基本一致，但是它会保存在zookeeper中/brokers/ids/0 的endpoints里。\n\n...\n"endpoints":["INTERNAL://172.17.0.10:9092","EXTERNAL://172.17.0.10:9094"]\n...\n\n\n1\n2\n3\n\n\nkafka客户端连接kafka broker时，会先获取所有brokers的元数据信息，获取到endpoints的信息，然后再通过其中的endpint进行对broker进行连接操作。\n\n问题来了，我都知道了kafka broker的IP地址+端口了，为什么还需要advertised.listeners?\n\n在需要代理才能连接kafka broker时，在这种场景时，需要将advertised.listeners 设置为代理的地址。\n\n在公有云场景下部署kafka集群，公网IP不是在本节点网卡上的，所以无法通过listener进行绑定，所以只能通过0.0.0.0进行绑定。但是在集群外部时，kafka客户端进行连接，它是需要有能力访问kafka的每一个broker节点的，所以需要在advertised.listeners中配置公网IP，并存储在zookeeper中，这样kafka客户端就能拿到所有broker节点的公网IP并进行访问。\n\n\n# 内外网分流\n\n在公有云场景下，我们希望在集群内部客户端访问时不需要认证，而外部客户端访问时需要走认证加密访问。配置如下：\n\nlisteners: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9094\nadvertised_listeners: INTERNAL://内网IP:9092,EXTERNAL://公网IP:9094\nkafka_listener_security_protocol_map: "INTERNAL:PLAINTEXT,EXTERNAL:SASL_PLAINTEXT"\n\n\n1\n2\n3\n\n\nlisteners都设置成对0.0.0.0进行监听也就是监听所有的网卡，但它们的端口不同，9092端口使用PLAINTEXT协议，而9094端口走的是SASL_PLAINTEXT协议\n\nadvertised_listeners，内网IP使用PLAINTEXT协议，公网IP使用SASL_PLAINTEXT协议。\n\n当内网客户端访问时，会先获取到所有brokers的advertised_listeners信息，然后通过PLAINTEXT协议走内网IP访问kafka集群。\n\n当公网客户端访问时，会先获取到所有brokers的advertised_listeners信息，然后通过SASL_PLAINTEXT走公网IP进行访问。\n\n‍\n\n\n# 参考链接\n\n * https://www.finclip.com/news/f/30226.html\n * https://juejin.cn/post/6893410969611927566',normalizedContent:'# listener\n\nlistener配置是用来绑定brokerip+端口地址 的，也就是只有通过绑定的地址才能够访问到该broker。除了绑定地址之外，还可以配置该监听地址的认证协议，也就是使用该地址连接broker时需要指定使用何种协议方式进行连接。\n\n如下配置：\n\nlisteners: internal://172.17.0.10:9092,external://172.17.0.10:9094\nkafka_listener_security_protocol_map: "internal:sasl_plaintext,external:sasl_plaintext"\n\n\n1\n2\n\n\n连接该broker的客户端只能通过172.17.0.10:9092 和172.17.0.10:9094 这两个地址访问kafka，并给前一个地址设置listener名称为internal ，后一个为external\n\n在kafka_listener_security_protocol_map 配置中设置listener所使用的通信协议，internal设置的是sasl_plaintext ，这也是常见的用户名和密码认证协议，external 设置也是该协议。\n\n最终，kafka 客户端连接该kafka broker，需要通过172.17.0.10:9092 或172.17.0.10:9094 地址进行连接，并且都需要使用用户名和密码进行认证。\n\n\n# advertised.listeners\n\n该配置指定kafka broker对外公开的网络ip和端口，用于告知客户端如何连接到kafka broker。公开的方式是通过存储在zookeeper中进行共享数据的。\n\n如下配置：\n\nlisteners: internal://172.17.0.10:9092,external://172.17.0.10:9094\nadvertised_listeners: internal://172.17.0.10:9092,external://公网ip:端口\nkafka_listener_security_protocol_map: "internal:sasl_plaintext,external:sasl_plaintext"\n\n\n1\n2\n3\n\n\nlisteners 和kafka_listener_security_protocol_map 的配置和上面讲的一样，而advertised_listeners 的配置和listeners 配置含义基本一致，但是它会保存在zookeeper中/brokers/ids/0 的endpoints里。\n\n...\n"endpoints":["internal://172.17.0.10:9092","external://172.17.0.10:9094"]\n...\n\n\n1\n2\n3\n\n\nkafka客户端连接kafka broker时，会先获取所有brokers的元数据信息，获取到endpoints的信息，然后再通过其中的endpint进行对broker进行连接操作。\n\n问题来了，我都知道了kafka broker的ip地址+端口了，为什么还需要advertised.listeners?\n\n在需要代理才能连接kafka broker时，在这种场景时，需要将advertised.listeners 设置为代理的地址。\n\n在公有云场景下部署kafka集群，公网ip不是在本节点网卡上的，所以无法通过listener进行绑定，所以只能通过0.0.0.0进行绑定。但是在集群外部时，kafka客户端进行连接，它是需要有能力访问kafka的每一个broker节点的，所以需要在advertised.listeners中配置公网ip，并存储在zookeeper中，这样kafka客户端就能拿到所有broker节点的公网ip并进行访问。\n\n\n# 内外网分流\n\n在公有云场景下，我们希望在集群内部客户端访问时不需要认证，而外部客户端访问时需要走认证加密访问。配置如下：\n\nlisteners: internal://0.0.0.0:9092,external://0.0.0.0:9094\nadvertised_listeners: internal://内网ip:9092,external://公网ip:9094\nkafka_listener_security_protocol_map: "internal:plaintext,external:sasl_plaintext"\n\n\n1\n2\n3\n\n\nlisteners都设置成对0.0.0.0进行监听也就是监听所有的网卡，但它们的端口不同，9092端口使用plaintext协议，而9094端口走的是sasl_plaintext协议\n\nadvertised_listeners，内网ip使用plaintext协议，公网ip使用sasl_plaintext协议。\n\n当内网客户端访问时，会先获取到所有brokers的advertised_listeners信息，然后通过plaintext协议走内网ip访问kafka集群。\n\n当公网客户端访问时，会先获取到所有brokers的advertised_listeners信息，然后通过sasl_plaintext走公网ip进行访问。\n\n‍\n\n\n# 参考链接\n\n * https://www.finclip.com/news/f/30226.html\n * https://juejin.cn/post/6893410969611927566',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"mysql之日志",frontmatter:{title:"mysql之日志",date:"2023-01-01T20:23:07.000Z",permalink:"/pages/2d69c7/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。",feed:{enable:!0},tags:["mysql","数据库"],categories:["数据库","mysql"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16699026890611669902688907.png"},{name:"twitter:title",content:"mysql之日志"},{name:"twitter:description",content:"一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16699026890611669902688907.png"},{name:"twitter:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/01.mysql%E4%B9%8B%E6%97%A5%E5%BF%97.html"},{property:"og:type",content:"article"},{property:"og:title",content:"mysql之日志"},{property:"og:description",content:"一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16699026890611669902688907.png"},{property:"og:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/01.mysql%E4%B9%8B%E6%97%A5%E5%BF%97.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-01-01T20:23:07.000Z"},{property:"article:tag",content:"mysql"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"mysql之日志"},{itemprop:"description",content:"一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16699026890611669902688907.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/01.mysql%E4%B9%8B%E6%97%A5%E5%BF%97.html",relativePath:"03.中间件/03.mysql/01.mysql之日志.md",key:"v-cc91cd44",path:"/pages/2d69c7/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"buffer pool",slug:"buffer-pool",normalizedTitle:"buffer pool",charIndex:146},{level:2,title:"undo log",slug:"undo-log",normalizedTitle:"undo log",charIndex:105},{level:2,title:"redo log",slug:"redo-log",normalizedTitle:"redo log",charIndex:114},{level:3,title:"redo log 的作用",slug:"redo-log-的作用",normalizedTitle:"redo log 的作用",charIndex:537},{level:3,title:"redo log文件结构",slug:"redo-log文件结构",normalizedTitle:"redo log文件结构",charIndex:1128},{level:2,title:"binlog",slug:"binlog",normalizedTitle:"binlog",charIndex:1333},{level:2,title:"两阶段提交",slug:"两阶段提交",normalizedTitle:"两阶段提交",charIndex:1764},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:2647}],headersStr:"前言 buffer pool undo log redo log redo log 的作用 redo log文件结构 binlog 两阶段提交 相关链接",content:"# 前言\n\n一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。\n\n\n# buffer pool\n\n在数据更新的时候，数据并不是实时同步到硬盘中，而是在一块缓存 buffer pool 中更新，如果缓存中没有查询到该数据，则从磁盘中加载到 buffer pool 中。\n\n当然，缓存的作用是为了提高 IO 性能，可以通过将数据先保留在缓存中，然后在适当的时机，批量写入到硬盘中。\n\n并且在查询数据时，先是从缓存中进行查询，不用去磁盘中查找，减少 IO 的操作，加快查询的速度。\n\n\n# undo log\n\n我们知道 InnoDB 是支持事务的，在事务提交失败时，是会回滚到执行之前的状态，那么肯定是需要保存之前的状态才可以进行恢复的，这个就是通过 undo log 来实现的。\n\n在数据写入 buffer pool 的同时会将更新前的数据保存在 undo log 中，通过该日志语句便可以在事务回滚时，恢复到之前的状态。\n\n\n# redo log\n\n\n# redo log 的作用\n\n再回到 buffer pool ，因为它是缓存，是在内存中，所有它的缺点也显而易见，那就是当服务器宕机中，缓存中的数据会丢失，那么 mysql 是如何保证数据的持久性呢？这个时候就要来介绍介绍 redo log 了。\n\n在数据更新到 buffer pool 后，这个时候会将更新后的数据记录到 redo log buffer 中，这个也是一个缓存区，它当然也具备了缓存优缺点，并且默认是在提交事务的时候写入到 redo log 中，刷盘的策略可以根据 innodb_flush_log_at_trx_commit 来设置\n\n * 0，不刷入磁盘\n * 1，立即刷入磁盘（默认）\n * 2，先刷入到 os cache 中\n\n因为 redo log 是顺序写入，所以 IO 性能不会太差。\n\n当 buffer pool 中的数据还没有写入到磁盘中时，发生了宕机，当 mysql 重启时，会读取已经持久化 redo log 中的数据，再恢复到 buffer pool 中。\n\n在开启事务准备更新一条记录时，InnoDB 会先在 buffer pool 中更新数据，然后将更新后的数据记录到 redo log buffer 中，这也是一个缓存。当然这个时候也是会发生宕机，但是没关系，如果该部分数据丢失，则认为该次事务提交失败，数据会恢复到之前的状态。\n\n\n# redo log文件结构\n\nredolog 是由多个固定大小的文件组成的一个环形结构，并在这个环形结构中不断的写入与覆盖的过程。\n\n * write pos：记录当前的位置\n * checkpoint：当前要擦除的位置\n\n当有新的 redo log 写入时，从 wirte pos 位置往后写，而 check point 是上一次已经刷入磁盘的数据的位置，也是要不断的往后推进，然后将数据刷入磁盘中。\n\n\n# binlog\n\n是在 mysql 层级记录的日志，主要是用于主从复制和数据恢复，可以通过某个时间的全量备份+binlog 来恢复到任意时间内的状态。\n\n和 redo log 的区别\n\n性质   REDO LOG                      BIN LOG                        \n实现   innodb 独有实现                   mysql server 层级实现，所有的引擎都可以使用   \n内容   物理 log, 记录的是“在某个数据页上做了什么修改”   逻辑 log，给 ID=2 这一行的 c 字段加 1     \n写入   循环写入                          追加写，写到一定大小切换下一个文件继续写           \n应用   崩溃恢复(crash-safe)              主从同步，数据恢复                      \n\n\n# 两阶段提交\n\n为什么需要两阶段提交？\n\n是为了让 redo log 和 bin log 保持逻辑一致性。\n\n 1. 如果先写 redolog 后写 bin log。假设 redo log 写完，写 bin log 时 crash 了。\n\n因为 redo log 写完了，所以即使系统崩溃，也可以恢复数据，但是 bin log 没写完 crash 了，这个时候 bin log 中少了该条语句，因此数据备份的时候，如果使用了该份 bin log 则会少一次更新。\n\n 2. 如果先写 bin log 后写 redo log。假设 bin log 写完，写 redo log 时 crash 了。\n\n因为 redo log 没写完，所以该事务没有生效，但是 binlog 中已经有该条记录，所以使用 bin log 时，会多出一个事务，与原来的数据不一致。\n\n所以使用两阶段提交可以解决上面两种场景。\n\n两阶段提交的实现逻辑\n\n 1. 在更新数据时，会先在 redo log 中记录当前更新的数据，并且标记为 prepare 状态\n 2. binlog 再进行写入\n 3. 事务提交时， redo log 再将该条记录标记为 commit 状态并且刷入到磁盘中。\n\n通过 prepare 和 commit 两种状态来完成两阶段的提交实现。\n\n验证两阶段提交\n\n 1. 如果在两阶段提交的第一步后发生 crash，也就是 redo log 已经更新了数据并且为 Prepare 状态，但是 binlog 还未写入就出现了 crash，这个时候，mysql 重启后，因为 redo log 未 commit，可以通过回滚将数据恢复。\n 2. 如果在第二步发生 crash，也就是 redo log 为 prepare 状态，并且 binlog 已经写入，但是这时候出现了 crash，在 mysql 重启后，因为 binlog 已经有了记录，所以会继续提交该事务，否则 bin log 中数据新增了一条，而 redo log 没提交则可能发生两者数据不一致的情况。\n\n\n# 相关链接\n\n * 一条 SQL 的执行过程详解\n * 基于Redo Log和Undo Log的MySQL崩溃恢复流程",normalizedContent:"# 前言\n\n一条数据在更新过程当中，如果中途 mysql crash 了，mysql 是如何保证数据的一致性和持久性的？在这个过程中 mysql 的日志系统起到了至关重要的作用。本文将会介绍 mysql 中的 undo log、redo log 和 bin log 在这其中的作用。\n\n\n# buffer pool\n\n在数据更新的时候，数据并不是实时同步到硬盘中，而是在一块缓存 buffer pool 中更新，如果缓存中没有查询到该数据，则从磁盘中加载到 buffer pool 中。\n\n当然，缓存的作用是为了提高 io 性能，可以通过将数据先保留在缓存中，然后在适当的时机，批量写入到硬盘中。\n\n并且在查询数据时，先是从缓存中进行查询，不用去磁盘中查找，减少 io 的操作，加快查询的速度。\n\n\n# undo log\n\n我们知道 innodb 是支持事务的，在事务提交失败时，是会回滚到执行之前的状态，那么肯定是需要保存之前的状态才可以进行恢复的，这个就是通过 undo log 来实现的。\n\n在数据写入 buffer pool 的同时会将更新前的数据保存在 undo log 中，通过该日志语句便可以在事务回滚时，恢复到之前的状态。\n\n\n# redo log\n\n\n# redo log 的作用\n\n再回到 buffer pool ，因为它是缓存，是在内存中，所有它的缺点也显而易见，那就是当服务器宕机中，缓存中的数据会丢失，那么 mysql 是如何保证数据的持久性呢？这个时候就要来介绍介绍 redo log 了。\n\n在数据更新到 buffer pool 后，这个时候会将更新后的数据记录到 redo log buffer 中，这个也是一个缓存区，它当然也具备了缓存优缺点，并且默认是在提交事务的时候写入到 redo log 中，刷盘的策略可以根据 innodb_flush_log_at_trx_commit 来设置\n\n * 0，不刷入磁盘\n * 1，立即刷入磁盘（默认）\n * 2，先刷入到 os cache 中\n\n因为 redo log 是顺序写入，所以 io 性能不会太差。\n\n当 buffer pool 中的数据还没有写入到磁盘中时，发生了宕机，当 mysql 重启时，会读取已经持久化 redo log 中的数据，再恢复到 buffer pool 中。\n\n在开启事务准备更新一条记录时，innodb 会先在 buffer pool 中更新数据，然后将更新后的数据记录到 redo log buffer 中，这也是一个缓存。当然这个时候也是会发生宕机，但是没关系，如果该部分数据丢失，则认为该次事务提交失败，数据会恢复到之前的状态。\n\n\n# redo log文件结构\n\nredolog 是由多个固定大小的文件组成的一个环形结构，并在这个环形结构中不断的写入与覆盖的过程。\n\n * write pos：记录当前的位置\n * checkpoint：当前要擦除的位置\n\n当有新的 redo log 写入时，从 wirte pos 位置往后写，而 check point 是上一次已经刷入磁盘的数据的位置，也是要不断的往后推进，然后将数据刷入磁盘中。\n\n\n# binlog\n\n是在 mysql 层级记录的日志，主要是用于主从复制和数据恢复，可以通过某个时间的全量备份+binlog 来恢复到任意时间内的状态。\n\n和 redo log 的区别\n\n性质   redo log                      bin log                        \n实现   innodb 独有实现                   mysql server 层级实现，所有的引擎都可以使用   \n内容   物理 log, 记录的是“在某个数据页上做了什么修改”   逻辑 log，给 id=2 这一行的 c 字段加 1     \n写入   循环写入                          追加写，写到一定大小切换下一个文件继续写           \n应用   崩溃恢复(crash-safe)              主从同步，数据恢复                      \n\n\n# 两阶段提交\n\n为什么需要两阶段提交？\n\n是为了让 redo log 和 bin log 保持逻辑一致性。\n\n 1. 如果先写 redolog 后写 bin log。假设 redo log 写完，写 bin log 时 crash 了。\n\n因为 redo log 写完了，所以即使系统崩溃，也可以恢复数据，但是 bin log 没写完 crash 了，这个时候 bin log 中少了该条语句，因此数据备份的时候，如果使用了该份 bin log 则会少一次更新。\n\n 2. 如果先写 bin log 后写 redo log。假设 bin log 写完，写 redo log 时 crash 了。\n\n因为 redo log 没写完，所以该事务没有生效，但是 binlog 中已经有该条记录，所以使用 bin log 时，会多出一个事务，与原来的数据不一致。\n\n所以使用两阶段提交可以解决上面两种场景。\n\n两阶段提交的实现逻辑\n\n 1. 在更新数据时，会先在 redo log 中记录当前更新的数据，并且标记为 prepare 状态\n 2. binlog 再进行写入\n 3. 事务提交时， redo log 再将该条记录标记为 commit 状态并且刷入到磁盘中。\n\n通过 prepare 和 commit 两种状态来完成两阶段的提交实现。\n\n验证两阶段提交\n\n 1. 如果在两阶段提交的第一步后发生 crash，也就是 redo log 已经更新了数据并且为 prepare 状态，但是 binlog 还未写入就出现了 crash，这个时候，mysql 重启后，因为 redo log 未 commit，可以通过回滚将数据恢复。\n 2. 如果在第二步发生 crash，也就是 redo log 为 prepare 状态，并且 binlog 已经写入，但是这时候出现了 crash，在 mysql 重启后，因为 binlog 已经有了记录，所以会继续提交该事务，否则 bin log 中数据新增了一条，而 redo log 没提交则可能发生两者数据不一致的情况。\n\n\n# 相关链接\n\n * 一条 sql 的执行过程详解\n * 基于redo log和undo log的mysql崩溃恢复流程",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"mysql之MVCC原理",frontmatter:{title:"mysql之MVCC原理",date:"2023-01-01T20:23:21.000Z",permalink:"/pages/0d8f4a/",tags:["mysql","数据库"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"MVCC 的全称是 Multi- [Version](https://so.csdn.net/so/search?q=Version&spm=1001.2101.3001.7020) Concurrency Control，也就是多版本并发控制，该机制是只有支持事务的 InnoDB 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。",feed:{enable:!0},categories:["数据库","mysql"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210821150008.png"},{name:"twitter:title",content:"mysql之MVCC原理"},{name:"twitter:description",content:"MVCC 的全称是 Multi- [Version](https://so.csdn.net/so/search?q=Version&spm=1001.2101.3001.7020) Concurrency Control，也就是多版本并发控制，该机制是只有支持事务的 InnoDB 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210821150008.png"},{name:"twitter:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/02.mysql%E4%B9%8BMVCC%E5%8E%9F%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"mysql之MVCC原理"},{property:"og:description",content:"MVCC 的全称是 Multi- [Version](https://so.csdn.net/so/search?q=Version&spm=1001.2101.3001.7020) Concurrency Control，也就是多版本并发控制，该机制是只有支持事务的 InnoDB 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210821150008.png"},{property:"og:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/02.mysql%E4%B9%8BMVCC%E5%8E%9F%E7%90%86.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-01-01T20:23:21.000Z"},{property:"article:tag",content:"mysql"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"mysql之MVCC原理"},{itemprop:"description",content:"MVCC 的全称是 Multi- [Version](https://so.csdn.net/so/search?q=Version&spm=1001.2101.3001.7020) Concurrency Control，也就是多版本并发控制，该机制是只有支持事务的 InnoDB 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210821150008.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/03.mysql/02.mysql%E4%B9%8BMVCC%E5%8E%9F%E7%90%86.html",relativePath:"03.中间件/03.mysql/02.mysql之MVCC原理.md",key:"v-16efd28d",path:"/pages/0d8f4a/",headers:[{level:2,title:"什么是 MVCC?",slug:"什么是-mvcc",normalizedTitle:"什么是 mvcc?",charIndex:2},{level:2,title:"MVCC 的实现原理",slug:"mvcc-的实现原理",normalizedTitle:"mvcc 的实现原理",charIndex:145},{level:2,title:"ReadView",slug:"readview",normalizedTitle:"readview",charIndex:373},{level:2,title:"Undo 日志",slug:"undo-日志",normalizedTitle:"undo 日志",charIndex:824},{level:2,title:"快照读和当前读",slug:"快照读和当前读",normalizedTitle:"快照读和当前读",charIndex:1026},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:1314}],headersStr:"什么是 MVCC? MVCC 的实现原理 ReadView Undo 日志 快照读和当前读 相关链接",content:"# 什么是 MVCC?\n\nMVCC 的全称是 Multi- Version Concurrency Control，也就是多版本并发控制，该机制是只有支持事务的 InnoDB 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。\n\n那么它是如何实现的呢？\n\n\n# MVCC 的实现原理\n\n在 Innodb 的每一行数据中都会保存多个版本，每个版本都有对应的事务 ID。\n\n在开启每一个事务时，都会生成当前事务的版本号，当在该事务中操作修改数据时，都会生成一个新的数据行，该数据行在提交之前对其他事务来说是不可见的，然后将版本号更新到数据行中，这样就保证了每个事务操作的数据都是互不影响的，也不存在锁的问题。\n\n在读操作时，我们只去快照读，而不读取正在修改的数据，这是两个不同版本的数据，所以操作上不会发生冲突。\n\n\n# ReadView\n\nRead View 是来表示当前事务的可见性的，通过上面的 MVCC 原理知道所有的行数据都是有版本的，那么哪些版本的数据在当前事务是可见的，也就是可读到的，哪些是不可见的。\n\n创建 Read View 时，会构造一个数组来保存当前事务启动瞬间启动了但是没有提交的事务 ID。\n\n * 如果小于最小值，则是已经提交的事务，是可见的\n * 如果大于最大值，则代表是将来启动的事务，不可见\n * 如果在数组列表中，表示还没提交的事务，不可见\n * 如果大于最小值，小于最大值，但不在数组中，表示是已经提交了的事务，可见\n\n创建 Read View 的时机在不同的隔离级别是不同。\n\n * 在读未提交中，直接读取的是最新版本的数据\n * 在读已提交中，在每次读取数据前，就会生成一个 Read View，然后再读取可见版本的数据。\n * 在可重复读中，在每次开启事务的时候，就会生成 Read View，在提交之前都一直如此使用。\n * 在串行化中，是通过加锁的方式来访问数据。\n\n\n# Undo 日志\n\n每条记录更新时，都会同时记录一条回滚操作。记录上的最新值都可通过回滚操作得到前一个状态值\n\n在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。系统会判断在没有事务需要用到回滚日志时，回滚日志会被删除\n\n不建议使用长事务的原因是，在事务提交之前，回滚日志都需要保存，导致占用大量存储空间。\n\n\n\n\n# 快照读和当前读\n\n快照读，就是当进行查询时，是根据 Read View 的视图可见性来读取对应版本的数据。\n\n有这么一个场景，当前是可重复读的隔离界别，开始事务的顺序分别是 A、B、C，事务 C 更新 K 之后，最新的版本 102，当事务 B，根据 Read View 是看不到 102 版本的数据，那么其更新只能在 90 版本上去+1，这样的结果肯定是不对的，因为不是在最新的结果上进行+1，所以这里需要用到 当前读，也就是去读取当前数据的最新版本的数据，然后再进行+1。该当前读会对该行数据进行加锁，在该事务 commit 之前，其他事务都不能对其进行操作。\n\n\n\n\n# 相关链接\n\n * https://blog.csdn.net/SIESTA030/article/details/123113437\n * https://blog.csdn.net/huaishu/article/details/89924250",normalizedContent:"# 什么是 mvcc?\n\nmvcc 的全称是 multi- version concurrency control，也就是多版本并发控制，该机制是只有支持事务的 innodb 引擎下才存在的，用来实现提高数据库的并发性能，可以做到：读不加锁，读写不冲突。\n\n那么它是如何实现的呢？\n\n\n# mvcc 的实现原理\n\n在 innodb 的每一行数据中都会保存多个版本，每个版本都有对应的事务 id。\n\n在开启每一个事务时，都会生成当前事务的版本号，当在该事务中操作修改数据时，都会生成一个新的数据行，该数据行在提交之前对其他事务来说是不可见的，然后将版本号更新到数据行中，这样就保证了每个事务操作的数据都是互不影响的，也不存在锁的问题。\n\n在读操作时，我们只去快照读，而不读取正在修改的数据，这是两个不同版本的数据，所以操作上不会发生冲突。\n\n\n# readview\n\nread view 是来表示当前事务的可见性的，通过上面的 mvcc 原理知道所有的行数据都是有版本的，那么哪些版本的数据在当前事务是可见的，也就是可读到的，哪些是不可见的。\n\n创建 read view 时，会构造一个数组来保存当前事务启动瞬间启动了但是没有提交的事务 id。\n\n * 如果小于最小值，则是已经提交的事务，是可见的\n * 如果大于最大值，则代表是将来启动的事务，不可见\n * 如果在数组列表中，表示还没提交的事务，不可见\n * 如果大于最小值，小于最大值，但不在数组中，表示是已经提交了的事务，可见\n\n创建 read view 的时机在不同的隔离级别是不同。\n\n * 在读未提交中，直接读取的是最新版本的数据\n * 在读已提交中，在每次读取数据前，就会生成一个 read view，然后再读取可见版本的数据。\n * 在可重复读中，在每次开启事务的时候，就会生成 read view，在提交之前都一直如此使用。\n * 在串行化中，是通过加锁的方式来访问数据。\n\n\n# undo 日志\n\n每条记录更新时，都会同时记录一条回滚操作。记录上的最新值都可通过回滚操作得到前一个状态值\n\n在视图 a、b、c 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（mvcc）。系统会判断在没有事务需要用到回滚日志时，回滚日志会被删除\n\n不建议使用长事务的原因是，在事务提交之前，回滚日志都需要保存，导致占用大量存储空间。\n\n\n\n\n# 快照读和当前读\n\n快照读，就是当进行查询时，是根据 read view 的视图可见性来读取对应版本的数据。\n\n有这么一个场景，当前是可重复读的隔离界别，开始事务的顺序分别是 a、b、c，事务 c 更新 k 之后，最新的版本 102，当事务 b，根据 read view 是看不到 102 版本的数据，那么其更新只能在 90 版本上去+1，这样的结果肯定是不对的，因为不是在最新的结果上进行+1，所以这里需要用到 当前读，也就是去读取当前数据的最新版本的数据，然后再进行+1。该当前读会对该行数据进行加锁，在该事务 commit 之前，其他事务都不能对其进行操作。\n\n\n\n\n# 相关链接\n\n * https://blog.csdn.net/siesta030/article/details/123113437\n * https://blog.csdn.net/huaishu/article/details/89924250",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"kube-proxy源码分析",frontmatter:{title:"kube-proxy源码分析",date:"2024-01-18T16:43:23.000Z",permalink:"/pages/6e0045/",categories:["云原生","k8s"],tags:["k8s","源码分析","go"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据[kubernetes1.23.9](https://github.com/kubernetes/kubernetes/tree/v1.23.9)版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。",comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/image-20240118162033-mma8vs8.png"},{name:"twitter:title",content:"kube-proxy源码分析"},{name:"twitter:description",content:"本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据[kubernetes1.23.9](https://github.com/kubernetes/kubernetes/tree/v1.23.9)版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/image-20240118162033-mma8vs8.png"},{name:"twitter:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/17.kube-proxy%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kube-proxy源码分析"},{property:"og:description",content:"本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据[kubernetes1.23.9](https://github.com/kubernetes/kubernetes/tree/v1.23.9)版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/image-20240118162033-mma8vs8.png"},{property:"og:url",content:"https://www.msqfx.cc/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/17.kube-proxy%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2024-01-18T16:43:23.000Z"},{property:"article:tag",content:"k8s"},{property:"article:tag",content:"源码分析"},{property:"article:tag",content:"go"},{itemprop:"name",content:"kube-proxy源码分析"},{itemprop:"description",content:"本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据[kubernetes1.23.9](https://github.com/kubernetes/kubernetes/tree/v1.23.9)版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/image-20240118162033-mma8vs8.png"}],readingShow:"top"},regularPath:"/01.%E4%BA%91%E5%8E%9F%E7%94%9F/07.k8s/17.kube-proxy%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html",relativePath:"01.云原生/07.k8s/17.kube-proxy源码分析.md",key:"v-079101b0",path:"/pages/6e0045/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:21},{level:2,title:"初始化",slug:"初始化",normalizedTitle:"初始化",charIndex:119},{level:2,title:"Run",slug:"run",normalizedTitle:"run",charIndex:225},{level:2,title:"service 和 endpointslice 变更事件",slug:"service-和-endpointslice-变更事件",normalizedTitle:"service 和 endpointslice 变更事件",charIndex:12013},{level:2,title:"BoundedFrequencyRunner",slug:"boundedfrequencyrunner",normalizedTitle:"boundedfrequencyrunner",charIndex:9187},{level:2,title:"syncProxyRules",slug:"syncproxyrules",normalizedTitle:"syncproxyrules",charIndex:9117},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:19890},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:20381}],headersStr:"简介 初始化 Run service 和 endpointslice 变更事件 BoundedFrequencyRunner syncProxyRules 总结 相关链接",content:'# kube-proxy源码分析\n\n\n# 简介\n\n本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据kubernetes1.23.9版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。\n\n\n# 初始化\n\nkube-proxy入口文件在cmd/kube-proxy/proxy.go\n\nfunc main() {\n\tcommand := app.NewProxyCommand()\n\tcode := cli.Run(command)\n\tos.Exit(code)\n}\n\n\n1\n2\n3\n4\n5\n\n\n查看app.NewProxyCommand()方法，使用的cobra命令行解析库来作为程序入口\n\nfunc NewProxyCommand() *cobra.Command {\n\topts := NewOptions()\n\n\tcmd := &cobra.Command{\n\t\tUse: "kube-proxy",\n\t\tLong: `The Kubernetes network proxy runs on each node. This\nreflects services as defined in the Kubernetes API on each node and can do simple\nTCP, UDP, and SCTP stream forwarding or round robin TCP, UDP, and SCTP forwarding across a set of backends.\nService cluster IPs and ports are currently found through Docker-links-compatible\nenvironment variables specifying ports opened by the service proxy. There is an optional\naddon that provides cluster DNS for these cluster IPs. The user must create a service\nwith the apiserver API to configure the proxy.`,\n\t\tRunE: func(cmd *cobra.Command, args []string) error {\n\t\t\tverflag.PrintAndExitIfRequested()\n\t\t\tcliflag.PrintFlags(cmd.Flags())\n\n\t\t\tif err := initForOS(opts.WindowsService); err != nil {\n\t\t\t\treturn fmt.Errorf("failed os init: %w", err)\n\t\t\t}\n\n\t\t\t// 1. 加载配置文件kubeproxyconfig.KubeProxyConfiguration\n\t\t\t// 2. 监控文件变化\n\t\t\tif err := opts.Complete(); err != nil {\n\t\t\t\treturn fmt.Errorf("failed complete: %w", err)\n\t\t\t}\n\n\t\t\t// 配置参数的校验\n\t\t\tif err := opts.Validate(); err != nil {\n\t\t\t\treturn fmt.Errorf("failed validate: %w", err)\n\t\t\t}\n\n\t\t\t// 运行服务\n\t\t\tif err := opts.Run(); err != nil {\n\t\t\t\tklog.ErrorS(err, "Error running ProxyServer")\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn nil\n\t\t},\n\t\tArgs: func(cmd *cobra.Command, args []string) error {\n\t\t\tfor _, arg := range args {\n\t\t\t\tif len(arg) > 0 {\n\t\t\t\t\treturn fmt.Errorf("%q does not take any arguments, got %q", cmd.CommandPath(), args)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t}\n\n\tvar err error\n    // 填充一些默认配置\n\topts.config, err = opts.ApplyDefaults(opts.config)\n\tif err != nil {\n\t\tklog.ErrorS(err, "Unable to create flag defaults")\n\t\t// ACTION REQUIRED: Exit code changed from 255 to 1\n\t\tos.Exit(1)\n\t}\n\n\tfs := cmd.Flags()\n\topts.AddFlags(fs)\n\t// 将go的命令行参数也加到命令行参数中\n\tfs.AddGoFlagSet(goflag.CommandLine) // for --boot-id-file and --machine-id-file\n\n\t_ = cmd.MarkFlagFilename("config", "yaml", "yml", "json")\n\n\treturn cmd\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n\n 1. 读取配置文件KubeProxyConfiguration，并监听变化收到对应的事件\n 2. 对配置KubeProxyConfiguration进行校验\n 3. 启动服务\n\n再来看opts.Run() 服务启动的实现\n\nfunc (o *Options) Run() error {\n\tdefer close(o.errCh)\n\n    // 如果配置了该字段，将配置文件写入指定位置，然后退出\n\tif len(o.WriteConfigTo) > 0 {\n\t\treturn o.writeConfigFile()\n\t}\n\n    // 创建代理服务\n\tproxyServer, err := NewProxyServer(o)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// 清除所有的iptables规则\n\tif o.CleanupAndExit {\n\t\treturn proxyServer.CleanupAndExit()\n\t}\n\n\t// 启动代理服务\n\to.proxyServer = proxyServer\n\treturn o.runLoop()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再看NewProxyServer() 的实现，主要是用来创建proxyServer对象，并且在其中根据当前的网络模式，通过iptables.NewProxier来创建proxier对象。\n\nfunc NewProxyServer(o *Options) (*ProxyServer, error) {\n\treturn newProxyServer(o.config, o.CleanupAndExit, o.master)\n}\n\nfunc newProxyServer(\n\tconfig *proxyconfigapi.KubeProxyConfiguration,\n\tcleanupAndExit bool,\n\tmaster string) (*ProxyServer, error) {\n\n\t// 执行本地命令的控制器\n\texecer := exec.New()\n\n\tkernelHandler = ipvs.NewLinuxKernelHandler() \n    // 创建ipset命令的执行器\n\tipsetInterface = utilipset.New(execer)\n    // 判断是否支持ipvs\n\tcanUseIPVS, err := ipvs.CanUseIPVSProxier(kernelHandler, ipsetInterface, config.IPVS.Scheduler)\n\tif string(config.Mode) == proxyModeIPVS && err != nil {\n\t\tklog.ErrorS(err, "Can\'t use the IPVS proxier")\n\t}\n\n\tif canUseIPVS {\n        // 如果支持的话，创建ipvs执行器\n\t\tipvsInterface = utilipvs.New()\n\t}\n\n\t// 创建事件记录器\n\teventBroadcaster := events.NewBroadcaster(&events.EventSinkImpl{Interface: client.EventsV1()})\n\trecorder := eventBroadcaster.NewRecorder(scheme.Scheme, "kube-proxy")\n\n\t// 创建健康检查服务\n\tvar healthzServer healthcheck.ProxierHealthUpdater\n\tif len(config.HealthzBindAddress) > 0 {\n\t\thealthzServer = healthcheck.NewProxierHealthServer(config.HealthzBindAddress, 2*config.IPTables.SyncPeriod.Duration, recorder, nodeRef)\n\t}\n\n    // 获取当前的代理模式\n\tproxyMode := getProxyMode(string(config.Mode), canUseIPVS, iptables.LinuxKernelCompatTester{})\n\t\n    // 获取当前的主要的IP协议\n\tprimaryProtocol := utiliptables.ProtocolIPv4\n\tif netutils.IsIPv6(nodeIP) {\n\t\tprimaryProtocol = utiliptables.ProtocolIPv6\n\t}\n\n\t// 创建iptables执行器\n\tiptInterface = utiliptables.New(execer, primaryProtocol)\n\n\t// 可能支持ipv4和ipv6两种执行器\n\tvar ipt [2]utiliptables.Interface\n\tdualStack := true // While we assume that node supports, we do further checks below\n\n\t// 如果支持的是iptables模式\n\tif proxyMode == proxyModeIPTables {\n\n\t\t// 双端模式，支持IP4和IPV6\n\t\tif dualStack {\n\t\t\tproxier, err = iptables.NewDualStackProxier(\n\t\t\t\tipt,\n\t\t\t\tutilsysctl.New(),\n\t\t\t\texecer,\n\t\t\t\tconfig.IPTables.SyncPeriod.Duration,\n\t\t\t\tconfig.IPTables.MinSyncPeriod.Duration,\n\t\t\t\tconfig.IPTables.MasqueradeAll,\n\t\t\t\tint(*config.IPTables.MasqueradeBit),\n\t\t\t\tlocalDetectors,\n\t\t\t\thostname,\n\t\t\t\tnodeIPTuple(config.BindAddress),\n\t\t\t\trecorder,\n\t\t\t\thealthzServer,\n\t\t\t\tconfig.NodePortAddresses,\n\t\t\t)\n\t\t} else {\n\t\t\tproxier, err = iptables.NewProxier(\n\t\t\t\tiptInterface,\n\t\t\t\tutilsysctl.New(),\n\t\t\t\texecer,\n\t\t\t\tconfig.IPTables.SyncPeriod.Duration,\n\t\t\t\tconfig.IPTables.MinSyncPeriod.Duration,\n\t\t\t\tconfig.IPTables.MasqueradeAll,\n\t\t\t\tint(*config.IPTables.MasqueradeBit),\n\t\t\t\tlocalDetector,\n\t\t\t\thostname,\n\t\t\t\tnodeIP,\n\t\t\t\trecorder,\n\t\t\t\thealthzServer,\n\t\t\t\tconfig.NodePortAddresses,\n\t\t\t)\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf("unable to create proxier: %v", err)\n\t\t}\n\t\tproxymetrics.RegisterMetrics()\n\n\telse if proxyMode == proxyModeIPVS {\n\t\t...\n\t}\n\n\treturn &ProxyServer{\n\t\tClient:                 client,\n\t\tEventClient:            eventClient,\n\t\tIptInterface:           iptInterface,\n\t\tIpvsInterface:          ipvsInterface,\n\t\tIpsetInterface:         ipsetInterface,\n\t\texecer:                 execer,\n\t\tProxier:                proxier,\n\t\tBroadcaster:            eventBroadcaster,\n\t\tRecorder:               recorder,\n\t\tConntrackConfiguration: config.Conntrack,\n\t\tConntracker:            &realConntracker{},\n\t\tProxyMode:              proxyMode,\n\t\tNodeRef:                nodeRef,\n\t\tMetricsBindAddress:     config.MetricsBindAddress,\n\t\tBindAddressHardFail:    config.BindAddressHardFail,\n\t\tEnableProfiling:        config.EnableProfiling,\n\t\tOOMScoreAdj:            config.OOMScoreAdj,\n\t\tConfigSyncPeriod:       config.ConfigSyncPeriod.Duration,\n\t\tHealthzServer:          healthzServer,\n\t\tUseEndpointSlices:      useEndpointSlices,\n\t}, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n\n\n再来看iptables.NewProxier() 方法\n\nfunc NewProxier(ipt utiliptables.Interface,\n\tsysctl utilsysctl.Interface,\n\texec utilexec.Interface,\n\tsyncPeriod time.Duration,\n\tminSyncPeriod time.Duration,\n\tmasqueradeAll bool,\n\tmasqueradeBit int,\n\tlocalDetector proxyutiliptables.LocalTrafficDetector,\n\thostname string,\n\tnodeIP net.IP,\n\trecorder events.EventRecorder,\n\thealthzServer healthcheck.ProxierHealthUpdater,\n\tnodePortAddresses []string,\n) (*Proxier, error) {\n\n\t// 这个就是0x4000，也就是给数据包打上标记，在出主机的时候会进行SNAT\n\tmasqueradeValue := 1 << uint(masqueradeBit)\n\tmasqueradeMark := fmt.Sprintf("%#08x", masqueradeValue)\n\n    // 创建健康检查服务\n\tserviceHealthServer := healthcheck.NewServiceHealthServer(hostname, recorder, nodePortAddresses)\n\n\tproxier := &Proxier{\n\t\tserviceMap:               make(proxy.ServiceMap),\n\t\tserviceChanges:           proxy.NewServiceChangeTracker(newServiceInfo, ipFamily, recorder, nil),\n\t\tendpointsMap:             make(proxy.EndpointsMap),\n\t\tendpointsChanges:         proxy.NewEndpointChangeTracker(hostname, newEndpointInfo, ipFamily, recorder, nil),\n\t\tsyncPeriod:               syncPeriod,\n\t\tiptables:                 ipt,\n\t\tmasqueradeAll:            masqueradeAll,\n\t\tmasqueradeMark:           masqueradeMark,\n\t\texec:                     exec,\n\t\tlocalDetector:            localDetector,\n\t\thostname:                 hostname,\n\t\tnodeIP:                   nodeIP,\n\t\trecorder:                 recorder,\n\t\tserviceHealthServer:      serviceHealthServer,\n\t\thealthzServer:            healthzServer,\n\t\tprecomputedProbabilities: make([]string, 0, 1001),\n\t\tiptablesData:             bytes.NewBuffer(nil),\n\t\texistingFilterChainsData: bytes.NewBuffer(nil),\n\t\tfilterChains:             utilproxy.LineBuffer{},\n\t\tfilterRules:              utilproxy.LineBuffer{},\n\t\tnatChains:                utilproxy.LineBuffer{},\n\t\tnatRules:                 utilproxy.LineBuffer{},\n\t\tnodePortAddresses:        nodePortAddresses,\n\t\tnetworkInterfacer:        utilproxy.RealNetwork{},\n\t}\n\n\tburstSyncs := 2\n    // syncRunner是用来控制刷新iptables规则频率的运行器，proxier.syncProxyRules方法就是真正刷新iptables规则的方法\n   \tproxier.syncRunner = async.NewBoundedFrequencyRunner("sync-runner", proxier.syncProxyRules, minSyncPeriod, time.Hour, burstSyncs)\n\n\t// 这里启用一个goroutine。在三个表中都创建一个KUBE-PROXY-CANARY子链，通过子链是否存在来判断iptables是否被刷掉。\n\t// 如果该链不存在，说明iptables被刷掉了，再次执行syncProxyRules方法刷回来。\n\tgo ipt.Monitor(kubeProxyCanaryChain, []utiliptables.Table{utiliptables.TableMangle, utiliptables.TableNAT, utiliptables.TableFilter},\n\t\tproxier.syncProxyRules, syncPeriod, wait.NeverStop)\n\treturn proxier, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n以上主要的对象已经初始化完成了。\n\n\n# Run\n\n回到o.Run() 方法中，先是创建ProxyServer对象，然后在其中又创建proxier对象，做了一系列初始化动作，接下来就是运行代理服务了，现在看向runLoop 方法\n\nfunc (o *Options) runLoop() error {\n\t// 开启文件监听\n\tif o.watcher != nil {\n\t\to.watcher.Run()\n\t}\n\n\t// run the proxy in goroutine\n\tgo func() {\n\t\terr := o.proxyServer.Run()\n\t\to.errCh <- err\n\t}()\n\n    // 如果接受到errCh则停止服务\n\tfor {\n\t\terr := <-o.errCh\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n再看向o.proxyServer.Run() 方法，运行代理服务的主流程。\n\nfunc (s *ProxyServer) Run() error {\n\t// 设置当前进程的OOM参数，资源紧张时，不优先kill掉kube-proxy\n\tvar oomAdjuster *oom.OOMAdjuster\n\tif s.OOMScoreAdj != nil {\n\t\toomAdjuster = oom.NewOOMAdjuster()\n\t\tif err := oomAdjuster.ApplyOOMScoreAdj(0, int(*s.OOMScoreAdj)); err != nil {\n\t\t\tklog.V(2).InfoS("Failed to apply OOMScore", "err", err)\n\t\t}\n\t}\n\n\t// 开启健康检查服务\n\tserveHealthz(s.HealthzServer, errCh)\n\n\t// 开启指标上报服务\n\tserveMetrics(s.MetricsBindAddress, s.ProxyMode, s.EnableProfiling, errCh)\n\n\t// 创建informer\n\tinformerFactory := informers.NewSharedInformerFactoryWithOptions(s.Client, s.ConfigSyncPeriod,\n\t\tinformers.WithTweakListOptions(func(options *metav1.ListOptions) {\n\t\t\toptions.LabelSelector = labelSelector.String()\n\t\t}))\n\n\t// 监听service和endpoint并注册事件，当发生变化时，则会进行刷新iptables规则\n\tserviceConfig := config.NewServiceConfig(informerFactory.Core().V1().Services(), s.ConfigSyncPeriod)\n\tserviceConfig.RegisterEventHandler(s.Proxier)\n\tgo serviceConfig.Run(wait.NeverStop)\n\n\tif endpointsHandler, ok := s.Proxier.(config.EndpointsHandler); ok && !s.UseEndpointSlices {\n\t\tendpointsConfig := config.NewEndpointsConfig(informerFactory.Core().V1().Endpoints(), s.ConfigSyncPeriod)\n\t\tendpointsConfig.RegisterEventHandler(endpointsHandler)\n\t\tgo endpointsConfig.Run(wait.NeverStop)\n\t} else {\n\t\tendpointSliceConfig := config.NewEndpointSliceConfig(informerFactory.Discovery().V1().EndpointSlices(), s.ConfigSyncPeriod)\n\t\tendpointSliceConfig.RegisterEventHandler(s.Proxier)\n\t\tgo endpointSliceConfig.Run(wait.NeverStop)\n\t}\n\n\tinformerFactory.Start(wait.NeverStop)\n\n\t// 发送启动事件\n\ts.birthCry()\n\n\tgo s.Proxier.SyncLoop()\n\n\treturn <-errCh\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n\n\n\n# service 和 endpointslice 变更事件\n\n程序中是通过informer来实现对service和endpoint发生变化的监听，感知变化，并触发事件并进行相应的处理。\n\n先看一下NewServiceConfig() 方法，其中注册了当service发生增、删、改事件时，分别执行result.handleAddService 、result.handleUpdateService 、result.handleDeleteService 方法。\n\nfunc NewServiceConfig(serviceInformer coreinformers.ServiceInformer, resyncPeriod time.Duration) *ServiceConfig {\n\tresult := &ServiceConfig{\n\t\tlisterSynced: serviceInformer.Informer().HasSynced,\n\t}\n\n\t// 注册变更事件\n\tserviceInformer.Informer().AddEventHandlerWithResyncPeriod(\n\t\tcache.ResourceEventHandlerFuncs{\n\t\t\tAddFunc:    result.handleAddService,\n\t\t\tUpdateFunc: result.handleUpdateService,\n\t\t\tDeleteFunc: result.handleDeleteService,\n\t\t},\n\t\tresyncPeriod,\n\t)\n\n\treturn result\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n再看看其中的handleAddService() 方法，传入的参数obj就是新增的service对象，然后传入eventHandler.OnServiceAdd()方法进行处理。\n\nfunc (c *ServiceConfig) handleAddService(obj interface{}) {\n\tservice, ok := obj.(*v1.Service)\n\tif !ok {\n\t\tutilruntime.HandleError(fmt.Errorf("unexpected object type: %v", obj))\n\t\treturn\n\t}\n\tfor i := range c.eventHandlers {\n\t\tklog.V(4).InfoS("Calling handler.OnServiceAdd")\n\t\tc.eventHandlers[i].OnServiceAdd(service)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n这里c.eventHanlders其实就是proxier对象，在RegisterEventHandler()方法中将其添加进去的。\n\nserviceConfig.RegisterEventHandler(s.Proxier)\n\n\n1\n\n\n也就是说，proxier.OnServiceAdd()才是需要触发的处理方法\n\nfunc (proxier *Proxier) OnServiceAdd(service *v1.Service) {\n\tproxier.OnServiceUpdate(nil, service)\n}\n\n\n1\n2\n3\n\n\n第一个参数为旧的service，第二参数为新的参数。该方法给可以OnServiceAdd 复用，传入的第一个参数为nil，第二个参数不为nil，就是新增的操作。\n\nfunc (proxier *Proxier) OnServiceUpdate(oldService, service *v1.Service) {\n\tif proxier.serviceChanges.Update(oldService, service) && proxier.isInitialized() {\n\t\tproxier.Sync()\n\t}\n}\n\n\n1\n2\n3\n4\n5\n\n\n还可以看到删除操作也能复用，有旧的service，而新service为nil代表删除。\n\n// OnServiceDelete is called whenever deletion of an existing service\n// object is observed.\nfunc (proxier *Proxier) OnServiceDelete(service *v1.Service) {\n\tproxier.OnServiceUpdate(service, nil)\n}\n\n\n1\n2\n3\n4\n5\n\n\n无论是增、删、改都会执行到proxier.Sync()方法\n\nfunc (proxier *Proxier) Sync() {\n\tif proxier.healthzServer != nil {\n\t\tproxier.healthzServer.QueuedUpdate()\n\t}\n\tmetrics.SyncProxyRulesLastQueuedTimestamp.SetToCurrentTime()\n\tproxier.syncRunner.Run()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n最终到proxier.syncRunner.Run() 方法，可以看出它会发送一个信号到bfr.run管道中。该方法除了是service发生事件执行操作的终点外，endpoint发生事件后最终也会执行到这里。\n\nfunc (bfr *BoundedFrequencyRunner) Run() {\n\t// If it takes a lot of time to run the underlying function, noone is really\n\t// processing elements from <run> channel. So to avoid blocking here on the\n\t// putting element to it, we simply skip it if there is already an element\n\t// in it.\n\tselect {\n\tcase bfr.run <- struct{}{}:\n\tdefault:\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# BoundedFrequencyRunner\n\n我们再回到代理服务的ProxyServe.Run 方法，最后执行了s.Proxier.SyncLoop()\n\nfunc (proxier *Proxier) SyncLoop() {\n\t// Update healthz timestamp at beginning in case Sync() never succeeds.\n\tif proxier.healthzServer != nil {\n\t\tproxier.healthzServer.Updated()\n\t}\n\n\t// synthesize "last change queued" time as the informers are syncing.\n\tmetrics.SyncProxyRulesLastQueuedTimestamp.SetToCurrentTime()\n\tproxier.syncRunner.Loop(wait.NeverStop)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n然后再执行proxier.syncRunner.Loop() 方法\n\nfunc (bfr *BoundedFrequencyRunner) Loop(stop <-chan struct{}) {\n\tklog.V(3).Infof("%s Loop running", bfr.name)\n\tbfr.timer.Reset(bfr.maxInterval)\n\tfor {\n\t\tselect {\n\t\tcase <-stop:\n\t\t\tbfr.stop()\n\t\t\tklog.V(3).Infof("%s Loop stopping", bfr.name)\n\t\t\treturn\n\t\tcase <-bfr.timer.C():\n\t\t\tbfr.tryRun()\n\t\tcase <-bfr.run:\n\t\t\tbfr.tryRun()\n\t\tcase <-bfr.retry:\n\t\t\tbfr.doRetry()\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n可以看到如果bfr.run管道接收到了信号，会执行brf.tryRun() 方法，在这个方法中会执行proxier.syncProxyRules() 进行刷新iptables规则。\n\n// assumes the lock is not held\nfunc (bfr *BoundedFrequencyRunner) tryRun() {\n\tbfr.mu.Lock()\n\tdefer bfr.mu.Unlock()\n\n    // 这里会限制访问速率，看是否可以执行。\n\tif bfr.limiter.TryAccept() {\n        // 这里的fn就是proxier.syncProxyRules方法\n\t\tbfr.fn()\n\t\tbfr.lastRun = bfr.timer.Now()\n\t\tbfr.timer.Stop()\n\t\tbfr.timer.Reset(bfr.maxInterval)\n\t\tklog.V(3).Infof("%s: ran, next possible in %v, periodic in %v", bfr.name, bfr.minInterval, bfr.maxInterval)\n\t\treturn\n\t}\n\n\t// It can\'t run right now, figure out when it can run next.\n\telapsed := bfr.timer.Since(bfr.lastRun)   // how long since last run\n\tnextPossible := bfr.minInterval - elapsed // time to next possible run\n\tnextScheduled := bfr.timer.Remaining()    // time to next scheduled run\n\tklog.V(4).Infof("%s: %v since last run, possible in %v, scheduled in %v", bfr.name, elapsed, nextPossible, nextScheduled)\n\n\t// It\'s hard to avoid race conditions in the unit tests unless we always reset\n\t// the timer here, even when it\'s unchanged\n\tif nextPossible < nextScheduled {\n\t\tnextScheduled = nextPossible\n\t}\n\tbfr.timer.Stop()\n\tbfr.timer.Reset(nextScheduled)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n\n# syncProxyRules\n\n该方法主要是更新节点上的iptables规则。\n\nfunc (proxier *Proxier) syncProxyRules() {\n\n\t// 获取service和endpoint发生变化的数据\n\tserviceUpdateResult := proxier.serviceMap.Update(proxier.serviceChanges)\n\tendpointUpdateResult := proxier.endpointsMap.Update(proxier.endpointsChanges)\n\n\n\t// 创建一些必要的iptables链\n\tfor _, jump := range iptablesJumpChains {\n\t\tif _, err := proxier.iptables.EnsureChain(jump.table, jump.dstChain); err != nil {\n\t\t\tklog.ErrorS(err, "Failed to ensure chain exists", "table", jump.table, "chain", jump.dstChain)\n\t\t\treturn\n\t\t}\n\t\targs := append(jump.extraArgs,\n\t\t\t"-m", "comment", "--comment", jump.comment,\n\t\t\t"-j", string(jump.dstChain),\n\t\t)\n\t\tif _, err := proxier.iptables.EnsureRule(utiliptables.Prepend, jump.table, jump.srcChain, args...); err != nil {\n\t\t\tklog.ErrorS(err, "Failed to ensure chain jumps", "table", jump.table, "srcChain", jump.srcChain, "dstChain", jump.dstChain)\n\t\t\treturn\n\t\t}\n\t}\n\n\tfor _, ch := range iptablesEnsureChains {\n\t\tif _, err := proxier.iptables.EnsureChain(ch.table, ch.chain); err != nil {\n\t\t\tklog.ErrorS(err, "Failed to ensure chain exists", "table", ch.table, "chain", ch.chain)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// 将当前filter表中所有存在的规则写入existingFilterChainsData中\n\tproxier.existingFilterChainsData.Reset()\n\terr := proxier.iptables.SaveInto(utiliptables.TableFilter, proxier.existingFilterChainsData)\n\n\t// 将nat表中所有存在的规则写入iptablesData中\n\tproxier.iptablesData.Reset()\n\terr = proxier.iptables.SaveInto(utiliptables.TableNAT, proxier.iptablesData)\n\n\t// 将filter和nat链中必要添加的子链，通过字符串拼接的方式写入变量filterChains和natChains中\n\tfor _, chainName := range []utiliptables.Chain{kubeServicesChain, kubeExternalServicesChain, kubeForwardChain, kubeNodePortsChain} {\n\t\tif chain, ok := existingFilterChains[chainName]; ok {\n\t\t\tproxier.filterChains.WriteBytes(chain)\n\t\t} else {\n\t\t\tproxier.filterChains.Write(utiliptables.MakeChainLine(chainName))\n\t\t}\n\t}\n\tfor _, chainName := range []utiliptables.Chain{kubeServicesChain, kubeNodePortsChain, kubePostroutingChain, KubeMarkMasqChain} {\n\t\tif chain, ok := existingNATChains[chainName]; ok {\n\t\t\tproxier.natChains.WriteBytes(chain)\n\t\t} else {\n\t\t\tproxier.natChains.Write(utiliptables.MakeChainLine(chainName))\n\t\t}\n\t}\n\n\t// 后面就是将各种的iptables规则通过字符串拼接起来\n    ...\n\n\t// 将所有链和规则的iptables全部集成到一起iptablesData，然后再通过iptables-restore命令刷新到节点中。\n\tproxier.iptablesData.Reset()\n\tproxier.iptablesData.Write(proxier.filterChains.Bytes())\n\tproxier.iptablesData.Write(proxier.filterRules.Bytes())\n\tproxier.iptablesData.Write(proxier.natChains.Bytes())\n\tproxier.iptablesData.Write(proxier.natRules.Bytes())\n\terr = proxier.iptables.RestoreAll(proxier.iptablesData.Bytes(), utiliptables.NoFlushTables, utiliptables.RestoreCounters)\n\tif err != nil {\n\t\tklog.ErrorS(err, "Failed to execute iptables-restore")\n\t\tmetrics.IptablesRestoreFailuresTotal.Inc()\n\t\treturn\n\t}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n\n\n总结\n\n 1. 获取发生变更的 service 和 endpoint 信息\n 2. 创建一些必要的链\n 3. 使用 iptables-save 命令，将当前环境中 nat 和 filter 表中的 iptables 规则全部加载到程序中。\n 4. 通过拼接字符串，构造出需要创建的 iptables 规则字符串。\n 5. 通过 iptables-restore 命令，将构造的 iptables 规则字符串全部再刷新到节点上\n\n思考\n\n因为每一次都会将当前所有的iptables规则全部刷新到节点上，如果规则量过大的话，性能会受到影响，所以才有ipvs模式。\n\n\n# 总结\n\n整体代码流程如下：\n\n 1. 首先是各种对象套娃式的初始化，Options->ProxyServier->proxier->syncRunner\n 2. 然后是向informer中注册service和endpoint事件，当发生改动时，会给bfr.run发送信号\n 3. syncRunner收到信号会去执行proxier.syncProxyRules()方法，刷新主机的iptables规则\n\n\n\n\n# 相关链接\n\nkubernetes 源码-kube-proxy 原理和源码分析（一）\n\nkube-proxy 源码解析\n\nkube-proxy 保姆级别源码阅读\n\n连接跟踪 conntrack\n\nkubernetes 之 client-go 之 informer 工作原理源码解析\n\nKubernetes EndpointSlice 和 Endpoint 对象的区别\n\n‍',normalizedContent:'# kube-proxy源码分析\n\n\n# 简介\n\n本文主要是对kube-proxy的源码分析，了解其代码结构和实现原理。这里是根据kubernetes1.23.9版本来进行分析的。在下面贴上的代码会一定裁剪，主要用于理解主流程。\n\n\n# 初始化\n\nkube-proxy入口文件在cmd/kube-proxy/proxy.go\n\nfunc main() {\n\tcommand := app.newproxycommand()\n\tcode := cli.run(command)\n\tos.exit(code)\n}\n\n\n1\n2\n3\n4\n5\n\n\n查看app.newproxycommand()方法，使用的cobra命令行解析库来作为程序入口\n\nfunc newproxycommand() *cobra.command {\n\topts := newoptions()\n\n\tcmd := &cobra.command{\n\t\tuse: "kube-proxy",\n\t\tlong: `the kubernetes network proxy runs on each node. this\nreflects services as defined in the kubernetes api on each node and can do simple\ntcp, udp, and sctp stream forwarding or round robin tcp, udp, and sctp forwarding across a set of backends.\nservice cluster ips and ports are currently found through docker-links-compatible\nenvironment variables specifying ports opened by the service proxy. there is an optional\naddon that provides cluster dns for these cluster ips. the user must create a service\nwith the apiserver api to configure the proxy.`,\n\t\trune: func(cmd *cobra.command, args []string) error {\n\t\t\tverflag.printandexitifrequested()\n\t\t\tcliflag.printflags(cmd.flags())\n\n\t\t\tif err := initforos(opts.windowsservice); err != nil {\n\t\t\t\treturn fmt.errorf("failed os init: %w", err)\n\t\t\t}\n\n\t\t\t// 1. 加载配置文件kubeproxyconfig.kubeproxyconfiguration\n\t\t\t// 2. 监控文件变化\n\t\t\tif err := opts.complete(); err != nil {\n\t\t\t\treturn fmt.errorf("failed complete: %w", err)\n\t\t\t}\n\n\t\t\t// 配置参数的校验\n\t\t\tif err := opts.validate(); err != nil {\n\t\t\t\treturn fmt.errorf("failed validate: %w", err)\n\t\t\t}\n\n\t\t\t// 运行服务\n\t\t\tif err := opts.run(); err != nil {\n\t\t\t\tklog.errors(err, "error running proxyserver")\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn nil\n\t\t},\n\t\targs: func(cmd *cobra.command, args []string) error {\n\t\t\tfor _, arg := range args {\n\t\t\t\tif len(arg) > 0 {\n\t\t\t\t\treturn fmt.errorf("%q does not take any arguments, got %q", cmd.commandpath(), args)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t}\n\n\tvar err error\n    // 填充一些默认配置\n\topts.config, err = opts.applydefaults(opts.config)\n\tif err != nil {\n\t\tklog.errors(err, "unable to create flag defaults")\n\t\t// action required: exit code changed from 255 to 1\n\t\tos.exit(1)\n\t}\n\n\tfs := cmd.flags()\n\topts.addflags(fs)\n\t// 将go的命令行参数也加到命令行参数中\n\tfs.addgoflagset(goflag.commandline) // for --boot-id-file and --machine-id-file\n\n\t_ = cmd.markflagfilename("config", "yaml", "yml", "json")\n\n\treturn cmd\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n\n 1. 读取配置文件kubeproxyconfiguration，并监听变化收到对应的事件\n 2. 对配置kubeproxyconfiguration进行校验\n 3. 启动服务\n\n再来看opts.run() 服务启动的实现\n\nfunc (o *options) run() error {\n\tdefer close(o.errch)\n\n    // 如果配置了该字段，将配置文件写入指定位置，然后退出\n\tif len(o.writeconfigto) > 0 {\n\t\treturn o.writeconfigfile()\n\t}\n\n    // 创建代理服务\n\tproxyserver, err := newproxyserver(o)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// 清除所有的iptables规则\n\tif o.cleanupandexit {\n\t\treturn proxyserver.cleanupandexit()\n\t}\n\n\t// 启动代理服务\n\to.proxyserver = proxyserver\n\treturn o.runloop()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再看newproxyserver() 的实现，主要是用来创建proxyserver对象，并且在其中根据当前的网络模式，通过iptables.newproxier来创建proxier对象。\n\nfunc newproxyserver(o *options) (*proxyserver, error) {\n\treturn newproxyserver(o.config, o.cleanupandexit, o.master)\n}\n\nfunc newproxyserver(\n\tconfig *proxyconfigapi.kubeproxyconfiguration,\n\tcleanupandexit bool,\n\tmaster string) (*proxyserver, error) {\n\n\t// 执行本地命令的控制器\n\texecer := exec.new()\n\n\tkernelhandler = ipvs.newlinuxkernelhandler() \n    // 创建ipset命令的执行器\n\tipsetinterface = utilipset.new(execer)\n    // 判断是否支持ipvs\n\tcanuseipvs, err := ipvs.canuseipvsproxier(kernelhandler, ipsetinterface, config.ipvs.scheduler)\n\tif string(config.mode) == proxymodeipvs && err != nil {\n\t\tklog.errors(err, "can\'t use the ipvs proxier")\n\t}\n\n\tif canuseipvs {\n        // 如果支持的话，创建ipvs执行器\n\t\tipvsinterface = utilipvs.new()\n\t}\n\n\t// 创建事件记录器\n\teventbroadcaster := events.newbroadcaster(&events.eventsinkimpl{interface: client.eventsv1()})\n\trecorder := eventbroadcaster.newrecorder(scheme.scheme, "kube-proxy")\n\n\t// 创建健康检查服务\n\tvar healthzserver healthcheck.proxierhealthupdater\n\tif len(config.healthzbindaddress) > 0 {\n\t\thealthzserver = healthcheck.newproxierhealthserver(config.healthzbindaddress, 2*config.iptables.syncperiod.duration, recorder, noderef)\n\t}\n\n    // 获取当前的代理模式\n\tproxymode := getproxymode(string(config.mode), canuseipvs, iptables.linuxkernelcompattester{})\n\t\n    // 获取当前的主要的ip协议\n\tprimaryprotocol := utiliptables.protocolipv4\n\tif netutils.isipv6(nodeip) {\n\t\tprimaryprotocol = utiliptables.protocolipv6\n\t}\n\n\t// 创建iptables执行器\n\tiptinterface = utiliptables.new(execer, primaryprotocol)\n\n\t// 可能支持ipv4和ipv6两种执行器\n\tvar ipt [2]utiliptables.interface\n\tdualstack := true // while we assume that node supports, we do further checks below\n\n\t// 如果支持的是iptables模式\n\tif proxymode == proxymodeiptables {\n\n\t\t// 双端模式，支持ip4和ipv6\n\t\tif dualstack {\n\t\t\tproxier, err = iptables.newdualstackproxier(\n\t\t\t\tipt,\n\t\t\t\tutilsysctl.new(),\n\t\t\t\texecer,\n\t\t\t\tconfig.iptables.syncperiod.duration,\n\t\t\t\tconfig.iptables.minsyncperiod.duration,\n\t\t\t\tconfig.iptables.masqueradeall,\n\t\t\t\tint(*config.iptables.masqueradebit),\n\t\t\t\tlocaldetectors,\n\t\t\t\thostname,\n\t\t\t\tnodeiptuple(config.bindaddress),\n\t\t\t\trecorder,\n\t\t\t\thealthzserver,\n\t\t\t\tconfig.nodeportaddresses,\n\t\t\t)\n\t\t} else {\n\t\t\tproxier, err = iptables.newproxier(\n\t\t\t\tiptinterface,\n\t\t\t\tutilsysctl.new(),\n\t\t\t\texecer,\n\t\t\t\tconfig.iptables.syncperiod.duration,\n\t\t\t\tconfig.iptables.minsyncperiod.duration,\n\t\t\t\tconfig.iptables.masqueradeall,\n\t\t\t\tint(*config.iptables.masqueradebit),\n\t\t\t\tlocaldetector,\n\t\t\t\thostname,\n\t\t\t\tnodeip,\n\t\t\t\trecorder,\n\t\t\t\thealthzserver,\n\t\t\t\tconfig.nodeportaddresses,\n\t\t\t)\n\t\t}\n\n\t\tif err != nil {\n\t\t\treturn nil, fmt.errorf("unable to create proxier: %v", err)\n\t\t}\n\t\tproxymetrics.registermetrics()\n\n\telse if proxymode == proxymodeipvs {\n\t\t...\n\t}\n\n\treturn &proxyserver{\n\t\tclient:                 client,\n\t\teventclient:            eventclient,\n\t\tiptinterface:           iptinterface,\n\t\tipvsinterface:          ipvsinterface,\n\t\tipsetinterface:         ipsetinterface,\n\t\texecer:                 execer,\n\t\tproxier:                proxier,\n\t\tbroadcaster:            eventbroadcaster,\n\t\trecorder:               recorder,\n\t\tconntrackconfiguration: config.conntrack,\n\t\tconntracker:            &realconntracker{},\n\t\tproxymode:              proxymode,\n\t\tnoderef:                noderef,\n\t\tmetricsbindaddress:     config.metricsbindaddress,\n\t\tbindaddresshardfail:    config.bindaddresshardfail,\n\t\tenableprofiling:        config.enableprofiling,\n\t\toomscoreadj:            config.oomscoreadj,\n\t\tconfigsyncperiod:       config.configsyncperiod.duration,\n\t\thealthzserver:          healthzserver,\n\t\tuseendpointslices:      useendpointslices,\n\t}, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n107\n108\n109\n110\n111\n112\n113\n114\n115\n116\n117\n118\n119\n120\n121\n122\n\n\n再来看iptables.newproxier() 方法\n\nfunc newproxier(ipt utiliptables.interface,\n\tsysctl utilsysctl.interface,\n\texec utilexec.interface,\n\tsyncperiod time.duration,\n\tminsyncperiod time.duration,\n\tmasqueradeall bool,\n\tmasqueradebit int,\n\tlocaldetector proxyutiliptables.localtrafficdetector,\n\thostname string,\n\tnodeip net.ip,\n\trecorder events.eventrecorder,\n\thealthzserver healthcheck.proxierhealthupdater,\n\tnodeportaddresses []string,\n) (*proxier, error) {\n\n\t// 这个就是0x4000，也就是给数据包打上标记，在出主机的时候会进行snat\n\tmasqueradevalue := 1 << uint(masqueradebit)\n\tmasquerademark := fmt.sprintf("%#08x", masqueradevalue)\n\n    // 创建健康检查服务\n\tservicehealthserver := healthcheck.newservicehealthserver(hostname, recorder, nodeportaddresses)\n\n\tproxier := &proxier{\n\t\tservicemap:               make(proxy.servicemap),\n\t\tservicechanges:           proxy.newservicechangetracker(newserviceinfo, ipfamily, recorder, nil),\n\t\tendpointsmap:             make(proxy.endpointsmap),\n\t\tendpointschanges:         proxy.newendpointchangetracker(hostname, newendpointinfo, ipfamily, recorder, nil),\n\t\tsyncperiod:               syncperiod,\n\t\tiptables:                 ipt,\n\t\tmasqueradeall:            masqueradeall,\n\t\tmasquerademark:           masquerademark,\n\t\texec:                     exec,\n\t\tlocaldetector:            localdetector,\n\t\thostname:                 hostname,\n\t\tnodeip:                   nodeip,\n\t\trecorder:                 recorder,\n\t\tservicehealthserver:      servicehealthserver,\n\t\thealthzserver:            healthzserver,\n\t\tprecomputedprobabilities: make([]string, 0, 1001),\n\t\tiptablesdata:             bytes.newbuffer(nil),\n\t\texistingfilterchainsdata: bytes.newbuffer(nil),\n\t\tfilterchains:             utilproxy.linebuffer{},\n\t\tfilterrules:              utilproxy.linebuffer{},\n\t\tnatchains:                utilproxy.linebuffer{},\n\t\tnatrules:                 utilproxy.linebuffer{},\n\t\tnodeportaddresses:        nodeportaddresses,\n\t\tnetworkinterfacer:        utilproxy.realnetwork{},\n\t}\n\n\tburstsyncs := 2\n    // syncrunner是用来控制刷新iptables规则频率的运行器，proxier.syncproxyrules方法就是真正刷新iptables规则的方法\n   \tproxier.syncrunner = async.newboundedfrequencyrunner("sync-runner", proxier.syncproxyrules, minsyncperiod, time.hour, burstsyncs)\n\n\t// 这里启用一个goroutine。在三个表中都创建一个kube-proxy-canary子链，通过子链是否存在来判断iptables是否被刷掉。\n\t// 如果该链不存在，说明iptables被刷掉了，再次执行syncproxyrules方法刷回来。\n\tgo ipt.monitor(kubeproxycanarychain, []utiliptables.table{utiliptables.tablemangle, utiliptables.tablenat, utiliptables.tablefilter},\n\t\tproxier.syncproxyrules, syncperiod, wait.neverstop)\n\treturn proxier, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n以上主要的对象已经初始化完成了。\n\n\n# run\n\n回到o.run() 方法中，先是创建proxyserver对象，然后在其中又创建proxier对象，做了一系列初始化动作，接下来就是运行代理服务了，现在看向runloop 方法\n\nfunc (o *options) runloop() error {\n\t// 开启文件监听\n\tif o.watcher != nil {\n\t\to.watcher.run()\n\t}\n\n\t// run the proxy in goroutine\n\tgo func() {\n\t\terr := o.proxyserver.run()\n\t\to.errch <- err\n\t}()\n\n    // 如果接受到errch则停止服务\n\tfor {\n\t\terr := <-o.errch\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n再看向o.proxyserver.run() 方法，运行代理服务的主流程。\n\nfunc (s *proxyserver) run() error {\n\t// 设置当前进程的oom参数，资源紧张时，不优先kill掉kube-proxy\n\tvar oomadjuster *oom.oomadjuster\n\tif s.oomscoreadj != nil {\n\t\toomadjuster = oom.newoomadjuster()\n\t\tif err := oomadjuster.applyoomscoreadj(0, int(*s.oomscoreadj)); err != nil {\n\t\t\tklog.v(2).infos("failed to apply oomscore", "err", err)\n\t\t}\n\t}\n\n\t// 开启健康检查服务\n\tservehealthz(s.healthzserver, errch)\n\n\t// 开启指标上报服务\n\tservemetrics(s.metricsbindaddress, s.proxymode, s.enableprofiling, errch)\n\n\t// 创建informer\n\tinformerfactory := informers.newsharedinformerfactorywithoptions(s.client, s.configsyncperiod,\n\t\tinformers.withtweaklistoptions(func(options *metav1.listoptions) {\n\t\t\toptions.labelselector = labelselector.string()\n\t\t}))\n\n\t// 监听service和endpoint并注册事件，当发生变化时，则会进行刷新iptables规则\n\tserviceconfig := config.newserviceconfig(informerfactory.core().v1().services(), s.configsyncperiod)\n\tserviceconfig.registereventhandler(s.proxier)\n\tgo serviceconfig.run(wait.neverstop)\n\n\tif endpointshandler, ok := s.proxier.(config.endpointshandler); ok && !s.useendpointslices {\n\t\tendpointsconfig := config.newendpointsconfig(informerfactory.core().v1().endpoints(), s.configsyncperiod)\n\t\tendpointsconfig.registereventhandler(endpointshandler)\n\t\tgo endpointsconfig.run(wait.neverstop)\n\t} else {\n\t\tendpointsliceconfig := config.newendpointsliceconfig(informerfactory.discovery().v1().endpointslices(), s.configsyncperiod)\n\t\tendpointsliceconfig.registereventhandler(s.proxier)\n\t\tgo endpointsliceconfig.run(wait.neverstop)\n\t}\n\n\tinformerfactory.start(wait.neverstop)\n\n\t// 发送启动事件\n\ts.birthcry()\n\n\tgo s.proxier.syncloop()\n\n\treturn <-errch\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n\n\n\n# service 和 endpointslice 变更事件\n\n程序中是通过informer来实现对service和endpoint发生变化的监听，感知变化，并触发事件并进行相应的处理。\n\n先看一下newserviceconfig() 方法，其中注册了当service发生增、删、改事件时，分别执行result.handleaddservice 、result.handleupdateservice 、result.handledeleteservice 方法。\n\nfunc newserviceconfig(serviceinformer coreinformers.serviceinformer, resyncperiod time.duration) *serviceconfig {\n\tresult := &serviceconfig{\n\t\tlistersynced: serviceinformer.informer().hassynced,\n\t}\n\n\t// 注册变更事件\n\tserviceinformer.informer().addeventhandlerwithresyncperiod(\n\t\tcache.resourceeventhandlerfuncs{\n\t\t\taddfunc:    result.handleaddservice,\n\t\t\tupdatefunc: result.handleupdateservice,\n\t\t\tdeletefunc: result.handledeleteservice,\n\t\t},\n\t\tresyncperiod,\n\t)\n\n\treturn result\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n再看看其中的handleaddservice() 方法，传入的参数obj就是新增的service对象，然后传入eventhandler.onserviceadd()方法进行处理。\n\nfunc (c *serviceconfig) handleaddservice(obj interface{}) {\n\tservice, ok := obj.(*v1.service)\n\tif !ok {\n\t\tutilruntime.handleerror(fmt.errorf("unexpected object type: %v", obj))\n\t\treturn\n\t}\n\tfor i := range c.eventhandlers {\n\t\tklog.v(4).infos("calling handler.onserviceadd")\n\t\tc.eventhandlers[i].onserviceadd(service)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n这里c.eventhanlders其实就是proxier对象，在registereventhandler()方法中将其添加进去的。\n\nserviceconfig.registereventhandler(s.proxier)\n\n\n1\n\n\n也就是说，proxier.onserviceadd()才是需要触发的处理方法\n\nfunc (proxier *proxier) onserviceadd(service *v1.service) {\n\tproxier.onserviceupdate(nil, service)\n}\n\n\n1\n2\n3\n\n\n第一个参数为旧的service，第二参数为新的参数。该方法给可以onserviceadd 复用，传入的第一个参数为nil，第二个参数不为nil，就是新增的操作。\n\nfunc (proxier *proxier) onserviceupdate(oldservice, service *v1.service) {\n\tif proxier.servicechanges.update(oldservice, service) && proxier.isinitialized() {\n\t\tproxier.sync()\n\t}\n}\n\n\n1\n2\n3\n4\n5\n\n\n还可以看到删除操作也能复用，有旧的service，而新service为nil代表删除。\n\n// onservicedelete is called whenever deletion of an existing service\n// object is observed.\nfunc (proxier *proxier) onservicedelete(service *v1.service) {\n\tproxier.onserviceupdate(service, nil)\n}\n\n\n1\n2\n3\n4\n5\n\n\n无论是增、删、改都会执行到proxier.sync()方法\n\nfunc (proxier *proxier) sync() {\n\tif proxier.healthzserver != nil {\n\t\tproxier.healthzserver.queuedupdate()\n\t}\n\tmetrics.syncproxyruleslastqueuedtimestamp.settocurrenttime()\n\tproxier.syncrunner.run()\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n最终到proxier.syncrunner.run() 方法，可以看出它会发送一个信号到bfr.run管道中。该方法除了是service发生事件执行操作的终点外，endpoint发生事件后最终也会执行到这里。\n\nfunc (bfr *boundedfrequencyrunner) run() {\n\t// if it takes a lot of time to run the underlying function, noone is really\n\t// processing elements from <run> channel. so to avoid blocking here on the\n\t// putting element to it, we simply skip it if there is already an element\n\t// in it.\n\tselect {\n\tcase bfr.run <- struct{}{}:\n\tdefault:\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# boundedfrequencyrunner\n\n我们再回到代理服务的proxyserve.run 方法，最后执行了s.proxier.syncloop()\n\nfunc (proxier *proxier) syncloop() {\n\t// update healthz timestamp at beginning in case sync() never succeeds.\n\tif proxier.healthzserver != nil {\n\t\tproxier.healthzserver.updated()\n\t}\n\n\t// synthesize "last change queued" time as the informers are syncing.\n\tmetrics.syncproxyruleslastqueuedtimestamp.settocurrenttime()\n\tproxier.syncrunner.loop(wait.neverstop)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n然后再执行proxier.syncrunner.loop() 方法\n\nfunc (bfr *boundedfrequencyrunner) loop(stop <-chan struct{}) {\n\tklog.v(3).infof("%s loop running", bfr.name)\n\tbfr.timer.reset(bfr.maxinterval)\n\tfor {\n\t\tselect {\n\t\tcase <-stop:\n\t\t\tbfr.stop()\n\t\t\tklog.v(3).infof("%s loop stopping", bfr.name)\n\t\t\treturn\n\t\tcase <-bfr.timer.c():\n\t\t\tbfr.tryrun()\n\t\tcase <-bfr.run:\n\t\t\tbfr.tryrun()\n\t\tcase <-bfr.retry:\n\t\t\tbfr.doretry()\n\t\t}\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n可以看到如果bfr.run管道接收到了信号，会执行brf.tryrun() 方法，在这个方法中会执行proxier.syncproxyrules() 进行刷新iptables规则。\n\n// assumes the lock is not held\nfunc (bfr *boundedfrequencyrunner) tryrun() {\n\tbfr.mu.lock()\n\tdefer bfr.mu.unlock()\n\n    // 这里会限制访问速率，看是否可以执行。\n\tif bfr.limiter.tryaccept() {\n        // 这里的fn就是proxier.syncproxyrules方法\n\t\tbfr.fn()\n\t\tbfr.lastrun = bfr.timer.now()\n\t\tbfr.timer.stop()\n\t\tbfr.timer.reset(bfr.maxinterval)\n\t\tklog.v(3).infof("%s: ran, next possible in %v, periodic in %v", bfr.name, bfr.mininterval, bfr.maxinterval)\n\t\treturn\n\t}\n\n\t// it can\'t run right now, figure out when it can run next.\n\telapsed := bfr.timer.since(bfr.lastrun)   // how long since last run\n\tnextpossible := bfr.mininterval - elapsed // time to next possible run\n\tnextscheduled := bfr.timer.remaining()    // time to next scheduled run\n\tklog.v(4).infof("%s: %v since last run, possible in %v, scheduled in %v", bfr.name, elapsed, nextpossible, nextscheduled)\n\n\t// it\'s hard to avoid race conditions in the unit tests unless we always reset\n\t// the timer here, even when it\'s unchanged\n\tif nextpossible < nextscheduled {\n\t\tnextscheduled = nextpossible\n\t}\n\tbfr.timer.stop()\n\tbfr.timer.reset(nextscheduled)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n\n# syncproxyrules\n\n该方法主要是更新节点上的iptables规则。\n\nfunc (proxier *proxier) syncproxyrules() {\n\n\t// 获取service和endpoint发生变化的数据\n\tserviceupdateresult := proxier.servicemap.update(proxier.servicechanges)\n\tendpointupdateresult := proxier.endpointsmap.update(proxier.endpointschanges)\n\n\n\t// 创建一些必要的iptables链\n\tfor _, jump := range iptablesjumpchains {\n\t\tif _, err := proxier.iptables.ensurechain(jump.table, jump.dstchain); err != nil {\n\t\t\tklog.errors(err, "failed to ensure chain exists", "table", jump.table, "chain", jump.dstchain)\n\t\t\treturn\n\t\t}\n\t\targs := append(jump.extraargs,\n\t\t\t"-m", "comment", "--comment", jump.comment,\n\t\t\t"-j", string(jump.dstchain),\n\t\t)\n\t\tif _, err := proxier.iptables.ensurerule(utiliptables.prepend, jump.table, jump.srcchain, args...); err != nil {\n\t\t\tklog.errors(err, "failed to ensure chain jumps", "table", jump.table, "srcchain", jump.srcchain, "dstchain", jump.dstchain)\n\t\t\treturn\n\t\t}\n\t}\n\n\tfor _, ch := range iptablesensurechains {\n\t\tif _, err := proxier.iptables.ensurechain(ch.table, ch.chain); err != nil {\n\t\t\tklog.errors(err, "failed to ensure chain exists", "table", ch.table, "chain", ch.chain)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// 将当前filter表中所有存在的规则写入existingfilterchainsdata中\n\tproxier.existingfilterchainsdata.reset()\n\terr := proxier.iptables.saveinto(utiliptables.tablefilter, proxier.existingfilterchainsdata)\n\n\t// 将nat表中所有存在的规则写入iptablesdata中\n\tproxier.iptablesdata.reset()\n\terr = proxier.iptables.saveinto(utiliptables.tablenat, proxier.iptablesdata)\n\n\t// 将filter和nat链中必要添加的子链，通过字符串拼接的方式写入变量filterchains和natchains中\n\tfor _, chainname := range []utiliptables.chain{kubeserviceschain, kubeexternalserviceschain, kubeforwardchain, kubenodeportschain} {\n\t\tif chain, ok := existingfilterchains[chainname]; ok {\n\t\t\tproxier.filterchains.writebytes(chain)\n\t\t} else {\n\t\t\tproxier.filterchains.write(utiliptables.makechainline(chainname))\n\t\t}\n\t}\n\tfor _, chainname := range []utiliptables.chain{kubeserviceschain, kubenodeportschain, kubepostroutingchain, kubemarkmasqchain} {\n\t\tif chain, ok := existingnatchains[chainname]; ok {\n\t\t\tproxier.natchains.writebytes(chain)\n\t\t} else {\n\t\t\tproxier.natchains.write(utiliptables.makechainline(chainname))\n\t\t}\n\t}\n\n\t// 后面就是将各种的iptables规则通过字符串拼接起来\n    ...\n\n\t// 将所有链和规则的iptables全部集成到一起iptablesdata，然后再通过iptables-restore命令刷新到节点中。\n\tproxier.iptablesdata.reset()\n\tproxier.iptablesdata.write(proxier.filterchains.bytes())\n\tproxier.iptablesdata.write(proxier.filterrules.bytes())\n\tproxier.iptablesdata.write(proxier.natchains.bytes())\n\tproxier.iptablesdata.write(proxier.natrules.bytes())\n\terr = proxier.iptables.restoreall(proxier.iptablesdata.bytes(), utiliptables.noflushtables, utiliptables.restorecounters)\n\tif err != nil {\n\t\tklog.errors(err, "failed to execute iptables-restore")\n\t\tmetrics.iptablesrestorefailurestotal.inc()\n\t\treturn\n\t}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n\n\n总结\n\n 1. 获取发生变更的 service 和 endpoint 信息\n 2. 创建一些必要的链\n 3. 使用 iptables-save 命令，将当前环境中 nat 和 filter 表中的 iptables 规则全部加载到程序中。\n 4. 通过拼接字符串，构造出需要创建的 iptables 规则字符串。\n 5. 通过 iptables-restore 命令，将构造的 iptables 规则字符串全部再刷新到节点上\n\n思考\n\n因为每一次都会将当前所有的iptables规则全部刷新到节点上，如果规则量过大的话，性能会受到影响，所以才有ipvs模式。\n\n\n# 总结\n\n整体代码流程如下：\n\n 1. 首先是各种对象套娃式的初始化，options->proxyservier->proxier->syncrunner\n 2. 然后是向informer中注册service和endpoint事件，当发生改动时，会给bfr.run发送信号\n 3. syncrunner收到信号会去执行proxier.syncproxyrules()方法，刷新主机的iptables规则\n\n\n\n\n# 相关链接\n\nkubernetes 源码-kube-proxy 原理和源码分析（一）\n\nkube-proxy 源码解析\n\nkube-proxy 保姆级别源码阅读\n\n连接跟踪 conntrack\n\nkubernetes 之 client-go 之 informer 工作原理源码解析\n\nkubernetes endpointslice 和 endpoint 对象的区别\n\n‍',charsets:{cjk:!0},lastUpdated:"2024/01/18, 19:50:43",lastUpdatedTimestamp:1705578643e3},{title:"redis之五种基本数据类型",frontmatter:{title:"redis之五种基本数据类型",date:"2022-12-01T15:16:14.000Z",permalink:"/pages/2bbeb3/",tags:["redis","数据库"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文主要讲解 redis 的五种基本数据类型：String、List、Set、Sorted Set、Hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210820163352.png"},{name:"twitter:title",content:"redis之五种基本数据类型"},{name:"twitter:description",content:"本文主要讲解 redis 的五种基本数据类型：String、List、Set、Sorted Set、Hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210820163352.png"},{name:"twitter:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/01.redis%E4%B9%8B%E4%BA%94%E7%A7%8D%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之五种基本数据类型"},{property:"og:description",content:"本文主要讲解 redis 的五种基本数据类型：String、List、Set、Sorted Set、Hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210820163352.png"},{property:"og:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/01.redis%E4%B9%8B%E4%BA%94%E7%A7%8D%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-12-01T15:16:14.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之五种基本数据类型"},{itemprop:"description",content:"本文主要讲解 redis 的五种基本数据类型：String、List、Set、Sorted Set、Hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210820163352.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/01.redis%E4%B9%8B%E4%BA%94%E7%A7%8D%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html",relativePath:"03.中间件/05.redis/01.redis之五种基本数据类型.md",key:"v-27753cf3",path:"/pages/2bbeb3/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. String",slug:"_1-string",normalizedTitle:"1. string",charIndex:127},{level:3,title:"1.1 简单使用",slug:"_1-1-简单使用",normalizedTitle:"1.1 简单使用",charIndex:141},{level:3,title:"1.2 数据编码",slug:"_1-2-数据编码",normalizedTitle:"1.2 数据编码",charIndex:843},{level:3,title:"1.3 简单动态字符串(SDS)",slug:"_1-3-简单动态字符串-sds",normalizedTitle:"1.3 简单动态字符串(sds)",charIndex:1330},{level:3,title:"1.4 使用场景",slug:"_1-4-使用场景",normalizedTitle:"1.4 使用场景",charIndex:2193},{level:2,title:"2. List",slug:"_2-list",normalizedTitle:"2. list",charIndex:2267},{level:3,title:"2.1 简单使用",slug:"_2-1-简单使用",normalizedTitle:"2.1 简单使用",charIndex:2279},{level:3,title:"2.2 数据编码",slug:"_2-2-数据编码",normalizedTitle:"2.2 数据编码",charIndex:2884},{level:3,title:"2.3 压缩列表(ziplist)",slug:"_2-3-压缩列表-ziplist",normalizedTitle:"2.3 压缩列表(ziplist)",charIndex:3066},{level:3,title:"2.4 快速列表(quicklist)",slug:"_2-4-快速列表-quicklist",normalizedTitle:"2.4 快速列表(quicklist)",charIndex:4017},{level:3,title:"2.5 使用场景",slug:"_2-5-使用场景",normalizedTitle:"2.5 使用场景",charIndex:4241},{level:2,title:"3. Set",slug:"_3-set",normalizedTitle:"3. set",charIndex:4274},{level:3,title:"3.1 简单使用",slug:"_3-1-简单使用",normalizedTitle:"3.1 简单使用",charIndex:4319},{level:3,title:"3.2 数据编码",slug:"_3-2-数据编码",normalizedTitle:"3.2 数据编码",charIndex:4685},{level:3,title:"3.3 整型数组(intset)",slug:"_3-3-整型数组-intset",normalizedTitle:"3.3 整型数组(intset)",charIndex:4986},{level:3,title:"3.4 使用场景",slug:"_3-4-使用场景",normalizedTitle:"3.4 使用场景",charIndex:5534},{level:2,title:"4. Sorted Set",slug:"_4-sorted-set",normalizedTitle:"4. sorted set",charIndex:5618},{level:3,title:"4.1 简单使用",slug:"_4-1-简单使用",normalizedTitle:"4.1 简单使用",charIndex:5680},{level:3,title:"4.2 数据编码",slug:"_4-2-数据编码",normalizedTitle:"4.2 数据编码",charIndex:6235},{level:3,title:"4.3 跳表(skiplist)",slug:"_4-3-跳表-skiplist",normalizedTitle:"4.3 跳表(skiplist)",charIndex:6528},{level:3,title:"4.4 使用场景",slug:"_4-4-使用场景",normalizedTitle:"4.4 使用场景",charIndex:6643},{level:2,title:"5. hash",slug:"_5-hash",normalizedTitle:"5. hash",charIndex:6684},{level:3,title:"5.1 简单使用",slug:"_5-1-简单使用",normalizedTitle:"5.1 简单使用",charIndex:6725},{level:3,title:"5.2 数据编码",slug:"_5-2-数据编码",normalizedTitle:"5.2 数据编码",charIndex:7229},{level:3,title:"5.3 使用场景",slug:"_5-3-使用场景",normalizedTitle:"5.3 使用场景",charIndex:7365},{level:2,title:"6. 总结",slug:"_6-总结",normalizedTitle:"6. 总结",charIndex:7391},{level:2,title:"7. 相关链接",slug:"_7-相关链接",normalizedTitle:"7. 相关链接",charIndex:7469}],headersStr:"0. 前言 1. String 1.1 简单使用 1.2 数据编码 1.3 简单动态字符串(SDS) 1.4 使用场景 2. List 2.1 简单使用 2.2 数据编码 2.3 压缩列表(ziplist) 2.4 快速列表(quicklist) 2.5 使用场景 3. Set 3.1 简单使用 3.2 数据编码 3.3 整型数组(intset) 3.4 使用场景 4. Sorted Set 4.1 简单使用 4.2 数据编码 4.3 跳表(skiplist) 4.4 使用场景 5. hash 5.1 简单使用 5.2 数据编码 5.3 使用场景 6. 总结 7. 相关链接",content:'# 0. 前言\n\n本文主要讲解 redis 的五种基本数据类型：String、List、Set、Sorted Set、Hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。\n\n\n# 1. String\n\n\n# 1.1 简单使用\n\nString 是 redis 最简单的且最常用的数据类型，可以用来存储字符串、整型以及浮点型。\n\n * 字符串\n\n127.0.0.1:6379> set name zhangsan\nOK\n127.0.0.1:6379> get name\n"zhangsan"\n\n\n1\n2\n3\n4\n\n * 整型\n\n虽然 get age 时返回的是字符串，但是可以通过 object encoding age 看到其真正的类型。\n\n127.0.0.1:6379> set age 18\nOK\n127.0.0.1:6379> get age\n"18"\n127.0.0.1:6379> object encoding age\n"int"\n\n# 自增\n127.0.0.1:6379> incr age\n(integer) 19\n\n# 自减\n127.0.0.1:6379> decr age\n(integer) 18\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n * 浮点型\n\n写入的浮点型，但还是通过字符串来保存的，但是在使用的时候，会将字符串转换成浮点数。\n\n127.0.0.1:6379> set height 1.77\nOK\n127.0.0.1:6379> get height\n"1.77"\n127.0.0.1:6379> object encoding height\n"embstr"\n\n# 浮点数操作\n127.0.0.1:6379> incrbyfloat height 1\n"2.77"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n更多的操作请参考官网\n\n\n# 1.2 数据编码\n\nString 支持的编码类型有 int、embstr 和 raw，在不同条件时，会转换成对应的编码。\n\n * int 当存储的数据为整型时，会使用 int 编码。其实现是，会直接将整型值存储在 redisObject 的 ptr（将 void* 转换成 long） 中，并且将字符串的对象的编码设置为 int。\n\n * raw 该种编码是使用一种简单动态字符串(SDS)的数据结构存储，当字符串的长度大于 44 时，会使用该种数据编码方式。\n\n * embstr 也是使用 简单动态字符串(SDS)的数据结构存储，是当字符串长度小于等于 44 时使用。\n\nembstr 和 raw 的区别是什么呢？\n\n创建 string 使用 raw 编码时，会调用两次内存分配来创建 redisObject 和 sds 的数据结构，而 embstr 只会调用一次来创建连续的内存空间来存储 redisObject 和 sds 。\n\n当字符串较小时，embstr 少调用一次内存分配，释放也只需要一次，明显更快，并且连续的内存空间可以更好的利用 cpu 缓存。\n\n\n# 1.3 简单动态字符串(SDS)\n\n在数据编码中提到 embstr 和 raw 都是使用 SDS 数据结构，那么这种数据结构的是怎么样的，有什么好处呢？\n\n数据结构如下图所示：\n\nstruct sdshdr {\n    //记录buf数组中已使用字节的数量，等于SDS所保存字符串的长度\n    int len;\n \n    //记录buf 数组中未使用字节的数量\n    int free;\n \n    //字节数组，用于保存字符串\n    char buf[];\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n * free: 表示还有多少空余空间\n * len: 已使用多少空间\n * buf: 存储字符串的数组\n\n问题：String 为什么使用简单动态字符串来实现，而不是使用 C 传统字符串来实现呢？\n\n * 防止缓存区溢出\n\n在扩充字符串时，需要考虑缓冲区是否足够，SDS 提供 API 来帮助我们判断并扩充空间。\n\n * 常数获取字符串长度\n\nC 传统字符串需要遍历才能知道具体的长度，时间复杂度为 O(n)，而 SDS 可以直接读 len 属性获取长度，时间复杂度为 O(1)\n\n * 减少内存分配的次数\n\n在扩大字符串长度时，需要重新申请更大的内存空间，然后拷贝到新的内存空间中，然后再释放旧的内存空间。\n\n在缩小时也是一样，需要申请新的空间，再释放旧的空间。\n\n在 SDS 中可以通过以下的方式来减少内存分配和释放，提高效率。\n\n 1. 空间预分配，在分配空间时，除了必要的空间外，可以额外的分配未使用的空间，在下次使用，可以快速使用这部分的空间，而不必重新分配。\n 2. 惰性释放空间，在缩小字符串时，不需要马上释放多余的空间，可以预留给下次使用。\n\n * 二进制安全\n\nC 语言中是以空字符来表示字符串的结束，而一些二进制文件内容可能是包含空字符串的，因此 C 语言字符串无法正确读取，所以 SDS 都是以二进制方式处理 buf，并且不以空字符串判断是否结束，而是用 len 来判断。\n\n\n# 1.4 使用场景\n\n * 缓存，存储热点数据作为缓存，降低持久化数据库的读写压力。\n * 分布式锁\n * 计数器，可以使用 incr 命令\n\n\n# 2. List\n\n\n# 2.1 简单使用\n\n命令       说明\nlpush    将值从左边推入列表\nrpush    将值从右边推入列表\nlpop     将值从列表左边弹出返回\nrpop     将值从列表右边弹出返回\nlrange   根据索引查看列表中的数据\n\n127.0.0.1:6379> lpush mylist 1 2 3\n(integer) 3\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "3"\n2) "2"\n3) "1"\n\n127.0.0.1:6379> rpush mylist 4\n(integer) 4\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "3"\n2) "2"\n3) "1"\n4) "4"\n\n127.0.0.1:6379> lpop mylist\n"3"\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "2"\n2) "1"\n3) "4"\n\n127.0.0.1:6379> rpop mylist\n"4"\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "2"\n2) "1"\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2.2 数据编码\n\n在 redis3.2 之前使用的是 ziplist 和 linkedlist 两种编码方式。在数据量少的时候使用 ziplist，而数据多的时候使用 linkedlist。\n\n而之后的版本使用的是 quicklist\n\n127.0.0.1:6379> object encoding mylist\n"quicklist"\n\n\n1\n2\n\n\n\n# 2.3 压缩列表(ziplist)\n\n该数据结构类似于一个数组，在数组的表头添加三个字段 zlbytes、zltail、zlen，再在表尾添加 zlend 表示列表结束。\n\n\n\n * zlbytes：内存字节数\n * zltail：列表尾偏移量\n * zllen：列表元素个数\n * zlend：列表结束标记\n\n通过这几个字段可以快速定位第一个元素和最后元素，时间复杂度为 O(1)。\n\n除了表头与表尾之外，其他元素都是节点，节点的数据结构如下图：\n\n\n\n * previous_entry_length : 上一个节点的长度。可以推算出上一个节点的地址\n * encoding: 该节点的数据类型及长度\n * content: 节点的值\n\n连锁更新问题\n\n对于 previous_entry_length：\n\n * 前一个节点长度小于 254 字节，previous_entry_length 长度需要用 1 字节保存长度值\n * 前一个节点长度大于 254 字节，previous_entry_length 长度需要用 5 字节保存长度值\n\n有这一种场景，如果压缩列表中有多个连续的节点长度在 250-253 字节之间，这些节点 previous_entry_length 使用 1 个字节存储大小。\n\n * 当在最前方添加一个节点大于等于 254 字节的节点时，后面的节点 previous_entry_length 都需要从 1 字节扩充到 5 字节，起到连锁更新，后面的节点都需要更新。\n\n\n\n * 当删除其中 small 节点时，其后节点 previous_entry_length 需要保存前面的 big 节点，需要扩充节点空间，并且后面发生连锁更新\n\n\n\n虽然连锁更新复杂度很高，但是造成的可能性很低。\n\n * 长度需要在 250 到 253 字节之间\n * 被更新的节点数量不多，也不会造成性能影响\n\n优点\n\n * 内存地址连续，减少了内存碎片化，可以使用到缓存进行优化\n * 如果是双向链表，节点的头尾都需要指针来指向上一个或者下一个节点，而压缩列表省去了该部分内存空间的占用。\n\n缺点\n\n * 对于删除和插入操作都需要移动该节点位置后面的元素，并且可能会触发连锁更新反应\n\n\n# 2.4 快速列表(quicklist)\n\nquicklist 是压缩列表和双向链表结合实现的，在宏观上它是一个双向链表，然后其每个结点上都挂了一个 ziplist。如下图所示：\n\nziplist 在列表数量大的时候性能会下降，很难分配一大块连续的内存空间，并且在删除和插入操作性能下降的更为厉害。\n\n而双向链表会导致大量的碎片化空间，而且每个节点的头尾指针都会占用一定的内存空间。\n\n而 quicklist 算是在两者之间取得了一个平衡。\n\n\n# 2.5 使用场景\n\n * 消息队列\n * 列表及分页展示\n\n\n# 3. Set\n\n是一个无序的集合，集合元素是唯一的，会自动对添加的数据进行去重。\n\n\n# 3.1 简单使用\n\n命令          说明\nSADD        向集合添加一个或多个元素\nSCARD       获取集合的数量\nSMEMBERS    获取集合全部元素\nSISMEMBER   判断集合中是否指定元素\n\n127.0.0.1:6379> sadd myset zheng wen feng zheng\n(integer) 3\n\n127.0.0.1:6379> scard myset\n(integer) 3\n\n127.0.0.1:6379> smembers myset\n1) "zheng"\n2) "feng"\n3) "wen"\n\n127.0.0.1:6379> sismember myset feng\n(integer) 1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 3.2 数据编码\n\n该数据类型使用数据编码的是 intset 或者 hashtable，当 set 满足以下条件时，使用的 inset，其他情况都是 hashtable。\n\n * 当所有的元素都是整数值时\n * 元素个数不超过 512 个时\n\n127.0.0.1:6379> sadd myset2 1 2 4 4\n(integer) 3\n\n127.0.0.1:6379> SMEMBERS myset2\n1) "1"\n2) "2"\n3) "4"\n\n127.0.0.1:6379> OBJECT ENCODING myset2\n"intset"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 3.3 整型数组(intset)\n\nintset 数据结构如下所示：\n\ntypedef struct intset {\n    // 编码方式\n    uint32_t encoding;\n    // 集合包含的元素数量\n    uint32_t length;\n    // 保存元素的数组\n    int8_t contents[];\n} intset;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * encoding：contents 中存储的数据类型取决于该字段\n * length: 数组长度\n * contnets: 存储数据的整型数组，数据的数据类型取决于 encoding，从小到大排序\n\ncontents 数组中每一个元素的类型都是由 encoding 决定的，但是当原来的数据类型是 int16 时，现在要插入一个 int32 时，该如何操作呢？\n\n升级\n\n这个时候需要对 contents 中的每个元素都进行升级：\n\n * 根据新元素的类型，扩大 contents 数组的空间大小\n * 将数组的所有元素转换成新元素相同的类型并放入数组中\n * 最后改变 encoding 的值\n\n这么做的好处是，当所有的数据都是小整型时，可以节省内存的开销。\n\n目前不支持降级。\n\n\n# 3.4 使用场景\n\n * 标签，给用户打上标签，以标签为 key，用户 ID 为 value 放入 set 中\n * 点赞，收藏等，利用 set 的唯一特性。\n\n\n# 4. Sorted Set\n\n是一个不允许重复元素的集合，但是每个元素会关联一个分数，可以通过分数对集合进行排序。\n\n\n# 4.1 简单使用\n\n命令       说明\nZADD     向集合添加一个或多个元素\nZRANGE   根据位置查询获取集合多个元素\nZREM     如果元素存在集合中，则进行删除\n\n127.0.0.1:6379> zadd myzset 100 zheng 99 wen 80 feng\n(integer) 3\n\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "wen"\n3) "zheng"\n\n127.0.0.1:6379> zadd myzset 91 hello\n(integer) 1\n\n# 默认是根据score升序查询\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "hello"\n3) "wen"\n4) "zheng"\n\n127.0.0.1:6379> zrem myzset wen\n(integer) 1\n\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "hello"\n3) "zheng"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# 4.2 数据编码\n\n该类型的数据编码可以为 ziplist 或者 skiplist，当满足以下条件时，使用的 ziplist，其他情况是 skiplist\n\n * 元素数量小于 128\n * 搜索元素长度小于 64\n\n当数据编码为 skiplist 时，redis 中使用的存储结构是 zset 数据结构，其中包含了 zskiplist 和 dict\n\ntypedef struct zset {\n    zskiplist *zs1;\n    dict *dict;\n}\n\n\n1\n2\n3\n4\n\n\n通过 zskiplist 可以快速的范围查询，dict 可以快速定位单个元素。\n\n\n# 4.3 跳表(skiplist)\n\n在有序的链表上添加了多级索引，通过索引位置的跳转，实现数据的快速定位。如下图所示：\n\n优点：\n\n 1. 在通过范围查询或排序时，可以在跳表中先找到最小值，然后再在最底层链表中遍历获取。\n\n\n# 4.4 使用场景\n\n * 排行榜，通过给视频、文章打分，然后进行排序展示\n\n\n# 5. hash\n\n用于存储 string 类型的键值对，适用于存储对象。\n\n\n# 5.1 简单使用\n\n命令        说明\nhset      设置键值对\nhget      获取指定 hash 的键对应的值\nhgetall   获取指定 hash 中的所有键值对\nhdel      删除指定 hash 中的键值对\n\n127.0.0.1:6379> hset person name zhangsan\n(integer) 1\n\n127.0.0.1:6379> hset person age 18\n(integer) 1\n\n127.0.0.1:6379> hget persion name\n"zhangsan"\n\n127.0.0.1:6379> hgetall person\n1) "name"\n2) "zhangsan"\n3) "age"\n4) "18"\n\n127.0.0.1:6379> hdel person age\n(integer) 1\n\n127.0.0.1:6379> hgetall person\n1) "name"\n2) "zhangsan"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n\n# 5.2 数据编码\n\n使用的数据编码是 ziplist 或 hashtable，满足以下条件选择使用 ziplist，其他情况使用 hashtable\n\n * hash 对象保存的键和值字符串长度都小于 64 字节\n * hash 对象保存的键值对数量小于 512\n\n\n# 5.3 使用场景\n\n * 用来存储对象信息\n\n\n# 6. 总结\n\nredis 之所以快，正是因为其有着丰富的数据结构，所以我们需要理解它们，在设计方案时，就能正确的选择数据类型来实现我们的业务需求。\n\n\n# 7. 相关链接\n\n * Redis 设计与实现\n * 图解 redis 五种数据结构底层实现\n * Redis 设计与实现\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来',normalizedContent:'# 0. 前言\n\n本文主要讲解 redis 的五种基本数据类型：string、list、set、sorted set、hash。学习如何使用它们，并且了解它们的底层数据结构实现，这样我们才能在适当的应用场景选择最适合的数据类型来解决我们的需求。\n\n\n# 1. string\n\n\n# 1.1 简单使用\n\nstring 是 redis 最简单的且最常用的数据类型，可以用来存储字符串、整型以及浮点型。\n\n * 字符串\n\n127.0.0.1:6379> set name zhangsan\nok\n127.0.0.1:6379> get name\n"zhangsan"\n\n\n1\n2\n3\n4\n\n * 整型\n\n虽然 get age 时返回的是字符串，但是可以通过 object encoding age 看到其真正的类型。\n\n127.0.0.1:6379> set age 18\nok\n127.0.0.1:6379> get age\n"18"\n127.0.0.1:6379> object encoding age\n"int"\n\n# 自增\n127.0.0.1:6379> incr age\n(integer) 19\n\n# 自减\n127.0.0.1:6379> decr age\n(integer) 18\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n * 浮点型\n\n写入的浮点型，但还是通过字符串来保存的，但是在使用的时候，会将字符串转换成浮点数。\n\n127.0.0.1:6379> set height 1.77\nok\n127.0.0.1:6379> get height\n"1.77"\n127.0.0.1:6379> object encoding height\n"embstr"\n\n# 浮点数操作\n127.0.0.1:6379> incrbyfloat height 1\n"2.77"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n更多的操作请参考官网\n\n\n# 1.2 数据编码\n\nstring 支持的编码类型有 int、embstr 和 raw，在不同条件时，会转换成对应的编码。\n\n * int 当存储的数据为整型时，会使用 int 编码。其实现是，会直接将整型值存储在 redisobject 的 ptr（将 void* 转换成 long） 中，并且将字符串的对象的编码设置为 int。\n\n * raw 该种编码是使用一种简单动态字符串(sds)的数据结构存储，当字符串的长度大于 44 时，会使用该种数据编码方式。\n\n * embstr 也是使用 简单动态字符串(sds)的数据结构存储，是当字符串长度小于等于 44 时使用。\n\nembstr 和 raw 的区别是什么呢？\n\n创建 string 使用 raw 编码时，会调用两次内存分配来创建 redisobject 和 sds 的数据结构，而 embstr 只会调用一次来创建连续的内存空间来存储 redisobject 和 sds 。\n\n当字符串较小时，embstr 少调用一次内存分配，释放也只需要一次，明显更快，并且连续的内存空间可以更好的利用 cpu 缓存。\n\n\n# 1.3 简单动态字符串(sds)\n\n在数据编码中提到 embstr 和 raw 都是使用 sds 数据结构，那么这种数据结构的是怎么样的，有什么好处呢？\n\n数据结构如下图所示：\n\nstruct sdshdr {\n    //记录buf数组中已使用字节的数量，等于sds所保存字符串的长度\n    int len;\n \n    //记录buf 数组中未使用字节的数量\n    int free;\n \n    //字节数组，用于保存字符串\n    char buf[];\n};\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n * free: 表示还有多少空余空间\n * len: 已使用多少空间\n * buf: 存储字符串的数组\n\n问题：string 为什么使用简单动态字符串来实现，而不是使用 c 传统字符串来实现呢？\n\n * 防止缓存区溢出\n\n在扩充字符串时，需要考虑缓冲区是否足够，sds 提供 api 来帮助我们判断并扩充空间。\n\n * 常数获取字符串长度\n\nc 传统字符串需要遍历才能知道具体的长度，时间复杂度为 o(n)，而 sds 可以直接读 len 属性获取长度，时间复杂度为 o(1)\n\n * 减少内存分配的次数\n\n在扩大字符串长度时，需要重新申请更大的内存空间，然后拷贝到新的内存空间中，然后再释放旧的内存空间。\n\n在缩小时也是一样，需要申请新的空间，再释放旧的空间。\n\n在 sds 中可以通过以下的方式来减少内存分配和释放，提高效率。\n\n 1. 空间预分配，在分配空间时，除了必要的空间外，可以额外的分配未使用的空间，在下次使用，可以快速使用这部分的空间，而不必重新分配。\n 2. 惰性释放空间，在缩小字符串时，不需要马上释放多余的空间，可以预留给下次使用。\n\n * 二进制安全\n\nc 语言中是以空字符来表示字符串的结束，而一些二进制文件内容可能是包含空字符串的，因此 c 语言字符串无法正确读取，所以 sds 都是以二进制方式处理 buf，并且不以空字符串判断是否结束，而是用 len 来判断。\n\n\n# 1.4 使用场景\n\n * 缓存，存储热点数据作为缓存，降低持久化数据库的读写压力。\n * 分布式锁\n * 计数器，可以使用 incr 命令\n\n\n# 2. list\n\n\n# 2.1 简单使用\n\n命令       说明\nlpush    将值从左边推入列表\nrpush    将值从右边推入列表\nlpop     将值从列表左边弹出返回\nrpop     将值从列表右边弹出返回\nlrange   根据索引查看列表中的数据\n\n127.0.0.1:6379> lpush mylist 1 2 3\n(integer) 3\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "3"\n2) "2"\n3) "1"\n\n127.0.0.1:6379> rpush mylist 4\n(integer) 4\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "3"\n2) "2"\n3) "1"\n4) "4"\n\n127.0.0.1:6379> lpop mylist\n"3"\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "2"\n2) "1"\n3) "4"\n\n127.0.0.1:6379> rpop mylist\n"4"\n\n127.0.0.1:6379> lrange mylist 0 -1\n1) "2"\n2) "1"\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2.2 数据编码\n\n在 redis3.2 之前使用的是 ziplist 和 linkedlist 两种编码方式。在数据量少的时候使用 ziplist，而数据多的时候使用 linkedlist。\n\n而之后的版本使用的是 quicklist\n\n127.0.0.1:6379> object encoding mylist\n"quicklist"\n\n\n1\n2\n\n\n\n# 2.3 压缩列表(ziplist)\n\n该数据结构类似于一个数组，在数组的表头添加三个字段 zlbytes、zltail、zlen，再在表尾添加 zlend 表示列表结束。\n\n\n\n * zlbytes：内存字节数\n * zltail：列表尾偏移量\n * zllen：列表元素个数\n * zlend：列表结束标记\n\n通过这几个字段可以快速定位第一个元素和最后元素，时间复杂度为 o(1)。\n\n除了表头与表尾之外，其他元素都是节点，节点的数据结构如下图：\n\n\n\n * previous_entry_length : 上一个节点的长度。可以推算出上一个节点的地址\n * encoding: 该节点的数据类型及长度\n * content: 节点的值\n\n连锁更新问题\n\n对于 previous_entry_length：\n\n * 前一个节点长度小于 254 字节，previous_entry_length 长度需要用 1 字节保存长度值\n * 前一个节点长度大于 254 字节，previous_entry_length 长度需要用 5 字节保存长度值\n\n有这一种场景，如果压缩列表中有多个连续的节点长度在 250-253 字节之间，这些节点 previous_entry_length 使用 1 个字节存储大小。\n\n * 当在最前方添加一个节点大于等于 254 字节的节点时，后面的节点 previous_entry_length 都需要从 1 字节扩充到 5 字节，起到连锁更新，后面的节点都需要更新。\n\n\n\n * 当删除其中 small 节点时，其后节点 previous_entry_length 需要保存前面的 big 节点，需要扩充节点空间，并且后面发生连锁更新\n\n\n\n虽然连锁更新复杂度很高，但是造成的可能性很低。\n\n * 长度需要在 250 到 253 字节之间\n * 被更新的节点数量不多，也不会造成性能影响\n\n优点\n\n * 内存地址连续，减少了内存碎片化，可以使用到缓存进行优化\n * 如果是双向链表，节点的头尾都需要指针来指向上一个或者下一个节点，而压缩列表省去了该部分内存空间的占用。\n\n缺点\n\n * 对于删除和插入操作都需要移动该节点位置后面的元素，并且可能会触发连锁更新反应\n\n\n# 2.4 快速列表(quicklist)\n\nquicklist 是压缩列表和双向链表结合实现的，在宏观上它是一个双向链表，然后其每个结点上都挂了一个 ziplist。如下图所示：\n\nziplist 在列表数量大的时候性能会下降，很难分配一大块连续的内存空间，并且在删除和插入操作性能下降的更为厉害。\n\n而双向链表会导致大量的碎片化空间，而且每个节点的头尾指针都会占用一定的内存空间。\n\n而 quicklist 算是在两者之间取得了一个平衡。\n\n\n# 2.5 使用场景\n\n * 消息队列\n * 列表及分页展示\n\n\n# 3. set\n\n是一个无序的集合，集合元素是唯一的，会自动对添加的数据进行去重。\n\n\n# 3.1 简单使用\n\n命令          说明\nsadd        向集合添加一个或多个元素\nscard       获取集合的数量\nsmembers    获取集合全部元素\nsismember   判断集合中是否指定元素\n\n127.0.0.1:6379> sadd myset zheng wen feng zheng\n(integer) 3\n\n127.0.0.1:6379> scard myset\n(integer) 3\n\n127.0.0.1:6379> smembers myset\n1) "zheng"\n2) "feng"\n3) "wen"\n\n127.0.0.1:6379> sismember myset feng\n(integer) 1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 3.2 数据编码\n\n该数据类型使用数据编码的是 intset 或者 hashtable，当 set 满足以下条件时，使用的 inset，其他情况都是 hashtable。\n\n * 当所有的元素都是整数值时\n * 元素个数不超过 512 个时\n\n127.0.0.1:6379> sadd myset2 1 2 4 4\n(integer) 3\n\n127.0.0.1:6379> smembers myset2\n1) "1"\n2) "2"\n3) "4"\n\n127.0.0.1:6379> object encoding myset2\n"intset"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 3.3 整型数组(intset)\n\nintset 数据结构如下所示：\n\ntypedef struct intset {\n    // 编码方式\n    uint32_t encoding;\n    // 集合包含的元素数量\n    uint32_t length;\n    // 保存元素的数组\n    int8_t contents[];\n} intset;\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * encoding：contents 中存储的数据类型取决于该字段\n * length: 数组长度\n * contnets: 存储数据的整型数组，数据的数据类型取决于 encoding，从小到大排序\n\ncontents 数组中每一个元素的类型都是由 encoding 决定的，但是当原来的数据类型是 int16 时，现在要插入一个 int32 时，该如何操作呢？\n\n升级\n\n这个时候需要对 contents 中的每个元素都进行升级：\n\n * 根据新元素的类型，扩大 contents 数组的空间大小\n * 将数组的所有元素转换成新元素相同的类型并放入数组中\n * 最后改变 encoding 的值\n\n这么做的好处是，当所有的数据都是小整型时，可以节省内存的开销。\n\n目前不支持降级。\n\n\n# 3.4 使用场景\n\n * 标签，给用户打上标签，以标签为 key，用户 id 为 value 放入 set 中\n * 点赞，收藏等，利用 set 的唯一特性。\n\n\n# 4. sorted set\n\n是一个不允许重复元素的集合，但是每个元素会关联一个分数，可以通过分数对集合进行排序。\n\n\n# 4.1 简单使用\n\n命令       说明\nzadd     向集合添加一个或多个元素\nzrange   根据位置查询获取集合多个元素\nzrem     如果元素存在集合中，则进行删除\n\n127.0.0.1:6379> zadd myzset 100 zheng 99 wen 80 feng\n(integer) 3\n\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "wen"\n3) "zheng"\n\n127.0.0.1:6379> zadd myzset 91 hello\n(integer) 1\n\n# 默认是根据score升序查询\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "hello"\n3) "wen"\n4) "zheng"\n\n127.0.0.1:6379> zrem myzset wen\n(integer) 1\n\n127.0.0.1:6379> zrange myzset 0 -1\n1) "feng"\n2) "hello"\n3) "zheng"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# 4.2 数据编码\n\n该类型的数据编码可以为 ziplist 或者 skiplist，当满足以下条件时，使用的 ziplist，其他情况是 skiplist\n\n * 元素数量小于 128\n * 搜索元素长度小于 64\n\n当数据编码为 skiplist 时，redis 中使用的存储结构是 zset 数据结构，其中包含了 zskiplist 和 dict\n\ntypedef struct zset {\n    zskiplist *zs1;\n    dict *dict;\n}\n\n\n1\n2\n3\n4\n\n\n通过 zskiplist 可以快速的范围查询，dict 可以快速定位单个元素。\n\n\n# 4.3 跳表(skiplist)\n\n在有序的链表上添加了多级索引，通过索引位置的跳转，实现数据的快速定位。如下图所示：\n\n优点：\n\n 1. 在通过范围查询或排序时，可以在跳表中先找到最小值，然后再在最底层链表中遍历获取。\n\n\n# 4.4 使用场景\n\n * 排行榜，通过给视频、文章打分，然后进行排序展示\n\n\n# 5. hash\n\n用于存储 string 类型的键值对，适用于存储对象。\n\n\n# 5.1 简单使用\n\n命令        说明\nhset      设置键值对\nhget      获取指定 hash 的键对应的值\nhgetall   获取指定 hash 中的所有键值对\nhdel      删除指定 hash 中的键值对\n\n127.0.0.1:6379> hset person name zhangsan\n(integer) 1\n\n127.0.0.1:6379> hset person age 18\n(integer) 1\n\n127.0.0.1:6379> hget persion name\n"zhangsan"\n\n127.0.0.1:6379> hgetall person\n1) "name"\n2) "zhangsan"\n3) "age"\n4) "18"\n\n127.0.0.1:6379> hdel person age\n(integer) 1\n\n127.0.0.1:6379> hgetall person\n1) "name"\n2) "zhangsan"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n\n# 5.2 数据编码\n\n使用的数据编码是 ziplist 或 hashtable，满足以下条件选择使用 ziplist，其他情况使用 hashtable\n\n * hash 对象保存的键和值字符串长度都小于 64 字节\n * hash 对象保存的键值对数量小于 512\n\n\n# 5.3 使用场景\n\n * 用来存储对象信息\n\n\n# 6. 总结\n\nredis 之所以快，正是因为其有着丰富的数据结构，所以我们需要理解它们，在设计方案时，就能正确的选择数据类型来实现我们的业务需求。\n\n\n# 7. 相关链接\n\n * redis 设计与实现\n * 图解 redis 五种数据结构底层实现\n * redis 设计与实现\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来',charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"redis之持久化",frontmatter:{title:"redis之持久化",date:"2022-12-01T15:18:02.000Z",permalink:"/pages/4c6b13/",tags:["redis","数据库"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210805185829.png"},{name:"twitter:title",content:"redis之持久化"},{name:"twitter:description",content:"本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210805185829.png"},{name:"twitter:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/02.redis%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之持久化"},{property:"og:description",content:"本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210805185829.png"},{property:"og:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/02.redis%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-12-01T15:18:02.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之持久化"},{itemprop:"description",content:"本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210805185829.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/02.redis%E4%B9%8B%E6%8C%81%E4%B9%85%E5%8C%96.html",relativePath:"03.中间件/05.redis/02.redis之持久化.md",key:"v-d04209ac",path:"/pages/4c6b13/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. AOF",slug:"_1-aof",normalizedTitle:"1. aof",charIndex:143},{level:3,title:"1.1 为什么是 AOF ?",slug:"_1-1-为什么是-aof",normalizedTitle:"1.1 为什么是 aof ?",charIndex:204},{level:3,title:"1.2 AOF 重写机制",slug:"_1-2-aof-重写机制",normalizedTitle:"1.2 aof 重写机制",charIndex:461},{level:2,title:"2. RDB 内存快照",slug:"_2-rdb-内存快照",normalizedTitle:"2. rdb 内存快照",charIndex:1331},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:2178},{level:2,title:"4. 参考文章",slug:"_4-参考文章",normalizedTitle:"4. 参考文章",charIndex:2449}],headersStr:"0. 前言 1. AOF 1.1 为什么是 AOF ? 1.2 AOF 重写机制 2. RDB 内存快照 3. 总结 4. 参考文章",content:"# 0. 前言\n\n本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。\n\n\n# 1. AOF\n\nAOF，称为后写日志，就是先执行命令，把数据写入到数据库中之后，再进行记录日志。过程如下图所示：\n\n\n# 1.1 为什么是 AOF ?\n\nRedis 向 AOF 写日志时，并不会校验命令的语法，如果先记日志，则可能保存了错误的命令导致出错。所以让系统先执行命令，执行成功后再记录日志。\n\n后写日志也不会阻塞当前操作，但是下一次操作有阻塞风险。AOF 也是在主线程执行，如果写入的时候磁盘压力过大，就可能会大致阻塞。\n\n但该种方式有风险，如果写入内存成功，记日志时发生宕机，则会丢失日志。\n\n正因为有这个风险，所以 redis 提供三种写入策略：\n\n这三种策略就是性能与可靠性的权衡，可以根据具体的业务进行选择。\n\n\n# 1.2 AOF 重写机制\n\nAOF 记录的是 Redis 的每一条命令，以文本形式保存，那么当 AOF 日志写的越来越多的时候，AOF 文件越来越大，以后通过 AOF 恢复数据也会变得很慢，redis 提供了 AOF 重写机制来减小 AOF 日志文件。\n\n将 AOF 文件生成的最新数据生成最新的操作日志并记录到新的 AOF 文件中，这样新的 AOF 文件中就没有了冗余命令，再替换掉旧的 AOF 文件。\n\nAOF 重写过程\n\nAOF 重写的过程会 fork 出 bgrewriteof 后台子进程，fork 会将主线程的数据内存拷贝到子进程，子进程在不影响主线程的情况下将拷贝的数据转换成操作写入到重写日志中。\n\n在重写日志时，主线程任然接受新的操作，操作会记录到 AOF 缓冲和 AOF 重写缓冲区，AOF 日志不会丢失最新的操作，在拷贝数据重写完成后，再将 AOF 重写缓冲区的日志记录写入新的 AOF 文件中，保证新的 AOF 文件的数据也是最新的状态。此时就可以放心将新写入的 AOF 文件代替旧文件。\n\n\n\n写时复制 copy on write\n\nfork 采用操作系统的 写时复制机制，避免一次性拷贝大量内存数据给子进程。fork 子进程时，子进程会拷贝父进程的内存页表(虚拟内存和物理内存的映射索引表)而不会拷贝其所有的物理内存数据，这样两个进程使用的数据是同一份内存空间。当主线程写入新数据时，会拷贝一份新数据并进行修改，这样并不影响子进程的读取。\n\nAOF 重写阻塞点\n\n * 在 fork 子进程时，即使是拷贝页表和一些必要的数据结构也是需要消耗大量的 CPU，会对主线程进行阻塞\n * 在 AOF 重写过程中，如果有 big key 写入时，会拷贝旧数据到创建的新内存空间中，也会进行阻塞。\n\nAOF 重写日志为什么不共享 AOF 本身日志？\n\n * 两个进程操作同一个文件，存在竞争问题，影响父进程性能\n * 如果重写失败，AOF 日志则被污染了，无法恢复使用。重写一个文件，如果重写失败，删除重来即可。\n\n\n# 2. RDB 内存快照\n\nAOF 方法恢复数据需要将操作日志全部执行一遍，如果日志非常多，则恢复的过程缓慢。而内存快照是将某一时刻的数据以文件(RDB)记录到磁盘上，在恢复的时候，直接读入内存即可。\n\n会不会阻塞主线程?\n\nRedis 提供 save 和 bgsave 两个命令生成 RDB 文件\n\n * save 是在主线程执行会阻塞，不建议在线上使用\n * bgsave 会创建子进程生成 RDB，默认。\n\n如果在触发快照时，能修改数据吗？\n\n如果在 t 时刻，需要快照数据 A，在快照时修改了 A 数据为 A'，这时破坏了快照的完整性，这时 A'并不是 t 时刻的状态。\n\n如果在快照时，不允许修改，虽然解决了上面的问题，但是会影响业务。\n\n这里解决办法还是使用了操作系统的 写时复制机制，在新的数据需要写入时，主线程会将该数据复制一份，然后对该副本进行修改，而子进程使用原来的数据进行快照。\n\n\n\n既然可以使用 RDB 快速恢复数据，那么是否可以每秒做一次快照呢？\n\n两次快照之间的数据，如果遇到宕机，可能会发生丢失，所以需要尽量短的时间做快照。\n\n但虽然生成 RDB 文件使用子进程，但是频繁的执行全量快照还是会带来额外的开销：\n\n * 频繁的写磁盘，增大磁盘压力\n * fork 子进程时，如果数据内存过大，是会阻塞主线程的。\n\n如何解决快照间丢失数据？\n\n增量快照。混合使用 AOF 日志和内存快照。\n\n使用 AOF 记录两次快照间的操作。在生成快照时，使用 AOF 日志记录新进入的修改操作，在下一次快照前宕机都可以通过 AOF 日志进行恢复。下一次快照时可以再清空 AOF 日志重新记录\n\n\n\n如何在 AOF 和 RDB 进行选择?\n\n * 数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择；\n * 如果允许分钟级别的数据丢失，可以只使用 RDB；\n * 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。\n\n\n# 3. 总结\n\n通过上面的介绍，了解到 RDB 和 AOF 都是通过 fork 子进程来完成的，是为了不会造成主线程的阻塞，但是也并不能完全避免，所以我们需要尽可能的降低 fork 的频率。\n\n并且都使用了操作系统的 COW 机制，该机制可以大大的减少 cpu 与内存的消耗，我们在很多组件中会发现它们都用到了 linux 的一些好用的机制，像 Kafka 用到的零拷贝和 PageCache 等等。我们在设计中需要善用这些机制，可以非常大的优化程序的性能，并且简化我们需要做的时候交给操作系统去完成，并且完成的比我们做的更好更稳定。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",normalizedContent:"# 0. 前言\n\n本文主要是介绍 redis 是如何进行持久化数据的，我们知道 redis 是基于内存的数据库，那么只要服务器一旦宕机，那么数据则将全部丢失，如果从后端数据库进行恢复，则可能导致性能变慢，那么 redis 需要自身持久化，而不通过后端数据库来恢复数据是重要的。\n\n\n# 1. aof\n\naof，称为后写日志，就是先执行命令，把数据写入到数据库中之后，再进行记录日志。过程如下图所示：\n\n\n# 1.1 为什么是 aof ?\n\nredis 向 aof 写日志时，并不会校验命令的语法，如果先记日志，则可能保存了错误的命令导致出错。所以让系统先执行命令，执行成功后再记录日志。\n\n后写日志也不会阻塞当前操作，但是下一次操作有阻塞风险。aof 也是在主线程执行，如果写入的时候磁盘压力过大，就可能会大致阻塞。\n\n但该种方式有风险，如果写入内存成功，记日志时发生宕机，则会丢失日志。\n\n正因为有这个风险，所以 redis 提供三种写入策略：\n\n这三种策略就是性能与可靠性的权衡，可以根据具体的业务进行选择。\n\n\n# 1.2 aof 重写机制\n\naof 记录的是 redis 的每一条命令，以文本形式保存，那么当 aof 日志写的越来越多的时候，aof 文件越来越大，以后通过 aof 恢复数据也会变得很慢，redis 提供了 aof 重写机制来减小 aof 日志文件。\n\n将 aof 文件生成的最新数据生成最新的操作日志并记录到新的 aof 文件中，这样新的 aof 文件中就没有了冗余命令，再替换掉旧的 aof 文件。\n\naof 重写过程\n\naof 重写的过程会 fork 出 bgrewriteof 后台子进程，fork 会将主线程的数据内存拷贝到子进程，子进程在不影响主线程的情况下将拷贝的数据转换成操作写入到重写日志中。\n\n在重写日志时，主线程任然接受新的操作，操作会记录到 aof 缓冲和 aof 重写缓冲区，aof 日志不会丢失最新的操作，在拷贝数据重写完成后，再将 aof 重写缓冲区的日志记录写入新的 aof 文件中，保证新的 aof 文件的数据也是最新的状态。此时就可以放心将新写入的 aof 文件代替旧文件。\n\n\n\n写时复制 copy on write\n\nfork 采用操作系统的 写时复制机制，避免一次性拷贝大量内存数据给子进程。fork 子进程时，子进程会拷贝父进程的内存页表(虚拟内存和物理内存的映射索引表)而不会拷贝其所有的物理内存数据，这样两个进程使用的数据是同一份内存空间。当主线程写入新数据时，会拷贝一份新数据并进行修改，这样并不影响子进程的读取。\n\naof 重写阻塞点\n\n * 在 fork 子进程时，即使是拷贝页表和一些必要的数据结构也是需要消耗大量的 cpu，会对主线程进行阻塞\n * 在 aof 重写过程中，如果有 big key 写入时，会拷贝旧数据到创建的新内存空间中，也会进行阻塞。\n\naof 重写日志为什么不共享 aof 本身日志？\n\n * 两个进程操作同一个文件，存在竞争问题，影响父进程性能\n * 如果重写失败，aof 日志则被污染了，无法恢复使用。重写一个文件，如果重写失败，删除重来即可。\n\n\n# 2. rdb 内存快照\n\naof 方法恢复数据需要将操作日志全部执行一遍，如果日志非常多，则恢复的过程缓慢。而内存快照是将某一时刻的数据以文件(rdb)记录到磁盘上，在恢复的时候，直接读入内存即可。\n\n会不会阻塞主线程?\n\nredis 提供 save 和 bgsave 两个命令生成 rdb 文件\n\n * save 是在主线程执行会阻塞，不建议在线上使用\n * bgsave 会创建子进程生成 rdb，默认。\n\n如果在触发快照时，能修改数据吗？\n\n如果在 t 时刻，需要快照数据 a，在快照时修改了 a 数据为 a'，这时破坏了快照的完整性，这时 a'并不是 t 时刻的状态。\n\n如果在快照时，不允许修改，虽然解决了上面的问题，但是会影响业务。\n\n这里解决办法还是使用了操作系统的 写时复制机制，在新的数据需要写入时，主线程会将该数据复制一份，然后对该副本进行修改，而子进程使用原来的数据进行快照。\n\n\n\n既然可以使用 rdb 快速恢复数据，那么是否可以每秒做一次快照呢？\n\n两次快照之间的数据，如果遇到宕机，可能会发生丢失，所以需要尽量短的时间做快照。\n\n但虽然生成 rdb 文件使用子进程，但是频繁的执行全量快照还是会带来额外的开销：\n\n * 频繁的写磁盘，增大磁盘压力\n * fork 子进程时，如果数据内存过大，是会阻塞主线程的。\n\n如何解决快照间丢失数据？\n\n增量快照。混合使用 aof 日志和内存快照。\n\n使用 aof 记录两次快照间的操作。在生成快照时，使用 aof 日志记录新进入的修改操作，在下一次快照前宕机都可以通过 aof 日志进行恢复。下一次快照时可以再清空 aof 日志重新记录\n\n\n\n如何在 aof 和 rdb 进行选择?\n\n * 数据不能丢失时，内存快照和 aof 的混合使用是一个很好的选择；\n * 如果允许分钟级别的数据丢失，可以只使用 rdb；\n * 如果只用 aof，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。\n\n\n# 3. 总结\n\n通过上面的介绍，了解到 rdb 和 aof 都是通过 fork 子进程来完成的，是为了不会造成主线程的阻塞，但是也并不能完全避免，所以我们需要尽可能的降低 fork 的频率。\n\n并且都使用了操作系统的 cow 机制，该机制可以大大的减少 cpu 与内存的消耗，我们在很多组件中会发现它们都用到了 linux 的一些好用的机制，像 kafka 用到的零拷贝和 pagecache 等等。我们在设计中需要善用这些机制，可以非常大的优化程序的性能，并且简化我们需要做的时候交给操作系统去完成，并且完成的比我们做的更好更稳定。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"redis之主从库同步",frontmatter:{title:"redis之主从库同步",date:"2022-12-01T15:18:20.000Z",permalink:"/pages/8072eb/",tags:["redis","数据库"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210806172905.png"},{name:"twitter:title",content:"redis之主从库同步"},{name:"twitter:description",content:"在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210806172905.png"},{name:"twitter:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/03.%20redis%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%90%8C%E6%AD%A5.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之主从库同步"},{property:"og:description",content:"在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210806172905.png"},{property:"og:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/03.%20redis%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%90%8C%E6%AD%A5.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-12-01T15:18:20.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之主从库同步"},{itemprop:"description",content:"在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210806172905.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/03.%20redis%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%BA%93%E5%90%8C%E6%AD%A5.html",relativePath:"03.中间件/05.redis/03. redis之主从库同步.md",key:"v-7a226c10",path:"/pages/8072eb/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 读写分离模式",slug:"_1-读写分离模式",normalizedTitle:"1. 读写分离模式",charIndex:110},{level:2,title:"2. 全量复制",slug:"_2-全量复制",normalizedTitle:"2. 全量复制",charIndex:314},{level:3,title:"2.1 主从库同步的过程",slug:"_2-1-主从库同步的过程",normalizedTitle:"2.1 主从库同步的过程",charIndex:326},{level:3,title:"2.2 如何减少主从同步时，对主库的压力?",slug:"_2-2-如何减少主从同步时-对主库的压力",normalizedTitle:"2.2 如何减少主从同步时，对主库的压力?",charIndex:692},{level:2,title:"3. 增量复制",slug:"_3-增量复制",normalizedTitle:"3. 增量复制",charIndex:905},{level:3,title:"3.1 增量复制的过程",slug:"_3-1-增量复制的过程",normalizedTitle:"3.1 增量复制的过程",charIndex:1106},{level:2,title:"4. 参考文章",slug:"_4-参考文章",normalizedTitle:"4. 参考文章",charIndex:1760}],headersStr:"0. 前言 1. 读写分离模式 2. 全量复制 2.1 主从库同步的过程 2.2 如何减少主从同步时，对主库的压力? 3. 增量复制 3.1 增量复制的过程 4. 参考文章",content:"# 0. 前言\n\n在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。\n\n\n# 1. 读写分离模式\n\n通过该模式构建多个数据副本，使用读写分离的方式\n\n * 读操作: 主从库都可以进行读取。\n * 写操作: 先写入到主库，在同步到从库。\n\n\n\n为什么要读写分离呢？\n\n如果从库也可以进行写操作，那么主从库在同一个 key 中存储的值可能会不一致，如果要保证一致性，需要通过加锁来解决，但这样会造成性能的损耗。\n\n但如果只有主库写入，在同步给从库，则能保证所有实例中数据的一致性。\n\n\n# 2. 全量复制\n\n\n# 2.1 主从库同步的过程\n\n第一阶段\n\n从库向主库发送psync命令进行数据同步，该命令包含主库的runID和复制进度offset\n\n * runID，每个实例自动生成的随机 ID，第一次从库不知道主库 runID，设置为?\n * offset，记录复制的进度，第一次进度设置为-1\n\n主库会回复 runID 和 offset 给从库\n\n第二阶段\n\n主从第一次同步是采用全量复制的方式，主库生成 RDB 文件，然后发送给从库，从库清空当前数据再读入 RDB 文件完成第一次同步。\n\n在生成 RDB 文件时，还是会有新的操作的会进行，为了保持数据的一致性，会将新的操作记录到 replication buffer 中。\n\n第三阶段\n\nRDB 文件发送到从库后，再 replication buffer 中的操作再发送给从库。\n\n\n# 2.2 如何减少主从同步时，对主库的压力?\n\n主从同步有哪些压力？\n\n * 生成 RDB，这个操作会 fork 子进程，会阻塞主线程的正常请求。\n * 传输 RDB，会占用主库的网络带宽\n\n主-从-从模式\n\n可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。由从库生成 RDB 再传输给从库，减少了主库的压力。\n\n在主库全量复制之后，会维护一个长连接，后需的操作命令通过该连接同步给从库\n\n\n\n\n# 3. 增量复制\n\n全量复制是通过生成 RDB 发送到从库然后进行读取后进行同步。我们知道生成 RDB 本身就是一个消耗 CPU 的操作，并且存在阻塞主线程的风险，所以我们需要尽量少的执行全量复制的操作。\n\n所以在第一次使用 RDB 全量复制后，主从库会建立一个长连接，主库收到的新命令会再同步到从库，这样就避免频繁全量复制。\n\n但是有一个风险点是，如果过程发生了网络中断或者阻塞，该如何解决？\n\n\n# 3.1 增量复制的过程\n\n当主从连接时，会将新的操作的命令写入 replication buffer 和 repl_backlog_buffer 缓冲区中\n\nrepl_backlog_buffer 是一个环形缓冲区，主库会记录当前的偏移量 master_repl_offset，记录自己写到的位置，而从库在上面也有对应的偏移量 slave_repl_offset，记录自己正在读到的偏移量。\n\n在恢复连接时，从库会通过 psync 命令将自己的偏移量 slave_repl_offset 发送给主库，主库会将 slave_repl_offset 和 master_repl_offset 之间的命令同步给从库即可。\n\n\n\n举了例子： 主库和从库之间相差了 put d e 和 put d f 两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。\n\n因为 replication buffer 是一个环形的缓存，当主从库长期断开时，是有可能被覆盖掉旧的数据，这个时候是会重新发起全量复制，主库根据从库发送的 slave_repl_offset 来判断是增量还是全量的复制。\n\n那为什么全量复制使用 RDB 而不是使用 AOF 呢？\n\n * RDB 文件是经过压缩的二进制文件，AOF 文件是记录每一次的操作，包含对同一个 key 的多次冗余操作，文件比 RDB 要大的多，使用 AOF 可以减少带宽\n * RDB 是二进制数据，从库还原速度快。而 AOF 需要依次重放每一个命令，恢复速度慢。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",normalizedContent:"# 0. 前言\n\n在单点故障后，我们需要保证服务不间断，所以需要使用冗余的副本提供集群服务，从而达到服务的高可用。redis 提供了主从库数据同步机制，从而保证数据副本的一致性，而主从库使用的是读写分离的机制。\n\n\n# 1. 读写分离模式\n\n通过该模式构建多个数据副本，使用读写分离的方式\n\n * 读操作: 主从库都可以进行读取。\n * 写操作: 先写入到主库，在同步到从库。\n\n\n\n为什么要读写分离呢？\n\n如果从库也可以进行写操作，那么主从库在同一个 key 中存储的值可能会不一致，如果要保证一致性，需要通过加锁来解决，但这样会造成性能的损耗。\n\n但如果只有主库写入，在同步给从库，则能保证所有实例中数据的一致性。\n\n\n# 2. 全量复制\n\n\n# 2.1 主从库同步的过程\n\n第一阶段\n\n从库向主库发送psync命令进行数据同步，该命令包含主库的runid和复制进度offset\n\n * runid，每个实例自动生成的随机 id，第一次从库不知道主库 runid，设置为?\n * offset，记录复制的进度，第一次进度设置为-1\n\n主库会回复 runid 和 offset 给从库\n\n第二阶段\n\n主从第一次同步是采用全量复制的方式，主库生成 rdb 文件，然后发送给从库，从库清空当前数据再读入 rdb 文件完成第一次同步。\n\n在生成 rdb 文件时，还是会有新的操作的会进行，为了保持数据的一致性，会将新的操作记录到 replication buffer 中。\n\n第三阶段\n\nrdb 文件发送到从库后，再 replication buffer 中的操作再发送给从库。\n\n\n# 2.2 如何减少主从同步时，对主库的压力?\n\n主从同步有哪些压力？\n\n * 生成 rdb，这个操作会 fork 子进程，会阻塞主线程的正常请求。\n * 传输 rdb，会占用主库的网络带宽\n\n主-从-从模式\n\n可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。由从库生成 rdb 再传输给从库，减少了主库的压力。\n\n在主库全量复制之后，会维护一个长连接，后需的操作命令通过该连接同步给从库\n\n\n\n\n# 3. 增量复制\n\n全量复制是通过生成 rdb 发送到从库然后进行读取后进行同步。我们知道生成 rdb 本身就是一个消耗 cpu 的操作，并且存在阻塞主线程的风险，所以我们需要尽量少的执行全量复制的操作。\n\n所以在第一次使用 rdb 全量复制后，主从库会建立一个长连接，主库收到的新命令会再同步到从库，这样就避免频繁全量复制。\n\n但是有一个风险点是，如果过程发生了网络中断或者阻塞，该如何解决？\n\n\n# 3.1 增量复制的过程\n\n当主从连接时，会将新的操作的命令写入 replication buffer 和 repl_backlog_buffer 缓冲区中\n\nrepl_backlog_buffer 是一个环形缓冲区，主库会记录当前的偏移量 master_repl_offset，记录自己写到的位置，而从库在上面也有对应的偏移量 slave_repl_offset，记录自己正在读到的偏移量。\n\n在恢复连接时，从库会通过 psync 命令将自己的偏移量 slave_repl_offset 发送给主库，主库会将 slave_repl_offset 和 master_repl_offset 之间的命令同步给从库即可。\n\n\n\n举了例子： 主库和从库之间相差了 put d e 和 put d f 两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。\n\n因为 replication buffer 是一个环形的缓存，当主从库长期断开时，是有可能被覆盖掉旧的数据，这个时候是会重新发起全量复制，主库根据从库发送的 slave_repl_offset 来判断是增量还是全量的复制。\n\n那为什么全量复制使用 rdb 而不是使用 aof 呢？\n\n * rdb 文件是经过压缩的二进制文件，aof 文件是记录每一次的操作，包含对同一个 key 的多次冗余操作，文件比 rdb 要大的多，使用 aof 可以减少带宽\n * rdb 是二进制数据，从库还原速度快。而 aof 需要依次重放每一个命令，恢复速度慢。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"redis之哨兵机制",frontmatter:{title:"redis之哨兵机制",date:"2022-12-01T15:18:35.000Z",permalink:"/pages/ffee9e/",tags:["redis","数据库"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文主要介绍的是 Redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210807101732.png"},{name:"twitter:title",content:"redis之哨兵机制"},{name:"twitter:description",content:"本文主要介绍的是 Redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210807101732.png"},{name:"twitter:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/04.%20redis%E4%B9%8B%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之哨兵机制"},{property:"og:description",content:"本文主要介绍的是 Redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210807101732.png"},{property:"og:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/04.%20redis%E4%B9%8B%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-12-01T15:18:35.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之哨兵机制"},{itemprop:"description",content:"本文主要介绍的是 Redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210807101732.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/04.%20redis%E4%B9%8B%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6.html",relativePath:"03.中间件/05.redis/04. redis之哨兵机制.md",key:"v-97fa14a4",path:"/pages/ffee9e/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 哨兵如何保证高可用？",slug:"_1-哨兵如何保证高可用",normalizedTitle:"1. 哨兵如何保证高可用？",charIndex:140},{level:3,title:"1.1 监控",slug:"_1-1-监控",normalizedTitle:"1.1 监控",charIndex:158},{level:3,title:"1.2 选择新主库",slug:"_1-2-选择新主库",normalizedTitle:"1.2 选择新主库",charIndex:297},{level:3,title:"1.3 通知",slug:"_1-3-通知",normalizedTitle:"1.3 通知",charIndex:457},{level:2,title:"2. 哨兵集群的组建",slug:"_2-哨兵集群的组建",normalizedTitle:"2. 哨兵集群的组建",charIndex:562},{level:3,title:"2.1 哨兵与从库建立连接",slug:"_2-1-哨兵与从库建立连接",normalizedTitle:"2.1 哨兵与从库建立连接",charIndex:748},{level:3,title:"2.2 哨兵与客户端建立连接",slug:"_2-2-哨兵与客户端建立连接",normalizedTitle:"2.2 哨兵与客户端建立连接",charIndex:868},{level:2,title:"3. 由哪个哨兵来执行主从切换 ？",slug:"_3-由哪个哨兵来执行主从切换",normalizedTitle:"3. 由哪个哨兵来执行主从切换 ？",charIndex:1019},{level:2,title:"4. 参考文章",slug:"_4-参考文章",normalizedTitle:"4. 参考文章",charIndex:1248}],headersStr:"0. 前言 1. 哨兵如何保证高可用？ 1.1 监控 1.2 选择新主库 1.3 通知 2. 哨兵集群的组建 2.1 哨兵与从库建立连接 2.2 哨兵与客户端建立连接 3. 由哪个哨兵来执行主从切换 ？ 4. 参考文章",content:'# 0. 前言\n\n我们知道，只有主库才能有写操作，而从库只能进行读操作，那么当主库宕机后，如何保证服务的正常进行呢？\n\n本文主要介绍的是 Redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。\n\n\n# 1. 哨兵如何保证高可用？\n\n\n# 1.1 监控\n\n哨兵进程会发送 PING 命令给主从库检测网络连接，如果超时，则判断为"主观下线"。\n\n但是如果哨兵误判可能会导致主从切换，导致性能的额外开销，所以引入了哨兵集群，只有多数哨兵认为主库已经主观下线，主库会被标记为"客观下线"，这时才会进行主从切换。\n\n\n\n\n# 1.2 选择新主库\n\n通过一定的筛选条件，把不符合条件的从库去掉，再按照一定规则给从库打分，得分最高的为新主库\n\n\n\n筛选条件：\n\n * 当前从库的状态\n * 之前一段时间的网络状态\n\n打分规则：\n\n * 用户可以给从库 slave-priority 配置优先级\n * 主从库同步程度\n * ID 号小的得分高\n\n\n# 1.3 通知\n\n哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。\n\n\n# 2. 哨兵集群的组建\n\n哨兵实例之间互相发现是基于 Redis 提供的 pub/sub 机制，发布/订阅机制。\n\n哨兵只要与主库建立连接，会在主库 __sentinel__:hello 频道上发布消息，比如自己的 ip 地址和端口信息，订阅了该频道的其他哨兵会获取到发布消息哨兵的 IP 和端口，即可以与其建立网络连接，之后相互间就可以通过网络连接进行通信。\n\n\n\n\n# 2.1 哨兵与从库建立连接\n\n哨兵还需要和从库建立连接，这样才能监控从库的连接状态，当主库下线后，才能从它们中选举出新的主库。\n\n哨兵使用 INFO 命令发送给主库，主库会返回从库列表连接信息，这样也能和从库建立连接并进行监控\n\n\n\n\n# 2.2 哨兵与客户端建立连接\n\n当主库下线后，客户端需要得知主库下线的消息，写操作需要切换到新的主库中，所以哨兵需要与客户端建立连接，并及时通知客户端。\n\n客户端可以从哨兵订阅消息，获取到主从切换的各种事件。\n\n客户端读取哨兵的配置文件，获取哨兵的地址和端口，建立连接，然后即可订阅消息。\n\n\n\n\n# 3. 由哪个哨兵来执行主从切换 ？\n\n任何一个哨兵判断主库 主观下线 就会向其他哨兵发送 is-master-down-by-addr 命令。其他实例会更具自己与主库的连接情况投出赞成票或反对票。当多数哨兵投赞成票时，则主库被认为 客观下线。\n\n此时，该哨兵再发命令给其他哨兵进行 leader选举，希望由自己来进行主从切换。在这个过程中，任何一个哨兵都可以参与选举，只要票数半数以上并且大于等于 quorum 值，则可以成为 leader\n\n\n\n\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来',normalizedContent:'# 0. 前言\n\n我们知道，只有主库才能有写操作，而从库只能进行读操作，那么当主库宕机后，如何保证服务的正常进行呢？\n\n本文主要介绍的是 redis 提供的哨兵机制，通过哨兵监控主库的状况，如果发现主库下线，则会从从库中选择一个状态优秀的当做主库，从而保证服务的高可用。\n\n\n# 1. 哨兵如何保证高可用？\n\n\n# 1.1 监控\n\n哨兵进程会发送 ping 命令给主从库检测网络连接，如果超时，则判断为"主观下线"。\n\n但是如果哨兵误判可能会导致主从切换，导致性能的额外开销，所以引入了哨兵集群，只有多数哨兵认为主库已经主观下线，主库会被标记为"客观下线"，这时才会进行主从切换。\n\n\n\n\n# 1.2 选择新主库\n\n通过一定的筛选条件，把不符合条件的从库去掉，再按照一定规则给从库打分，得分最高的为新主库\n\n\n\n筛选条件：\n\n * 当前从库的状态\n * 之前一段时间的网络状态\n\n打分规则：\n\n * 用户可以给从库 slave-priority 配置优先级\n * 主从库同步程度\n * id 号小的得分高\n\n\n# 1.3 通知\n\n哨兵会把新主库的连接信息发给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。\n\n\n# 2. 哨兵集群的组建\n\n哨兵实例之间互相发现是基于 redis 提供的 pub/sub 机制，发布/订阅机制。\n\n哨兵只要与主库建立连接，会在主库 __sentinel__:hello 频道上发布消息，比如自己的 ip 地址和端口信息，订阅了该频道的其他哨兵会获取到发布消息哨兵的 ip 和端口，即可以与其建立网络连接，之后相互间就可以通过网络连接进行通信。\n\n\n\n\n# 2.1 哨兵与从库建立连接\n\n哨兵还需要和从库建立连接，这样才能监控从库的连接状态，当主库下线后，才能从它们中选举出新的主库。\n\n哨兵使用 info 命令发送给主库，主库会返回从库列表连接信息，这样也能和从库建立连接并进行监控\n\n\n\n\n# 2.2 哨兵与客户端建立连接\n\n当主库下线后，客户端需要得知主库下线的消息，写操作需要切换到新的主库中，所以哨兵需要与客户端建立连接，并及时通知客户端。\n\n客户端可以从哨兵订阅消息，获取到主从切换的各种事件。\n\n客户端读取哨兵的配置文件，获取哨兵的地址和端口，建立连接，然后即可订阅消息。\n\n\n\n\n# 3. 由哪个哨兵来执行主从切换 ？\n\n任何一个哨兵判断主库 主观下线 就会向其他哨兵发送 is-master-down-by-addr 命令。其他实例会更具自己与主库的连接情况投出赞成票或反对票。当多数哨兵投赞成票时，则主库被认为 客观下线。\n\n此时，该哨兵再发命令给其他哨兵进行 leader选举，希望由自己来进行主从切换。在这个过程中，任何一个哨兵都可以参与选举，只要票数半数以上并且大于等于 quorum 值，则可以成为 leader\n\n\n\n\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来',charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"redis之分片集群",frontmatter:{title:"redis之分片集群",date:"2022-12-01T15:18:45.000Z",permalink:"/pages/1c2914/",tags:["redis","数据库"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210808133416.png"},{name:"twitter:title",content:"redis之分片集群"},{name:"twitter:description",content:"在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210808133416.png"},{name:"twitter:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/05.%20redis%E4%B9%8B%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之分片集群"},{property:"og:description",content:"在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210808133416.png"},{property:"og:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/05.%20redis%E4%B9%8B%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-12-01T15:18:45.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之分片集群"},{itemprop:"description",content:"在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20210808133416.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/05.%20redis%E4%B9%8B%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4.html",relativePath:"03.中间件/05.redis/05. redis之分片集群.md",key:"v-8855b59c",path:"/pages/1c2914/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 分片集群是什么？",slug:"_1-分片集群是什么",normalizedTitle:"1. 分片集群是什么？",charIndex:81},{level:2,title:"2. 分片集群的组建",slug:"_2-分片集群的组建",normalizedTitle:"2. 分片集群的组建",charIndex:279},{level:2,title:"3. 客户端如何读取分片集群",slug:"_3-客户端如何读取分片集群",normalizedTitle:"3. 客户端如何读取分片集群",charIndex:587},{level:2,title:"4. 参考文章",slug:"_4-参考文章",normalizedTitle:"4. 参考文章",charIndex:1418}],headersStr:"0. 前言 1. 分片集群是什么？ 2. 分片集群的组建 3. 客户端如何读取分片集群 4. 参考文章",content:"# 0. 前言\n\n在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。\n\n\n# 1. 分片集群是什么？\n\n分片集群主要是将 redis 的数据划分成多份，每一份都由一个实例来保存，然后由多个实例来组成一个一个集群。\n\n为什么使用分片集群而不是增加内存？\n\n * 在 RDB 进行持久化时，会 fork 子进程来完成，fork 操作会阻塞主线程的时长与数据量成正比。\n * 硬件成本，把内存从 32GB 扩展到 64GB 还算容易，但是，要想扩充到 1TB，成本太高。\n\n\n# 2. 分片集群的组建\n\n在 Redis Cluster 方案中，一个切片集群有 16384 个哈希槽，每个键值对的 key 会进行计算并对 16384 取模，分配到一个对应编号的哈希槽。\n\n在使用 cluster create 命令创建集群时，会自动将 16384 个槽平均分配到集群实例中。也可以通过 cluster meet 命令手动建立实例间的连接形成集群，再使用 cluster addslots 命令指定每个实例上的哈希槽的个数。\n\n在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。\n\n数据分配到哪个实例?\n\n数据根据分配到哈希槽编号写入到对应的实例中。\n\n\n# 3. 客户端如何读取分片集群\n\n客户端从哪个实例中读取数据？\n\n客户端与集群建立连接后，实例会将哈希槽的分配信息发送给客户端。客户端将哈希槽信息缓存在本地，当客户端操作键值对时，先计算得到对应的哈希槽，再发送请求到相应的实例。\n\n但哈希槽与实例的映射关系并不是一成不变的，可能会发生变化：\n\n * 集群中，实例有新增或删除，redis 会重新分配哈希槽\n * 为了负载均衡，redis 会将哈希槽在所有实例中重新分布。\n\n当映射关系变化时，客户端如何感知？\n\n重定向机制。客户端发送数据给一个实例，但是并没有这个键值对的哈希槽信息，则实例会发送 MOVED 命令结果给客户端，包含新实例的访问地址。客户端更新本地缓存实例与哈希槽的映射关系，并向新实例发送请求。\n\nGET hello:key\n(error) MOVED 13320 172.16.19.5:6379\n\n\n1\n2\n\n\n客户端请求的哈希槽 13320 在 172.16.19.5 这个实例上\n\n\n\n如果访问的数据正在迁移的哈希槽，该如何访问数据?\n\nSlot 2 正在从实例 2 往实例 3 迁移，key1 和 key2 已经迁移过去，key3 和 key4 还在实例 2。客户端向实例 2 请求 key2 后，就会收到实例 2 返回的 ASK 命令。\n\nASK 命令表示两层含义：第一，表明 Slot 数据还在迁移中；第二，ASK 命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 ASKING 命令，然后再发送操作命令。\n\n和 MOVED 命令不同，ASK 命令并不会更新客户端缓存的哈希槽分配信息。\n\nASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例。\n\n\n\n客户端为什么可以在任意一个实例获取所有的哈希槽信息？\n\nredis 实例之间也会建立连接，分享自己的哈希槽信息。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",normalizedContent:"# 0. 前言\n\n在海量的数据面前，单个 redis 实例的能力是有限的，无可能无限增大的内存，所以必须要构建分片集群，来横向拓展来支持保存更多的数据。\n\n\n# 1. 分片集群是什么？\n\n分片集群主要是将 redis 的数据划分成多份，每一份都由一个实例来保存，然后由多个实例来组成一个一个集群。\n\n为什么使用分片集群而不是增加内存？\n\n * 在 rdb 进行持久化时，会 fork 子进程来完成，fork 操作会阻塞主线程的时长与数据量成正比。\n * 硬件成本，把内存从 32gb 扩展到 64gb 还算容易，但是，要想扩充到 1tb，成本太高。\n\n\n# 2. 分片集群的组建\n\n在 redis cluster 方案中，一个切片集群有 16384 个哈希槽，每个键值对的 key 会进行计算并对 16384 取模，分配到一个对应编号的哈希槽。\n\n在使用 cluster create 命令创建集群时，会自动将 16384 个槽平均分配到集群实例中。也可以通过 cluster meet 命令手动建立实例间的连接形成集群，再使用 cluster addslots 命令指定每个实例上的哈希槽的个数。\n\n在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 redis 集群无法正常工作。\n\n数据分配到哪个实例?\n\n数据根据分配到哈希槽编号写入到对应的实例中。\n\n\n# 3. 客户端如何读取分片集群\n\n客户端从哪个实例中读取数据？\n\n客户端与集群建立连接后，实例会将哈希槽的分配信息发送给客户端。客户端将哈希槽信息缓存在本地，当客户端操作键值对时，先计算得到对应的哈希槽，再发送请求到相应的实例。\n\n但哈希槽与实例的映射关系并不是一成不变的，可能会发生变化：\n\n * 集群中，实例有新增或删除，redis 会重新分配哈希槽\n * 为了负载均衡，redis 会将哈希槽在所有实例中重新分布。\n\n当映射关系变化时，客户端如何感知？\n\n重定向机制。客户端发送数据给一个实例，但是并没有这个键值对的哈希槽信息，则实例会发送 moved 命令结果给客户端，包含新实例的访问地址。客户端更新本地缓存实例与哈希槽的映射关系，并向新实例发送请求。\n\nget hello:key\n(error) moved 13320 172.16.19.5:6379\n\n\n1\n2\n\n\n客户端请求的哈希槽 13320 在 172.16.19.5 这个实例上\n\n\n\n如果访问的数据正在迁移的哈希槽，该如何访问数据?\n\nslot 2 正在从实例 2 往实例 3 迁移，key1 和 key2 已经迁移过去，key3 和 key4 还在实例 2。客户端向实例 2 请求 key2 后，就会收到实例 2 返回的 ask 命令。\n\nask 命令表示两层含义：第一，表明 slot 数据还在迁移中；第二，ask 命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 asking 命令，然后再发送操作命令。\n\n和 moved 命令不同，ask 命令并不会更新客户端缓存的哈希槽分配信息。\n\nask 命令的作用只是让客户端能给新实例发送一次请求，而不像 moved 命令那样，会更改本地缓存，让后续所有命令都发往新实例。\n\n\n\n客户端为什么可以在任意一个实例获取所有的哈希槽信息？\n\nredis 实例之间也会建立连接，分享自己的哈希槽信息。\n\n\n# 4. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"redis之缓存",frontmatter:{title:"redis之缓存",date:"2022-12-01T15:18:55.000Z",permalink:"/pages/0d7b25/",tags:["redis","数据库"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"reids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。",feed:{enable:!0},categories:["数据库","redis"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16698736280551669873627898.png"},{name:"twitter:title",content:"redis之缓存"},{name:"twitter:description",content:"reids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16698736280551669873627898.png"},{name:"twitter:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/06.%20redis%E4%B9%8B%E7%BC%93%E5%AD%98.html"},{property:"og:type",content:"article"},{property:"og:title",content:"redis之缓存"},{property:"og:description",content:"reids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16698736280551669873627898.png"},{property:"og:url",content:"https://www.msqfx.cc/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/06.%20redis%E4%B9%8B%E7%BC%93%E5%AD%98.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-12-01T15:18:55.000Z"},{property:"article:tag",content:"redis"},{property:"article:tag",content:"数据库"},{itemprop:"name",content:"redis之缓存"},{itemprop:"description",content:"reids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/16698736280551669873627898.png"}],readingShow:"top"},regularPath:"/03.%E4%B8%AD%E9%97%B4%E4%BB%B6/05.redis/06.%20redis%E4%B9%8B%E7%BC%93%E5%AD%98.html",relativePath:"03.中间件/05.redis/06. redis之缓存.md",key:"v-3dc84304",path:"/pages/0d7b25/",headers:[{level:2,title:"1. 前言",slug:"_1-前言",normalizedTitle:"1. 前言",charIndex:2},{level:2,title:"2. 缓存类型",slug:"_2-缓存类型",normalizedTitle:"2. 缓存类型",charIndex:83},{level:3,title:"2.1 只读缓存",slug:"_2-1-只读缓存",normalizedTitle:"2.1 只读缓存",charIndex:95},{level:3,title:"2.2 读写缓存",slug:"_2-2-读写缓存",normalizedTitle:"2.2 读写缓存",charIndex:250},{level:2,title:"2. 缓存和数据库的数据一致性",slug:"_2-缓存和数据库的数据一致性",normalizedTitle:"2. 缓存和数据库的数据一致性",charIndex:468},{level:3,title:"2.1 哪些情况会导致数据不一致 ？",slug:"_2-1-哪些情况会导致数据不一致",normalizedTitle:"2.1 哪些情况会导致数据不一致 ？",charIndex:488},{level:3,title:"2.3 队列+重试机制",slug:"_2-3-队列-重试机制",normalizedTitle:"2.3 队列+重试机制",charIndex:738},{level:2,title:"3. 淘汰策略",slug:"_3-淘汰策略",normalizedTitle:"3. 淘汰策略",charIndex:1364},{level:2,title:"4. 缓存雪崩",slug:"_4-缓存雪崩",normalizedTitle:"4. 缓存雪崩",charIndex:1896},{level:2,title:"5. 缓存击穿",slug:"_5-缓存击穿",normalizedTitle:"5. 缓存击穿",charIndex:2234},{level:2,title:"6. 缓存穿透",slug:"_6-缓存穿透",normalizedTitle:"6. 缓存穿透",charIndex:2445},{level:2,title:"7. 参考文章",slug:"_7-参考文章",normalizedTitle:"7. 参考文章",charIndex:2741}],headersStr:"1. 前言 2. 缓存类型 2.1 只读缓存 2.2 读写缓存 2. 缓存和数据库的数据一致性 2.1 哪些情况会导致数据不一致 ？ 2.3 队列+重试机制 3. 淘汰策略 4. 缓存雪崩 5. 缓存击穿 6. 缓存穿透 7. 参考文章",content:"# 1. 前言\n\nreids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。\n\n\n# 2. 缓存类型\n\n\n# 2.1 只读缓存\n\n当写入数据时，直接操作后端数据库，进行增删改。删和改操作，如果 redis 已经缓存了对应的数据，则需要进行删除。当应用读取数据时，发生缓存缺失，则会从后端数据库读取到 redis 中使用。\n\n\n\n好处是所有的数据都在后端数据库中，而后端数据提供可靠性保障，不会有丢失数据的风险。\n\n\n# 2.2 读写缓存\n\n最新的数据在 redis 中。在写入数据时，优先写入到 redis，并且因为缓存的高性能访问，可以快速返回给业务应用。\n\n但是由于 redis 是内存数据库存在数据丢失的风险，所以还是需要写入到后端数据库中保证可靠性。有两种写入策略：\n\n * 同步直写：在写 redis 时，同步写入到后端数据库，完成后再返回给业务。会增加响应延迟。\n * 异步直写：等待增改的数据要被从缓存淘汰时。再写回后端数据库。\n\n\n\n\n# 2. 缓存和数据库的数据一致性\n\n\n# 2.1 哪些情况会导致数据不一致 ？\n\n * 我们假设应用先删除缓存，再更新数据库，如果缓存删除成功，但是数据库更新失败，那么，应用再访问数据时，缓存中没有数据，就会发生缓存缺失。然后，应用再访问数据库，但是数据库中的值为旧值，应用就访问到旧值了。\n\n * 如果应用先完成了数据库的更新，但是，在删除缓存时失败了，那么，数据库中的值是新值，而缓存中的是旧值，这肯定是不一致的。这个时候，如果有其他的并发请求来访问数据，按照正常的缓存访问流程，就会先在缓存中查询，但此时，就会读到旧值了。\n\n\n\n\n# 2.3 队列+重试机制\n\n可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 Kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。\n\n如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作\n\n但是在并发情况下，无论是先删数据库还是先删缓存操作失败的情况下，还是会有读取到不一致数据的情况。\n\n * 情况一，先删除缓存，再更新数据库。\n\n在更新数据库失败的情况下，另一个线程进来读取数据，发现缓存缺失，查询数据库的数据，并更新到缓存中，最终缓存中存储的是旧的数据。\n\n延迟双删\n\n在线程 A 更新完数据库的值以后，再让它 sleep 一会儿，再删除缓存。目的是为了让线程 B 可以将数据库的值写入到缓存中，然后再删除它。 伪代码如下：\n\nredis.delKey(X)\ndb.update(X)\nThread.sleep(N)\nredis.delKey(X)\n\n\n1\n2\n3\n4\n\n\n网上有使用这种方案来解决，个人是不推荐这种方案，在高并发的情况下，这个 sleep 时间不好确定，并不知道其他线程什么时候执行和结束。\n\n * 情况二，先更新数据库值，再删除缓存值。\n\n在删除缓存值失败的情况下，并发时，会有多个线程拿到旧的数据情况。\n\n这两种并发场景，个人感觉唯一的办法就是使用同步来完成这两个操作，可以使用分布式锁或者其他。\n\n\n# 3. 淘汰策略\n\n缓存的容量是有限的，那么当缓存满了，可以是用淘汰策略来将部分数据淘汰。\n\n缓存设置成多大比较合适？ 按照二八原理，一般 20%数据会占用 80%的访问，所以建议将缓存的容量设置为总数据量的 15%或者 30%会比较合理。\n\n淘汰策略有哪些?\n\n * 不淘汰\n   * noeviction，如果缓存已满再有写请求，则返回错误\n * 对设置过期时间的数据进行淘汰\n   * volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。\n   * volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。\n   * volatile-lru 会使用 LRU 算法筛选设置了过期时间的键值对。\n   * volatile-lfu 会使用 LFU 算法选择设置了过期时间的键值对。\n * 对所有数据进行淘汰\n   * allkeys-random 策略，从所有键值对中随机选择并删除数据；\n   * allkeys-lru 策略，使用 LRU 算法在所有数据中进行筛选。\n   * allkeys-lfu 策略，使用 LFU 算法在所有数据中进行筛选。\n\n\n# 4. 缓存雪崩\n\n缓存雪崩是指大量的应用请求无法在 Redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。\n\n产生的原因\n\n * 缓存中有大量数据同时过期，导致大量请求无法得到处理\n * redis服务宕机\n\n发生后有损解决办法\n\n 1. 是在业务系统中实现服务熔断或请求限流机制。\n\n\n\n 2. 服务降级。非核心数据，直接返回预定义信息，错误或空值。核心业务仍然查询缓存。减少数据库压力\n\n提前预防\n\n上面的都是发生后有损的解决措施，所以最好的办法是提前预防，让它不要发生。\n\n 1. 避免大量数据设置相同点额过期时间，如果有，可以加个随机数。\n 2. 搭建高可用集群，主节点故障宕机，从节点可以切换成主节点，继续提供缓存服务。\n\n\n# 5. 缓存击穿\n\n缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时\n\n\n\n产生的原因\n\n * 热点数据发生过期被淘汰导致访问后端数据库\n\n发生后有损的解决办法\n\n * 接口限流与熔断，降级。\n\n提前预防\n\n * 设置热点数据永远不过期。\n\n\n# 6. 缓存穿透\n\n缓存穿透是指要访问的数据既不在 Redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。\n\n产生的原因\n\n * 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；\n * 恶意攻击：专门访问数据库中没有的数据。\n\n\n\n应对方案\n\n * 在请求入口做合法性校验，把恶意请求过滤掉。\n * 布隆过滤器，快速校验数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。\n * 一旦发生数据不存在的情况，可以缓存一个缺省值，下次还使用该 ID 访问时，可以返回缺省值。\n\n\n# 7. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",normalizedContent:"# 1. 前言\n\nreids 是基于内存的数据库，它的特性之一就快，缓存是其最主要的应用场景，本文主要介绍 redis 的缓存特性，以及该如何正确的使用它。\n\n\n# 2. 缓存类型\n\n\n# 2.1 只读缓存\n\n当写入数据时，直接操作后端数据库，进行增删改。删和改操作，如果 redis 已经缓存了对应的数据，则需要进行删除。当应用读取数据时，发生缓存缺失，则会从后端数据库读取到 redis 中使用。\n\n\n\n好处是所有的数据都在后端数据库中，而后端数据提供可靠性保障，不会有丢失数据的风险。\n\n\n# 2.2 读写缓存\n\n最新的数据在 redis 中。在写入数据时，优先写入到 redis，并且因为缓存的高性能访问，可以快速返回给业务应用。\n\n但是由于 redis 是内存数据库存在数据丢失的风险，所以还是需要写入到后端数据库中保证可靠性。有两种写入策略：\n\n * 同步直写：在写 redis 时，同步写入到后端数据库，完成后再返回给业务。会增加响应延迟。\n * 异步直写：等待增改的数据要被从缓存淘汰时。再写回后端数据库。\n\n\n\n\n# 2. 缓存和数据库的数据一致性\n\n\n# 2.1 哪些情况会导致数据不一致 ？\n\n * 我们假设应用先删除缓存，再更新数据库，如果缓存删除成功，但是数据库更新失败，那么，应用再访问数据时，缓存中没有数据，就会发生缓存缺失。然后，应用再访问数据库，但是数据库中的值为旧值，应用就访问到旧值了。\n\n * 如果应用先完成了数据库的更新，但是，在删除缓存时失败了，那么，数据库中的值是新值，而缓存中的是旧值，这肯定是不一致的。这个时候，如果有其他的并发请求来访问数据，按照正常的缓存访问流程，就会先在缓存中查询，但此时，就会读到旧值了。\n\n\n\n\n# 2.3 队列+重试机制\n\n可以把要删除的缓存值或者是要更新的数据库值暂存到消息队列中（例如使用 kafka 消息队列）。当应用没有能够成功地删除缓存值或者是更新数据库值时，可以从消息队列中重新读取这些值，然后再次进行删除或更新。\n\n如果能够成功地删除或更新，我们就要把这些值从消息队列中去除，以免重复操作\n\n但是在并发情况下，无论是先删数据库还是先删缓存操作失败的情况下，还是会有读取到不一致数据的情况。\n\n * 情况一，先删除缓存，再更新数据库。\n\n在更新数据库失败的情况下，另一个线程进来读取数据，发现缓存缺失，查询数据库的数据，并更新到缓存中，最终缓存中存储的是旧的数据。\n\n延迟双删\n\n在线程 a 更新完数据库的值以后，再让它 sleep 一会儿，再删除缓存。目的是为了让线程 b 可以将数据库的值写入到缓存中，然后再删除它。 伪代码如下：\n\nredis.delkey(x)\ndb.update(x)\nthread.sleep(n)\nredis.delkey(x)\n\n\n1\n2\n3\n4\n\n\n网上有使用这种方案来解决，个人是不推荐这种方案，在高并发的情况下，这个 sleep 时间不好确定，并不知道其他线程什么时候执行和结束。\n\n * 情况二，先更新数据库值，再删除缓存值。\n\n在删除缓存值失败的情况下，并发时，会有多个线程拿到旧的数据情况。\n\n这两种并发场景，个人感觉唯一的办法就是使用同步来完成这两个操作，可以使用分布式锁或者其他。\n\n\n# 3. 淘汰策略\n\n缓存的容量是有限的，那么当缓存满了，可以是用淘汰策略来将部分数据淘汰。\n\n缓存设置成多大比较合适？ 按照二八原理，一般 20%数据会占用 80%的访问，所以建议将缓存的容量设置为总数据量的 15%或者 30%会比较合理。\n\n淘汰策略有哪些?\n\n * 不淘汰\n   * noeviction，如果缓存已满再有写请求，则返回错误\n * 对设置过期时间的数据进行淘汰\n   * volatile-ttl 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。\n   * volatile-random 就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。\n   * volatile-lru 会使用 lru 算法筛选设置了过期时间的键值对。\n   * volatile-lfu 会使用 lfu 算法选择设置了过期时间的键值对。\n * 对所有数据进行淘汰\n   * allkeys-random 策略，从所有键值对中随机选择并删除数据；\n   * allkeys-lru 策略，使用 lru 算法在所有数据中进行筛选。\n   * allkeys-lfu 策略，使用 lfu 算法在所有数据中进行筛选。\n\n\n# 4. 缓存雪崩\n\n缓存雪崩是指大量的应用请求无法在 redis 缓存中进行处理，紧接着，应用将大量请求发送到数据库层，导致数据库层的压力激增。\n\n产生的原因\n\n * 缓存中有大量数据同时过期，导致大量请求无法得到处理\n * redis服务宕机\n\n发生后有损解决办法\n\n 1. 是在业务系统中实现服务熔断或请求限流机制。\n\n\n\n 2. 服务降级。非核心数据，直接返回预定义信息，错误或空值。核心业务仍然查询缓存。减少数据库压力\n\n提前预防\n\n上面的都是发生后有损的解决措施，所以最好的办法是提前预防，让它不要发生。\n\n 1. 避免大量数据设置相同点额过期时间，如果有，可以加个随机数。\n 2. 搭建高可用集群，主节点故障宕机，从节点可以切换成主节点，继续提供缓存服务。\n\n\n# 5. 缓存击穿\n\n缓存击穿是指，针对某个访问非常频繁的热点数据的请求，无法在缓存中进行处理，紧接着，访问该数据的大量请求，一下子都发送到了后端数据库，导致了数据库压力激增，会影响数据库处理其他请求。缓存击穿的情况，经常发生在热点数据过期失效时\n\n\n\n产生的原因\n\n * 热点数据发生过期被淘汰导致访问后端数据库\n\n发生后有损的解决办法\n\n * 接口限流与熔断，降级。\n\n提前预防\n\n * 设置热点数据永远不过期。\n\n\n# 6. 缓存穿透\n\n缓存穿透是指要访问的数据既不在 redis 缓存中，也不在数据库中，导致请求在访问缓存时，发生缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据。\n\n产生的原因\n\n * 业务层误操作：缓存中的数据和数据库中的数据被误删除了，所以缓存和数据库中都没有数据；\n * 恶意攻击：专门访问数据库中没有的数据。\n\n\n\n应对方案\n\n * 在请求入口做合法性校验，把恶意请求过滤掉。\n * 布隆过滤器，快速校验数据是否存在，避免从数据库中查询数据是否存在，减轻数据库压力。\n * 一旦发生数据不存在的情况，可以缓存一个缺省值，下次还使用该 id 访问时，可以返回缺省值。\n\n\n# 7. 参考文章\n\n * 本文主要是学习《极客时间-redis 核心技术与实战》专栏总结而来",charsets:{cjk:!0},lastUpdated:"2023/11/01, 11:48:43",lastUpdatedTimestamp:1698810523e3},{title:"python迭代器与生成器",frontmatter:{title:"python迭代器与生成器",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/e31b06/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文介绍了python的迭代器与生成器的用法与原理",feed:{enable:!0},tags:["python"],categories:["编程","python","基础"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604801659428.png#crop=0&crop=0&crop=1&crop=1&id=Wm3Ir&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:title",content:"python迭代器与生成器"},{name:"twitter:description",content:"本文介绍了python的迭代器与生成器的用法与原理"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604801659428.png#crop=0&crop=0&crop=1&crop=1&id=Wm3Ir&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/01.python%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python迭代器与生成器"},{property:"og:description",content:"本文介绍了python的迭代器与生成器的用法与原理"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604801659428.png#crop=0&crop=0&crop=1&crop=1&id=Wm3Ir&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/01.python%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python迭代器与生成器"},{itemprop:"description",content:"本文介绍了python的迭代器与生成器的用法与原理"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604801659428.png#crop=0&crop=0&crop=1&crop=1&id=Wm3Ir&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/01.python%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E7%94%9F%E6%88%90%E5%99%A8.html",relativePath:"04.编程/01.python/01.基础/01.python迭代器与生成器.md",key:"v-cee6b5d2",path:"/pages/e31b06/",headers:[{level:2,title:"迭代器和可迭代对象",slug:"迭代器和可迭代对象",normalizedTitle:"迭代器和可迭代对象",charIndex:2},{level:2,title:"如何实现迭代器？",slug:"如何实现迭代器",normalizedTitle:"如何实现迭代器？",charIndex:146},{level:2,title:"生成器和生成器函数",slug:"生成器和生成器函数",normalizedTitle:"生成器和生成器函数",charIndex:661},{level:3,title:"生成器函数创建生成器",slug:"生成器函数创建生成器",normalizedTitle:"生成器函数创建生成器",charIndex:698},{level:3,title:"生成器表达式创建生成器",slug:"生成器表达式创建生成器",normalizedTitle:"生成器表达式创建生成器",charIndex:1146}],headersStr:"迭代器和可迭代对象 如何实现迭代器？ 生成器和生成器函数 生成器函数创建生成器 生成器表达式创建生成器",content:'# 迭代器和可迭代对象\n\n实现了__iter__的对象是可迭代对象.\n\n实现了__iter__和__next__的是迭代器.\n\n两者之间的关系: Python从可迭代的对象中获取迭代器\n\n可迭代对象的抽象基类是abc.Iterable 迭代器的抽象基类是abc.Iterator\n\n\n\n\n# 如何实现迭代器？\n\n定义__iter__方法返回带有__next__方法的对象，__iter__可以简单的返回self.\n\n当没有数据返回时，会抛出StopIteration异常停止返回数据。\n\n\nclass MyIter():\n    def __init__(self, data):\n        self.data = data\n        self.index = len(data)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.index == 0:\n            raise StopIteration\n        \n        self.index = self.index - 1\n        return self.data[self.index]\n\nmy_iter = MyIter()\niter(my_iter)   # 返回一个迭代器\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n\n# 生成器和生成器函数\n\n函数中有yield关键字的，就是生成器函数\n\n\n# 生成器函数创建生成器\n\n下面的__iter__是一个生成器函数，通过该生成器函数创建生成器对象，包装生成器函数的定义。把生成器传给next(...)函数时，生成器函数会向前，执行函数定义体中的下一个yield语句，返回产出的值，并在函数定义体的当前位置暂停。当无数据返回时，生成器对象会抛出StopIteration异常。\n\n\n\n例子:\n\n\nimport re\nimport reprlib\n\nRE_WORD = re.compile("\\w+")\n\nclass Sentence:\n    def __init__(self, text):\n        self.text = text\n        \n    def __iter__(self):\n        for match in RE_WORD.finditer(self.text):\n            yield matc.group()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 生成器表达式创建生成器\n\n生成器表达式可以理解为列表推导的惰性版本: 不会迫切地构建列表，而是返回一个生成器，按需惰性生成元素。\n\n列表表达式。 会马上加载所有的元素到内存中\n\n[i for i in range(10)]\n\n\n1\n\n\n生成器表达式: 会得到一个生成器对象，可以通过next或者循环的方式惰性求值。\n\n(i for i in range(10))\n\n\n1\n\n\n虽然下面的__iter__没有yield关键字，但是却有具有生成器表达式，所以__iter__得到的也是一个生成器对象。\n\n例子:\n\nclass A:\n    def __iter__(self):\n        return (x*3 for x in range(10))\n\n\n1\n2\n3\n',normalizedContent:'# 迭代器和可迭代对象\n\n实现了__iter__的对象是可迭代对象.\n\n实现了__iter__和__next__的是迭代器.\n\n两者之间的关系: python从可迭代的对象中获取迭代器\n\n可迭代对象的抽象基类是abc.iterable 迭代器的抽象基类是abc.iterator\n\n\n\n\n# 如何实现迭代器？\n\n定义__iter__方法返回带有__next__方法的对象，__iter__可以简单的返回self.\n\n当没有数据返回时，会抛出stopiteration异常停止返回数据。\n\n\nclass myiter():\n    def __init__(self, data):\n        self.data = data\n        self.index = len(data)\n\n    def __iter__(self):\n        return self\n\n    def __next__(self):\n        if self.index == 0:\n            raise stopiteration\n        \n        self.index = self.index - 1\n        return self.data[self.index]\n\nmy_iter = myiter()\niter(my_iter)   # 返回一个迭代器\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n\n# 生成器和生成器函数\n\n函数中有yield关键字的，就是生成器函数\n\n\n# 生成器函数创建生成器\n\n下面的__iter__是一个生成器函数，通过该生成器函数创建生成器对象，包装生成器函数的定义。把生成器传给next(...)函数时，生成器函数会向前，执行函数定义体中的下一个yield语句，返回产出的值，并在函数定义体的当前位置暂停。当无数据返回时，生成器对象会抛出stopiteration异常。\n\n\n\n例子:\n\n\nimport re\nimport reprlib\n\nre_word = re.compile("\\w+")\n\nclass sentence:\n    def __init__(self, text):\n        self.text = text\n        \n    def __iter__(self):\n        for match in re_word.finditer(self.text):\n            yield matc.group()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 生成器表达式创建生成器\n\n生成器表达式可以理解为列表推导的惰性版本: 不会迫切地构建列表，而是返回一个生成器，按需惰性生成元素。\n\n列表表达式。 会马上加载所有的元素到内存中\n\n[i for i in range(10)]\n\n\n1\n\n\n生成器表达式: 会得到一个生成器对象，可以通过next或者循环的方式惰性求值。\n\n(i for i in range(10))\n\n\n1\n\n\n虽然下面的__iter__没有yield关键字，但是却有具有生成器表达式，所以__iter__得到的也是一个生成器对象。\n\n例子:\n\nclass a:\n    def __iter__(self):\n        return (x*3 for x in range(10))\n\n\n1\n2\n3\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"python垃圾回收机制",frontmatter:{title:"python垃圾回收机制",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/78c648/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"python的垃圾回收机制的几种方式：引用计数、标记清楚及分代回收，介绍他们的原理。",feed:{enable:!0},tags:["python"],categories:["编程","python","基础"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220907215650.png"},{name:"twitter:title",content:"python垃圾回收机制"},{name:"twitter:description",content:"python的垃圾回收机制的几种方式：引用计数、标记清楚及分代回收，介绍他们的原理。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220907215650.png"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/03.python%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python垃圾回收机制"},{property:"og:description",content:"python的垃圾回收机制的几种方式：引用计数、标记清楚及分代回收，介绍他们的原理。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220907215650.png"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/03.python%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python垃圾回收机制"},{itemprop:"description",content:"python的垃圾回收机制的几种方式：引用计数、标记清楚及分代回收，介绍他们的原理。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220907215650.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/03.python%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6.html",relativePath:"04.编程/01.python/01.基础/03.python垃圾回收机制.md",key:"v-5be0bc4c",path:"/pages/78c648/",headers:[{level:2,title:"引用计数",slug:"引用计数",normalizedTitle:"引用计数",charIndex:2},{level:2,title:"标记-清除",slug:"标记-清除",normalizedTitle:"标记-清除",charIndex:68},{level:2,title:"分代回收",slug:"分代回收",normalizedTitle:"分代回收",charIndex:428},{level:2,title:"垃圾回收触发情况",slug:"垃圾回收触发情况",normalizedTitle:"垃圾回收触发情况",charIndex:684}],headersStr:"引用计数 标记-清除 分代回收 垃圾回收触发情况",content:"# 引用计数\n\n每次对象被引用时，会被计数加1，当计数为0时，则回收该对象。\n\n注意： 循环引用的情况，引用计数不能解决.\n\n\n\n\n# 标记-清除\n\n对所有活跃的对象进行标记，对非活跃对象进行回收。可以有效的解决循环引用的问题\n\n原理 对象之间通过引用构建有向图，从root object(全局变量，寄存器等不可删除的对象)出发，沿着有向边遍历对象，可达的对象标记为活跃对象，不可达的对象就是要被清除的非活动对象。\n\n在下图中，从黑点开始出发，1对象可达，2、3间接可达，1、2、3是活跃对象，4,5不可达，所以是非活跃对象，进行回收。\n\n过程 找到root object集合, 在内存建立两条连表，一条链表维护root object集合，另一条链表哦维护剩下的对象，在标记的过程中，如果在不可达链表中存在被root链表中的独享，直接或间接引用独享，就将其从不可达链表移到root链表中。当完成标记后，不可达链表剩下的对象都是垃圾对象，进行回收。\n\n\n# 分代回收\n\n对象分在不同集合中，每个集合称为一个代, Python中分为3代，年轻代(第0代)、中年代(第1代)、老年代(第二代)，对应3各链表，每一代GC频率不同，第0代最高，第1代次之，第二代最低(越年轻的对象越容易死掉，而老的对象通常会存错更久)，新生的对象放入第0代，如果该对象在第0代的一次GC中存活，则移动到第1代，如果第一代对象在第1代GC中存错，则移动到第2代。\n\n什么情况触发GC， 可以设置阈值，也可以手动调用gc.collect()\n\n每次扫描全部对象，费时费力，提高GC的效率。\n\n\n# 垃圾回收触发情况\n\n调用gc.collect(),需要先导入gc模块。\n\n当gc模块的计数器达到阈值的时候。阈值可以设置",normalizedContent:"# 引用计数\n\n每次对象被引用时，会被计数加1，当计数为0时，则回收该对象。\n\n注意： 循环引用的情况，引用计数不能解决.\n\n\n\n\n# 标记-清除\n\n对所有活跃的对象进行标记，对非活跃对象进行回收。可以有效的解决循环引用的问题\n\n原理 对象之间通过引用构建有向图，从root object(全局变量，寄存器等不可删除的对象)出发，沿着有向边遍历对象，可达的对象标记为活跃对象，不可达的对象就是要被清除的非活动对象。\n\n在下图中，从黑点开始出发，1对象可达，2、3间接可达，1、2、3是活跃对象，4,5不可达，所以是非活跃对象，进行回收。\n\n过程 找到root object集合, 在内存建立两条连表，一条链表维护root object集合，另一条链表哦维护剩下的对象，在标记的过程中，如果在不可达链表中存在被root链表中的独享，直接或间接引用独享，就将其从不可达链表移到root链表中。当完成标记后，不可达链表剩下的对象都是垃圾对象，进行回收。\n\n\n# 分代回收\n\n对象分在不同集合中，每个集合称为一个代, python中分为3代，年轻代(第0代)、中年代(第1代)、老年代(第二代)，对应3各链表，每一代gc频率不同，第0代最高，第1代次之，第二代最低(越年轻的对象越容易死掉，而老的对象通常会存错更久)，新生的对象放入第0代，如果该对象在第0代的一次gc中存活，则移动到第1代，如果第一代对象在第1代gc中存错，则移动到第2代。\n\n什么情况触发gc， 可以设置阈值，也可以手动调用gc.collect()\n\n每次扫描全部对象，费时费力，提高gc的效率。\n\n\n# 垃圾回收触发情况\n\n调用gc.collect(),需要先导入gc模块。\n\n当gc模块的计数器达到阈值的时候。阈值可以设置",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"python上下文管理器",frontmatter:{title:"python上下文管理器",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/a6b804/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"python的上下文管理的使用及实现的几种方式",feed:{enable:!0},tags:["python"],categories:["编程","python","基础"],comment:!0,meta:[{name:"twitter:title",content:"python上下文管理器"},{name:"twitter:description",content:"python的上下文管理的使用及实现的几种方式"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/04.python%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python上下文管理器"},{property:"og:description",content:"python的上下文管理的使用及实现的几种方式"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/04.python%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python上下文管理器"},{itemprop:"description",content:"python的上下文管理的使用及实现的几种方式"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/04.python%E4%B8%8A%E4%B8%8B%E6%96%87%E7%AE%A1%E7%90%86%E5%99%A8.html",relativePath:"04.编程/01.python/01.基础/04.python上下文管理器.md",key:"v-54ae2f6d",path:"/pages/a6b804/",headers:[{level:2,title:"什么是上下文管理器",slug:"什么是上下文管理器",normalizedTitle:"什么是上下文管理器",charIndex:2},{level:2,title:"经典open案例",slug:"经典open案例",normalizedTitle:"经典open案例",charIndex:89},{level:2,title:"自定义上下文管理器",slug:"自定义上下文管理器",normalizedTitle:"自定义上下文管理器",charIndex:314},{level:3,title:"类实现",slug:"类实现",normalizedTitle:"类实现",charIndex:328},{level:3,title:"方法实现",slug:"方法实现",normalizedTitle:"方法实现",charIndex:631}],headersStr:"什么是上下文管理器 经典open案例 自定义上下文管理器 类实现 方法实现",content:'# 什么是上下文管理器\n\npython中使用with来使用上下文管理器.\n\n在使用某个资源时，可以对该资源进行初始化和资源的清理两个操作，在这两个操作之间边成为上下文。\n\n\n# 经典open案例\n\n对文件操作时，需要打开文件及关闭文件。然后在这之间进行文件的操作。\n\nf = open("a.txt")\nf.write("hello world")\nf.close()\n\n\n1\n2\n3\n\n\n使用上下文管理器 打开文件后，得到文件描述符，在with代码块中对f进行操作，结束时，会自动的进行关闭操作.\n\nwith open("a.txt") as f:\n    f.write("hello world")\n\n\n1\n2\n\n\n\n# 自定义上下文管理器\n\n\n# 类实现\n\n进入上下文时，调用__enter__方法进行初始化，退出时，调用__exit__退出。\n\n\nclass A:\ndef __enter__(self):\n    print("进入")\n\ndef __exit__(self, exc_type, exc_val, exc_tb):\n    print("释放资源")\n\nwith A() as f:\n    print("hello")\n    print("world")\n   \noutput: \n进入\nhello\nworld\n释放资源\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# 方法实现\n\n使用contextlib.contextmanager 对方法实现上下文管理器. 使用生成器完成。\n\n\nimport contextlib\n\n@contextlib.contextmanager\ndef test(a):\n    print("open..")\n    yield a\n    print("close")\n    \nwith test(2) as f:\n    print(f)\n\noutput:\nopen..\n2\nclose\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n',normalizedContent:'# 什么是上下文管理器\n\npython中使用with来使用上下文管理器.\n\n在使用某个资源时，可以对该资源进行初始化和资源的清理两个操作，在这两个操作之间边成为上下文。\n\n\n# 经典open案例\n\n对文件操作时，需要打开文件及关闭文件。然后在这之间进行文件的操作。\n\nf = open("a.txt")\nf.write("hello world")\nf.close()\n\n\n1\n2\n3\n\n\n使用上下文管理器 打开文件后，得到文件描述符，在with代码块中对f进行操作，结束时，会自动的进行关闭操作.\n\nwith open("a.txt") as f:\n    f.write("hello world")\n\n\n1\n2\n\n\n\n# 自定义上下文管理器\n\n\n# 类实现\n\n进入上下文时，调用__enter__方法进行初始化，退出时，调用__exit__退出。\n\n\nclass a:\ndef __enter__(self):\n    print("进入")\n\ndef __exit__(self, exc_type, exc_val, exc_tb):\n    print("释放资源")\n\nwith a() as f:\n    print("hello")\n    print("world")\n   \noutput: \n进入\nhello\nworld\n释放资源\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# 方法实现\n\n使用contextlib.contextmanager 对方法实现上下文管理器. 使用生成器完成。\n\n\nimport contextlib\n\n@contextlib.contextmanager\ndef test(a):\n    print("open..")\n    yield a\n    print("close")\n    \nwith test(2) as f:\n    print(f)\n\noutput:\nopen..\n2\nclose\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"python元编程",frontmatter:{title:"python元编程",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/5fa368/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文介绍python中元编程的属性及使用方法",feed:{enable:!0},tags:["python"],categories:["编程","python","基础"],comment:!0,meta:[{name:"twitter:title",content:"python元编程"},{name:"twitter:description",content:"本文介绍python中元编程的属性及使用方法"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/02.python%E5%85%83%E7%BC%96%E7%A8%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python元编程"},{property:"og:description",content:"本文介绍python中元编程的属性及使用方法"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/02.python%E5%85%83%E7%BC%96%E7%A8%8B.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python元编程"},{itemprop:"description",content:"本文介绍python中元编程的属性及使用方法"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/02.python%E5%85%83%E7%BC%96%E7%A8%8B.html",relativePath:"04.编程/01.python/01.基础/02.python元编程.md",key:"v-6b5349e8",path:"/pages/5fa368/",headers:[{level:2,title:"property动态属性",slug:"property动态属性",normalizedTitle:"property动态属性",charIndex:2},{level:2,title:"_getattribute 和 getattr_",slug:"getattribute-和-getattr",normalizedTitle:"<em>getattribute 和 getattr</em>",charIndex:null},{level:2,title:"属性描述符",slug:"属性描述符",normalizedTitle:"属性描述符",charIndex:744},{level:3,title:"属性描述符查找过程",slug:"属性描述符查找过程",normalizedTitle:"属性描述符查找过程",charIndex:1032},{level:2,title:"元类",slug:"元类",normalizedTitle:"元类",charIndex:2152},{level:3,title:"通过type创建class",slug:"通过type创建class",normalizedTitle:"通过type创建class",charIndex:2211},{level:3,title:"自定义元类",slug:"自定义元类",normalizedTitle:"自定义元类",charIndex:2588}],headersStr:"property动态属性 _getattribute 和 getattr_ 属性描述符 属性描述符查找过程 元类 通过type创建class 自定义元类",content:'# property动态属性\n\n通过使用property可以将方法像属性一样获取值。使用setter对方法进行赋值操作\n\n\nfrom datetime import datetime, date\nclass Student:\n\n    def __init__(self, name, birthday):\n        self.name = name\n        self.birthday = birthday\n        self._age = 0\n    \n    @property\n    def age(self):\n        return datetime.now().year - self.birthday.year\n    \n    @age.setter\n    def age(self, value):\n        self._age = value\n    \nstu = Student("zhangsan", date(year=1995, month=3, day=7))\nstu.age = 4\nprint(stu.age)\n\noutput: 24\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n# getattribute 和 getattr\n\n__getattr__在类中找不到属性时，调用该函数。 __getattribute__首先调用该函数，然后找属性.\n\n在__getattribute__中抛出AttributeError时，会调用__getattr__\n\n调用顺序 __getattribute__ > __getattr__\n\n\n# 属性描述符\n\n在类中只要实现了__get__、__set__、__delete__方法中的一个就认为是描述符. 只实现了__get__的对象是非数据描述符. 只读 实现了__get__和__set__的对象是数据描述符. 可读可写.\n\nclass IntField:\n    def __get__(self):\n        pass\n        \n    def __set__(self):\n        pass\n        \n    def __delete__(self):\n        pass\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 属性描述符查找过程\n\n属性描述符发生的过程在__getattribute__中.\n\n如果age是属性描述符，则调用IntField中的__get__获得属性值，如果获取失败，则调用__dict__获取值。如果age不是属性描述符，则直接获取__dict__对应的值。\n\n\nimport numbers\nclass IntField:\n    # 数据描述符\n    def __get__(self, instance, owner):\n        return self.value\n        \n    def __set__(self, instance, value):\n        if not isinstance(value, numbers.Integral):\n            raise ValueError("int value need")\n        if value < 0:\n            raise ValueError("positive value need")\n        self.value = value\n        \n    def __delete__(self, instance):\n        pass\n    \nclass NonDataIntField:\n    # 非数据属性描述符\n    def __get__(self, instance, owner):\n        return "NonDataIntField = {}".format(self.value)\n\nclass User:\n    age = IntField()\n    #age = NonDataIntField()\n\nuser = User()\nuser.name = "zhangsan"    # name不是属性描述符，所以直接加入到`__dict__`中\nprint(user.__dict__)\n\nuser.age = 12               # age是属性描述符, 调用`IntField`中的`__set__`方法， 而不会加入到`__dict__`中\nprint(user.__dict__)\nprint(user.age)              # 调用`IntField`中的`__get__`方法\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n\n# 元类\n\n元类是创建类的类. type -> class -> 对象\n\n所有的类都是通过type实例化得到的。\n\n\n# 通过type创建class\n\n使用type创建User类，该类继承Base类，并且有test方法和name属性\n\n\nclass Base:\n    def __init__(self, *args, **kwargs):\n        print("Base __init__")\n        super().__init__(*args, **kwargs)\n\ndef test(self):\n    print("test = {}".format(self.name))\n \nUser = type("User", (Base,), {"test": test, "name": "zhangsan"})\nuser = User()\nuser.test()\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# 自定义元类\n\n自定义元类需要通过继承type实现\n\n如果父类有metaclass，则子类和父类的创建都需要通过该元类实例化得到。\n\n\n\nclass BaseMeta(type):\n\n    def __new__(cls, name, bases, args, **kwargs):\n        # print(name)\n        # print(bases)\n        # print(args)\n        print("BaseMeta __new__..")\n        \n        if name == "Base":\n            return super().__new__(cls, name, bases, args, **kwargs)\n            \n        meta = args[\'Meta\']\n        name = getattr(meta, "name")    # 获取到A中meta的name的值. django的orm也是这样实现的\n        print(name)\n        \n        return super().__new__(cls, name, bases, args, **kwargs)\n\n\n\nclass Base(metaclass=BaseMeta):\n\n    def __new__(cls, *args, **kwargs):\n        print("Base __new__..")\n        return super().__new__(cls, *args, **kwargs)\n        \n    def __init__(self, *args, **kwargs):\n        print("Base init..")\n        super().__init__(*args, **kwargs)\n    \nclass A(Base):\n\n    def __new__(cls, *args, **kwargs):\n        print("A __new__..")\n        return super().__new__(cls, *args, **kwargs)\n        \n    def __init__(self, *args, **kwargs):\n        print("A init..")\n        super().__init__(*args, **kwargs)\n        \n    class Meta:\n        name = "zhangsan"\n\n\n# A和Base都会通过BaseMeta创建，所以会调用两次__new__创建实例\noutput:\n\nBaseMeta __new__..\nBaseMeta __new__..\nzhangsan\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n\n\n元类的经典例子是django ORM',normalizedContent:'# property动态属性\n\n通过使用property可以将方法像属性一样获取值。使用setter对方法进行赋值操作\n\n\nfrom datetime import datetime, date\nclass student:\n\n    def __init__(self, name, birthday):\n        self.name = name\n        self.birthday = birthday\n        self._age = 0\n    \n    @property\n    def age(self):\n        return datetime.now().year - self.birthday.year\n    \n    @age.setter\n    def age(self, value):\n        self._age = value\n    \nstu = student("zhangsan", date(year=1995, month=3, day=7))\nstu.age = 4\nprint(stu.age)\n\noutput: 24\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n\n# getattribute 和 getattr\n\n__getattr__在类中找不到属性时，调用该函数。 __getattribute__首先调用该函数，然后找属性.\n\n在__getattribute__中抛出attributeerror时，会调用__getattr__\n\n调用顺序 __getattribute__ > __getattr__\n\n\n# 属性描述符\n\n在类中只要实现了__get__、__set__、__delete__方法中的一个就认为是描述符. 只实现了__get__的对象是非数据描述符. 只读 实现了__get__和__set__的对象是数据描述符. 可读可写.\n\nclass intfield:\n    def __get__(self):\n        pass\n        \n    def __set__(self):\n        pass\n        \n    def __delete__(self):\n        pass\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 属性描述符查找过程\n\n属性描述符发生的过程在__getattribute__中.\n\n如果age是属性描述符，则调用intfield中的__get__获得属性值，如果获取失败，则调用__dict__获取值。如果age不是属性描述符，则直接获取__dict__对应的值。\n\n\nimport numbers\nclass intfield:\n    # 数据描述符\n    def __get__(self, instance, owner):\n        return self.value\n        \n    def __set__(self, instance, value):\n        if not isinstance(value, numbers.integral):\n            raise valueerror("int value need")\n        if value < 0:\n            raise valueerror("positive value need")\n        self.value = value\n        \n    def __delete__(self, instance):\n        pass\n    \nclass nondataintfield:\n    # 非数据属性描述符\n    def __get__(self, instance, owner):\n        return "nondataintfield = {}".format(self.value)\n\nclass user:\n    age = intfield()\n    #age = nondataintfield()\n\nuser = user()\nuser.name = "zhangsan"    # name不是属性描述符，所以直接加入到`__dict__`中\nprint(user.__dict__)\n\nuser.age = 12               # age是属性描述符, 调用`intfield`中的`__set__`方法， 而不会加入到`__dict__`中\nprint(user.__dict__)\nprint(user.age)              # 调用`intfield`中的`__get__`方法\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n\n# 元类\n\n元类是创建类的类. type -> class -> 对象\n\n所有的类都是通过type实例化得到的。\n\n\n# 通过type创建class\n\n使用type创建user类，该类继承base类，并且有test方法和name属性\n\n\nclass base:\n    def __init__(self, *args, **kwargs):\n        print("base __init__")\n        super().__init__(*args, **kwargs)\n\ndef test(self):\n    print("test = {}".format(self.name))\n \nuser = type("user", (base,), {"test": test, "name": "zhangsan"})\nuser = user()\nuser.test()\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n\n# 自定义元类\n\n自定义元类需要通过继承type实现\n\n如果父类有metaclass，则子类和父类的创建都需要通过该元类实例化得到。\n\n\n\nclass basemeta(type):\n\n    def __new__(cls, name, bases, args, **kwargs):\n        # print(name)\n        # print(bases)\n        # print(args)\n        print("basemeta __new__..")\n        \n        if name == "base":\n            return super().__new__(cls, name, bases, args, **kwargs)\n            \n        meta = args[\'meta\']\n        name = getattr(meta, "name")    # 获取到a中meta的name的值. django的orm也是这样实现的\n        print(name)\n        \n        return super().__new__(cls, name, bases, args, **kwargs)\n\n\n\nclass base(metaclass=basemeta):\n\n    def __new__(cls, *args, **kwargs):\n        print("base __new__..")\n        return super().__new__(cls, *args, **kwargs)\n        \n    def __init__(self, *args, **kwargs):\n        print("base init..")\n        super().__init__(*args, **kwargs)\n    \nclass a(base):\n\n    def __new__(cls, *args, **kwargs):\n        print("a __new__..")\n        return super().__new__(cls, *args, **kwargs)\n        \n    def __init__(self, *args, **kwargs):\n        print("a init..")\n        super().__init__(*args, **kwargs)\n        \n    class meta:\n        name = "zhangsan"\n\n\n# a和base都会通过basemeta创建，所以会调用两次__new__创建实例\noutput:\n\nbasemeta __new__..\nbasemeta __new__..\nzhangsan\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n\n\n元类的经典例子是django orm',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"使用python实现单例模式的三种方式",frontmatter:{title:"使用python实现单例模式的三种方式",date:"2022-12-10T16:47:40.000Z",permalink:"/pages/33b8d0/",tags:["python"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文主要介绍使用python的三种实现单例模式的方式。",feed:{enable:!0},categories:["编程","python","基础"],comment:!0,meta:[{name:"twitter:title",content:"使用python实现单例模式的三种方式"},{name:"twitter:description",content:"本文主要介绍使用python的三种实现单例模式的方式。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/06.%E4%BD%BF%E7%94%A8python%E5%AE%9E%E7%8E%B0%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F.html"},{property:"og:type",content:"article"},{property:"og:title",content:"使用python实现单例模式的三种方式"},{property:"og:description",content:"本文主要介绍使用python的三种实现单例模式的方式。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/06.%E4%BD%BF%E7%94%A8python%E5%AE%9E%E7%8E%B0%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-12-10T16:47:40.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"使用python实现单例模式的三种方式"},{itemprop:"description",content:"本文主要介绍使用python的三种实现单例模式的方式。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/06.%E4%BD%BF%E7%94%A8python%E5%AE%9E%E7%8E%B0%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%B8%89%E7%A7%8D%E6%96%B9%E5%BC%8F.html",relativePath:"04.编程/01.python/01.基础/06.使用python实现单例模式的三种方式.md",key:"v-788e5ef9",path:"/pages/33b8d0/",headers:[{level:2,title:"0 . 前言",slug:"_0-前言",normalizedTitle:"0 . 前言",charIndex:2},{level:2,title:"1. 在类中_new_方法中实现",slug:"_1-在类中-new-方法中实现",normalizedTitle:"1. 在类中_new_方法中实现",charIndex:null},{level:2,title:"2. 通过元类实现",slug:"_2-通过元类实现",normalizedTitle:"2. 通过元类实现",charIndex:627},{level:2,title:"3. 通过装饰器实现单例",slug:"_3-通过装饰器实现单例",normalizedTitle:"3. 通过装饰器实现单例",charIndex:2516}],headersStr:"0 . 前言 1. 在类中_new_方法中实现 2. 通过元类实现 3. 通过装饰器实现单例",content:'# 0 . 前言\n\n在整个进程中，有且只有一个对象存在，在任何地点使用都是同一个对象，可以解决多线程资源竞争问题，也常用于配置信息。\n\n本文主要介绍使用python的三种实现单例模式的方式。\n\n\n# 1. 在类中__new__方法中实现\n\n在需要实现单例的 class 中添加__new__方法，在创建该 class 对象时会调用该方法，使用类变量 _instance 来保存当前对象，每次创建之前都会判断是否有该对象，没有则创建，有则直接返回。\n\nfrom typing import Any\n\nclass A:\n    def __new__(cls, *args, **kwargs) -> Any:\n        if not hasattr(cls, "_instance"):\n            cls._instance = super().__new__(cls, *args, **kwargs)\n    return cls._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们创建两个 class A 对象，然后分别打印他们的内存 ID，会发现两者 ID 是一致的，也就是是同一个对象。\n\na1 = A()  \na2 = A()  \nprint(id(a1))  \nprint(id(a2))\n\nOutput: \n2659742107728\n2659742107728\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2. 通过元类实现\n\n上面的方式需要在每一个单例类中都要添加一个__new__方法，有大量的重复代码。接下来我们介绍通过元类来实现单例。\n\n * 第一版\n\n首先创建 class Singleton 来继承 type，该类为我们自定义的元类。然后创建我们需要单例的 class A 和 B，它们都需要通过 metaclass=Singleton 来选择 Singleton 作为它们的元类。\n\n在元类中，创建 __call__ 方法，该方法会在 class A 和 B 创建对象时调用，在该方法中会调用 __new__ 和 __init__ 方法，创建完对象后，再将该对象放在类变量 _instance 中，和 1. 在__new__中实现单例 的方法一样。\n\nfrom typing import Any\n\nclass Singleton(type):\n    def __call__(self, *args: Any, **kwds: Any) -> Any:\n        if not hasattr(self, "_instance"):\n            self._instance = super(Singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\nclass A(metaclass=Singleton):\n    pass\n\nclass B(metaclass=Singleton):\n    pass\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n我们再通过测试，可以看到 class A 和 B 都实现了单例。\n\na1 = A()\na2 = A()\nprint(id(a1))\nprint(id(a2))\n\nb1 = B()\nb2 = B()\nprint(id(b1))\nprint(id(b2))\n\nOutput:\n>>> 2802632572784\n>>> 2802632572784\n>>> 2802632572400\n>>> 2802632572400\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n但这个单例设计只适用于单线程，在多线程中，如果两个线程都停留 hasattr 下面，可能还是会创建两个对象，达不到单例的效果。\n\n * 第二版\n\n通过加锁解决上面并发的问题。\n\nimport threading\n\nclass Singleton(type):\n    lock = threading.Lock()\n    \n    def __call__(self, *args: Any, **kwds: Any) -> Any:\n        with Singleton.lock:\n            if not hasattr(self, "_instance"):\n                self._instance = super(Singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n但是其实只有第一次创建对象时，需要通过锁同步获取单例对象，在已有对象时，不需要再用锁了，在这种情况下，每次获取对象都经过锁，会影响性能。\n\n * 最终版\n\n所以再加上一重判断，减少每次锁判断带来的性能消耗。\n\nimport threading\nclass Singleton(type):\n    lock = threading.Lock()\n    \n    def __call__(self, *args: Any, **kwds: Any) -> Any:\n        if not hasattr(self, "_instance"):\n            with Singleton.lock:\n                if not hasattr(self, "_instance"):\n                    self._instance = super(Singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 3. 通过装饰器实现单例\n\n该方法是通过实现一个装饰器，在需要实现类上添加该装饰器即可完成，使用简单。\n\n通过将所有的单例对象保存在装饰器的 _instance 字典中，以类为 key，对象为 value 进行存储。\n\ndef Singleton(cls):\n    _instance = {}\n    def _singleton(*args, **kargs):\n        if cls not in _instance:\n            _instance[cls] = cls(*args, **kargs)\n        return _instance[cls]\n    return _singleton\n@Singleton\nclass A:\n    pass\n  \n@Singleton\nclass B:\n    pass\n  \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n',normalizedContent:'# 0 . 前言\n\n在整个进程中，有且只有一个对象存在，在任何地点使用都是同一个对象，可以解决多线程资源竞争问题，也常用于配置信息。\n\n本文主要介绍使用python的三种实现单例模式的方式。\n\n\n# 1. 在类中__new__方法中实现\n\n在需要实现单例的 class 中添加__new__方法，在创建该 class 对象时会调用该方法，使用类变量 _instance 来保存当前对象，每次创建之前都会判断是否有该对象，没有则创建，有则直接返回。\n\nfrom typing import any\n\nclass a:\n    def __new__(cls, *args, **kwargs) -> any:\n        if not hasattr(cls, "_instance"):\n            cls._instance = super().__new__(cls, *args, **kwargs)\n    return cls._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n我们创建两个 class a 对象，然后分别打印他们的内存 id，会发现两者 id 是一致的，也就是是同一个对象。\n\na1 = a()  \na2 = a()  \nprint(id(a1))  \nprint(id(a2))\n\noutput: \n2659742107728\n2659742107728\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2. 通过元类实现\n\n上面的方式需要在每一个单例类中都要添加一个__new__方法，有大量的重复代码。接下来我们介绍通过元类来实现单例。\n\n * 第一版\n\n首先创建 class singleton 来继承 type，该类为我们自定义的元类。然后创建我们需要单例的 class a 和 b，它们都需要通过 metaclass=singleton 来选择 singleton 作为它们的元类。\n\n在元类中，创建 __call__ 方法，该方法会在 class a 和 b 创建对象时调用，在该方法中会调用 __new__ 和 __init__ 方法，创建完对象后，再将该对象放在类变量 _instance 中，和 1. 在__new__中实现单例 的方法一样。\n\nfrom typing import any\n\nclass singleton(type):\n    def __call__(self, *args: any, **kwds: any) -> any:\n        if not hasattr(self, "_instance"):\n            self._instance = super(singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\nclass a(metaclass=singleton):\n    pass\n\nclass b(metaclass=singleton):\n    pass\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n我们再通过测试，可以看到 class a 和 b 都实现了单例。\n\na1 = a()\na2 = a()\nprint(id(a1))\nprint(id(a2))\n\nb1 = b()\nb2 = b()\nprint(id(b1))\nprint(id(b2))\n\noutput:\n>>> 2802632572784\n>>> 2802632572784\n>>> 2802632572400\n>>> 2802632572400\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n但这个单例设计只适用于单线程，在多线程中，如果两个线程都停留 hasattr 下面，可能还是会创建两个对象，达不到单例的效果。\n\n * 第二版\n\n通过加锁解决上面并发的问题。\n\nimport threading\n\nclass singleton(type):\n    lock = threading.lock()\n    \n    def __call__(self, *args: any, **kwds: any) -> any:\n        with singleton.lock:\n            if not hasattr(self, "_instance"):\n                self._instance = super(singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n但是其实只有第一次创建对象时，需要通过锁同步获取单例对象，在已有对象时，不需要再用锁了，在这种情况下，每次获取对象都经过锁，会影响性能。\n\n * 最终版\n\n所以再加上一重判断，减少每次锁判断带来的性能消耗。\n\nimport threading\nclass singleton(type):\n    lock = threading.lock()\n    \n    def __call__(self, *args: any, **kwds: any) -> any:\n        if not hasattr(self, "_instance"):\n            with singleton.lock:\n                if not hasattr(self, "_instance"):\n                    self._instance = super(singleton, self).__call__(*args, **kwds)\n\n        return self._instance\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 3. 通过装饰器实现单例\n\n该方法是通过实现一个装饰器，在需要实现类上添加该装饰器即可完成，使用简单。\n\n通过将所有的单例对象保存在装饰器的 _instance 字典中，以类为 key，对象为 value 进行存储。\n\ndef singleton(cls):\n    _instance = {}\n    def _singleton(*args, **kargs):\n        if cls not in _instance:\n            _instance[cls] = cls(*args, **kargs)\n        return _instance[cls]\n    return _singleton\n@singleton\nclass a:\n    pass\n  \n@singleton\nclass b:\n    pass\n  \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"python装饰器的使用方法",frontmatter:{title:"python装饰器的使用方法",date:"2022-10-23T17:18:08.000Z",permalink:"/pages/7434f1/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍python中的装饰器的几种常见的使用方法并理解它们的实现原理。",feed:{enable:!0},tags:["python"],categories:["编程","python","基础"],comment:!0,meta:[{name:"twitter:title",content:"python装饰器的使用方法"},{name:"twitter:description",content:"介绍python中的装饰器的几种常见的使用方法并理解它们的实现原理。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/05.python%E8%A3%85%E9%A5%B0%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python装饰器的使用方法"},{property:"og:description",content:"介绍python中的装饰器的几种常见的使用方法并理解它们的实现原理。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/05.python%E8%A3%85%E9%A5%B0%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-10-23T17:18:08.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python装饰器的使用方法"},{itemprop:"description",content:"介绍python中的装饰器的几种常见的使用方法并理解它们的实现原理。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/05.python%E8%A3%85%E9%A5%B0%E5%99%A8%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95.html",relativePath:"04.编程/01.python/01.基础/05.python装饰器的使用方法.md",key:"v-597fc7ce",path:"/pages/7434f1/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 使用",slug:"_1-使用",normalizedTitle:"1. 使用",charIndex:87},{level:3,title:"1.1 在函数上添加装饰器",slug:"_1-1-在函数上添加装饰器",normalizedTitle:"1.1 在函数上添加装饰器",charIndex:97},{level:3,title:"1.2 装饰器的运行过程",slug:"_1-2-装饰器的运行过程",normalizedTitle:"1.2 装饰器的运行过程",charIndex:547},{level:3,title:"1.3 保存原函数信息",slug:"_1-3-保存原函数信息",normalizedTitle:"1.3 保存原函数信息",charIndex:1077},{level:3,title:"1.4 调用原函数",slug:"_1-4-调用原函数",normalizedTitle:"1.4 调用原函数",charIndex:2311},{level:3,title:"1.5 带参数的装饰器",slug:"_1-5-带参数的装饰器",normalizedTitle:"1.5 带参数的装饰器",charIndex:2824},{level:3,title:"1.6 带可选参数的装饰器",slug:"_1-6-带可选参数的装饰器",normalizedTitle:"1.6 带可选参数的装饰器",charIndex:3581},{level:3,title:"1.7 在类上添加装饰器",slug:"_1-7-在类上添加装饰器",normalizedTitle:"1.7 在类上添加装饰器",charIndex:4553},{level:3,title:"1.8 类装饰器",slug:"_1-8-类装饰器",normalizedTitle:"1.8 类装饰器",charIndex:5209},{level:3,title:"1.9 暴露被装饰的元信息",slug:"_1-9-暴露被装饰的元信息",normalizedTitle:"1.9 暴露被装饰的元信息",charIndex:5869},{level:3,title:"1.10 带参数的类装饰器",slug:"_1-10-带参数的类装饰器",normalizedTitle:"1.10 带参数的类装饰器",charIndex:6595},{level:2,title:"2. 总结",slug:"_2-总结",normalizedTitle:"2. 总结",charIndex:7334},{level:2,title:"3. 参考资料",slug:"_3-参考资料",normalizedTitle:"3. 参考资料",charIndex:7395}],headersStr:"0. 前言 1. 使用 1.1 在函数上添加装饰器 1.2 装饰器的运行过程 1.3 保存原函数信息 1.4 调用原函数 1.5 带参数的装饰器 1.6 带可选参数的装饰器 1.7 在类上添加装饰器 1.8 类装饰器 1.9 暴露被装饰的元信息 1.10 带参数的类装饰器 2. 总结 3. 参考资料",content:'# 0. 前言\n\n装饰器在 python 中使用的频率非常高，它可以在不改动原有函数的基础上对其进行增强功能。\n\n下面主要是介绍装饰器的各种用法，并理解其运行过程。\n\n\n# 1. 使用\n\n\n# 1.1 在函数上添加装饰器\n\ndecro 是一个装饰器函数，其实现是将内部的函数 wrapper 作为返回值返回出去。\n\n在函数 test 上添加 @decro 进行使用，可以将本函数作为一个参数传入到 decro 函数中，然后，然后得到的是装饰器函数内部返回的函数 wrapper, 我们在调用 test 方法时，其实调用的是装饰器返回的 wrapper 函数，该函数中会调用被装饰的函数 test\n\ndef decro(func):  \n    def wrapper(*args, **kwargs):  \n        print("wrapper")  \n        return func()  \n  \n    return wrapper\n\n\n@decro  \ndef test():  \n    print("test")  \n\n\ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n输出：\n\nwrapper\ntest\n\n\n1\n2\n\n\n\n# 1.2 装饰器的运行过程\n\n装饰器时在被装饰的函数定义之后立即运行的，当执行到@decro 装饰 test 函数时，会马上执行函数 decro，然后将 wrapper 给返回出去。\n\ndef decro(func):  \n    print("decro")  \n  \n    def wrapper(*args, **kwargs):  \n        print("wrapper")  \n        return func()  \n  \n    return wrapper  \n  \nprint("start")  \n  \n@decro  \ndef test():  \n    print("test")  \n  \nprint("end")\n\ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n输出如下，可以看到先执行了 start，然后马上执行了装饰器 decro，然后再执行 end，当我们调用 test 函数时，执行了装饰器内部函数 wrapper，然后再调用被装饰的函数 test\n\nstart\ndecro\nend\nwrapper\ntest\n\n\n1\n2\n3\n4\n5\n\n\n\n# 1.3 保存原函数信息\n\n在使用装饰器时，调用的原方法已经被替换为装饰器返回的新方法了，所以方法的元信息已经被替换了, 通过 name、doc 得到的元数据已经被替换成了新方法的。\n\ndef decro(func):  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \nprint("test\'s __name__ = {}".format(test.__name__))  \nprint("test\'s __doc__ = {}".format(test.__doc__))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n输出如下，会发现函数 test 的函数信息 __name__ 和 __doc__ 变成 wrapper 的信息。\n\ntest\'s __name__ = wrapper\ntest\'s __doc__ =  wrapper doc\n\n\n1\n2\n\n\n但是我们不想要改变原方法的元信息，这个时候需要使用 functools.wraps 解决。\n\nfrom functools import wraps  \n  \ndef decro(func):  \n  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \nprint("test\'s __name__ = {}".format(test.__name__))  \nprint("test\'s __doc__ = {}".format(test.__doc__))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n输出如下，会发现，test 函数信息没有被替换掉，保证了函数的原汁原味。\n\ntest\'s __name__ = test\ntest\'s __doc__ =  test doc \n\n\n1\n2\n\n\n\n# 1.4 调用原函数\n\n装饰器可以增强函数的功能，但是在某些场景我就想要使用原函数，而不想使用装饰之后的函数，可以通过调用__wrapped__来调用原函数。\n\nfrom functools import wraps  \n  \n\ndef decro(func):  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \ntest.__wrapped__()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n输出如下，输出 text，而没有输出 wrapper，说明调用的是原函数。\n\ntest\n\n\n1\n\n\n\n# 1.5 带参数的装饰器\n\n还有这么一种场景，我们想要在装饰器中添加参数。\n\n想要通过参数决定日志级别，这里的 logged 接收 level 参数并将它作用在内部函数中，返回值是将 decro 函数返回，然后再将函数 test 作为参数从传入到 decro 函数中，再将 wrapper 返回，最终 test 还是替换成了 wrapper，在该方法中使用了传入的 ERROR 的日志级别。\n\nfrom functools import wraps  \nimport logging  \n  \n  \ndef logged(level):  \n    def decro(func):  \n        @wraps(func)  \n        def wrapper(*args, **kwargs):  \n            """ wrapper doc """  \n            logging.log(level, func.__name__)  \n            return func(*args, **kwargs)  \n  \n        return wrapper  \n  \n    return decro  \n  \n  \n@logged(level=logging.ERROR)  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n输出了 ERROR 日志级别的日志：\n\nERROR:root:test\ntest\n\n\n1\n2\n\n\n\n# 1.6 带可选参数的装饰器\n\n上面实现的装饰器是必须要带上参数的，但是有的时候，我们不需要带参数，那么该如何实现？\n\n装饰器的 func 默认值为 None，当传入 level 参数时，则返回偏函数 partial ，该函数会基于 logged 创建一个仅包含 level 的新的函数，这个新的函数作为新的装饰器来装饰 add 函数。\n\n当没有传入 level 参数时，就和普通的装饰器一样使用。\n\nfrom functools import wraps, partial  \nimport logging  \n  \n  \ndef logged(func=None, level=logging.INFO):  \n    if func is None:  \n        return partial(logged, level=level)  \n  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        logging.log(level, func.__name__)  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@logged(level=logging.ERROR)  \ndef add(a, b):  \n    print("add")  \n    return a + b  \n  \n  \n@logged  \ndef add2(a, b):  \n    print("add2")  \n    return a + b  \n  \n  \nprint(add(1, 2))  \nprint("-" * 10)  \nprint(add2(1, 2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n输出如下，add 函数的装饰器传入了日志级别为 ERROR 的参数，输出了 ERROR 的日志，而add2 没有。\n\nERROR:root:add\nadd\n3\n----------\nadd2\n3\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 1.7 在类上添加装饰器\n\n上面都是使用装饰器来增强函数的功能，但它还可以增强类的功能，对类进行装饰。\n\n下面的例子中，decro 将被装饰的类 Demo 传入进来，主要是将其类中 __getattribute__ 方法替换成了 new_getattribute 方法。\n\ndef decro(cls):  \n    orig_getattribute = cls.__getattribute__  \n  \n    def new_getattribute(self, name):  \n        print("get name = {}".format(name))  \n        return orig_getattribute(self, name)  \n  \n    cls.__getattribute__ = new_getattribute  \n    return cls  \n  \n  \n@decro  \nclass Demo:  \n  \n    def __init__(self, num):  \n        self.num = num  \n  \n  \nd = Demo(1)  \nprint(d.num)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n输出如下，获取 num 的值时，调用了装饰器替换的 new_getattribute 方法。\n\nget name = num\n1\n\n\n1\n2\n\n\n\n# 1.8 类装饰器\n\n之前都是使用函数方法来定义装饰器，但其实也可以通过类来定义装饰器。\n\n在类装饰器中定义__init__方法，被它装饰的函数会被传入到 func 参数中，这个时候该类装饰器已经被实例化了，也就是将该实例对象替换了被装饰的函数 say。\n\n当我们调用 say 函数时，其实调用的是类装饰器的对象，这个时候会调用__call__方法，该方法中可以对原函数进行增强，并进行调用原方法。\n\nclass logger(object):  \n    def __init__(self, func):  \n        self.func = func  \n  \n    def __call__(self, *args, **kwargs):  \n        print("the function {func}() is running...".format(func=self.func.__name__))  \n        return self.func(*args, **kwargs)  \n  \n  \n@logger  \ndef say(something):  \n    print("say {}!".format(something))  \n  \n  \nsay("hello")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n输出如下：\n\nthe function say() is running...\nsay hello!\n\n\n1\n2\n\n\n\n# 1.9 暴露被装饰的元信息\n\n这个时候会出现和函数装饰器一样的问题，那就是被装饰的函数的元信息已经被替换掉了，这个时候我们还是想保留原有的原信息。\n\n还是使用 wraps 函数来解决该问题。\n\nfrom functools import wraps  \n  \n  \nclass logger(object):  \n    """ logger doc """  \n  \n    def __init__(self, func):  \n        wraps(func)(self)  \n  \n    def __call__(self, *args, **kwargs):  \n        print("the function {func}() is running...".format(func=self.__wrapped__.__name__))  \n        return self.__wrapped__(*args, **kwargs)  \n  \n  \n@logger  \ndef say(something):  \n    """ say doc """  \n    print("say {}!".format(something))  \n  \n  \nsay("hello2")  \nprint(say.__doc__)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n输出的是 say 方法的 doc：\n\nthe function say() is running...\nsay hello2!\n say doc \n\n\n1\n2\n3\n\n\n\n# 1.10 带参数的类装饰器\n\n那么带参数的类装饰器该如何实现呢？\n\n在 __init__ 方法中接收装饰器传入的参数，保存起来，然后再通过 __call__ 函数将内部函数 wrapper 给返回出去，这个时候被装饰的函数已经被 wrapper 给替换了。\n\nclass logger(object):  \n  \n    def __init__(self, level="INFO"):  \n        self.level = level  \n  \n    def __call__(self, func):  \n        def wrapper(*args, **kwargs): \n\t        print("[{level}]: the function {func}() is running...".format(level=self.level, func=func.__name__)) \n            func(*args, **kwargs)  \n  \n        return wrapper  \n  \n  \n@logger(level="ERROR")  \ndef say(something):  \n    print("say {}!".format(something))  \n  \n  \nsay("hello2")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n输出如下，调用 say 函数也就是调用 wrapper 函数：\n\n[ERROR]: the function say() is running...\nsay hello2!\n\n\n1\n2\n\n\n\n# 2. 总结\n\n装饰器的用法很多，封装成库，给其他人使用也非常的方便，我们需要理解它的运行过程，才能更好的使用它。\n\n\n# 3. 参考资料\n\n * https://python3-cookbook.readthedocs.io/zh_CN/latest/c09/p01_put_wrapper_around_function.html',normalizedContent:'# 0. 前言\n\n装饰器在 python 中使用的频率非常高，它可以在不改动原有函数的基础上对其进行增强功能。\n\n下面主要是介绍装饰器的各种用法，并理解其运行过程。\n\n\n# 1. 使用\n\n\n# 1.1 在函数上添加装饰器\n\ndecro 是一个装饰器函数，其实现是将内部的函数 wrapper 作为返回值返回出去。\n\n在函数 test 上添加 @decro 进行使用，可以将本函数作为一个参数传入到 decro 函数中，然后，然后得到的是装饰器函数内部返回的函数 wrapper, 我们在调用 test 方法时，其实调用的是装饰器返回的 wrapper 函数，该函数中会调用被装饰的函数 test\n\ndef decro(func):  \n    def wrapper(*args, **kwargs):  \n        print("wrapper")  \n        return func()  \n  \n    return wrapper\n\n\n@decro  \ndef test():  \n    print("test")  \n\n\ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n输出：\n\nwrapper\ntest\n\n\n1\n2\n\n\n\n# 1.2 装饰器的运行过程\n\n装饰器时在被装饰的函数定义之后立即运行的，当执行到@decro 装饰 test 函数时，会马上执行函数 decro，然后将 wrapper 给返回出去。\n\ndef decro(func):  \n    print("decro")  \n  \n    def wrapper(*args, **kwargs):  \n        print("wrapper")  \n        return func()  \n  \n    return wrapper  \n  \nprint("start")  \n  \n@decro  \ndef test():  \n    print("test")  \n  \nprint("end")\n\ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n输出如下，可以看到先执行了 start，然后马上执行了装饰器 decro，然后再执行 end，当我们调用 test 函数时，执行了装饰器内部函数 wrapper，然后再调用被装饰的函数 test\n\nstart\ndecro\nend\nwrapper\ntest\n\n\n1\n2\n3\n4\n5\n\n\n\n# 1.3 保存原函数信息\n\n在使用装饰器时，调用的原方法已经被替换为装饰器返回的新方法了，所以方法的元信息已经被替换了, 通过 name、doc 得到的元数据已经被替换成了新方法的。\n\ndef decro(func):  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \nprint("test\'s __name__ = {}".format(test.__name__))  \nprint("test\'s __doc__ = {}".format(test.__doc__))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n输出如下，会发现函数 test 的函数信息 __name__ 和 __doc__ 变成 wrapper 的信息。\n\ntest\'s __name__ = wrapper\ntest\'s __doc__ =  wrapper doc\n\n\n1\n2\n\n\n但是我们不想要改变原方法的元信息，这个时候需要使用 functools.wraps 解决。\n\nfrom functools import wraps  \n  \ndef decro(func):  \n  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \nprint("test\'s __name__ = {}".format(test.__name__))  \nprint("test\'s __doc__ = {}".format(test.__doc__))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n输出如下，会发现，test 函数信息没有被替换掉，保证了函数的原汁原味。\n\ntest\'s __name__ = test\ntest\'s __doc__ =  test doc \n\n\n1\n2\n\n\n\n# 1.4 调用原函数\n\n装饰器可以增强函数的功能，但是在某些场景我就想要使用原函数，而不想使用装饰之后的函数，可以通过调用__wrapped__来调用原函数。\n\nfrom functools import wraps  \n  \n\ndef decro(func):  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        """ wrapper doc """  \n        print("wrapper")  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@decro  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \ntest.__wrapped__()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n输出如下，输出 text，而没有输出 wrapper，说明调用的是原函数。\n\ntest\n\n\n1\n\n\n\n# 1.5 带参数的装饰器\n\n还有这么一种场景，我们想要在装饰器中添加参数。\n\n想要通过参数决定日志级别，这里的 logged 接收 level 参数并将它作用在内部函数中，返回值是将 decro 函数返回，然后再将函数 test 作为参数从传入到 decro 函数中，再将 wrapper 返回，最终 test 还是替换成了 wrapper，在该方法中使用了传入的 error 的日志级别。\n\nfrom functools import wraps  \nimport logging  \n  \n  \ndef logged(level):  \n    def decro(func):  \n        @wraps(func)  \n        def wrapper(*args, **kwargs):  \n            """ wrapper doc """  \n            logging.log(level, func.__name__)  \n            return func(*args, **kwargs)  \n  \n        return wrapper  \n  \n    return decro  \n  \n  \n@logged(level=logging.error)  \ndef test():  \n    """ test doc """  \n    print("test")  \n  \n  \ntest()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n输出了 error 日志级别的日志：\n\nerror:root:test\ntest\n\n\n1\n2\n\n\n\n# 1.6 带可选参数的装饰器\n\n上面实现的装饰器是必须要带上参数的，但是有的时候，我们不需要带参数，那么该如何实现？\n\n装饰器的 func 默认值为 none，当传入 level 参数时，则返回偏函数 partial ，该函数会基于 logged 创建一个仅包含 level 的新的函数，这个新的函数作为新的装饰器来装饰 add 函数。\n\n当没有传入 level 参数时，就和普通的装饰器一样使用。\n\nfrom functools import wraps, partial  \nimport logging  \n  \n  \ndef logged(func=none, level=logging.info):  \n    if func is none:  \n        return partial(logged, level=level)  \n  \n    @wraps(func)  \n    def wrapper(*args, **kwargs):  \n        logging.log(level, func.__name__)  \n        return func(*args, **kwargs)  \n  \n    return wrapper  \n  \n  \n@logged(level=logging.error)  \ndef add(a, b):  \n    print("add")  \n    return a + b  \n  \n  \n@logged  \ndef add2(a, b):  \n    print("add2")  \n    return a + b  \n  \n  \nprint(add(1, 2))  \nprint("-" * 10)  \nprint(add2(1, 2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n输出如下，add 函数的装饰器传入了日志级别为 error 的参数，输出了 error 的日志，而add2 没有。\n\nerror:root:add\nadd\n3\n----------\nadd2\n3\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 1.7 在类上添加装饰器\n\n上面都是使用装饰器来增强函数的功能，但它还可以增强类的功能，对类进行装饰。\n\n下面的例子中，decro 将被装饰的类 demo 传入进来，主要是将其类中 __getattribute__ 方法替换成了 new_getattribute 方法。\n\ndef decro(cls):  \n    orig_getattribute = cls.__getattribute__  \n  \n    def new_getattribute(self, name):  \n        print("get name = {}".format(name))  \n        return orig_getattribute(self, name)  \n  \n    cls.__getattribute__ = new_getattribute  \n    return cls  \n  \n  \n@decro  \nclass demo:  \n  \n    def __init__(self, num):  \n        self.num = num  \n  \n  \nd = demo(1)  \nprint(d.num)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n输出如下，获取 num 的值时，调用了装饰器替换的 new_getattribute 方法。\n\nget name = num\n1\n\n\n1\n2\n\n\n\n# 1.8 类装饰器\n\n之前都是使用函数方法来定义装饰器，但其实也可以通过类来定义装饰器。\n\n在类装饰器中定义__init__方法，被它装饰的函数会被传入到 func 参数中，这个时候该类装饰器已经被实例化了，也就是将该实例对象替换了被装饰的函数 say。\n\n当我们调用 say 函数时，其实调用的是类装饰器的对象，这个时候会调用__call__方法，该方法中可以对原函数进行增强，并进行调用原方法。\n\nclass logger(object):  \n    def __init__(self, func):  \n        self.func = func  \n  \n    def __call__(self, *args, **kwargs):  \n        print("the function {func}() is running...".format(func=self.func.__name__))  \n        return self.func(*args, **kwargs)  \n  \n  \n@logger  \ndef say(something):  \n    print("say {}!".format(something))  \n  \n  \nsay("hello")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n输出如下：\n\nthe function say() is running...\nsay hello!\n\n\n1\n2\n\n\n\n# 1.9 暴露被装饰的元信息\n\n这个时候会出现和函数装饰器一样的问题，那就是被装饰的函数的元信息已经被替换掉了，这个时候我们还是想保留原有的原信息。\n\n还是使用 wraps 函数来解决该问题。\n\nfrom functools import wraps  \n  \n  \nclass logger(object):  \n    """ logger doc """  \n  \n    def __init__(self, func):  \n        wraps(func)(self)  \n  \n    def __call__(self, *args, **kwargs):  \n        print("the function {func}() is running...".format(func=self.__wrapped__.__name__))  \n        return self.__wrapped__(*args, **kwargs)  \n  \n  \n@logger  \ndef say(something):  \n    """ say doc """  \n    print("say {}!".format(something))  \n  \n  \nsay("hello2")  \nprint(say.__doc__)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n输出的是 say 方法的 doc：\n\nthe function say() is running...\nsay hello2!\n say doc \n\n\n1\n2\n3\n\n\n\n# 1.10 带参数的类装饰器\n\n那么带参数的类装饰器该如何实现呢？\n\n在 __init__ 方法中接收装饰器传入的参数，保存起来，然后再通过 __call__ 函数将内部函数 wrapper 给返回出去，这个时候被装饰的函数已经被 wrapper 给替换了。\n\nclass logger(object):  \n  \n    def __init__(self, level="info"):  \n        self.level = level  \n  \n    def __call__(self, func):  \n        def wrapper(*args, **kwargs): \n\t        print("[{level}]: the function {func}() is running...".format(level=self.level, func=func.__name__)) \n            func(*args, **kwargs)  \n  \n        return wrapper  \n  \n  \n@logger(level="error")  \ndef say(something):  \n    print("say {}!".format(something))  \n  \n  \nsay("hello2")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n输出如下，调用 say 函数也就是调用 wrapper 函数：\n\n[error]: the function say() is running...\nsay hello2!\n\n\n1\n2\n\n\n\n# 2. 总结\n\n装饰器的用法很多，封装成库，给其他人使用也非常的方便，我们需要理解它的运行过程，才能更好的使用它。\n\n\n# 3. 参考资料\n\n * https://python3-cookbook.readthedocs.io/zh_cn/latest/c09/p01_put_wrapper_around_function.html',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"python中import原理",frontmatter:{title:"python中import原理",date:"2023-02-07T09:34:33.000Z",permalink:"/pages/d8fd49/",categories:["编程","python","基础"],tags:["python"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文介绍python正在import module时做了什么，它又是如何加载module的。",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"python中import原理"},{name:"twitter:description",content:"本文介绍python正在import module时做了什么，它又是如何加载module的。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/07.python%E4%B8%ADimport%E5%8E%9F%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python中import原理"},{property:"og:description",content:"本文介绍python正在import module时做了什么，它又是如何加载module的。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/07.python%E4%B8%ADimport%E5%8E%9F%E7%90%86.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-02-07T09:34:33.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python中import原理"},{itemprop:"description",content:"本文介绍python正在import module时做了什么，它又是如何加载module的。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/01.%E5%9F%BA%E7%A1%80/07.python%E4%B8%ADimport%E5%8E%9F%E7%90%86.html",relativePath:"04.编程/01.python/01.基础/07.python中import原理.md",key:"v-0e418e98",path:"/pages/d8fd49/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 什么是 module？",slug:"_1-什么是-module",normalizedTitle:"1. 什么是 module？",charIndex:84},{level:2,title:"2. 什么是 Package?",slug:"_2-什么是-package",normalizedTitle:"2. 什么是 package?",charIndex:471},{level:2,title:"3. module 缓存",slug:"_3-module-缓存",normalizedTitle:"3. module 缓存",charIndex:1510},{level:2,title:"4. 搜索路径",slug:"_4-搜索路径",normalizedTitle:"4. 搜索路径",charIndex:4108},{level:2,title:"5. 总结",slug:"_5-总结",normalizedTitle:"5. 总结",charIndex:4366},{level:2,title:"6. 加入腾讯云开发者社区",slug:"_6-加入腾讯云开发者社区",normalizedTitle:"6. 加入腾讯云开发者社区",charIndex:4527}],headersStr:"0. 前言 1. 什么是 module？ 2. 什么是 Package? 3. module 缓存 4. 搜索路径 5. 总结 6. 加入腾讯云开发者社区",content:"# 0. 前言\n\n在 python 中引入 Module 是再常见不过了，那么当我们 import 时它做了什么事情呢？它是如何加载 Module 使用的呢？\n\n\n# 1. 什么是 module？\n\n一般，Module 是一个后缀为 .py 的文件，其 module 名称一般是文件名称去除 .py，我们可以通过 __name__ 来查看 module 名称。\n\ndemo.py 是需要被引入的 module，main.py 是入口程序，它们在同一级目录。\n\n# demo.py\nprint(__name__)\n\n# main.py\nimport demo\n\n>>> python main.py\ndemo\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n如果 module 为入口文件，则__name__为 __main__，这也是常见 if __name__ == __main__: 的写法由来。\n\n# demo.py\nprint(__name__)\n\n>>> python demo.py\n__main__\n\n\n1\n2\n3\n4\n5\n\n\n\n# 2. 什么是 Package?\n\n包含了 __init__ 文件的目录为 Package，该目录包含多个 py 文件，都属于 Module。我们在 import package 时，会初始化执行 package 的 __init__.py 文件，然后将其作为一个 Module 对象给放在当前的全局变量中。\n\n├───demo\n│   │   __init__.py\n|   main.py\n\n\n1\n2\n3\n\n\n# __init__.py\nprint(\"demo __init__\")\n\n# main.py\nimport demo\nprint(demo)\nprint(globals()[\"demo\"])\n\n>>> python main.py\noutput: \ndemo __init__.py\n<module 'demo' from 'D:\\\\code\\\\my_demo\\\\demo\\\\__init__.py'>\n<module 'demo' from 'D:\\\\code\\\\my_demo\\\\demo\\\\__init__.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到 package 的名称 demo 是在 globals()中的，并且其是一个 module 对象，包含了该 __init__.py 文件所在的路径。\n\n如果想要导入 package 下的 module，可以通过 from package import module 的方式将其加载到当前的全局变量中。\n\n├───demo\n│   │   __init__.py\n|   |   a.py\n|   main.py\n\n\n1\n2\n3\n4\n\n\n# __init__.py\n\n# a.py\nclass Demo:\n\tpass\n\n# main.py\nfrom demo import a\nprint(a)\nprint(a.Demo)\nprint(globals()[\"a\"])\n\n>>> python main.py\n<module 'demo.a' from 'D:\\\\code\\\\my_demo\\\\demo\\\\a.py'>\n<class 'demo.a.Demo'>\n<module 'demo.a' from 'D:\\\\code\\\\my_demo\\\\demo\\\\a.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 3. module 缓存\n\n * module 缓存初始化\n\n在 python 程序初始化时，会将大批的内置 module 提前加载到内存中，保存在 sys.modules 中，这是一个字典，是以 module 名称或者 package 名称为 key，module 对象为 value 存储。\n\n>>> import sys\n>>> sys.modules\n{... 'os': <module 'os' from '/usr/lib64/python3.6/os.py'> ...}\n>>> sys.modules[\"os\"].cpu_count()\n8\n>>> os.cpu_count()\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nNameError: name 'os' is not defined\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n * 将 module 添加到当前去全局变量中\n\n既然提前加载了，但是这里为什么找不到 os 呢？这是因为虽然 sys.modules 中已经存在了，但是并没有把 os 加入到当前的全局变量中。\n\n>>> globals()[\"os\"]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nKeyError: 'os'\n\n\n1\n2\n3\n4\n\n\n所以当我们通过 import os 时，它会通过模块名称在 sys.modules 找到其 module 对象，然后再将其加入到当前的全局变量中，这样就可以使用它了。\n\n>>> import os\n>>> globals()[\"os\"]\n<module 'os' from '/usr/lib64/python3.6/os.py'>\n>>> os.cpu_count()\n8\n>>> id(sys.modules[\"os\"])\n140260375998856\n>>> id(os)\n140260375998856\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到从 sys.modules 中拿到的 os 对象的地址和当前导入的 os 的地址是一致的，无论 import 多少次相同的 module，都是从该全局 sys.modules 中获取，拿到的都是同一个对象，也是单例模式实现的一种。\n\n * 导入 module 中的属性\n\n如果我只是引入 module 中的一个属性变量呢？那 sys.modules 中还是会加载该 module，将其属性变量作为全局变量引入。\n\n>>> import sys\n>>> sys.modules[\"json\"]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nKeyError: 'json'\n>>> from json import load\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * 模块不需要了，del 销毁\n\ndel 销毁的只是销毁当前全局变量中的变量，并不会影响 sys.modules 中的缓存。为什么不销毁 sys.modules 中的呢？是因为该销毁的 module 可能还会在其他的文件中引用。\n\n>>> import json\n>>> import sys\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> globals()[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> del json\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> globals()[\"json\"]\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nKeyError: 'json'\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n * module 重新加载\n\n因为每次 import 都是从 sys.modules 的缓存中获取，那么如果 module 文件变动，则无法拿到最新的 module，这个时候需要通过手动调用 importlib.reload 来重新加载，从本地文件中重新加载 module 对象到 sys.modules 中。\n\n在当前目录下创建 demo.py 文件，内容为空\n\n# demo.py\n\n>>> import demo\n>>> demo.Demo\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nAttributeError: module 'demo' has no attribute 'Demo'\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n这个时候在 demo.py 中添加：\n\nclass Demo:\n    pass\n\n\n1\n2\n\n\nreload demo 后，可以看到加载到 Demo 了。\n\n>>> reload(demo)\n<module 'demo' from '/root/work/mydemo/demo.py'>\n>>> demo.Demo\n<class 'demo.Demo'>\n\n\n1\n2\n3\n4\n\n\n那如果 import 的 module 或者 package 没有在 sys.modules 中呢，这个时候就要去 sys.path 中去本地搜索了。\n\n\n# 4. 搜索路径\n\nsys.path 是一个列表，其中包含了要去搜索 module 的本地路径。当 sys.modules 中查找不到 module 时，将会从该路径中搜索到 module 文件并将其加载到 sys.modules 中来。\n\nsys.path 的路径的来源有：\n\n * 运行脚本所在的目录\n * PYTHONPATH 环境变量\n * python 安装时的默认设置\n\n当在搜索路径找到该 module 的本地路径后，会将其加载到 sys.modules 中，然后再将其添加到当前的全局变量中。\n\n\n# 5. 总结\n\nimport 的加载过程：\n\n 1. 先从 sys.modules 中查看是否有导入的模块，有，则获取该模块，并加入到当前的全局变量中。\n 2. 如果 sys.modules 中没有需要导入的模块，则按照 sys.path 中的目录路径进行搜索找到对应的模块文件再加载到 module 对象中返回。\n\n\n# 6. 加入腾讯云开发者社区\n\n我的博客即将同步至腾讯云开发者社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=3u3wcswfaeiok",normalizedContent:"# 0. 前言\n\n在 python 中引入 module 是再常见不过了，那么当我们 import 时它做了什么事情呢？它是如何加载 module 使用的呢？\n\n\n# 1. 什么是 module？\n\n一般，module 是一个后缀为 .py 的文件，其 module 名称一般是文件名称去除 .py，我们可以通过 __name__ 来查看 module 名称。\n\ndemo.py 是需要被引入的 module，main.py 是入口程序，它们在同一级目录。\n\n# demo.py\nprint(__name__)\n\n# main.py\nimport demo\n\n>>> python main.py\ndemo\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n如果 module 为入口文件，则__name__为 __main__，这也是常见 if __name__ == __main__: 的写法由来。\n\n# demo.py\nprint(__name__)\n\n>>> python demo.py\n__main__\n\n\n1\n2\n3\n4\n5\n\n\n\n# 2. 什么是 package?\n\n包含了 __init__ 文件的目录为 package，该目录包含多个 py 文件，都属于 module。我们在 import package 时，会初始化执行 package 的 __init__.py 文件，然后将其作为一个 module 对象给放在当前的全局变量中。\n\n├───demo\n│   │   __init__.py\n|   main.py\n\n\n1\n2\n3\n\n\n# __init__.py\nprint(\"demo __init__\")\n\n# main.py\nimport demo\nprint(demo)\nprint(globals()[\"demo\"])\n\n>>> python main.py\noutput: \ndemo __init__.py\n<module 'demo' from 'd:\\\\code\\\\my_demo\\\\demo\\\\__init__.py'>\n<module 'demo' from 'd:\\\\code\\\\my_demo\\\\demo\\\\__init__.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n可以看到 package 的名称 demo 是在 globals()中的，并且其是一个 module 对象，包含了该 __init__.py 文件所在的路径。\n\n如果想要导入 package 下的 module，可以通过 from package import module 的方式将其加载到当前的全局变量中。\n\n├───demo\n│   │   __init__.py\n|   |   a.py\n|   main.py\n\n\n1\n2\n3\n4\n\n\n# __init__.py\n\n# a.py\nclass demo:\n\tpass\n\n# main.py\nfrom demo import a\nprint(a)\nprint(a.demo)\nprint(globals()[\"a\"])\n\n>>> python main.py\n<module 'demo.a' from 'd:\\\\code\\\\my_demo\\\\demo\\\\a.py'>\n<class 'demo.a.demo'>\n<module 'demo.a' from 'd:\\\\code\\\\my_demo\\\\demo\\\\a.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n\n# 3. module 缓存\n\n * module 缓存初始化\n\n在 python 程序初始化时，会将大批的内置 module 提前加载到内存中，保存在 sys.modules 中，这是一个字典，是以 module 名称或者 package 名称为 key，module 对象为 value 存储。\n\n>>> import sys\n>>> sys.modules\n{... 'os': <module 'os' from '/usr/lib64/python3.6/os.py'> ...}\n>>> sys.modules[\"os\"].cpu_count()\n8\n>>> os.cpu_count()\ntraceback (most recent call last):\n  file \"<stdin>\", line 1, in <module>\nnameerror: name 'os' is not defined\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n * 将 module 添加到当前去全局变量中\n\n既然提前加载了，但是这里为什么找不到 os 呢？这是因为虽然 sys.modules 中已经存在了，但是并没有把 os 加入到当前的全局变量中。\n\n>>> globals()[\"os\"]\ntraceback (most recent call last):\n  file \"<stdin>\", line 1, in <module>\nkeyerror: 'os'\n\n\n1\n2\n3\n4\n\n\n所以当我们通过 import os 时，它会通过模块名称在 sys.modules 找到其 module 对象，然后再将其加入到当前的全局变量中，这样就可以使用它了。\n\n>>> import os\n>>> globals()[\"os\"]\n<module 'os' from '/usr/lib64/python3.6/os.py'>\n>>> os.cpu_count()\n8\n>>> id(sys.modules[\"os\"])\n140260375998856\n>>> id(os)\n140260375998856\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n可以看到从 sys.modules 中拿到的 os 对象的地址和当前导入的 os 的地址是一致的，无论 import 多少次相同的 module，都是从该全局 sys.modules 中获取，拿到的都是同一个对象，也是单例模式实现的一种。\n\n * 导入 module 中的属性\n\n如果我只是引入 module 中的一个属性变量呢？那 sys.modules 中还是会加载该 module，将其属性变量作为全局变量引入。\n\n>>> import sys\n>>> sys.modules[\"json\"]\ntraceback (most recent call last):\n  file \"<stdin>\", line 1, in <module>\nkeyerror: 'json'\n>>> from json import load\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * 模块不需要了，del 销毁\n\ndel 销毁的只是销毁当前全局变量中的变量，并不会影响 sys.modules 中的缓存。为什么不销毁 sys.modules 中的呢？是因为该销毁的 module 可能还会在其他的文件中引用。\n\n>>> import json\n>>> import sys\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> globals()[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> del json\n>>> sys.modules[\"json\"]\n<module 'json' from '/usr/lib64/python3.6/json/__init__.py'>\n>>> globals()[\"json\"]\ntraceback (most recent call last):\n  file \"<stdin>\", line 1, in <module>\nkeyerror: 'json'\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n * module 重新加载\n\n因为每次 import 都是从 sys.modules 的缓存中获取，那么如果 module 文件变动，则无法拿到最新的 module，这个时候需要通过手动调用 importlib.reload 来重新加载，从本地文件中重新加载 module 对象到 sys.modules 中。\n\n在当前目录下创建 demo.py 文件，内容为空\n\n# demo.py\n\n>>> import demo\n>>> demo.demo\ntraceback (most recent call last):\n  file \"<stdin>\", line 1, in <module>\nattributeerror: module 'demo' has no attribute 'demo'\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n这个时候在 demo.py 中添加：\n\nclass demo:\n    pass\n\n\n1\n2\n\n\nreload demo 后，可以看到加载到 demo 了。\n\n>>> reload(demo)\n<module 'demo' from '/root/work/mydemo/demo.py'>\n>>> demo.demo\n<class 'demo.demo'>\n\n\n1\n2\n3\n4\n\n\n那如果 import 的 module 或者 package 没有在 sys.modules 中呢，这个时候就要去 sys.path 中去本地搜索了。\n\n\n# 4. 搜索路径\n\nsys.path 是一个列表，其中包含了要去搜索 module 的本地路径。当 sys.modules 中查找不到 module 时，将会从该路径中搜索到 module 文件并将其加载到 sys.modules 中来。\n\nsys.path 的路径的来源有：\n\n * 运行脚本所在的目录\n * pythonpath 环境变量\n * python 安装时的默认设置\n\n当在搜索路径找到该 module 的本地路径后，会将其加载到 sys.modules 中，然后再将其添加到当前的全局变量中。\n\n\n# 5. 总结\n\nimport 的加载过程：\n\n 1. 先从 sys.modules 中查看是否有导入的模块，有，则获取该模块，并加入到当前的全局变量中。\n 2. 如果 sys.modules 中没有需要导入的模块，则按照 sys.path 中的目录路径进行搜索找到对应的模块文件再加载到 module 对象中返回。\n\n\n# 6. 加入腾讯云开发者社区\n\n我的博客即将同步至腾讯云开发者社区，邀请大家一同入驻：https://cloud.tencent.com/developer/support-plan?invite_code=3u3wcswfaeiok",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"使用ddt实现unittest的参数化测试",frontmatter:{title:"使用ddt实现unittest的参数化测试",date:"2022-10-12T14:48:10.000Z",permalink:"/pages/8d9ab9/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文介绍如何使用ddt库来完成unitest的参数化设置。",feed:{enable:!0},tags:["python"],categories:["编程","python","第三方库"],comment:!0,meta:[{name:"twitter:title",content:"使用ddt实现unittest的参数化测试"},{name:"twitter:description",content:"本文介绍如何使用ddt库来完成unitest的参数化设置。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/01.%E4%BD%BF%E7%94%A8ddt%E5%AE%9E%E7%8E%B0unittest%E7%9A%84%E5%8F%82%E6%95%B0%E5%8C%96%E6%B5%8B%E8%AF%95.html"},{property:"og:type",content:"article"},{property:"og:title",content:"使用ddt实现unittest的参数化测试"},{property:"og:description",content:"本文介绍如何使用ddt库来完成unitest的参数化设置。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/01.%E4%BD%BF%E7%94%A8ddt%E5%AE%9E%E7%8E%B0unittest%E7%9A%84%E5%8F%82%E6%95%B0%E5%8C%96%E6%B5%8B%E8%AF%95.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-10-12T14:48:10.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"使用ddt实现unittest的参数化测试"},{itemprop:"description",content:"本文介绍如何使用ddt库来完成unitest的参数化设置。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/01.%E4%BD%BF%E7%94%A8ddt%E5%AE%9E%E7%8E%B0unittest%E7%9A%84%E5%8F%82%E6%95%B0%E5%8C%96%E6%B5%8B%E8%AF%95.html",relativePath:"04.编程/01.python/02.第三方库/01.使用ddt实现unittest的参数化测试.md",key:"v-208228f3",path:"/pages/8d9ab9/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 为什么需要参数化",slug:"_1-为什么需要参数化",normalizedTitle:"1. 为什么需要参数化",charIndex:67},{level:2,title:"2. 使用ddt实现参数化",slug:"_2-使用ddt实现参数化",normalizedTitle:"2. 使用ddt实现参数化",charIndex:677},{level:3,title:"2.1 基本使用",slug:"_2-1-基本使用",normalizedTitle:"2.1 基本使用",charIndex:733},{level:3,title:"2.2 多个值使用参数化",slug:"_2-2-多个值使用参数化",normalizedTitle:"2.2 多个值使用参数化",charIndex:1735},{level:3,title:"2.3 参数化扁平使用",slug:"_2-3-参数化扁平使用",normalizedTitle:"2.3 参数化扁平使用",charIndex:2586},{level:3,title:"2.4 命名参数",slug:"_2-4-命名参数",normalizedTitle:"2.4 命名参数",charIndex:3419},{level:3,title:"2.5 从json文件中读取参数进行单测",slug:"_2-5-从json文件中读取参数进行单测",normalizedTitle:"2.5 从json文件中读取参数进行单测",charIndex:4254},{level:2,title:"3. 总结",slug:"_3-总结",normalizedTitle:"3. 总结",charIndex:5266}],headersStr:"0. 前言 1. 为什么需要参数化 2. 使用ddt实现参数化 2.1 基本使用 2.2 多个值使用参数化 2.3 参数化扁平使用 2.4 命名参数 2.5 从json文件中读取参数进行单测 3. 总结",content:'# 0. 前言\n\n本文介绍如何使用ddt库来完成unitest的参数化设置。\n\nddt的github地址\n\nddt的官方文档\n\n\n# 1. 为什么需要参数化\n\n我们在写单测中，需要考虑到各种场景，通过输入各种场景的值执行目的的方法，来判断输出是否是我们所期待的值。\n\n如下代码代码所示，针对large_than_two方法进行了三种场景的校验写了三个单测，但其中逻辑代码是一致的，而只需要使用不同的参数值进行输入，导致有许多的重复代码进行复制粘贴。\n\nfrom unittest.case import TestCase\n\n\ndef large_than_two(value) -> bool:\n    return value > 2\n\n\nclass TestDemoCase(TestCase):\n\n    def test_larger_than_two_with_three(self):\n        self.assertTrue(large_than_two(3))\n\n    def test_larger_than_two_with_eight(self):\n        self.assertTrue(large_than_two(8))\n\n    def test_larger_than_two_with_five(self):\n        self.assertFalse(large_than_two(5))\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# 2. 使用ddt实现参数化\n\n首先需要通过pip来安装该库\n\npip install ddt\n\n\n1\n\n\n\n# 2.1 基本使用\n\n我们在TestCase上添加ddt装饰器，然后在单测方法上添加data装饰器，并添加了3种场景的输入参数，如下代码所示：\n\nfrom unittest.case import TestCase\n\nfrom ddt import ddt, data\n\n\ndef large_than_two(value) -> bool:\n    return value > 2\n\n\n@ddt\nclass TestDemoCase(TestCase):\n\n    @data(3, 8, 5)\n    def test_larger_than_two(self, value):\n        self.assertTrue(large_than_two(value))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n执行上面的单测，输入出如下：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::TestDemoCase::test_larger_than_two_with_three_1_3 PASSED   [ 33%]\ntest_demo.py::TestDemoCase::test_larger_than_two_with_three_2_8 PASSED   [ 66%]\ntest_demo.py::TestDemoCase::test_larger_than_two_with_three_3_5 PASSED   [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n会发现，虽然我们写了一个单测用例，但是却执行了3个用例，这是因为ddt会将data的3个参数分别注入到test_larger_than_two方法中value中并执行单测。\n\n在输出的单测信息中，会输出单测方法+第多少个单测+参数值来表示当前用例的执行。\n\n通过这种方式可以减少我们的重复代码。\n\n\n# 2.2 多个值使用参数化\n\n当我们需要在一个单测用例中注入多个值时，可以在data中传入多个元组进行参数化，但执行单例时，会将元组注入到value中，我们将其解开则能拿到多个值。代码如下图所示：\n\ndef greater(v1, v2) -> bool:\n    return v1 > v2\n\n\n@ddt\nclass TestDemoCase(TestCase):\n\n    @data(\n        (3, 2),\n        (4, 1),\n        (8, 6))\n    def test_greater(self, value):\n        v1, v2 = value\n        self.assertTrue(greater(v1, v2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n执行之后输出如下所示：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::TestDemoCase::test_greater_1__3__2_ PASSED                 [ 33%]\ntest_demo.py::TestDemoCase::test_greater_2__4__1_ PASSED                 [ 66%]\ntest_demo.py::TestDemoCase::test_greater_3__8__6_ PASSED                 [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.3 参数化扁平使用\n\n元组中的数据可以由ddt解开后注入到单测方法中的参数中。只需要在单测方法钱添加unpack装饰器即可。代码如下所示：\n\nfrom unittest.case import TestCase\n\nfrom ddt import ddt, data, unpack\n\n@ddt\nclass TestDemoCase(TestCase):\n\n    @unpack\n    @data(\n        (3, 2),\n        (4, 1),\n        (8, 6))\n    def test_greater(self, v1, v2):\n        self.assertTrue(greater(v1, v2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n执行后结果如下：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::TestDemoCase::test_greater_1__3__2_ PASSED                 [ 33%]\ntest_demo.py::TestDemoCase::test_greater_2__4__1_ PASSED                 [ 66%]\ntest_demo.py::TestDemoCase::test_greater_3__8__6_ PASSED                 [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.4 命名参数\n\n我们还可以给传入的参数进行命名而不是元组的形式，传入的参数名称与单测方法中参数的变量名对应，则不需要对应顺序传入，可读性更强了。代码如下：\n\n@ddt\nclass TestDemoCase(TestCase):\n\n    @unpack\n    @data(\n        {"first": 3, "second": 2},\n        {"first": 4, "second": 1},\n        {"first": 8, "second": 6}\n    )\n    def test_greater(self, second, first):\n        self.assertTrue(greater(first, second))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n执行后输出：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::TestDemoCase::test_greater_1 PASSED                        [ 33%]\ntest_demo.py::TestDemoCase::test_greater_2 PASSED                        [ 66%]\ntest_demo.py::TestDemoCase::test_greater_3 PASSED                        [100%]\n\n============================== 3 passed in 0.01s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.5 从json文件中读取参数进行单测\n\n在某些业务中，输入的参数过于复杂，并且场景繁多，如果将参数数据全部放在单测代码中，则会显得繁重，而且代码不易读，ddt提供了从json文件中读取参数来作为单测的输入数据。\n\n创建data.json文件，其中包含了参数数据。\n\n[\n  {\n    "first": 3,\n    "second": 2\n  },\n  {\n    "first": 4,\n    "second": 1\n  },\n  {\n    "first": 8,\n    "second": 6\n  }\n]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后使用file_data作为单测方法的装饰器，并传入上面数据文件的路径。\n\nfrom ddt import ddt, file_data\n\n@ddt\nclass TestDemoCase(TestCase):\n\n    @file_data("data.json")\n    def test_greater(self, second, first):\n        self.assertTrue(greater(first, second))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n执行成功并输出：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::TestDemoCase::test_greater_1 PASSED                        [ 33%]\ntest_demo.py::TestDemoCase::test_greater_2 PASSED                        [ 66%]\ntest_demo.py::TestDemoCase::test_greater_3 PASSED                        [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 3. 总结\n\n本文是介绍ddt的基本并常用的用法，如果想要深入使用可以参考官方文档。\n\n其实ddt有个缺点是不能针对某一个单测方法进行单独的执行，必须要运行整个Unittest class才行，这样在调试的过程中非常不方便。\n\n如果你看到本文其实我比较推荐你使用pytest来替代unittest使用，pytest中也有参数化的使用，并且可以单独的去运行每一个单测。\n\n我是因为在做一个django项目，其中使用的是django test来写单测的，而django test是基于Unittest来实现的，所以只能使用ddt来实现参数化。',normalizedContent:'# 0. 前言\n\n本文介绍如何使用ddt库来完成unitest的参数化设置。\n\nddt的github地址\n\nddt的官方文档\n\n\n# 1. 为什么需要参数化\n\n我们在写单测中，需要考虑到各种场景，通过输入各种场景的值执行目的的方法，来判断输出是否是我们所期待的值。\n\n如下代码代码所示，针对large_than_two方法进行了三种场景的校验写了三个单测，但其中逻辑代码是一致的，而只需要使用不同的参数值进行输入，导致有许多的重复代码进行复制粘贴。\n\nfrom unittest.case import testcase\n\n\ndef large_than_two(value) -> bool:\n    return value > 2\n\n\nclass testdemocase(testcase):\n\n    def test_larger_than_two_with_three(self):\n        self.asserttrue(large_than_two(3))\n\n    def test_larger_than_two_with_eight(self):\n        self.asserttrue(large_than_two(8))\n\n    def test_larger_than_two_with_five(self):\n        self.assertfalse(large_than_two(5))\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# 2. 使用ddt实现参数化\n\n首先需要通过pip来安装该库\n\npip install ddt\n\n\n1\n\n\n\n# 2.1 基本使用\n\n我们在testcase上添加ddt装饰器，然后在单测方法上添加data装饰器，并添加了3种场景的输入参数，如下代码所示：\n\nfrom unittest.case import testcase\n\nfrom ddt import ddt, data\n\n\ndef large_than_two(value) -> bool:\n    return value > 2\n\n\n@ddt\nclass testdemocase(testcase):\n\n    @data(3, 8, 5)\n    def test_larger_than_two(self, value):\n        self.asserttrue(large_than_two(value))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n执行上面的单测，输入出如下：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::testdemocase::test_larger_than_two_with_three_1_3 passed   [ 33%]\ntest_demo.py::testdemocase::test_larger_than_two_with_three_2_8 passed   [ 66%]\ntest_demo.py::testdemocase::test_larger_than_two_with_three_3_5 passed   [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n会发现，虽然我们写了一个单测用例，但是却执行了3个用例，这是因为ddt会将data的3个参数分别注入到test_larger_than_two方法中value中并执行单测。\n\n在输出的单测信息中，会输出单测方法+第多少个单测+参数值来表示当前用例的执行。\n\n通过这种方式可以减少我们的重复代码。\n\n\n# 2.2 多个值使用参数化\n\n当我们需要在一个单测用例中注入多个值时，可以在data中传入多个元组进行参数化，但执行单例时，会将元组注入到value中，我们将其解开则能拿到多个值。代码如下图所示：\n\ndef greater(v1, v2) -> bool:\n    return v1 > v2\n\n\n@ddt\nclass testdemocase(testcase):\n\n    @data(\n        (3, 2),\n        (4, 1),\n        (8, 6))\n    def test_greater(self, value):\n        v1, v2 = value\n        self.asserttrue(greater(v1, v2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n执行之后输出如下所示：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::testdemocase::test_greater_1__3__2_ passed                 [ 33%]\ntest_demo.py::testdemocase::test_greater_2__4__1_ passed                 [ 66%]\ntest_demo.py::testdemocase::test_greater_3__8__6_ passed                 [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.3 参数化扁平使用\n\n元组中的数据可以由ddt解开后注入到单测方法中的参数中。只需要在单测方法钱添加unpack装饰器即可。代码如下所示：\n\nfrom unittest.case import testcase\n\nfrom ddt import ddt, data, unpack\n\n@ddt\nclass testdemocase(testcase):\n\n    @unpack\n    @data(\n        (3, 2),\n        (4, 1),\n        (8, 6))\n    def test_greater(self, v1, v2):\n        self.asserttrue(greater(v1, v2))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n执行后结果如下：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::testdemocase::test_greater_1__3__2_ passed                 [ 33%]\ntest_demo.py::testdemocase::test_greater_2__4__1_ passed                 [ 66%]\ntest_demo.py::testdemocase::test_greater_3__8__6_ passed                 [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.4 命名参数\n\n我们还可以给传入的参数进行命名而不是元组的形式，传入的参数名称与单测方法中参数的变量名对应，则不需要对应顺序传入，可读性更强了。代码如下：\n\n@ddt\nclass testdemocase(testcase):\n\n    @unpack\n    @data(\n        {"first": 3, "second": 2},\n        {"first": 4, "second": 1},\n        {"first": 8, "second": 6}\n    )\n    def test_greater(self, second, first):\n        self.asserttrue(greater(first, second))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n执行后输出：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::testdemocase::test_greater_1 passed                        [ 33%]\ntest_demo.py::testdemocase::test_greater_2 passed                        [ 66%]\ntest_demo.py::testdemocase::test_greater_3 passed                        [100%]\n\n============================== 3 passed in 0.01s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 2.5 从json文件中读取参数进行单测\n\n在某些业务中，输入的参数过于复杂，并且场景繁多，如果将参数数据全部放在单测代码中，则会显得繁重，而且代码不易读，ddt提供了从json文件中读取参数来作为单测的输入数据。\n\n创建data.json文件，其中包含了参数数据。\n\n[\n  {\n    "first": 3,\n    "second": 2\n  },\n  {\n    "first": 4,\n    "second": 1\n  },\n  {\n    "first": 8,\n    "second": 6\n  }\n]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后使用file_data作为单测方法的装饰器，并传入上面数据文件的路径。\n\nfrom ddt import ddt, file_data\n\n@ddt\nclass testdemocase(testcase):\n\n    @file_data("data.json")\n    def test_greater(self, second, first):\n        self.asserttrue(greater(first, second))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n执行成功并输出：\n\n============================= test session starts =============================\ncollecting ... collected 3 items\n\ntest_demo.py::testdemocase::test_greater_1 passed                        [ 33%]\ntest_demo.py::testdemocase::test_greater_2 passed                        [ 66%]\ntest_demo.py::testdemocase::test_greater_3 passed                        [100%]\n\n============================== 3 passed in 0.02s ==============================\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 3. 总结\n\n本文是介绍ddt的基本并常用的用法，如果想要深入使用可以参考官方文档。\n\n其实ddt有个缺点是不能针对某一个单测方法进行单独的执行，必须要运行整个unittest class才行，这样在调试的过程中非常不方便。\n\n如果你看到本文其实我比较推荐你使用pytest来替代unittest使用，pytest中也有参数化的使用，并且可以单独的去运行每一个单测。\n\n我是因为在做一个django项目，其中使用的是django test来写单测的，而django test是基于unittest来实现的，所以只能使用ddt来实现参数化。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"ddt源码分析",frontmatter:{title:"ddt源码分析",date:"2022-10-23T20:04:51.000Z",permalink:"/pages/069c65/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"ddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，本文介绍源码解析该库，理解它的实现过程。",feed:{enable:!0},tags:["python"],categories:["编程","python","第三方库"],comment:!0,meta:[{name:"twitter:title",content:"ddt源码分析"},{name:"twitter:description",content:"ddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，本文介绍源码解析该库，理解它的实现过程。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/02.ddt%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"ddt源码分析"},{property:"og:description",content:"ddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，本文介绍源码解析该库，理解它的实现过程。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/02.ddt%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-10-23T20:04:51.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"ddt源码分析"},{itemprop:"description",content:"ddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，本文介绍源码解析该库，理解它的实现过程。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/02.ddt%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html",relativePath:"04.编程/01.python/02.第三方库/02.ddt源码分析.md",key:"v-4534d8ad",path:"/pages/069c65/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 源码分析",slug:"_1-源码分析",normalizedTitle:"1. 源码分析",charIndex:177},{level:3,title:"1.1 example",slug:"_1-1-example",normalizedTitle:"1.1 example",charIndex:189},{level:3,title:"1.2 源码分析流程",slug:"_1-2-源码分析流程",normalizedTitle:"1.2 源码分析流程",charIndex:2004},{level:2,title:"2. 总结",slug:"_2-总结",normalizedTitle:"2. 总结",charIndex:5859}],headersStr:"0. 前言 1. 源码分析 1.1 example 1.2 源码分析流程 2. 总结",content:'# 0. 前言\n\nddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，这个库的使用方法可以参考我之前写的使用ddt实现unittest的参数化测试。本文主要是讲自己在学习 ddt 库时所获。\n\nddt 库的使用方法是用装饰器来实现的，可以参考这边文章python装饰器的使用方法来学习装饰器.\n\n\n# 1. 源码分析\n\n\n# 1.1 example\n\n先看一个最简单的使用例子，我们创建 larger_than_two 函数，并使用 unittest 对其编写单测。\n\n这里使用了 @ddt 来装饰 DemoTestCase，并使用 @data 填写多个测试的参数，这样执行就完成了参数化的单测了。\n\nimport unittest  \nfrom ddt import ddt, data  \n  \n  \ndef larger_than_two(value):  \n    return value > 2  \n  \n  \n@ddt  \nclass DemoTestCase(unittest.TestCase):  \n  \n    @data(1, 2, 3)  \n    def test_larger_than_two(self, value):  \n        self.assertTrue(larger_than_two(value))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n我们执行上面的单测会发现，虽然我们代码只写了一个用例，但是执行却是 3 个用例，成功了 1 个，失败了 2 个，并且输出了失败的用例的名称，test_larger_than_two_1_1 和 test_larger_than_two_2_2，名称的规则是：单测的名称_索引_参数。\n\nFF.\n======================================================================\nFAIL: test_larger_than_two_1_1 (__main__.DemoTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File "c:\\crazyboy\\code\\ddt\\ddt.py", line 220, in wrapper\n    return func(self, *args, **kwargs)\n  File "C:\\CrazyBoy\\workspace\\demo\\demo.py", line 24, in test_larger_than_two\n    self.assertTrue(larger_than_two(value))\nAssertionError: False is not true\n\n======================================================================\nFAIL: test_larger_than_two_2_2 (__main__.DemoTestCase)\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File "c:\\crazyboy\\code\\ddt\\ddt.py", line 220, in wrapper\n    return func(self, *args, **kwargs)\n  File "C:\\CrazyBoy\\workspace\\demo\\demo.py", line 24, in test_larger_than_two\n    self.assertTrue(larger_than_two(value))\nAssertionError: False is not true\n\n----------------------------------------------------------------------\nRan 3 tests in 0.004s\n\nFAILED (failures=2)\n\nProcess finished with exit code 1\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n这是如何实现的呢？\n\n\n# 1.2 源码分析流程\n\n我们首先来看看 @data 装饰器里面做了什么？\n\ndef data(*values):  \n    return idata(values)\n\n\n1\n2\n\n\ndata 调用了函数 idata，我们再来看看 idata 的实现，通过 setattr 方法，给被装饰的单测用例添加两个属性\n\n * DATA_ATTR 是用来保存 data 的参数化的参数。\n * INDEX_LEN 用来保存参数化的长度。\n\nDATA_ATTR = \'%values\'\nINDEX_LEN = \'%index_len\'\n\ndef idata(iterable, index_len=None):  \n    if index_len is None:  \n        iterable = tuple(iterable)  \n        index_len = len(str(len(iterable)))  \n  \n    def wrapper(func):  \n        setattr(func, DATA_ATTR, iterable)  \n        setattr(func, INDEX_LEN, index_len)  \n        return func  \n  \n    return wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后我们再来看装饰器@ddt 中，传入的 cls 是被装饰的单测类，通过该类，找到上面使用@data 装饰器中添加的属性 DATA_ATTR 和对应的单测方法，其中的每条数据都是一个用例，通过遍历该属性中的参数值调用函数 mk_test_name 去构造每一条参数的用例名称。\n\n然后再调用 add_test 函数去生成对应的单测用例。\n\ndef ddt(arg=None, **kwargs):\n\tfmt_test_name = kwargs.get("testNameFormat", TestNameFormat.DEFAULT)  \n\t  \n\tdef wrapper(cls):  \n\t    for name, func in list(cls.__dict__.items()):  \n\t        if hasattr(func, DATA_ATTR):  \n\t            index_len = getattr(func, INDEX_LEN)  \n\t            for i, v in enumerate(getattr(func, DATA_ATTR)):  \n\t                test_name = mk_test_name(  \n\t                    name,  \n\t                    getattr(v, "__name__", v),  \n\t                    i,  \n\t                    index_len,  \n\t                    fmt_test_name  \n\t                )  \n\t                test_data_docstring = _get_test_data_docstring(func, v)  \n\t                if hasattr(func, UNPACK_ATTR):  \n\t                    if isinstance(v, tuple) or isinstance(v, list):  \n\t                        add_test(  \n\t                            cls,  \n\t                            test_name,  \n\t                            test_data_docstring,  \n\t                            func,  \n\t                            *v  \n\t                        )  \n\t                    else:  \n\t                        # unpack dictionary  \n\t                        add_test(  \n\t                            cls,  \n\t                            test_name,  \n\t                            test_data_docstring,  \n\t                            func,  \n\t                            **v  \n\t                        )  \n\t                else:  \n\t                    add_test(cls, test_name, test_data_docstring, func, v)  \n\t            delattr(cls, name)  \n\t        elif hasattr(func, FILE_ATTR):  \n\t            file_attr = getattr(func, FILE_ATTR)  \n\t            process_file_data(cls, name, func, file_attr)  \n\t            delattr(cls, name)  \n\t    return cls  \n\t  \n\t# ``arg`` is the unittest\'s test class when decorating with ``@ddt`` while  \n\t# it is ``None`` when decorating a test class with ``@ddt(k=v)``.  \n\treturn wrapper(arg) if inspect.isclass(arg) else wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n\n\n我们看看 add_test 做了什么？很简单，就是给单测的 TestCase 添加属性，以单测用例名称为名，feed_data 的返回值为值。\n\nfeed_data 中，根据单个参数值和被@data 装饰的函数组成一个新的单测用例，并返回出去。\n\ndef add_test(cls, test_name, test_docstring, func, *args, **kwargs):  \n\tsetattr(cls, test_name, feed_data(func, test_name, test_docstring, *args, **kwargs))\n\ndef feed_data(func, new_name, test_data_docstring, *args, **kwargs):      \n    @wraps(func)  \n    def wrapper(self):  \n        return func(self, *args, **kwargs)  \n    wrapper.__name__ = new_name  \n    wrapper.__wrapped__ = func  \n    # set docstring if exists  \n    if test_data_docstring is not None:  \n        wrapper.__doc__ = test_data_docstring  \n    else:  \n        # Try to call format on the docstring  \n        if func.__doc__:  \n            try:  \n                wrapper.__doc__ = func.__doc__.format(*args, **kwargs)  \n            except (IndexError, KeyError):  \n\t\t\t\tpass  \n    return wrapper\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n也就是说，参数化的每个值都会生成一个用例方法并注册到被@ddt 装饰的 TestCase 类中。\n\n\n# 2. 总结\n\n主要流程是：通过 @data 装饰器将参数化注册到该单测用例方法的 DATA_ATTR 属性中，然后@ddt 装饰器遍历当前 TestCase 的所有包含 DATA_ATTR 属性的用例方法，再遍历其 DATA_ATTR 的参数值，把每条参数值都生成一条用例方法，并注册到 TestCase 中。这样执行该 TestCase 时，虽然只编码了一条单测，但是却有多条用例被执行。\n\n整个过程都是对类和单测方法的元数据属性进行各种操作来实现的。',normalizedContent:'# 0. 前言\n\nddt 是 python 的第三方库，主要是解决使用 unittest 来写单测时可以支持参数化的配置，这个库的使用方法可以参考我之前写的使用ddt实现unittest的参数化测试。本文主要是讲自己在学习 ddt 库时所获。\n\nddt 库的使用方法是用装饰器来实现的，可以参考这边文章python装饰器的使用方法来学习装饰器.\n\n\n# 1. 源码分析\n\n\n# 1.1 example\n\n先看一个最简单的使用例子，我们创建 larger_than_two 函数，并使用 unittest 对其编写单测。\n\n这里使用了 @ddt 来装饰 demotestcase，并使用 @data 填写多个测试的参数，这样执行就完成了参数化的单测了。\n\nimport unittest  \nfrom ddt import ddt, data  \n  \n  \ndef larger_than_two(value):  \n    return value > 2  \n  \n  \n@ddt  \nclass demotestcase(unittest.testcase):  \n  \n    @data(1, 2, 3)  \n    def test_larger_than_two(self, value):  \n        self.asserttrue(larger_than_two(value))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n我们执行上面的单测会发现，虽然我们代码只写了一个用例，但是执行却是 3 个用例，成功了 1 个，失败了 2 个，并且输出了失败的用例的名称，test_larger_than_two_1_1 和 test_larger_than_two_2_2，名称的规则是：单测的名称_索引_参数。\n\nff.\n======================================================================\nfail: test_larger_than_two_1_1 (__main__.demotestcase)\n----------------------------------------------------------------------\ntraceback (most recent call last):\n  file "c:\\crazyboy\\code\\ddt\\ddt.py", line 220, in wrapper\n    return func(self, *args, **kwargs)\n  file "c:\\crazyboy\\workspace\\demo\\demo.py", line 24, in test_larger_than_two\n    self.asserttrue(larger_than_two(value))\nassertionerror: false is not true\n\n======================================================================\nfail: test_larger_than_two_2_2 (__main__.demotestcase)\n----------------------------------------------------------------------\ntraceback (most recent call last):\n  file "c:\\crazyboy\\code\\ddt\\ddt.py", line 220, in wrapper\n    return func(self, *args, **kwargs)\n  file "c:\\crazyboy\\workspace\\demo\\demo.py", line 24, in test_larger_than_two\n    self.asserttrue(larger_than_two(value))\nassertionerror: false is not true\n\n----------------------------------------------------------------------\nran 3 tests in 0.004s\n\nfailed (failures=2)\n\nprocess finished with exit code 1\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n这是如何实现的呢？\n\n\n# 1.2 源码分析流程\n\n我们首先来看看 @data 装饰器里面做了什么？\n\ndef data(*values):  \n    return idata(values)\n\n\n1\n2\n\n\ndata 调用了函数 idata，我们再来看看 idata 的实现，通过 setattr 方法，给被装饰的单测用例添加两个属性\n\n * data_attr 是用来保存 data 的参数化的参数。\n * index_len 用来保存参数化的长度。\n\ndata_attr = \'%values\'\nindex_len = \'%index_len\'\n\ndef idata(iterable, index_len=none):  \n    if index_len is none:  \n        iterable = tuple(iterable)  \n        index_len = len(str(len(iterable)))  \n  \n    def wrapper(func):  \n        setattr(func, data_attr, iterable)  \n        setattr(func, index_len, index_len)  \n        return func  \n  \n    return wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后我们再来看装饰器@ddt 中，传入的 cls 是被装饰的单测类，通过该类，找到上面使用@data 装饰器中添加的属性 data_attr 和对应的单测方法，其中的每条数据都是一个用例，通过遍历该属性中的参数值调用函数 mk_test_name 去构造每一条参数的用例名称。\n\n然后再调用 add_test 函数去生成对应的单测用例。\n\ndef ddt(arg=none, **kwargs):\n\tfmt_test_name = kwargs.get("testnameformat", testnameformat.default)  \n\t  \n\tdef wrapper(cls):  \n\t    for name, func in list(cls.__dict__.items()):  \n\t        if hasattr(func, data_attr):  \n\t            index_len = getattr(func, index_len)  \n\t            for i, v in enumerate(getattr(func, data_attr)):  \n\t                test_name = mk_test_name(  \n\t                    name,  \n\t                    getattr(v, "__name__", v),  \n\t                    i,  \n\t                    index_len,  \n\t                    fmt_test_name  \n\t                )  \n\t                test_data_docstring = _get_test_data_docstring(func, v)  \n\t                if hasattr(func, unpack_attr):  \n\t                    if isinstance(v, tuple) or isinstance(v, list):  \n\t                        add_test(  \n\t                            cls,  \n\t                            test_name,  \n\t                            test_data_docstring,  \n\t                            func,  \n\t                            *v  \n\t                        )  \n\t                    else:  \n\t                        # unpack dictionary  \n\t                        add_test(  \n\t                            cls,  \n\t                            test_name,  \n\t                            test_data_docstring,  \n\t                            func,  \n\t                            **v  \n\t                        )  \n\t                else:  \n\t                    add_test(cls, test_name, test_data_docstring, func, v)  \n\t            delattr(cls, name)  \n\t        elif hasattr(func, file_attr):  \n\t            file_attr = getattr(func, file_attr)  \n\t            process_file_data(cls, name, func, file_attr)  \n\t            delattr(cls, name)  \n\t    return cls  \n\t  \n\t# ``arg`` is the unittest\'s test class when decorating with ``@ddt`` while  \n\t# it is ``none`` when decorating a test class with ``@ddt(k=v)``.  \n\treturn wrapper(arg) if inspect.isclass(arg) else wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n\n\n我们看看 add_test 做了什么？很简单，就是给单测的 testcase 添加属性，以单测用例名称为名，feed_data 的返回值为值。\n\nfeed_data 中，根据单个参数值和被@data 装饰的函数组成一个新的单测用例，并返回出去。\n\ndef add_test(cls, test_name, test_docstring, func, *args, **kwargs):  \n\tsetattr(cls, test_name, feed_data(func, test_name, test_docstring, *args, **kwargs))\n\ndef feed_data(func, new_name, test_data_docstring, *args, **kwargs):      \n    @wraps(func)  \n    def wrapper(self):  \n        return func(self, *args, **kwargs)  \n    wrapper.__name__ = new_name  \n    wrapper.__wrapped__ = func  \n    # set docstring if exists  \n    if test_data_docstring is not none:  \n        wrapper.__doc__ = test_data_docstring  \n    else:  \n        # try to call format on the docstring  \n        if func.__doc__:  \n            try:  \n                wrapper.__doc__ = func.__doc__.format(*args, **kwargs)  \n            except (indexerror, keyerror):  \n\t\t\t\tpass  \n    return wrapper\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n也就是说，参数化的每个值都会生成一个用例方法并注册到被@ddt 装饰的 testcase 类中。\n\n\n# 2. 总结\n\n主要流程是：通过 @data 装饰器将参数化注册到该单测用例方法的 data_attr 属性中，然后@ddt 装饰器遍历当前 testcase 的所有包含 data_attr 属性的用例方法，再遍历其 data_attr 的参数值，把每条参数值都生成一条用例方法，并注册到 testcase 中。这样执行该 testcase 时，虽然只编码了一条单测，但是却有多条用例被执行。\n\n整个过程都是对类和单测方法的元数据属性进行各种操作来实现的。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django-apschedule定时任务异常停止",frontmatter:{title:"django-apschedule定时任务异常停止",date:"2023-10-30T16:53:28.000Z",permalink:"/pages/ec5110/",categories:["编程","python","第三方库"],tags:["python","django"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"在django项目中使用`django-apschedule`来实现定时任务，使用的是`BackgroundScheduler`调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。",comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"django-apschedule定时任务异常停止"},{name:"twitter:description",content:"在django项目中使用`django-apschedule`来实现定时任务，使用的是`BackgroundScheduler`调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/03.django-apschedule%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8%E5%81%9C%E6%AD%A2.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django-apschedule定时任务异常停止"},{property:"og:description",content:"在django项目中使用`django-apschedule`来实现定时任务，使用的是`BackgroundScheduler`调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/03.django-apschedule%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8%E5%81%9C%E6%AD%A2.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-10-30T16:53:28.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django-apschedule定时任务异常停止"},{itemprop:"description",content:"在django项目中使用`django-apschedule`来实现定时任务，使用的是`BackgroundScheduler`调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/02.%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93/03.django-apschedule%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E5%BC%82%E5%B8%B8%E5%81%9C%E6%AD%A2.html",relativePath:"04.编程/01.python/02.第三方库/03.django-apschedule定时任务异常停止.md",key:"v-98683fbe",path:"/pages/ec5110/",headers:[{level:2,title:"背景",slug:"背景",normalizedTitle:"背景",charIndex:2},{level:2,title:"源码分析原因",slug:"源码分析原因",normalizedTitle:"源码分析原因",charIndex:3211},{level:2,title:"搭建demo",slug:"搭建demo",normalizedTitle:"搭建demo",charIndex:5215},{level:2,title:"线程重启",slug:"线程重启",normalizedTitle:"线程重启",charIndex:7380},{level:2,title:"listener",slug:"listener",normalizedTitle:"listener",charIndex:7666},{level:2,title:"捕获线程中函数的异常",slug:"捕获线程中函数的异常",normalizedTitle:"捕获线程中函数的异常",charIndex:8659},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:9435}],headersStr:"背景 源码分析原因 搭建demo 线程重启 listener 捕获线程中函数的异常 相关链接",content:'# 背景\n\n在django项目中使用django-apschedule来实现定时任务，使用的是BackgroundScheduler调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。\n\n在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。\n\n具体的错误日志如下，通过分析，是update_job连接数据库异常，没有任何捕获机制，然后层层网上抛，最终导致线程停止，可以很肯定的是，绝对是因为数据库连接失败导致的定时任务失败，那为什么无法复现呢？\n\nTraceback (most recent call last):\n  File "/usr/local/python3/lib/python3.7/threading.py", line 926, in _bootstrap_inner\n    self.run()\n  File "/usr/local/python3/lib/python3.7/threading.py", line 870, in run\n    self._target(*self._args, **self._kwargs)\n  File "/usr/local/python3/lib/python3.7/site-packages/apscheduler/schedulers/blocking.py", line 32, in _main_loop\n    wait_seconds = self._process_jobs()\n  File "/usr/local/python3/lib/python3.7/site-packages/apscheduler/schedulers/base.py", line 1009, in _process_jobs\n    jobstore.update_job(job)\n  File "/usr/local/python3/lib/python3.7/site-packages/django_apscheduler/util.py", line 105, in func_wrapper\n    result = func(*args, **kwargs)\n  File "/usr/local/python3/lib/python3.7/site-packages/django_apscheduler/jobstores.py", line 249, in update_job\n    with transaction.atomic():\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/transaction.py", line 189, in __enter__\n    if not connection.get_autocommit():\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 389, in get_autocommit\n    self.ensure_connection()\n  File "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n     return func(*args, **kwargs)\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 219, in ensure_connection\n    self.connect()\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/utils.py", line 90, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 219, in ensure_connection\n    self.connect()\n  File "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n    return func(*args, **kwargs)\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 200, in connect\n    self.connection = self.get_new_connection(conn_params)\n  File "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n    return func(*args, **kwargs)\n  File "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/postgresql/base.py", line 187, in get_new_connection\n    connection = Database.connect(**conn_params)\n  File "/usr/local/python3/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect\n    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\ndjango.db.utils.OperationalError: connection to server at "xxxx.postgresql.svc.cluster.local" (xx.xx.xx.xx), port xxxx failed: server closed the connection unexpectedly\nThis probably means the server terminated abnormally\nbefore or while processing the request.\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# 源码分析原因\n\n可以先看下BackgroundScheduler的实现方式，在start方法中创建了个子线程。\n\nclass BackgroundScheduler(BlockingScheduler):\n\n    _thread = None\n\n    def start(self, *args, **kwargs):\n        if self._event is None or self._event.is_set():\n            self._event = Event()\n\n        BaseScheduler.start(self, *args, **kwargs)\n        self._thread = Thread(target=self._main_loop, name=\'APScheduler\')\n        self._thread.daemon = self._daemon\n        self._thread.start()\n\n    def shutdown(self, *args, **kwargs):\n        super(BackgroundScheduler, self).shutdown(*args, **kwargs)\n        self._thread.join()\n        del self._thread\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n其中_main_loop在BlockingScheduler中实现，是一个死循环，执行_process_jobs方法\n\nclass BlockingScheduler(BaseScheduler):\n    \n    ...\n\n    def _main_loop(self):\n        wait_seconds = TIMEOUT_MAX\n        while self.state != STATE_STOPPED:\n            self._event.wait(wait_seconds)\n            self._event.clear()\n            wait_seconds = self._process_jobs()\n    \n    ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n再看_process_jobs中的内容，在BaseScheduler实现的，主要流程如下，先找到所有要执行的job，然后进行遍历运行并更新Job的状态。之前的错误日志，也就是这里的update_job抛出异常，而这里并没有捕获异常，最终层层往上抛，update_job -> _process_jobs -> _main_loop，最终线程异常终止。\n\ndef _process_jobs(self):\n    for jobstore_alias, jobstore in six.iteritems(self._jobstores):\n        try:\n            due_jobs = jobstore.get_due_jobs(now)\n        except Exception as e:\n            ...\n            continue\n\n        ...\n                \n        for job in due_jobs:\n      \n            ...\n            \n            try:\n                executor.submit_job(job, run_times)\n            except BaseException:\n                ...\n\n            ...\n            jobstore.update_job(job)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n那为什么复现不了呢？这个是因为，关闭数据库连接时，程序不一定可以正好运行在update_job，可以看到前面的get_due_jobs进行了异常捕获，如果这里抛出数据库连接异常是可以捕获到的，然后跳过后面的操作，等待下一次定时任务的执行，如果还是失败，则再次等待，所以这里的异常不会抛到最上层导致线程停止。\n\n但如果某个时机，上面连接数据库都成功了，到update_job这里异常抛出，则会导致整个线程停止，定时任务不再执行。\n\n那如何解决该问题呢？\n\n\n# 搭建demo\n\n首先我们搭建一个demo出来，模拟复现该问题。\n\n 1. 创建django项目\n\n\ndjango-admin startproject apschedule_demo\n\npython manage.py startapp demo\n\npython manage.py makemigrations\n\npython manage.py migrate\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 2. 在settings.py中配置到好数据库信息\n\nDATABASES = {\n    "default": {\n        "ENGINE": "django.db.backends.postgresql",\n        "NAME": "apschedule_demo",\n        "HOST": "xxxx",\n        "PORT": 5432,\n        "USER": "xxx",\n        "PASSWORD": "xxx"\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 3. 根据django-apschedule官方提供的文档搭建demo\n\n在settings.py中添加该APP\n\nINSTALLED_APPS = (\n    # ...\n    "django_apscheduler",\n)\n\n\n1\n2\n3\n4\n\n\n创建目录demo/management/commands，并在其下面创建runapscheduler.py文件，代码内容如下：\n\nimport logging\n\nfrom django.conf import settings\n\nfrom apscheduler.schedulers.blocking import BlockingScheduler\nfrom apscheduler.triggers.cron import CronTrigger\nfrom django.core.management.base import BaseCommand\nfrom django_apscheduler.jobstores import DjangoJobStore\n\nlogger = logging.getLogger(__name__)\n\n\ndef my_job():\n  # Your job processing logic here...\n  print("job..")\n\n\nclass Command(BaseCommand):\n  help = "Runs APScheduler."\n\n  def handle(self, *args, **options):\n    scheduler = BlockingScheduler(timezone=settings.TIME_ZONE)\n    scheduler.add_jobstore(DjangoJobStore(), "default")\n\n    scheduler.add_job(\n      my_job,\n      trigger=CronTrigger(second="*/3"),  # Every 3 seconds\n      id="my_job",  # The `id` assigned to each job MUST be unique\n      max_instances=1,\n      replace_existing=True,\n    )\n    logger.info("Added job \'my_job\'.")\n\n    try:\n      logger.info("Starting scheduler...")\n      scheduler.start()\n\n    # 因为上面是非阻塞开启定时任务，所以这里需要阻塞，不让主线程结束。\n    while True:\n            time.sleep(10)\n    except KeyboardInterrupt:\n      logger.info("Stopping scheduler...")\n      scheduler.shutdown()\n      logger.info("Scheduler shut down successfully!")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n\n\n可以通过python manage.py runapscheduler执行上面的命令运行定时任务，该脚本创建了一个每3秒执行一次的任务。\n\n 4. 复现\n\n我们将断点打在jobstore.update_job(job)上，然后使用debug模式进行调试，当程序运行到断点上时，将数据库关闭，然后程序继续运行，则会报错，并抛出异常，线程停止了运行。至此，我们复现了该问题。\n\n\n# 线程重启\n\n我一开始想，我可以判断该线程是否异常，如果异常则将线程重启就好了\n\n    while True:\n        if not scheduler._thread.is_alive():\n            scheduler._thread.start()\n\n        time.sleep(10)\n\n\n1\n2\n3\n4\n5\n\n\n但事与愿违，抛出了异常，异常信息如下：\n\nRuntimeError: threads can only be started once\n\n\n1\n\n\n通过查看官方文档可以知道，线程的start方法只能调用一次。\n\n\n# listener\n\napschedule中提供了监听器机制，也就是在定时任务的成功、失败等状态都可以通过提前注册的listener方法来进行回调。但通过分析源码，其并不能捕获到定时任务线程的异常。\n\n下面是简化了代码的listeners的原理流程：\n\n 1. 外部通过add_listener方法注册回调方法\n 2. 在定时任务线程主流程_process_jobs中发生的各个事件添加到events中\n 3. 遍历events事件，然后通过与注册的回调方法mask进行匹配，匹配上则调用回调方法\n\nclass BaseScheduler:\n    def __init__(...):\n        self._listeners = []\n\n    def add_listener(self, callback, mask=EVENT_ALL):\n        self._listeners.append((callback, mask))\n\n    def _process_jobs(self):\n\n        events = []\n        \n        ...\n\n        events.append(event)\n \n        ...\n\n\n        for event in events:\n            self._dispatch_event(event)\n\n\n    def _dispatch_event(self, event):\n        for cb, mask in listeners:\n            if event.code & mask:\n                try:\n                    cb(event)\n                except BaseException:\n                    self._logger.exception(\'Error notifying listener\')\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n如果线程本身挂了，回调方法是不可执行的。\n\n\n# 捕获线程中函数的异常\n\n如果update_job抛出异常导致线程停止，那我捕获它的异常，然后再continue，等待下次定时任务运行再重试不就好了，但是这就需要改动源码，能不能改源码就尽量不改。所以这边我采用了继承BackgroundScheduler类，然后再重写_process_jobs方法来解决。\n\n在重写的_process_jobs方法中，对父类的_process_jobs()进行异常的捕获，然后再不断的进行重试，这样即使update_job抛出异常了，也可以不断的进行尝试恢复，直至成功。\n\nclass DemoBackgroundScheduler(BackgroundScheduler):\n    def _process_jobs(self):\n        while True:\n            try:\n                return super()._process_jobs()\n            except BaseException:\n                time.sleep(5)\n\nclass Command(BaseCommand):\n    help = "Runs APScheduler."\n\n    def handle(self, *args, **options):\n        scheduler = DemoBackgroundScheduler(timezone=settings.TIME_ZONE)\n        ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后再次尝试复现该问题，可以发现在断开数据库后，它能够一直进行重试，线程没有停止，当数据库恢复运行后，job执行成功，不再抛出异常。\n\n\n# 相关链接\n\n * APScheduler官方文档',normalizedContent:'# 背景\n\n在django项目中使用django-apschedule来实现定时任务，使用的是backgroundscheduler调度类，该调度的实现是通过后台线程的方式执行定时任务。其中任务都是持久化到数据库中的。\n\n在项目的运行过程中，因为数据库的异常，导致定时任务线程异常终止，即使数据库后续恢复正常，但也不再继续执行。我多次尝试复现未果，在开启定时任务期间，手动将数据库连接断开，定时任务执行失败，然后再将数据库建立连接，定时任务竟然重新恢复了，这让我一时摸不着头脑。\n\n具体的错误日志如下，通过分析，是update_job连接数据库异常，没有任何捕获机制，然后层层网上抛，最终导致线程停止，可以很肯定的是，绝对是因为数据库连接失败导致的定时任务失败，那为什么无法复现呢？\n\ntraceback (most recent call last):\n  file "/usr/local/python3/lib/python3.7/threading.py", line 926, in _bootstrap_inner\n    self.run()\n  file "/usr/local/python3/lib/python3.7/threading.py", line 870, in run\n    self._target(*self._args, **self._kwargs)\n  file "/usr/local/python3/lib/python3.7/site-packages/apscheduler/schedulers/blocking.py", line 32, in _main_loop\n    wait_seconds = self._process_jobs()\n  file "/usr/local/python3/lib/python3.7/site-packages/apscheduler/schedulers/base.py", line 1009, in _process_jobs\n    jobstore.update_job(job)\n  file "/usr/local/python3/lib/python3.7/site-packages/django_apscheduler/util.py", line 105, in func_wrapper\n    result = func(*args, **kwargs)\n  file "/usr/local/python3/lib/python3.7/site-packages/django_apscheduler/jobstores.py", line 249, in update_job\n    with transaction.atomic():\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/transaction.py", line 189, in __enter__\n    if not connection.get_autocommit():\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 389, in get_autocommit\n    self.ensure_connection()\n  file "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n     return func(*args, **kwargs)\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 219, in ensure_connection\n    self.connect()\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/utils.py", line 90, in __exit__\n    raise dj_exc_value.with_traceback(traceback) from exc_value\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 219, in ensure_connection\n    self.connect()\n  file "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n    return func(*args, **kwargs)\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/base/base.py", line 200, in connect\n    self.connection = self.get_new_connection(conn_params)\n  file "/usr/local/python3/lib/python3.7/site-packages/django/utils/asyncio.py", line 33, in inner\n    return func(*args, **kwargs)\n  file "/usr/local/python3/lib/python3.7/site-packages/django/db/backends/postgresql/base.py", line 187, in get_new_connection\n    connection = database.connect(**conn_params)\n  file "/usr/local/python3/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect\n    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\ndjango.db.utils.operationalerror: connection to server at "xxxx.postgresql.svc.cluster.local" (xx.xx.xx.xx), port xxxx failed: server closed the connection unexpectedly\nthis probably means the server terminated abnormally\nbefore or while processing the request.\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# 源码分析原因\n\n可以先看下backgroundscheduler的实现方式，在start方法中创建了个子线程。\n\nclass backgroundscheduler(blockingscheduler):\n\n    _thread = none\n\n    def start(self, *args, **kwargs):\n        if self._event is none or self._event.is_set():\n            self._event = event()\n\n        basescheduler.start(self, *args, **kwargs)\n        self._thread = thread(target=self._main_loop, name=\'apscheduler\')\n        self._thread.daemon = self._daemon\n        self._thread.start()\n\n    def shutdown(self, *args, **kwargs):\n        super(backgroundscheduler, self).shutdown(*args, **kwargs)\n        self._thread.join()\n        del self._thread\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n其中_main_loop在blockingscheduler中实现，是一个死循环，执行_process_jobs方法\n\nclass blockingscheduler(basescheduler):\n    \n    ...\n\n    def _main_loop(self):\n        wait_seconds = timeout_max\n        while self.state != state_stopped:\n            self._event.wait(wait_seconds)\n            self._event.clear()\n            wait_seconds = self._process_jobs()\n    \n    ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n再看_process_jobs中的内容，在basescheduler实现的，主要流程如下，先找到所有要执行的job，然后进行遍历运行并更新job的状态。之前的错误日志，也就是这里的update_job抛出异常，而这里并没有捕获异常，最终层层往上抛，update_job -> _process_jobs -> _main_loop，最终线程异常终止。\n\ndef _process_jobs(self):\n    for jobstore_alias, jobstore in six.iteritems(self._jobstores):\n        try:\n            due_jobs = jobstore.get_due_jobs(now)\n        except exception as e:\n            ...\n            continue\n\n        ...\n                \n        for job in due_jobs:\n      \n            ...\n            \n            try:\n                executor.submit_job(job, run_times)\n            except baseexception:\n                ...\n\n            ...\n            jobstore.update_job(job)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n那为什么复现不了呢？这个是因为，关闭数据库连接时，程序不一定可以正好运行在update_job，可以看到前面的get_due_jobs进行了异常捕获，如果这里抛出数据库连接异常是可以捕获到的，然后跳过后面的操作，等待下一次定时任务的执行，如果还是失败，则再次等待，所以这里的异常不会抛到最上层导致线程停止。\n\n但如果某个时机，上面连接数据库都成功了，到update_job这里异常抛出，则会导致整个线程停止，定时任务不再执行。\n\n那如何解决该问题呢？\n\n\n# 搭建demo\n\n首先我们搭建一个demo出来，模拟复现该问题。\n\n 1. 创建django项目\n\n\ndjango-admin startproject apschedule_demo\n\npython manage.py startapp demo\n\npython manage.py makemigrations\n\npython manage.py migrate\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 2. 在settings.py中配置到好数据库信息\n\ndatabases = {\n    "default": {\n        "engine": "django.db.backends.postgresql",\n        "name": "apschedule_demo",\n        "host": "xxxx",\n        "port": 5432,\n        "user": "xxx",\n        "password": "xxx"\n    }\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 3. 根据django-apschedule官方提供的文档搭建demo\n\n在settings.py中添加该app\n\ninstalled_apps = (\n    # ...\n    "django_apscheduler",\n)\n\n\n1\n2\n3\n4\n\n\n创建目录demo/management/commands，并在其下面创建runapscheduler.py文件，代码内容如下：\n\nimport logging\n\nfrom django.conf import settings\n\nfrom apscheduler.schedulers.blocking import blockingscheduler\nfrom apscheduler.triggers.cron import crontrigger\nfrom django.core.management.base import basecommand\nfrom django_apscheduler.jobstores import djangojobstore\n\nlogger = logging.getlogger(__name__)\n\n\ndef my_job():\n  # your job processing logic here...\n  print("job..")\n\n\nclass command(basecommand):\n  help = "runs apscheduler."\n\n  def handle(self, *args, **options):\n    scheduler = blockingscheduler(timezone=settings.time_zone)\n    scheduler.add_jobstore(djangojobstore(), "default")\n\n    scheduler.add_job(\n      my_job,\n      trigger=crontrigger(second="*/3"),  # every 3 seconds\n      id="my_job",  # the `id` assigned to each job must be unique\n      max_instances=1,\n      replace_existing=true,\n    )\n    logger.info("added job \'my_job\'.")\n\n    try:\n      logger.info("starting scheduler...")\n      scheduler.start()\n\n    # 因为上面是非阻塞开启定时任务，所以这里需要阻塞，不让主线程结束。\n    while true:\n            time.sleep(10)\n    except keyboardinterrupt:\n      logger.info("stopping scheduler...")\n      scheduler.shutdown()\n      logger.info("scheduler shut down successfully!")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n\n\n可以通过python manage.py runapscheduler执行上面的命令运行定时任务，该脚本创建了一个每3秒执行一次的任务。\n\n 4. 复现\n\n我们将断点打在jobstore.update_job(job)上，然后使用debug模式进行调试，当程序运行到断点上时，将数据库关闭，然后程序继续运行，则会报错，并抛出异常，线程停止了运行。至此，我们复现了该问题。\n\n\n# 线程重启\n\n我一开始想，我可以判断该线程是否异常，如果异常则将线程重启就好了\n\n    while true:\n        if not scheduler._thread.is_alive():\n            scheduler._thread.start()\n\n        time.sleep(10)\n\n\n1\n2\n3\n4\n5\n\n\n但事与愿违，抛出了异常，异常信息如下：\n\nruntimeerror: threads can only be started once\n\n\n1\n\n\n通过查看官方文档可以知道，线程的start方法只能调用一次。\n\n\n# listener\n\napschedule中提供了监听器机制，也就是在定时任务的成功、失败等状态都可以通过提前注册的listener方法来进行回调。但通过分析源码，其并不能捕获到定时任务线程的异常。\n\n下面是简化了代码的listeners的原理流程：\n\n 1. 外部通过add_listener方法注册回调方法\n 2. 在定时任务线程主流程_process_jobs中发生的各个事件添加到events中\n 3. 遍历events事件，然后通过与注册的回调方法mask进行匹配，匹配上则调用回调方法\n\nclass basescheduler:\n    def __init__(...):\n        self._listeners = []\n\n    def add_listener(self, callback, mask=event_all):\n        self._listeners.append((callback, mask))\n\n    def _process_jobs(self):\n\n        events = []\n        \n        ...\n\n        events.append(event)\n \n        ...\n\n\n        for event in events:\n            self._dispatch_event(event)\n\n\n    def _dispatch_event(self, event):\n        for cb, mask in listeners:\n            if event.code & mask:\n                try:\n                    cb(event)\n                except baseexception:\n                    self._logger.exception(\'error notifying listener\')\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n如果线程本身挂了，回调方法是不可执行的。\n\n\n# 捕获线程中函数的异常\n\n如果update_job抛出异常导致线程停止，那我捕获它的异常，然后再continue，等待下次定时任务运行再重试不就好了，但是这就需要改动源码，能不能改源码就尽量不改。所以这边我采用了继承backgroundscheduler类，然后再重写_process_jobs方法来解决。\n\n在重写的_process_jobs方法中，对父类的_process_jobs()进行异常的捕获，然后再不断的进行重试，这样即使update_job抛出异常了，也可以不断的进行尝试恢复，直至成功。\n\nclass demobackgroundscheduler(backgroundscheduler):\n    def _process_jobs(self):\n        while true:\n            try:\n                return super()._process_jobs()\n            except baseexception:\n                time.sleep(5)\n\nclass command(basecommand):\n    help = "runs apscheduler."\n\n    def handle(self, *args, **options):\n        scheduler = demobackgroundscheduler(timezone=settings.time_zone)\n        ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后再次尝试复现该问题，可以发现在断开数据库后，它能够一直进行重试，线程没有停止，当数据库恢复运行后，job执行成功，不再抛出异常。\n\n\n# 相关链接\n\n * apscheduler官方文档',charsets:{cjk:!0},lastUpdated:"2023/11/17, 16:03:58",lastUpdatedTimestamp:1700208238e3},{title:"django celery 结合使用",frontmatter:{title:"django celery 结合使用",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/853501/",tags:["python","django"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文主要介绍django和celery结合使用的案例。",feed:{enable:!0},categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217044049.png#alt=#crop=0&crop=0&crop=1&crop=1&id=kAMz1&originHeight=475&originWidth=564&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:title",content:"django celery 结合使用"},{name:"twitter:description",content:"本文主要介绍django和celery结合使用的案例。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217044049.png#alt=#crop=0&crop=0&crop=1&crop=1&id=kAMz1&originHeight=475&originWidth=564&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/01.django%20celery%20%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django celery 结合使用"},{property:"og:description",content:"本文主要介绍django和celery结合使用的案例。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217044049.png#alt=#crop=0&crop=0&crop=1&crop=1&id=kAMz1&originHeight=475&originWidth=564&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/01.django%20celery%20%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django celery 结合使用"},{itemprop:"description",content:"本文主要介绍django和celery结合使用的案例。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217044049.png#alt=#crop=0&crop=0&crop=1&crop=1&id=kAMz1&originHeight=475&originWidth=564&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/01.django%20celery%20%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8.html",relativePath:"04.编程/01.python/06.django/01.django celery 结合使用.md",key:"v-7dfe11b0",path:"/pages/853501/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"流程",slug:"流程",normalizedTitle:"流程",charIndex:143},{level:2,title:"消息分发与任务调度的实现机制",slug:"消息分发与任务调度的实现机制",normalizedTitle:"消息分发与任务调度的实现机制",charIndex:233},{level:2,title:"celery-beat",slug:"celery-beat",normalizedTitle:"celery-beat",charIndex:254},{level:2,title:"案例1",slug:"案例1",normalizedTitle:"案例1",charIndex:399},{level:3,title:"配置celery",slug:"配置celery",normalizedTitle:"配置celery",charIndex:425},{level:3,title:"在view中异步执行task",slug:"在view中异步执行task",normalizedTitle:"在view中异步执行task",charIndex:1933},{level:2,title:"案例2",slug:"案例2",normalizedTitle:"案例2",charIndex:2660},{level:3,title:"定时任务简介",slug:"定时任务简介",normalizedTitle:"定时任务简介",charIndex:2678},{level:3,title:"配置",slug:"配置",normalizedTitle:"配置",charIndex:425},{level:3,title:"定时任务",slug:"定时任务",normalizedTitle:"定时任务",charIndex:66},{level:2,title:"案例三-路由",slug:"案例三-路由",normalizedTitle:"案例三-路由",charIndex:3083},{level:3,title:"管理worker 进程",slug:"管理worker-进程",normalizedTitle:"管理worker 进程",charIndex:3819},{level:3,title:"基本操作",slug:"基本操作",normalizedTitle:"基本操作",charIndex:3861},{level:3,title:"命令",slug:"命令",normalizedTitle:"命令",charIndex:3970},{level:3,title:"配合celery使用",slug:"配合celery使用",normalizedTitle:"配合celery使用",charIndex:4105},{level:3,title:"问题",slug:"问题",normalizedTitle:"问题",charIndex:5604},{level:2,title:"使用flower监控celery",slug:"使用flower监控celery",normalizedTitle:"使用flower监控celery",charIndex:5786},{level:3,title:"持久化",slug:"持久化",normalizedTitle:"持久化",charIndex:5930},{level:3,title:"时区问题",slug:"时区问题",normalizedTitle:"时区问题",charIndex:6018}],headersStr:"简介 流程 消息分发与任务调度的实现机制 celery-beat 案例1 配置celery 在view中异步执行task 案例2 定时任务简介 配置 定时任务 案例三-路由 管理worker 进程 基本操作 命令 配合celery使用 问题 使用flower监控celery 持久化 时区问题",content:"# 简介\n\n本文主要介绍django和celery结合使用的案例。\n\ncelery 是一个异步任务的调度工具，可以完成一些异步任务和定时任务。\n\n本文使用djcelery来完成django和celery的结合使用。\n\n该案例在github中django_celery_demo\n\n\n# 流程\n\n任务发布者(Producer)将任务丢到消息队列(Broker)中，任务消费者(worker)从消息代理中获取任务执行，然后将保存存储结果(backend)。\n\n\n\n\n# 消息分发与任务调度的实现机制\n\n\n\n\n# celery-beat\n\ncelery 有个定时功能，通过定时去将task丢到broker中，然后worker去执行任务。但是有个确定是，该定时任务必须硬编写到代码中，不可在程序运行中动态增加任务。使用djcelery可以将定时任务写入到数据库中，然后通过操作数据库操作定时任务。\n\n\n# 案例1\n\n访问接口，异步调用程序中task\n\n\n# 配置celery\n\n安装**djcelery**\n\n> pip install django_celery\n\n在settings中设置celery配置\n\n代码: django_celery_demo/settings.py\n\nimport djcelery\ndjcelery.setup_loader() # 加载djcelery\n\n\n# 允许的格式\nCELERY_ACCEPT_CONTENT = ['pickle', 'json', 'yaml']\n\nBROKER_URL = 'redis://localhost:6379/1' # redis作为中间件\nBROKER_TRANSPORT = 'redis'\n\nCELERYBEAT_SCHEDULER = 'djcelery.schedulers.DatabaseScheduler' # 定时任务使用数据库来操作\nCELERY_RESULT_BACKEND = 'djcelery.backends.database:DatabaseBackend'  # 结果存储到数据库中\n\n# worker 并发数\nCELERY_CONCURRENCY = 2\n\n# 指定导入task任务\nCELERY_IMPORTS = {\n'tasks.tasks'\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\ncelery app 配置\n\n代码: django_celery_demo/celery.py\n\nimport os\n\nimport django\nfrom celery import Celery, shared_task\nfrom celery.schedules import crontab\nfrom celery.signals import task_success\nfrom django.conf import settings\nfrom django.utils import timezone\n\nos.environ.setdefault('DJANGO_SETTINGS_MODULE', 'django_celery_demo.settings')\ndjango.setup()\n\napp = Celery('django_celery_demo')\napp.config_from_object('django.conf:settings') # celery app 加载 settings中的配置\n\napp.now = timezone.now # 设置时间时区和django一样\n\n# 加载每个django app下的tasks.py中的task任务\napp.autodiscover_tasks(lambda: settings.INSTALLED_APPS)\n\n# 这个一个task\n@app.task(bind=True)\ndef debug_task(self):\n    print('Request: {0!r}'.format(self.request))\n    \n# 异步执行这个task\ndebug_task.delay()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n创建djcelery中的表\n\n会自动创建djcelery中的表。里面有保存定时记录、结果记录等等表。\n\n> python manage.py migrate\n\n\n# 在view中异步执行task\n\n在app中创建**add**task\n\n代码: demo/tasks.py\n\nfrom celery import shared_task\n\n@shared_task(name=\"add\")\ndef add(a, b):\n    return int(a) + int(b)\n\n\n1\n2\n3\n4\n5\n\n\n创建view去异步执行该task\n\n代码: demo/views.py\n\nfrom django.http import HttpResponse\nfrom demo.tasks import add as add_task\n\ndef add(request):\n    a = request.GET[\"a\"]\n    b = request.GET[\"b\"]\n    add_task.delay(a, b)\n    \n    return HttpResponse(\"success\")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nurl中配置view\n\nfrom demo.views import add\n\nurlpatterns = [\n    path('add', add),\n]\n\n\n1\n2\n3\n4\n5\n\n\n运行celery worker\n\n> celery -A django_celery_demo worker -l info\n\n运行项目\n\n> python manage.py runserver 0:8888\n\n访问接口\n\nhttp://127.0.0.1:8888/add?a=1&b=2\n\n结果: 返回success，在worker中可以看到add任务被调用，并且结果是3\n\n\n\n\n# 案例2\n\n定时调用异步任务\n\n\n# 定时任务简介\n\n有两种定时任务方式，这里使用的是常见的crontab，与linux一毛一样，方便很多。\n\n\n# 配置\n\n配置和案例1中一样。\n\n\n# 定时任务\n\n硬编码中创建定时任务\n\n每分钟调用一次add task\n\n代码: django_celery_demo/celery.py\n\n# 这个是硬编码的定时任务\napp.conf.beat_schedule = {\n    'aa': {\n        'task': 'add',\n        'schedule': crontab(minute=\"*/1\"),\n        'args': (2, 4)\n    },\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n开启celery beat\n\n> celery beat -A django_celery_demo -l info\n\n这个服务会将数据库中的定时任务丢到broker 中\n\n\n# 案例三-路由\n\n将不同的任务放到不同的队列中，放到不同的worker中。\n\n图: 消息分发与任务调度的实现机制\n\ndefault = Exchange('default', type=\"direct\")\nfrequent = Exchange('frequent', type=\"direct\")\n\nCELERY_QUEUES = {\n    Queue('default', default, routing_key=\"default\"),\n    Queue('frequent', frequent, routing_key=\"frequent\")\n}\n\napp.conf.task_default_queue = 'default'\n\ntask_routes = {\n    'apps.periodic.tasks.oozie_workflow_task': {'queue': 'default'},\n    'apps.periodic.tasks.oozie_workflow_status': {'queue': 'custom'}\n}\n\napp.conf.beat_schedule = {\n\n    # 每分钟检查oozie运行中的任务状态\n    'oozie_workflow_status': {\n        'task': 'oozie_workflow_status',\n        'schedule': crontab(),\n        'args': (2, 1)\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 管理worker 进程\n\n使用supervisor来管理worker进程。\n\n\n# 基本操作\n\n安装\n\n> pip install supervisor\n\n生成默认配置文件\n\n> echo_supervisord_conf > /etc/supervisor/supervisord.conf\n\n\n# 命令\n\nsupervisorctl\n\n命令          描述\nstatus      \nreread      读取配置文件\nupdate      加载最新的进程\nstop 进程名    \nstart 进程名   \nreload      重新加载配置\n\n\n# 配合celery使用\n\n在supervisord.conf中添加下面的配置。\n\n[include]\n; files = relative/directory/*.ini\nfiles = /home/jim/conf/supervisor/supervisord.conf.d/*.conf\n\n\n1\n2\n3\n\n\n创建配置文件/home/jim/conf/supervisor/supervisord.conf.d/celeryd_worker.conf，添加下面配置\n\n[program:celeryworker]\ncommand=celery -A datahub_poster worker -l info\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celeryworker.log\n;stderr_logfile=/yun/jim/log/supervisor/celeryworker_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[program:celerybeat]\ncommand=celery -A datahub_poster beat -l info\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celerybeat.log\n;stderr_logfile=/yun/jim/log/supervisor/celerybeat_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[program:celery_flower]\ncommand=celery -A datahub_poster flower --port=5555\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celery_flower.log\n;stderr_logfile=/yun/jim/log/supervisor/celery_flower_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[inet_http_server]\nport=127.0.0.1:9001\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n使用配置文件启动supervisor\n\n> supervisord -c /etc/supervisor/supervisord.conf\n\n\n# 问题\n\n 1. 在supervisorctl status时，出现http://localhost:9001 refused connection错误。\n\n解决办法：\n\n在配置文件supervisord.conf中添加\n\n[inet_http_server]\nport=127.0.0.1:9001\n\n\n1\n2\n\n\n然后再update或reload以下。\n\n\n# 使用flower监控celery\n\n可以通过flower监控celery中的worker、task等等。\n\n安装flower\n\n> pip install flower\n\n运行\n\n> celery flower --broker=redis://localhost:6379/0\n\n\n# 持久化\n\n问题: 每次重启flower之后发现，以前的task运行记录清空。\n\n解决: 启动flower时添加 --persistent=True，可以持久化task\n\n\n# 时区问题\n\nflower会读取celery的时区配置，在项目中配置下面参数即可。\n\nTIME_ZONE = 'Asia/Shanghai'\nCELERY_TIMEZONE = TIME_ZONE\n\n\n1\n2\n",normalizedContent:"# 简介\n\n本文主要介绍django和celery结合使用的案例。\n\ncelery 是一个异步任务的调度工具，可以完成一些异步任务和定时任务。\n\n本文使用djcelery来完成django和celery的结合使用。\n\n该案例在github中django_celery_demo\n\n\n# 流程\n\n任务发布者(producer)将任务丢到消息队列(broker)中，任务消费者(worker)从消息代理中获取任务执行，然后将保存存储结果(backend)。\n\n\n\n\n# 消息分发与任务调度的实现机制\n\n\n\n\n# celery-beat\n\ncelery 有个定时功能，通过定时去将task丢到broker中，然后worker去执行任务。但是有个确定是，该定时任务必须硬编写到代码中，不可在程序运行中动态增加任务。使用djcelery可以将定时任务写入到数据库中，然后通过操作数据库操作定时任务。\n\n\n# 案例1\n\n访问接口，异步调用程序中task\n\n\n# 配置celery\n\n安装**djcelery**\n\n> pip install django_celery\n\n在settings中设置celery配置\n\n代码: django_celery_demo/settings.py\n\nimport djcelery\ndjcelery.setup_loader() # 加载djcelery\n\n\n# 允许的格式\ncelery_accept_content = ['pickle', 'json', 'yaml']\n\nbroker_url = 'redis://localhost:6379/1' # redis作为中间件\nbroker_transport = 'redis'\n\ncelerybeat_scheduler = 'djcelery.schedulers.databasescheduler' # 定时任务使用数据库来操作\ncelery_result_backend = 'djcelery.backends.database:databasebackend'  # 结果存储到数据库中\n\n# worker 并发数\ncelery_concurrency = 2\n\n# 指定导入task任务\ncelery_imports = {\n'tasks.tasks'\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\ncelery app 配置\n\n代码: django_celery_demo/celery.py\n\nimport os\n\nimport django\nfrom celery import celery, shared_task\nfrom celery.schedules import crontab\nfrom celery.signals import task_success\nfrom django.conf import settings\nfrom django.utils import timezone\n\nos.environ.setdefault('django_settings_module', 'django_celery_demo.settings')\ndjango.setup()\n\napp = celery('django_celery_demo')\napp.config_from_object('django.conf:settings') # celery app 加载 settings中的配置\n\napp.now = timezone.now # 设置时间时区和django一样\n\n# 加载每个django app下的tasks.py中的task任务\napp.autodiscover_tasks(lambda: settings.installed_apps)\n\n# 这个一个task\n@app.task(bind=true)\ndef debug_task(self):\n    print('request: {0!r}'.format(self.request))\n    \n# 异步执行这个task\ndebug_task.delay()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n创建djcelery中的表\n\n会自动创建djcelery中的表。里面有保存定时记录、结果记录等等表。\n\n> python manage.py migrate\n\n\n# 在view中异步执行task\n\n在app中创建**add**task\n\n代码: demo/tasks.py\n\nfrom celery import shared_task\n\n@shared_task(name=\"add\")\ndef add(a, b):\n    return int(a) + int(b)\n\n\n1\n2\n3\n4\n5\n\n\n创建view去异步执行该task\n\n代码: demo/views.py\n\nfrom django.http import httpresponse\nfrom demo.tasks import add as add_task\n\ndef add(request):\n    a = request.get[\"a\"]\n    b = request.get[\"b\"]\n    add_task.delay(a, b)\n    \n    return httpresponse(\"success\")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\nurl中配置view\n\nfrom demo.views import add\n\nurlpatterns = [\n    path('add', add),\n]\n\n\n1\n2\n3\n4\n5\n\n\n运行celery worker\n\n> celery -a django_celery_demo worker -l info\n\n运行项目\n\n> python manage.py runserver 0:8888\n\n访问接口\n\nhttp://127.0.0.1:8888/add?a=1&b=2\n\n结果: 返回success，在worker中可以看到add任务被调用，并且结果是3\n\n\n\n\n# 案例2\n\n定时调用异步任务\n\n\n# 定时任务简介\n\n有两种定时任务方式，这里使用的是常见的crontab，与linux一毛一样，方便很多。\n\n\n# 配置\n\n配置和案例1中一样。\n\n\n# 定时任务\n\n硬编码中创建定时任务\n\n每分钟调用一次add task\n\n代码: django_celery_demo/celery.py\n\n# 这个是硬编码的定时任务\napp.conf.beat_schedule = {\n    'aa': {\n        'task': 'add',\n        'schedule': crontab(minute=\"*/1\"),\n        'args': (2, 4)\n    },\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n开启celery beat\n\n> celery beat -a django_celery_demo -l info\n\n这个服务会将数据库中的定时任务丢到broker 中\n\n\n# 案例三-路由\n\n将不同的任务放到不同的队列中，放到不同的worker中。\n\n图: 消息分发与任务调度的实现机制\n\ndefault = exchange('default', type=\"direct\")\nfrequent = exchange('frequent', type=\"direct\")\n\ncelery_queues = {\n    queue('default', default, routing_key=\"default\"),\n    queue('frequent', frequent, routing_key=\"frequent\")\n}\n\napp.conf.task_default_queue = 'default'\n\ntask_routes = {\n    'apps.periodic.tasks.oozie_workflow_task': {'queue': 'default'},\n    'apps.periodic.tasks.oozie_workflow_status': {'queue': 'custom'}\n}\n\napp.conf.beat_schedule = {\n\n    # 每分钟检查oozie运行中的任务状态\n    'oozie_workflow_status': {\n        'task': 'oozie_workflow_status',\n        'schedule': crontab(),\n        'args': (2, 1)\n    }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 管理worker 进程\n\n使用supervisor来管理worker进程。\n\n\n# 基本操作\n\n安装\n\n> pip install supervisor\n\n生成默认配置文件\n\n> echo_supervisord_conf > /etc/supervisor/supervisord.conf\n\n\n# 命令\n\nsupervisorctl\n\n命令          描述\nstatus      \nreread      读取配置文件\nupdate      加载最新的进程\nstop 进程名    \nstart 进程名   \nreload      重新加载配置\n\n\n# 配合celery使用\n\n在supervisord.conf中添加下面的配置。\n\n[include]\n; files = relative/directory/*.ini\nfiles = /home/jim/conf/supervisor/supervisord.conf.d/*.conf\n\n\n1\n2\n3\n\n\n创建配置文件/home/jim/conf/supervisor/supervisord.conf.d/celeryd_worker.conf，添加下面配置\n\n[program:celeryworker]\ncommand=celery -a datahub_poster worker -l info\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celeryworker.log\n;stderr_logfile=/yun/jim/log/supervisor/celeryworker_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[program:celerybeat]\ncommand=celery -a datahub_poster beat -l info\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celerybeat.log\n;stderr_logfile=/yun/jim/log/supervisor/celerybeat_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[program:celery_flower]\ncommand=celery -a datahub_poster flower --port=5555\ndirectory=/home/hadoop/jim/projs/datahub_poster\nstdout_logfile=/yun/jim/log/supervisor/celery_flower.log\n;stderr_logfile=/yun/jim/log/supervisor/celery_flower_err.log\nredirect_stderr=true\nautorestart=true\nautostart=true\nnumprocs=1\nstartsecs=10\nstopwaitsecs = 600\npriority=15\n\n[inet_http_server]\nport=127.0.0.1:9001\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n\n\n使用配置文件启动supervisor\n\n> supervisord -c /etc/supervisor/supervisord.conf\n\n\n# 问题\n\n 1. 在supervisorctl status时，出现http://localhost:9001 refused connection错误。\n\n解决办法：\n\n在配置文件supervisord.conf中添加\n\n[inet_http_server]\nport=127.0.0.1:9001\n\n\n1\n2\n\n\n然后再update或reload以下。\n\n\n# 使用flower监控celery\n\n可以通过flower监控celery中的worker、task等等。\n\n安装flower\n\n> pip install flower\n\n运行\n\n> celery flower --broker=redis://localhost:6379/0\n\n\n# 持久化\n\n问题: 每次重启flower之后发现，以前的task运行记录清空。\n\n解决: 启动flower时添加 --persistent=true，可以持久化task\n\n\n# 时区问题\n\nflower会读取celery的时区配置，在项目中配置下面参数即可。\n\ntime_zone = 'asia/shanghai'\ncelery_timezone = time_zone\n\n\n1\n2\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django rest_framework Authentication",frontmatter:{tags:["python","django"],title:"django rest_framework Authentication",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/626675/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文介绍的是 django rest_framework的认证方式.",feed:{enable:!0},categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217645776.png#alt="},{name:"twitter:title",content:"django rest_framework Authentication"},{name:"twitter:description",content:"本文介绍的是 django rest_framework的认证方式."},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217645776.png#alt="},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/03.django%20rest_framework%20Authentication.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework Authentication"},{property:"og:description",content:"本文介绍的是 django rest_framework的认证方式."},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217645776.png#alt="},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/03.django%20rest_framework%20Authentication.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django rest_framework Authentication"},{itemprop:"description",content:"本文介绍的是 django rest_framework的认证方式."},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217645776.png#alt="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/03.django%20rest_framework%20Authentication.html",relativePath:"04.编程/01.python/06.django/03.django rest_framework Authentication.md",key:"v-502d161c",path:"/pages/626675/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"源码解析",slug:"源码解析",normalizedTitle:"源码解析",charIndex:132},{level:2,title:"认证方式",slug:"认证方式",normalizedTitle:"认证方式",charIndex:35},{level:3,title:"Token",slug:"token",normalizedTitle:"token",charIndex:42},{level:4,title:"使用",slug:"使用",normalizedTitle:"使用",charIndex:124},{level:4,title:"缺陷",slug:"缺陷",normalizedTitle:"缺陷",charIndex:1493},{level:3,title:"session",slug:"session",normalizedTitle:"session",charIndex:1683}],headersStr:"简介 源码解析 认证方式 Token 使用 缺陷 session",content:"# 简介\n\n本文介绍的是 django rest_framework的认证方式.\n\nToken、Session、RemoteUser、jwt等认证方式。前三种是框架自带的，而jwt需要安装第三方库djangorestframework-jwt，然后使用。\n\n\n# 源码解析\n\n以下是认证源码认证流程.\n\n 1. 通过路由匹配后首先进入到ApiView.as_view中.\n\n 2. ApiView继承Django的View，然后调用View.as_view\n\n 3. 在View中调用dispatch方法，因为ApiView实现dispatch方法，所以调用的是ApiView.dispatch而不是View.dispatch.\n\n 4. 在ApiView.dispatch中将django.request再次封装成框架的rest_framework.request\n\n 5. 封装的过程中将配置的Authentication类注入到request中.\n\n 6. 封装完request后，调用ApiView.perform_authentication开始认证\n\n 7. 认证的过程是通过request.user，然后再调用request._authentication进行循环遍历所有注入的Authentiation类中authenticate方法进行认证，认证成功则返回user和auth两个结果.\n\n\n\n\n# 认证方式\n\n可以自定义认证类，只需要继承BaseAuthentication类，然后实现authenticate方法即可，然后将该类注入到request即可.\n\n或者使用框架自带的认证类也可。\n\n\n# Token\n\n是框架自带的认证方式之一.\n\n# 使用\n\n 1. 配置authtoken app settings\n\nINSTALLED_APPS = [\n    ...\n    'rest_framework.authtoken']\n\n\n1\n2\n3\n\n\n然后使用python manage.py migrate，会创建authtoken表，该表连接auth_user.表，每个用户都有对应一个token，用户每次访问带有该token，系统就能通过token得到当前user.\n\n 2. 局部添加认证方式.\n\n在TestView添加TokenAuthentication认证, 路由到TestView时，会调用该类中的authenticate方法，通过token获取到user.\n\nview.py\n\n\nfrom rest_framework.authentication import TokenAuthentication\n\nclass TestView(APIView):\n    authentication_classes = (TokenAuthentication,)\n\n    def get(self, *args, **kwargs):\n        return HttpResponse(self.request.user)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 3. 全局添加认证方式\n\n任何路由请求需要通过Token认证.\n\nsettings.py\n\nREST_FRAMEWORK = {\n    'DEFAULT_AUTHENTICATION_CLASSES': [\n        'rest_framework.authentication.TokenAuthentication',\n    ]\n}\n\n\n1\n2\n3\n4\n5\n\n\n# 缺陷\n\n * Token验证是放在一张表中，即authtoken_token中，key没有失效时间，永久有效，一旦泄露，后果不可想象，安全性极差。\n * 不利于分布式部署或多个系统使用一套验证，authtoken_token是放在某台服务器上的，如果分布式部署，将失效，或多个系统用一套验证，将必须复制该表到相应服务器上，麻烦费力。\n\n鉴于以上缺陷，使用jwt更加优秀.\n\n\n# session\n\ndrf中session认证，是通过django SessionMiddleware和AuthenticationMiddleware中将user存储到request中，然后获取到的.\n\n",normalizedContent:"# 简介\n\n本文介绍的是 django rest_framework的认证方式.\n\ntoken、session、remoteuser、jwt等认证方式。前三种是框架自带的，而jwt需要安装第三方库djangorestframework-jwt，然后使用。\n\n\n# 源码解析\n\n以下是认证源码认证流程.\n\n 1. 通过路由匹配后首先进入到apiview.as_view中.\n\n 2. apiview继承django的view，然后调用view.as_view\n\n 3. 在view中调用dispatch方法，因为apiview实现dispatch方法，所以调用的是apiview.dispatch而不是view.dispatch.\n\n 4. 在apiview.dispatch中将django.request再次封装成框架的rest_framework.request\n\n 5. 封装的过程中将配置的authentication类注入到request中.\n\n 6. 封装完request后，调用apiview.perform_authentication开始认证\n\n 7. 认证的过程是通过request.user，然后再调用request._authentication进行循环遍历所有注入的authentiation类中authenticate方法进行认证，认证成功则返回user和auth两个结果.\n\n\n\n\n# 认证方式\n\n可以自定义认证类，只需要继承baseauthentication类，然后实现authenticate方法即可，然后将该类注入到request即可.\n\n或者使用框架自带的认证类也可。\n\n\n# token\n\n是框架自带的认证方式之一.\n\n# 使用\n\n 1. 配置authtoken app settings\n\ninstalled_apps = [\n    ...\n    'rest_framework.authtoken']\n\n\n1\n2\n3\n\n\n然后使用python manage.py migrate，会创建authtoken表，该表连接auth_user.表，每个用户都有对应一个token，用户每次访问带有该token，系统就能通过token得到当前user.\n\n 2. 局部添加认证方式.\n\n在testview添加tokenauthentication认证, 路由到testview时，会调用该类中的authenticate方法，通过token获取到user.\n\nview.py\n\n\nfrom rest_framework.authentication import tokenauthentication\n\nclass testview(apiview):\n    authentication_classes = (tokenauthentication,)\n\n    def get(self, *args, **kwargs):\n        return httpresponse(self.request.user)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 3. 全局添加认证方式\n\n任何路由请求需要通过token认证.\n\nsettings.py\n\nrest_framework = {\n    'default_authentication_classes': [\n        'rest_framework.authentication.tokenauthentication',\n    ]\n}\n\n\n1\n2\n3\n4\n5\n\n\n# 缺陷\n\n * token验证是放在一张表中，即authtoken_token中，key没有失效时间，永久有效，一旦泄露，后果不可想象，安全性极差。\n * 不利于分布式部署或多个系统使用一套验证，authtoken_token是放在某台服务器上的，如果分布式部署，将失效，或多个系统用一套验证，将必须复制该表到相应服务器上，麻烦费力。\n\n鉴于以上缺陷，使用jwt更加优秀.\n\n\n# session\n\ndrf中session认证，是通过django sessionmiddleware和authenticationmiddleware中将user存储到request中，然后获取到的.\n\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django rest_framework异常处理",frontmatter:{tags:["python","django"],title:"django rest_framework异常处理",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/070fec/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。",feed:{enable:!0},categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django rest_framework异常处理"},{name:"twitter:description",content:"当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/04.django%20rest_framework%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework异常处理"},{property:"og:description",content:"当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/04.django%20rest_framework%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django rest_framework异常处理"},{itemprop:"description",content:"当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/04.django%20rest_framework%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.html",relativePath:"04.编程/01.python/06.django/04.django rest_framework异常处理.md",key:"v-abb9096c",path:"/pages/070fec/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"操作",slug:"操作",normalizedTitle:"操作",charIndex:62}],headersStr:"简介 操作",content:'# 简介\n\n当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。\n\n\n# 操作\n\n 1. 自定义json返回的格式\n\nlibs/response.py\n\nfrom rest_framework.response import Response\n\n\nclass JsonResponse(Response):\n    def __init__(self, data=None, code=None, msg=None, status=None,\n                 template_name=None, headers=None,\n                 exception=False, content_type=None):\n        rsp_data = {"code": code, "message": msg, "data": data}\n        super(JsonResponse, self).__init__(data=rsp_data, status=status, template_name=template_name,\n                                                 headers=headers,\n                                                 exception=exception, content_type=content_type)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 2. 自定义全局的异常处理方法 libs/exceptions.py\n\n\nfrom rest_framework import status\nfrom rest_framework.views import exception_handler\nfrom libs.response import JsonResponse\n\n\nclass DataException(Exception):\n\n    def __init__(self, message="", code=0, status=status.HTTP_400_BAD_REQUEST, data=None):\n        self.code = code\n        self.status = status\n        self.detail = message\n        self.data = data if data else {}\n\n        def __str__(self):\n            return self.message\n\n\ndef custom_exception_handler(exc, context):\n    data = exc.data if hasattr(exc, "data") else {}\n    return JsonResponse(msg=exc.detail, status=exc.status_code, data=data, code=exc.status_code)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n 3. 将该异常方法注册到rest_framework框架中 settings.py\n\nREST_FRAMEWORK = {\n    \'EXCEPTION_HANDLER\': \'libs.exceptions.custom_exception_handler\',\n}\n\n\n1\n2\n3\n',normalizedContent:'# 简介\n\n当程序中出现异常时，我们想要返回的是包含异常信息的json数据。返回正常的信息和异常信息的格式一致化。\n\n\n# 操作\n\n 1. 自定义json返回的格式\n\nlibs/response.py\n\nfrom rest_framework.response import response\n\n\nclass jsonresponse(response):\n    def __init__(self, data=none, code=none, msg=none, status=none,\n                 template_name=none, headers=none,\n                 exception=false, content_type=none):\n        rsp_data = {"code": code, "message": msg, "data": data}\n        super(jsonresponse, self).__init__(data=rsp_data, status=status, template_name=template_name,\n                                                 headers=headers,\n                                                 exception=exception, content_type=content_type)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n 2. 自定义全局的异常处理方法 libs/exceptions.py\n\n\nfrom rest_framework import status\nfrom rest_framework.views import exception_handler\nfrom libs.response import jsonresponse\n\n\nclass dataexception(exception):\n\n    def __init__(self, message="", code=0, status=status.http_400_bad_request, data=none):\n        self.code = code\n        self.status = status\n        self.detail = message\n        self.data = data if data else {}\n\n        def __str__(self):\n            return self.message\n\n\ndef custom_exception_handler(exc, context):\n    data = exc.data if hasattr(exc, "data") else {}\n    return jsonresponse(msg=exc.detail, status=exc.status_code, data=data, code=exc.status_code)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n 3. 将该异常方法注册到rest_framework框架中 settings.py\n\nrest_framework = {\n    \'exception_handler\': \'libs.exceptions.custom_exception_handler\',\n}\n\n\n1\n2\n3\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django rest_framework 自定义文档",frontmatter:{title:"django rest_framework 自定义文档",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/c3af6a/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"django rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django rest_framework 自定义文档"},{name:"twitter:description",content:"django rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/05.django%20rest_framework%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%A1%A3.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework 自定义文档"},{property:"og:description",content:"django rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/05.django%20rest_framework%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%A1%A3.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django rest_framework 自定义文档"},{itemprop:"description",content:"django rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/05.django%20rest_framework%20%E8%87%AA%E5%AE%9A%E4%B9%89%E6%96%87%E6%A1%A3.html",relativePath:"04.编程/01.python/06.django/05.django rest_framework 自定义文档.md",key:"v-2c646377",path:"/pages/c3af6a/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"配置",slug:"配置",normalizedTitle:"配置",charIndex:102},{level:2,title:"自定义文档",slug:"自定义文档",normalizedTitle:"自定义文档",charIndex:293},{level:2,title:"schema",slug:"schema",normalizedTitle:"schema",charIndex:335},{level:3,title:"方法一",slug:"方法一",normalizedTitle:"方法一",charIndex:371},{level:3,title:"方法二",slug:"方法二",normalizedTitle:"方法二",charIndex:3082},{level:2,title:"location",slug:"location",normalizedTitle:"location",charIndex:3219}],headersStr:"简介 配置 自定义文档 schema 方法一 方法二 location",content:'# 简介\n\ndjango rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。\n\n官网\n\n\n# 配置\n\nurls.py\n\nfrom rest_framework.documentation import include_docs_urls\n\nurlpatterns = [\n    ...\n    url(r\'^docs/\', include_docs_urls(title=\'My API title\'))]\n\n\n1\n2\n3\n4\n5\n\n\n即可使用该url对文档的访问\n\n\n# 自定义文档\n\n虽然可以自动生成文档，但是不是很完善，所以需要自定义写文档。\n\n\n# schema\n\n通过改写AutoSchema来完成自定义文档。\n\n\n# 方法一\n\nget_link是AutoSchema中的函数. 重写get_link函数，对文档中的每个字段的说明进行改写。\n\n集成AutoSchema，在__init__初始化params_desc_dict参数，该参数包含文档中字段对应的注释，然后在get_link对该参数进行解析，并替换字段注释.\n\nclass BaseSchema(AutoSchema):\n    """\n    自动生成的文档会有缺失，或者是因为可读性比较差。所以需要对文档中的字段进行自定义注解。\n    该类是通用的对文档中的get、post、put、delete、patch进行注释。\n    是在已有字段的基础上修改注释.\n    \n    `get`是对get中的字段进行注解说明。\n    `other`是`post`、`put`、`delete`、`patch`\n    \n    例子:\n        {\n            "get": {\n                "字段名": "对该字段进行注释"\n            },\n            "post": {\n                "字段名": "对该字段进行注释"\n            }\n        }\n\n    """\n    def __init__(self, manual_fields=None, params_desc_dict=None):\n        self.params_desc_dict = {\n            "get": {\n                "page": "当前页码",\n                "page_size": "每一页显示的行数. 默认传 10条"\n            },\n            "other": {\n\n            }\n        }\n\n        if params_desc_dict:\n            if \'get\' in params_desc_dict:\n                self.params_desc_dict[\'get\'].update(params_desc_dict[\'get\'])\n\n            if \'other\' in params_desc_dict:\n                self.params_desc_dict[\'other\'].update(params_desc_dict[\'other\'])\n\n        super(BaseSchema, self).__init__(manual_fields)\n\n    def get_link(self, path, method, base_url):\n        link = super(BaseSchema, self).get_link(path, method, base_url)\n\n        fields = []\n\n        params_method = \'get\' if method.lower() == \'get\' else \'other\'\n\n        for field in link.fields:\n            if field.name in self.params_desc_dict[params_method].keys():\n                field = field._replace(\n                    schema=coreschema.String(description=self.params_desc_dict[params_method][field.name]))\n\n            fields.append(field)\n\n        return coreapi.Link(\n            url=link.url,\n            action=link.action,\n            encoding=link.encoding,\n            fields=fields,\n            description=link.description\n        )\n\nperiodictaskSchema = BaseSchema(params_desc_dict={\n    \'other\': {\n        "crontab": "定时crontab. json。 包含的字段有: minute, hour, day_of_week, day_of_month, month_of_year",\n        "name": "该定时任务名称",\n        "task": "模板任务名",\n        "args": "传递给任务模板参数. 数组",\n        "kwargs": "传递给任务模板参数. json字符串",\n        "queue": "将任务放在哪个队列中.",\n        "enabled": "是否开启该任务. True or False. 默认为True",\n        "description": "定时任务说明"\n    }\n})\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n\n\n在view中绑定自定义的schema\n\nclass PeriodictasksViewSet(viewsets.ModelViewSet):\n    queryset = PeriodicTask.objects.all()\n    serializer_class = PeriodictaskSerializer\n    schema = periodictaskSchema\n\n\n1\n2\n3\n4\n\n\n\n# 方法二\n\n如果只是普通的APIView的话，直接在AutoSchema中添加字段即可。\n\ndatabaseInfoSchema = AutoSchema(manual_fields=[\n    coreapi.Field(name="db", required=True, location="query",\n                  schema=coreschema.String(description="数据库host, normal或者sub")),\n    coreapi.Field(name="database", location="query", schema=coreschema.String(description="数据库")),\n    coreapi.Field(name="table", required=True, location="query", schema=coreschema.String(description="数据库表"))\n])\n\n\n1\n2\n3\n4\n5\n6\n\n\n绑定自定义schema\n\nclass DataBaseInfo(APIView):\n    schema = databaseInfoSchema\n\n    def get(self, request):\n        pass\n\n\n1\n2\n3\n4\n5\n\n\n\n# location\n\nLOCATION   描述\nquery      查询. list\nform       表单提交. post\npath       在url中的，/oozieJob/{id}/. read',normalizedContent:'# 简介\n\ndjango rest_framework 自动生成文档的功能，能够很好的给前端提供帮助，在文档中可以看到api的参数和其提供的功能信息，并且还能够在上面直接测试api接口。\n\n官网\n\n\n# 配置\n\nurls.py\n\nfrom rest_framework.documentation import include_docs_urls\n\nurlpatterns = [\n    ...\n    url(r\'^docs/\', include_docs_urls(title=\'my api title\'))]\n\n\n1\n2\n3\n4\n5\n\n\n即可使用该url对文档的访问\n\n\n# 自定义文档\n\n虽然可以自动生成文档，但是不是很完善，所以需要自定义写文档。\n\n\n# schema\n\n通过改写autoschema来完成自定义文档。\n\n\n# 方法一\n\nget_link是autoschema中的函数. 重写get_link函数，对文档中的每个字段的说明进行改写。\n\n集成autoschema，在__init__初始化params_desc_dict参数，该参数包含文档中字段对应的注释，然后在get_link对该参数进行解析，并替换字段注释.\n\nclass baseschema(autoschema):\n    """\n    自动生成的文档会有缺失，或者是因为可读性比较差。所以需要对文档中的字段进行自定义注解。\n    该类是通用的对文档中的get、post、put、delete、patch进行注释。\n    是在已有字段的基础上修改注释.\n    \n    `get`是对get中的字段进行注解说明。\n    `other`是`post`、`put`、`delete`、`patch`\n    \n    例子:\n        {\n            "get": {\n                "字段名": "对该字段进行注释"\n            },\n            "post": {\n                "字段名": "对该字段进行注释"\n            }\n        }\n\n    """\n    def __init__(self, manual_fields=none, params_desc_dict=none):\n        self.params_desc_dict = {\n            "get": {\n                "page": "当前页码",\n                "page_size": "每一页显示的行数. 默认传 10条"\n            },\n            "other": {\n\n            }\n        }\n\n        if params_desc_dict:\n            if \'get\' in params_desc_dict:\n                self.params_desc_dict[\'get\'].update(params_desc_dict[\'get\'])\n\n            if \'other\' in params_desc_dict:\n                self.params_desc_dict[\'other\'].update(params_desc_dict[\'other\'])\n\n        super(baseschema, self).__init__(manual_fields)\n\n    def get_link(self, path, method, base_url):\n        link = super(baseschema, self).get_link(path, method, base_url)\n\n        fields = []\n\n        params_method = \'get\' if method.lower() == \'get\' else \'other\'\n\n        for field in link.fields:\n            if field.name in self.params_desc_dict[params_method].keys():\n                field = field._replace(\n                    schema=coreschema.string(description=self.params_desc_dict[params_method][field.name]))\n\n            fields.append(field)\n\n        return coreapi.link(\n            url=link.url,\n            action=link.action,\n            encoding=link.encoding,\n            fields=fields,\n            description=link.description\n        )\n\nperiodictaskschema = baseschema(params_desc_dict={\n    \'other\': {\n        "crontab": "定时crontab. json。 包含的字段有: minute, hour, day_of_week, day_of_month, month_of_year",\n        "name": "该定时任务名称",\n        "task": "模板任务名",\n        "args": "传递给任务模板参数. 数组",\n        "kwargs": "传递给任务模板参数. json字符串",\n        "queue": "将任务放在哪个队列中.",\n        "enabled": "是否开启该任务. true or false. 默认为true",\n        "description": "定时任务说明"\n    }\n})\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n\n\n在view中绑定自定义的schema\n\nclass periodictasksviewset(viewsets.modelviewset):\n    queryset = periodictask.objects.all()\n    serializer_class = periodictaskserializer\n    schema = periodictaskschema\n\n\n1\n2\n3\n4\n\n\n\n# 方法二\n\n如果只是普通的apiview的话，直接在autoschema中添加字段即可。\n\ndatabaseinfoschema = autoschema(manual_fields=[\n    coreapi.field(name="db", required=true, location="query",\n                  schema=coreschema.string(description="数据库host, normal或者sub")),\n    coreapi.field(name="database", location="query", schema=coreschema.string(description="数据库")),\n    coreapi.field(name="table", required=true, location="query", schema=coreschema.string(description="数据库表"))\n])\n\n\n1\n2\n3\n4\n5\n6\n\n\n绑定自定义schema\n\nclass databaseinfo(apiview):\n    schema = databaseinfoschema\n\n    def get(self, request):\n        pass\n\n\n1\n2\n3\n4\n5\n\n\n\n# location\n\nlocation   描述\nquery      查询. list\nform       表单提交. post\npath       在url中的，/ooziejob/{id}/. read',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django压缩文件下载",frontmatter:{title:"django压缩文件下载",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/f2738b/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍在django中，如何将数据生成zip文件提供给用户进行下载",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django压缩文件下载"},{name:"twitter:description",content:"介绍在django中，如何将数据生成zip文件提供给用户进行下载"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/06.django%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django压缩文件下载"},{property:"og:description",content:"介绍在django中，如何将数据生成zip文件提供给用户进行下载"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/06.django%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django压缩文件下载"},{itemprop:"description",content:"介绍在django中，如何将数据生成zip文件提供给用户进行下载"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/06.django%E5%8E%8B%E7%BC%A9%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD.html",relativePath:"04.编程/01.python/06.django/06.django压缩文件下载.md",key:"v-bb440a42",path:"/pages/f2738b/",headersStr:null,content:'# 简介\n\n需求: 需要在请求时，将数据生成zip文件提供给用户下载。\n\n不想要在生成后再提供给用户下载\n\n解决: 使用BytesIO在内存中写入数据，而不是落地到本地中。\n\n\n# 栗子\n\n\nfrom io import BytesIO\nimport zipfile\nfrom django.http import FileResponse\n\ndef view():\n\n    download_io = BytesIO()\n\n    with zipfile.ZipFile(pb_zip_io, "w", zipfile.ZIP_DEFLATED) as zip_fp:\n        zip_fp.open("a.txt", "w") as f:\n            f.write("hello world")\n\n\n    # 注意，需要要将指针指向内存的开始位置\n    download_io.seek(0)\n\n    return FileResponse(download_io, as_attachment=True, filename="a.zip")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n',normalizedContent:'# 简介\n\n需求: 需要在请求时，将数据生成zip文件提供给用户下载。\n\n不想要在生成后再提供给用户下载\n\n解决: 使用bytesio在内存中写入数据，而不是落地到本地中。\n\n\n# 栗子\n\n\nfrom io import bytesio\nimport zipfile\nfrom django.http import fileresponse\n\ndef view():\n\n    download_io = bytesio()\n\n    with zipfile.zipfile(pb_zip_io, "w", zipfile.zip_deflated) as zip_fp:\n        zip_fp.open("a.txt", "w") as f:\n            f.write("hello world")\n\n\n    # 注意，需要要将指针指向内存的开始位置\n    download_io.seek(0)\n\n    return fileresponse(download_io, as_attachment=true, filename="a.zip")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django rest_framework使用pytest单元测试",frontmatter:{title:"django rest_framework使用pytest单元测试",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/c28126/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍在django的rest_framework中如何使用pytest进行单元测试而不是自带的测试框架。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django rest_framework使用pytest单元测试"},{name:"twitter:description",content:"介绍在django的rest_framework中如何使用pytest进行单元测试而不是自带的测试框架。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/07.django%20rest_framework%E4%BD%BF%E7%94%A8pytest%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework使用pytest单元测试"},{property:"og:description",content:"介绍在django的rest_framework中如何使用pytest进行单元测试而不是自带的测试框架。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/07.django%20rest_framework%E4%BD%BF%E7%94%A8pytest%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django rest_framework使用pytest单元测试"},{itemprop:"description",content:"介绍在django的rest_framework中如何使用pytest进行单元测试而不是自带的测试框架。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/07.django%20rest_framework%E4%BD%BF%E7%94%A8pytest%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95.html",relativePath:"04.编程/01.python/06.django/07.django rest_framework使用pytest单元测试.md",key:"v-50cf7a82",path:"/pages/c28126/",headers:[{level:2,title:"djang自带测试",slug:"djang自带测试",normalizedTitle:"djang自带测试",charIndex:2},{level:2,title:"rest framework",slug:"rest-framework",normalizedTitle:"rest framework",charIndex:665}],headersStr:"djang自带测试 rest framework",content:'# djang自带测试\n\n> django本身自带了测试框架库，是基于unittest的。\n\n执行 python manager.py test 会对路径所有test*.py 进行测试\n\nfrom django.test import TestCase\nfrom event_track.models.app import Appclass \n\nAppTestCase(TestCase):    \n    def setUp(self):        \n        App.objects.create(name="app1", package_name="package1")        \n        App.objects.create(name="app2", package_name="package2")    \n    def test_app(self):        \n        app1 = App.objects.get(name="app1")        \n        self.assertEqual(app1.package_name, "package1")        \n        app1 = App.objects.get(name="app2")        \n        self.assertEqual(app1.package_name, "package3")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# rest framework\n\n> 下面是一个简单的测试案例。使用pytest对rest framework进行测试\n\n1. 添加一个配置文件 具体看pytest-django官网\n\n[pytest]\nDJANGO_SETTINGS_MODULE=event_track_root.settings\npython_files = tests.py test_*.py *_tests.py\n\n\n1\n2\n3\n\n\n2. 创建一个model app.py\n\nfrom django.db import models\nclass App(models.Model):    \n    name = models.CharField(max_length=24)    \n    package_name = models.CharField(max_length=50, unique=True)\n\n\n1\n2\n3\n4\n\n\n> 对app的model类进行增删改查的测试 model测试必须添加@pytest.mark.django_db才可以启用数据库。 使用APITestCase对接口进行测试\n\n3. 编写测试用例 test_app.py\n\n\n@pytest.mark.django_db\n@pytest.fixture(scope="module")\ndef init_app_data():\n    App.objects.create(name="app1", package_name="package1")\n    App.objects.create(name="app2", package_name="package2")\n    App.objects.create(name="app3", package_name="package3")\n    App.objects.create(name="app4", package_name="package4")\n\nclass AppTests(APITestCase):\n\n    def test_create_app(self):\n        url = reverse(\'event_track:App-list\')\n        data_list = [{"name": "app1", "package_name": "package1"},\n                     {"name": "app2", "package_name": "package2"},\n                     {"name": "app3", "package_name": "package3"},\n                     {"name": "app4", "package_name": "package4"}\n                     ]\n\n        for data in data_list:\n            response = self.client.post(url, data)\n            self.assertEqual(response.status_code, status.HTTP_201_CREATED)\n\n        self.assertEqual(App.objects.count(), 4)\n        self.assertEqual(App.objects.get(name="app1").package_name, "package1")\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_delete_app(self):\n        app = App.objects.get(package_name="package3")\n        url = reverse(\'event_track:App-detail\', [app.id])\n        response = self.client.delete(url)\n\n        self.assertEqual(App.objects.count(), 3)\n        with pytest.raises(App.DoesNotExist):\n            App.objects.get(package_name="package3")\n        self.assertEqual(response.status_code, 204)\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_update_app(self):\n        app = App.objects.get(name="app4")\n        url = reverse(\'event_track:App-detail\', [app.id])\n\n        app.package_name = "package_update"\n        response = self.client.put(url, AppSerializer(app).data)\n\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(response.data[\'package_name\'], \'package_update\')\n        self.assertEqual(App.objects.get(name="app4").package_name, \'package_update\')\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_list_app(self):\n        url = reverse(\'event_track:App-list\')\n        response = self.client.get(url, {\'limit\': 2, \'offset\': 2})\n\n        self.assertEqual(response.status_code, 200)\n        self.assertEqual(len(response.data[\'results\']), 2)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n',normalizedContent:'# djang自带测试\n\n> django本身自带了测试框架库，是基于unittest的。\n\n执行 python manager.py test 会对路径所有test*.py 进行测试\n\nfrom django.test import testcase\nfrom event_track.models.app import appclass \n\napptestcase(testcase):    \n    def setup(self):        \n        app.objects.create(name="app1", package_name="package1")        \n        app.objects.create(name="app2", package_name="package2")    \n    def test_app(self):        \n        app1 = app.objects.get(name="app1")        \n        self.assertequal(app1.package_name, "package1")        \n        app1 = app.objects.get(name="app2")        \n        self.assertequal(app1.package_name, "package3")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# rest framework\n\n> 下面是一个简单的测试案例。使用pytest对rest framework进行测试\n\n1. 添加一个配置文件 具体看pytest-django官网\n\n[pytest]\ndjango_settings_module=event_track_root.settings\npython_files = tests.py test_*.py *_tests.py\n\n\n1\n2\n3\n\n\n2. 创建一个model app.py\n\nfrom django.db import models\nclass app(models.model):    \n    name = models.charfield(max_length=24)    \n    package_name = models.charfield(max_length=50, unique=true)\n\n\n1\n2\n3\n4\n\n\n> 对app的model类进行增删改查的测试 model测试必须添加@pytest.mark.django_db才可以启用数据库。 使用apitestcase对接口进行测试\n\n3. 编写测试用例 test_app.py\n\n\n@pytest.mark.django_db\n@pytest.fixture(scope="module")\ndef init_app_data():\n    app.objects.create(name="app1", package_name="package1")\n    app.objects.create(name="app2", package_name="package2")\n    app.objects.create(name="app3", package_name="package3")\n    app.objects.create(name="app4", package_name="package4")\n\nclass apptests(apitestcase):\n\n    def test_create_app(self):\n        url = reverse(\'event_track:app-list\')\n        data_list = [{"name": "app1", "package_name": "package1"},\n                     {"name": "app2", "package_name": "package2"},\n                     {"name": "app3", "package_name": "package3"},\n                     {"name": "app4", "package_name": "package4"}\n                     ]\n\n        for data in data_list:\n            response = self.client.post(url, data)\n            self.assertequal(response.status_code, status.http_201_created)\n\n        self.assertequal(app.objects.count(), 4)\n        self.assertequal(app.objects.get(name="app1").package_name, "package1")\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_delete_app(self):\n        app = app.objects.get(package_name="package3")\n        url = reverse(\'event_track:app-detail\', [app.id])\n        response = self.client.delete(url)\n\n        self.assertequal(app.objects.count(), 3)\n        with pytest.raises(app.doesnotexist):\n            app.objects.get(package_name="package3")\n        self.assertequal(response.status_code, 204)\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_update_app(self):\n        app = app.objects.get(name="app4")\n        url = reverse(\'event_track:app-detail\', [app.id])\n\n        app.package_name = "package_update"\n        response = self.client.put(url, appserializer(app).data)\n\n        self.assertequal(response.status_code, 200)\n        self.assertequal(response.data[\'package_name\'], \'package_update\')\n        self.assertequal(app.objects.get(name="app4").package_name, \'package_update\')\n\n    @pytest.mark.usefixtures(\'init_app_data\')\n    def test_list_app(self):\n        url = reverse(\'event_track:app-list\')\n        response = self.client.get(url, {\'limit\': 2, \'offset\': 2})\n\n        self.assertequal(response.status_code, 200)\n        self.assertequal(len(response.data[\'results\']), 2)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django restframework choice 自定义输出数据",frontmatter:{title:"django restframework choice 自定义输出数据",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/b90015/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍如何在django restframework中使用choice来自定义输出数据。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django restframework choice 自定义输出数据"},{name:"twitter:description",content:"介绍如何在django restframework中使用choice来自定义输出数据。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/08.django%20restframework%20choice%20%E8%87%AA%E5%AE%9A%E4%B9%89%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django restframework choice 自定义输出数据"},{property:"og:description",content:"介绍如何在django restframework中使用choice来自定义输出数据。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/08.django%20restframework%20choice%20%E8%87%AA%E5%AE%9A%E4%B9%89%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django restframework choice 自定义输出数据"},{itemprop:"description",content:"介绍如何在django restframework中使用choice来自定义输出数据。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/08.django%20restframework%20choice%20%E8%87%AA%E5%AE%9A%E4%B9%89%E8%BE%93%E5%87%BA%E6%95%B0%E6%8D%AE.html",relativePath:"04.编程/01.python/06.django/08.django restframework choice 自定义输出数据.md",key:"v-6e6e165e",path:"/pages/b90015/",headers:[{level:2,title:"问题",slug:"问题",normalizedTitle:"问题",charIndex:2},{level:2,title:"解决方案",slug:"解决方案",normalizedTitle:"解决方案",charIndex:502}],headersStr:"问题 解决方案",content:"# 问题\n\n我有一个这样的需求，返回的数据json中返回的是id，但是我想要得到该id对应的name。\n\nid对应的name\n\nPlatformType = (   \n    (0, '通用'),   \n    (1, '前装'),   \n    (2, '后装'),   \n    (3, '海外前装'),   \n    (4, '海外后装'),   \n    (5, '小系统')\n)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nclass TrackSerializer(serializers.ModelSerializer):\n    \n    platform = serializers.ChoiceField(choices=PlatformType)\n    \n    class Meta:    \n        model = Track    \n        fields = \"__all__\"\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n返回的结果是:\n\n{\n    platform: 1\n}\n\n\n1\n2\n3\n\n\n但是我想要的是1对应的前装，这个时候需要自定义返回的数据。\n\n\n# 解决方案\n\n 1. 自定义字段类型，重写ChoiceField字段类，并重写to_representation方法，在序列化platform字段时，会调用to_representation方法转换成我们想要的格式。\n\nclass PlatFormField(serializers.ChoiceField):    \n    def to_representation(self, value: Any):        \n        return self.choices[value]\n\nclass TrackSerializer(serializers.ModelSerializer):\n    \n    platform = PlatFormField(choices=PlatformType)\n    \n    class Meta:    \n        model = Track    \n        fields = \"__all__\"\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n 2. 重写显示的字段。\n\n将platform字段重新进行改写，获取其显示的名字。\n\nclass TrackSerializer(serializers.ModelSerializer):\n    platform = serializers.SerializerMethodField()\n    class Meta:\n        model = Track\n        fields = \"__all__\"\n\ndef get_platform(self, obj):\n    return obj.get_platform_display()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n",normalizedContent:"# 问题\n\n我有一个这样的需求，返回的数据json中返回的是id，但是我想要得到该id对应的name。\n\nid对应的name\n\nplatformtype = (   \n    (0, '通用'),   \n    (1, '前装'),   \n    (2, '后装'),   \n    (3, '海外前装'),   \n    (4, '海外后装'),   \n    (5, '小系统')\n)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\nclass trackserializer(serializers.modelserializer):\n    \n    platform = serializers.choicefield(choices=platformtype)\n    \n    class meta:    \n        model = track    \n        fields = \"__all__\"\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n返回的结果是:\n\n{\n    platform: 1\n}\n\n\n1\n2\n3\n\n\n但是我想要的是1对应的前装，这个时候需要自定义返回的数据。\n\n\n# 解决方案\n\n 1. 自定义字段类型，重写choicefield字段类，并重写to_representation方法，在序列化platform字段时，会调用to_representation方法转换成我们想要的格式。\n\nclass platformfield(serializers.choicefield):    \n    def to_representation(self, value: any):        \n        return self.choices[value]\n\nclass trackserializer(serializers.modelserializer):\n    \n    platform = platformfield(choices=platformtype)\n    \n    class meta:    \n        model = track    \n        fields = \"__all__\"\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n 2. 重写显示的字段。\n\n将platform字段重新进行改写，获取其显示的名字。\n\nclass trackserializer(serializers.modelserializer):\n    platform = serializers.serializermethodfield()\n    class meta:\n        model = track\n        fields = \"__all__\"\n\ndef get_platform(self, obj):\n    return obj.get_platform_display()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django Filtering 使用",frontmatter:{title:"django Filtering 使用",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/cfdb5f/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍django-filter是如何使用的。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217188654.png#alt="},{name:"twitter:title",content:"django Filtering 使用"},{name:"twitter:description",content:"介绍django-filter是如何使用的。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217188654.png#alt="},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/09.django%20Filtering%20%E4%BD%BF%E7%94%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django Filtering 使用"},{property:"og:description",content:"介绍django-filter是如何使用的。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217188654.png#alt="},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/09.django%20Filtering%20%E4%BD%BF%E7%94%A8.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django Filtering 使用"},{itemprop:"description",content:"介绍django-filter是如何使用的。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217188654.png#alt="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/09.django%20Filtering%20%E4%BD%BF%E7%94%A8.html",relativePath:"04.编程/01.python/06.django/09.django Filtering 使用.md",key:"v-72f4b6b0",path:"/pages/cfdb5f/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"准备工作",slug:"准备工作",normalizedTitle:"准备工作",charIndex:157},{level:2,title:"DjangoFilterBackend",slug:"djangofilterbackend",normalizedTitle:"djangofilterbackend",charIndex:97},{level:2,title:"使用默认的过滤",slug:"使用默认的过滤",normalizedTitle:"使用默认的过滤",charIndex:334},{level:2,title:"自定义过滤",slug:"自定义过滤",normalizedTitle:"自定义过滤",charIndex:801},{level:2,title:"SearchFilter",slug:"searchfilter",normalizedTitle:"searchfilter",charIndex:121},{level:2,title:"OrderingFilter",slug:"orderingfilter",normalizedTitle:"orderingfilter",charIndex:138},{level:2,title:"自定义过滤条件",slug:"自定义过滤条件",normalizedTitle:"自定义过滤条件",charIndex:2994}],headersStr:"简介 准备工作 DjangoFilterBackend 使用默认的过滤 自定义过滤 SearchFilter OrderingFilter 自定义过滤条件",content:"# 简介\n\ndjango-filter是单独的一个库，不属于djangorestframework中的，属于外部库引用进来使用。下面就来介绍下filter\n\n有三种filter方式:\n\n 1. DjangoFilterBackend\n 2. SearchFilter\n 3. OrderingFilter\n\n\n# 准备工作\n\n首先需要安装django-filter\n\n> pip install django-filter\n\n然后需要将django_filters 添加到 INSTALLED_APPS中\n\nINSTALLED_APPS = [\n    'django_filters',\n]\n\n\n1\n2\n3\n\n\n\n# DjangoFilterBackend\n\n\n# 使用默认的过滤\n\n在View中添加filter_backends属性,设置过滤方式DjangoFilterBackend，并且设置过滤的属性。\n\n\nfrom django_filters.rest_framework import DjangoFilterBackend\n\nclass GoodsListViewSet(ModelViewSet):    \n    queryset = Goods.objects.all()    \n    serializer_class = GoodsSerializer    \n    pagination_class = MyPagination    \n    filter_backends = (DjangoFilterBackend,)    \n    filterset_fields = ('name', 'shop_price')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在调试界面中会出现过滤器选项, 可以在其中过滤name和shop_price两个属性的值\n\n\n# 自定义过滤\n\n创建filters.py，在里面定义自己的过滤器。 可以通过最小的价格、最大的价格，和模糊查询名字去过滤想要的数据。\n\nfrom django_filters import FilterSet, NumberFilter, CharFilter\nfrom .models import Goods\n\nclass GoodsFilter(FilterSet):   \n    \"\"\"    商品的过滤类    \"\"\"    \n    price_min = NumberFilter(field_name='shop_price', help_text=\"最低价格\", lookup_expr='gte')    \n    price_max = NumberFilter(field_name='shop_price', lookup_expr='lte')    \n    name = CharFilter(field_name='name', lookup_expr=\"icontains\")    \n    class Meta:        \n        model = Goods        \n        fields = ['price_min', 'price_max', 'name']\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n将该过滤器添加到view中 view.py\n\nclass GoodsListViewSet(ModelViewSet):    \n    queryset = Goods.objects.all()    \n    serializer_class = GoodsSerializer   \n    pagination_class = MyPagination    \n    filter_backends = (DjangoFilterBackend,)    \n    filter_class = GoodsFilter\n\n\n1\n2\n3\n4\n5\n6\n\n\n最后可以通过 http://127.0.0.1:8000/goods/?price_min=150&price_max=160&name=水果 去过滤得到想要的数据。\n\n\n# SearchFilter\n\n这个Filter是基于Django的搜索。现在我们将SearchFilter集成到过滤里面来。在filter_backends中添加SearchFiler，然后再在search_fields中添加需要搜索的字段即可，在搜索的字段前面字符变量来提高搜索效率。\n\n * '^' Starts-with search.\n * '=' Exact matches.\n * '@' Full-text search. (Currently only supported Django's MySQL backend.)\n * '$' Regex search.\n\nview.py\n\nfrom rest_framework.filters import SearchFilter\n\nclass GoodsListViewSet(ModelViewSet):    \n    queryset = Goods.objects.all()    \n    serializer_class = GoodsSerializer    \n    pagination_class = MyPagination    \n    filter_backends = (DjangoFilterBackend, SearchFilter)    \n    filter_class = GoodsFilter    \n    search_fields = (\"=name\", 'goods_brief', 'goods_desc')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# OrderingFilter\n\n可以对数据进行排序筛选数据。我们将其加入进去\n\nview.py\n\nfrom rest_framework.filters import SearchFilter, OrderingFilter\n\n\n\nclass GoodsListViewSet(ModelViewSet):    \n    queryset = Goods.objects.all()    \n    serializer_class = GoodsSerializer    \n    pagination_class = MyPagination    \n    filter_backends = (DjangoFilterBackend, SearchFilter, OrderingFilter) \n    filter_class = GoodsFilter    \n    search_fields = (\"=name\", 'goods_brief', 'goods_desc')\n    ordering_fields = (\"sold_num\", \"add_time\")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 自定义过滤条件\n\n修改filters.py文件，编写过滤方法top_category_filter绑定到top_category字段中，即可通过该属性名进行相应的筛选。\n\nclass GoodsFilter(FilterSet):    \n    \"\"\"    商品的过滤类    \"\"\"    \n    pricemin = NumberFilter(field_name='shop_price', help_text=\"最低价格\", lookup_expr='gte')    \n    pricemax = NumberFilter(field_name='shop_price', lookup_expr='lte')    \n    name = CharFilter(field_name='name', lookup_expr=\"icontains\")   \n    top_category = NumberFilter(method='top_category_filter')    \n    \n    def top_category_filter(self, queryset, name, value):        \n        return queryset.filter(Q(category_id=value) | Q(category__parent_category_id=value) | (category__parent_category__parent_category_id=value))\n    \n    class Meta:        \n        model = Goods\n        fields = ['pricemin', 'pricemax', 'name']\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",normalizedContent:"# 简介\n\ndjango-filter是单独的一个库，不属于djangorestframework中的，属于外部库引用进来使用。下面就来介绍下filter\n\n有三种filter方式:\n\n 1. djangofilterbackend\n 2. searchfilter\n 3. orderingfilter\n\n\n# 准备工作\n\n首先需要安装django-filter\n\n> pip install django-filter\n\n然后需要将django_filters 添加到 installed_apps中\n\ninstalled_apps = [\n    'django_filters',\n]\n\n\n1\n2\n3\n\n\n\n# djangofilterbackend\n\n\n# 使用默认的过滤\n\n在view中添加filter_backends属性,设置过滤方式djangofilterbackend，并且设置过滤的属性。\n\n\nfrom django_filters.rest_framework import djangofilterbackend\n\nclass goodslistviewset(modelviewset):    \n    queryset = goods.objects.all()    \n    serializer_class = goodsserializer    \n    pagination_class = mypagination    \n    filter_backends = (djangofilterbackend,)    \n    filterset_fields = ('name', 'shop_price')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在调试界面中会出现过滤器选项, 可以在其中过滤name和shop_price两个属性的值\n\n\n# 自定义过滤\n\n创建filters.py，在里面定义自己的过滤器。 可以通过最小的价格、最大的价格，和模糊查询名字去过滤想要的数据。\n\nfrom django_filters import filterset, numberfilter, charfilter\nfrom .models import goods\n\nclass goodsfilter(filterset):   \n    \"\"\"    商品的过滤类    \"\"\"    \n    price_min = numberfilter(field_name='shop_price', help_text=\"最低价格\", lookup_expr='gte')    \n    price_max = numberfilter(field_name='shop_price', lookup_expr='lte')    \n    name = charfilter(field_name='name', lookup_expr=\"icontains\")    \n    class meta:        \n        model = goods        \n        fields = ['price_min', 'price_max', 'name']\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n将该过滤器添加到view中 view.py\n\nclass goodslistviewset(modelviewset):    \n    queryset = goods.objects.all()    \n    serializer_class = goodsserializer   \n    pagination_class = mypagination    \n    filter_backends = (djangofilterbackend,)    \n    filter_class = goodsfilter\n\n\n1\n2\n3\n4\n5\n6\n\n\n最后可以通过 http://127.0.0.1:8000/goods/?price_min=150&price_max=160&name=水果 去过滤得到想要的数据。\n\n\n# searchfilter\n\n这个filter是基于django的搜索。现在我们将searchfilter集成到过滤里面来。在filter_backends中添加searchfiler，然后再在search_fields中添加需要搜索的字段即可，在搜索的字段前面字符变量来提高搜索效率。\n\n * '^' starts-with search.\n * '=' exact matches.\n * '@' full-text search. (currently only supported django's mysql backend.)\n * '$' regex search.\n\nview.py\n\nfrom rest_framework.filters import searchfilter\n\nclass goodslistviewset(modelviewset):    \n    queryset = goods.objects.all()    \n    serializer_class = goodsserializer    \n    pagination_class = mypagination    \n    filter_backends = (djangofilterbackend, searchfilter)    \n    filter_class = goodsfilter    \n    search_fields = (\"=name\", 'goods_brief', 'goods_desc')\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# orderingfilter\n\n可以对数据进行排序筛选数据。我们将其加入进去\n\nview.py\n\nfrom rest_framework.filters import searchfilter, orderingfilter\n\n\n\nclass goodslistviewset(modelviewset):    \n    queryset = goods.objects.all()    \n    serializer_class = goodsserializer    \n    pagination_class = mypagination    \n    filter_backends = (djangofilterbackend, searchfilter, orderingfilter) \n    filter_class = goodsfilter    \n    search_fields = (\"=name\", 'goods_brief', 'goods_desc')\n    ordering_fields = (\"sold_num\", \"add_time\")\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 自定义过滤条件\n\n修改filters.py文件，编写过滤方法top_category_filter绑定到top_category字段中，即可通过该属性名进行相应的筛选。\n\nclass goodsfilter(filterset):    \n    \"\"\"    商品的过滤类    \"\"\"    \n    pricemin = numberfilter(field_name='shop_price', help_text=\"最低价格\", lookup_expr='gte')    \n    pricemax = numberfilter(field_name='shop_price', lookup_expr='lte')    \n    name = charfilter(field_name='name', lookup_expr=\"icontains\")   \n    top_category = numberfilter(method='top_category_filter')    \n    \n    def top_category_filter(self, queryset, name, value):        \n        return queryset.filter(q(category_id=value) | q(category__parent_category_id=value) | (category__parent_category__parent_category_id=value))\n    \n    class meta:        \n        model = goods\n        fields = ['pricemin', 'pricemax', 'name']\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django viewset 和 Router 配合使用时报的错",frontmatter:{title:"django viewset 和 Router 配合使用时报的错",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/e75ceb/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"解决django viewset和router配合使用时报的错误",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django viewset 和 Router 配合使用时报的错"},{name:"twitter:description",content:"解决django viewset和router配合使用时报的错误"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/10.django%20viewset%20%E5%92%8C%20Router%20%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%E6%97%B6%E6%8A%A5%E7%9A%84%E9%94%99.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django viewset 和 Router 配合使用时报的错"},{property:"og:description",content:"解决django viewset和router配合使用时报的错误"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/10.django%20viewset%20%E5%92%8C%20Router%20%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%E6%97%B6%E6%8A%A5%E7%9A%84%E9%94%99.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django viewset 和 Router 配合使用时报的错"},{itemprop:"description",content:"解决django viewset和router配合使用时报的错误"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/10.django%20viewset%20%E5%92%8C%20Router%20%E9%85%8D%E5%90%88%E4%BD%BF%E7%94%A8%E6%97%B6%E6%8A%A5%E7%9A%84%E9%94%99.html",relativePath:"04.编程/01.python/06.django/10.django viewset 和 Router 配合使用时报的错.md",key:"v-3e16c4d8",path:"/pages/e75ceb/",headersStr:null,content:"报错内容:\n\n> 'basename' argument not specified, and could not automatically determine the name from the viewset, as it does not have a '.queryset' attribute.\n\nbasename是Router.register()中的一个属性。\n\n如果没有设置basename将会自动的基于viewset中的queryset属性。如果不使用queryset属性，自定义get_quertset方法，那么需要设置basename参数。\n\n示例代码如下. 这里使用了自定义的get_quertset方法，所以router.register()中必须加上basename，不然会出现以上错误 view.py\n\nclass GoodsListViewSet(ModelViewSet):    \n    # queryset = Goods.objects.all()    \n    serializer_class = GoodsSerializer    \n    pagination_class = MyPagination    \n    \n    def get_queryset(self):        \n        queryset = Goods.objects.all()        \n        price_min = self.request.query_params.get(\"price_min\", 0)        \n        if price_min:            \n            queryset = queryset.filter(shop_price__gt=int(price_min))        \n    \n    return queryset\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nurl.py\n\nfrom rest_framework.routers import DefaultRouter\nrouter = DefaultRouter()\nrouter.register(r'goods', GoodsListViewSet, base_name=\"goods\")\n\n\n1\n2\n3\n",normalizedContent:"报错内容:\n\n> 'basename' argument not specified, and could not automatically determine the name from the viewset, as it does not have a '.queryset' attribute.\n\nbasename是router.register()中的一个属性。\n\n如果没有设置basename将会自动的基于viewset中的queryset属性。如果不使用queryset属性，自定义get_quertset方法，那么需要设置basename参数。\n\n示例代码如下. 这里使用了自定义的get_quertset方法，所以router.register()中必须加上basename，不然会出现以上错误 view.py\n\nclass goodslistviewset(modelviewset):    \n    # queryset = goods.objects.all()    \n    serializer_class = goodsserializer    \n    pagination_class = mypagination    \n    \n    def get_queryset(self):        \n        queryset = goods.objects.all()        \n        price_min = self.request.query_params.get(\"price_min\", 0)        \n        if price_min:            \n            queryset = queryset.filter(shop_price__gt=int(price_min))        \n    \n    return queryset\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\nurl.py\n\nfrom rest_framework.routers import defaultrouter\nrouter = defaultrouter()\nrouter.register(r'goods', goodslistviewset, base_name=\"goods\")\n\n\n1\n2\n3\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django model的序列化",frontmatter:{title:"django model的序列化",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/acdd50/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"django model如何实现序列化。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217291865.png#alt="},{name:"twitter:title",content:"django model的序列化"},{name:"twitter:description",content:"django model如何实现序列化。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217291865.png#alt="},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/11.django%20model%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django model的序列化"},{property:"og:description",content:"django model如何实现序列化。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217291865.png#alt="},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/11.django%20model%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django model的序列化"},{itemprop:"description",content:"django model如何实现序列化。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604217291865.png#alt="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/11.django%20model%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96.html",relativePath:"04.编程/01.python/06.django/11.django model的序列化.md",key:"v-242c57bc",path:"/pages/acdd50/",headersStr:null,content:'网络传输数据现在流行的是json数据格式，所以非常需要将数据库查询的到对象数据序列化成json格式，然后返回给前端进行数据展示。\n\n下面讨论在django中如何更方便的将model 序列化。\n\n一个goods的modle如下。\n\n class Goods(models.Model):\n    name = models.CharField(max_length=100, verbose_name="商品名")\n    market_price = models.FloatField(default=0, verbose_name="市场价格")\n    goods_front_image = models.ImageField(upload_to="goods/images/", null=True, blank=True, verbose_name="封面图")    \n    .....\n\n\n\n1\n2\n3\n4\n5\n6\n\n\n序列化一. 最原始的model序列化，比较繁琐..太不智能了.\n\ngoodList = Goods.objects.all()[:10]\nfor good in goodList:\n    json_dict = {}\n    json_dict["name"] = good.name                    \n    json_dict["market_price"] = good.market_price\n    json_dict["add_time"] = good.add_time\n    json_list.append(json_dict)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n序列化二.\n\nfrom django.forms.models import model_to_dict\n\ngoodsList = Goods.objects.all()[:10]\nfor goods in goodsList:    json_list.append(model_to_dict(good))\n\n\n1\n2\n3\n4\n\n\n通过使用model_to_dict 更方便的去序列化goods对象。唯一不足的是无法序列化ImageField字段。\n\n\n\n序列化三.\n\ngoodsList = Goods.objects.all()[:10]\ngoods_json = serialize(\'json\', goodList)\n\n\n1\n2\n\n\n直接将整个goods list 进行序列化，更加方便的使用。但是虽然能够将ImageField序列化，但是得到的图片路径是从数据库中拿到的，并不是图片真实的路径，前端拿到后需要做处理才能使用。\n\n\n\n最后，还有没有更方便的序列化方式呢，当然有，去了解下djangorestframework吧，后期我也会有写关于该框架的博客。',normalizedContent:'网络传输数据现在流行的是json数据格式，所以非常需要将数据库查询的到对象数据序列化成json格式，然后返回给前端进行数据展示。\n\n下面讨论在django中如何更方便的将model 序列化。\n\n一个goods的modle如下。\n\n class goods(models.model):\n    name = models.charfield(max_length=100, verbose_name="商品名")\n    market_price = models.floatfield(default=0, verbose_name="市场价格")\n    goods_front_image = models.imagefield(upload_to="goods/images/", null=true, blank=true, verbose_name="封面图")    \n    .....\n\n\n\n1\n2\n3\n4\n5\n6\n\n\n序列化一. 最原始的model序列化，比较繁琐..太不智能了.\n\ngoodlist = goods.objects.all()[:10]\nfor good in goodlist:\n    json_dict = {}\n    json_dict["name"] = good.name                    \n    json_dict["market_price"] = good.market_price\n    json_dict["add_time"] = good.add_time\n    json_list.append(json_dict)\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n序列化二.\n\nfrom django.forms.models import model_to_dict\n\ngoodslist = goods.objects.all()[:10]\nfor goods in goodslist:    json_list.append(model_to_dict(good))\n\n\n1\n2\n3\n4\n\n\n通过使用model_to_dict 更方便的去序列化goods对象。唯一不足的是无法序列化imagefield字段。\n\n\n\n序列化三.\n\ngoodslist = goods.objects.all()[:10]\ngoods_json = serialize(\'json\', goodlist)\n\n\n1\n2\n\n\n直接将整个goods list 进行序列化，更加方便的使用。但是虽然能够将imagefield序列化，但是得到的图片路径是从数据库中拿到的，并不是图片真实的路径，前端拿到后需要做处理才能使用。\n\n\n\n最后，还有没有更方便的序列化方式呢，当然有，去了解下djangorestframework吧，后期我也会有写关于该框架的博客。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django中使用AbStractUser",frontmatter:{title:"django中使用AbStractUser",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/382755/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍在django中如何使用AbStractUser",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django中使用AbStractUser"},{name:"twitter:description",content:"介绍在django中如何使用AbStractUser"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/12.django%E4%B8%AD%E4%BD%BF%E7%94%A8AbStractUser.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django中使用AbStractUser"},{property:"og:description",content:"介绍在django中如何使用AbStractUser"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/12.django%E4%B8%AD%E4%BD%BF%E7%94%A8AbStractUser.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django中使用AbStractUser"},{itemprop:"description",content:"介绍在django中如何使用AbStractUser"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/12.django%E4%B8%AD%E4%BD%BF%E7%94%A8AbStractUser.html",relativePath:"04.编程/01.python/06.django/12.django中使用AbStractUser.md",key:"v-580c8dac",path:"/pages/382755/",headersStr:null,content:"> Django内置的User对象，已经包含了一些主要的属性，如username、password、email等，但实际情况可能还需要昵称、头像等其他属性，仅仅使用内置的User属性是不够的。\n> \n> 通过使用AbstractUser可以对User进行扩展使用，添加用户自定义的属性。\n\nUser模型源码如下。\n\nclass User(AbstractUser):\n    class Meta(AbstractUser.Meta):\n        swappable = 'AUTH_USER_MODEL'\n\n\n1\n2\n3\n\n\n由此可见，User对AbstractUser仅仅是继承，没有进行任何的扩展。所以我们继承AbstractUser可以获得User的所有特性。\n\n * model中使用\n\n继承AbstractUser\n\nfrom django.contrib.auth.models import AbstractUser\n\nclass MyUser(AbstractUser):\n    pass\n\n\n1\n2\n3\n4\n\n * 全局settings.py中设置\n\n覆盖默认的user model\n\nAUTH_USER_MODEL = 'app.MyUser'\n\n\n1\n\n * 在admin.py中注册MyUser\n\nfrom django.contrib import admin\nfrom .models import UserProfile\nadmin.site.register(UserProfile,UserAdmin)  \n#用UserAdmin去注册UserProfile\n\n\n1\n2\n3\n4\n",normalizedContent:"> django内置的user对象，已经包含了一些主要的属性，如username、password、email等，但实际情况可能还需要昵称、头像等其他属性，仅仅使用内置的user属性是不够的。\n> \n> 通过使用abstractuser可以对user进行扩展使用，添加用户自定义的属性。\n\nuser模型源码如下。\n\nclass user(abstractuser):\n    class meta(abstractuser.meta):\n        swappable = 'auth_user_model'\n\n\n1\n2\n3\n\n\n由此可见，user对abstractuser仅仅是继承，没有进行任何的扩展。所以我们继承abstractuser可以获得user的所有特性。\n\n * model中使用\n\n继承abstractuser\n\nfrom django.contrib.auth.models import abstractuser\n\nclass myuser(abstractuser):\n    pass\n\n\n1\n2\n3\n4\n\n * 全局settings.py中设置\n\n覆盖默认的user model\n\nauth_user_model = 'app.myuser'\n\n\n1\n\n * 在admin.py中注册myuser\n\nfrom django.contrib import admin\nfrom .models import userprofile\nadmin.site.register(userprofile,useradmin)  \n#用useradmin去注册userprofile\n\n\n1\n2\n3\n4\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users",frontmatter:{title:"django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/060c51/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"使用pycharm professional 开发django时出现以下异常。",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604218742346.png#alt="},{name:"twitter:title",content:"django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users"},{name:"twitter:description",content:"使用pycharm professional 开发django时出现以下异常。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604218742346.png#alt="},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/13.django.core.exceptions.ImproperlyConfigured%20Application%20labels%20aren't%20unique,%20duplicates%20users.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users"},{property:"og:description",content:"使用pycharm professional 开发django时出现以下异常。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604218742346.png#alt="},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/13.django.core.exceptions.ImproperlyConfigured%20Application%20labels%20aren't%20unique,%20duplicates%20users.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users"},{itemprop:"description",content:"使用pycharm professional 开发django时出现以下异常。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604218742346.png#alt="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/13.django.core.exceptions.ImproperlyConfigured%20Application%20labels%20aren't%20unique,%20duplicates%20users.html",relativePath:"04.编程/01.python/06.django/13.django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users.md",key:"v-669ddbd6",path:"/pages/060c51/",headersStr:null,content:"使用pycharm professional 开发django时出现以下异常。\n\n> django.core.exceptions.ImproperlyConfigured: Application labels aren't unique, duplicates: users\n\n查找资料后发现，因为users应用重复了，所以报错。\n\n> 在使用pycharm professional 创建django项目时，已经创建了users 应用，并自动添加到项目中。\n\n\n\n> 后面再在INSTALLED_APPS中添加users则会重复添加users应用。\n\n",normalizedContent:"使用pycharm professional 开发django时出现以下异常。\n\n> django.core.exceptions.improperlyconfigured: application labels aren't unique, duplicates: users\n\n查找资料后发现，因为users应用重复了，所以报错。\n\n> 在使用pycharm professional 创建django项目时，已经创建了users 应用，并自动添加到项目中。\n\n\n\n> 后面再在installed_apps中添加users则会重复添加users应用。\n\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django 中 media配置",frontmatter:{title:"django 中 media配置",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/de01e2/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"media文件夹一般用于上传媒体文件到服务中存放的地方。介绍在django中如何使用media的配置",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django 中 media配置"},{name:"twitter:description",content:"media文件夹一般用于上传媒体文件到服务中存放的地方。介绍在django中如何使用media的配置"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/14.django%20%E4%B8%AD%20media%E9%85%8D%E7%BD%AE.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django 中 media配置"},{property:"og:description",content:"media文件夹一般用于上传媒体文件到服务中存放的地方。介绍在django中如何使用media的配置"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/14.django%20%E4%B8%AD%20media%E9%85%8D%E7%BD%AE.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django 中 media配置"},{itemprop:"description",content:"media文件夹一般用于上传媒体文件到服务中存放的地方。介绍在django中如何使用media的配置"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/14.django%20%E4%B8%AD%20media%E9%85%8D%E7%BD%AE.html",relativePath:"04.编程/01.python/06.django/14.django 中 media配置.md",key:"v-5f11081e",path:"/pages/de01e2/",headersStr:null,content:'media文件夹一般用于上传媒体文件到服务中存放的地方。\n\n配置\n\n 1. 在项目中创建media文件夹\n\n 2. models 配置\n\nclass UserModel(models.Model):\n    \n    # 文件会上传到 /media/users目录下\n    image = models.ImageField(max_length=200, upload_to="users/")\n\n\n1\n2\n3\n4\n\n 3. settings 配置\n\nMEDIA_URL = "/media/"\nMEDIA_ROOT = os.path.join(BASE_DIR, "media")\n\n\n1\n2\n\n 4. urls.py 配置\n\nfrom django.urls import re_path\nfrom settings import MEDIA_ROOT\n\nurlpatterns = [    \n    re_path(r\'^media/(?P<path>.*)$\', serve, {"document_root": MEDIA_ROOT})\n]\n\n\n1\n2\n3\n4\n5\n6\n\n 5. 测试\n\n> 通过localhost:8000/media/user/a.jpg 可以访问图片',normalizedContent:'media文件夹一般用于上传媒体文件到服务中存放的地方。\n\n配置\n\n 1. 在项目中创建media文件夹\n\n 2. models 配置\n\nclass usermodel(models.model):\n    \n    # 文件会上传到 /media/users目录下\n    image = models.imagefield(max_length=200, upload_to="users/")\n\n\n1\n2\n3\n4\n\n 3. settings 配置\n\nmedia_url = "/media/"\nmedia_root = os.path.join(base_dir, "media")\n\n\n1\n2\n\n 4. urls.py 配置\n\nfrom django.urls import re_path\nfrom settings import media_root\n\nurlpatterns = [    \n    re_path(r\'^media/(?p<path>.*)$\', serve, {"document_root": media_root})\n]\n\n\n1\n2\n3\n4\n5\n6\n\n 5. 测试\n\n> 通过localhost:8000/media/user/a.jpg 可以访问图片',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django 外键引用自身和on_delete参数",frontmatter:{title:"django 外键引用自身和on_delete参数",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/b422bd/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"django中使用外键引用自身的方法及on_delete参数的配置",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django 外键引用自身和on_delete参数"},{name:"twitter:description",content:"django中使用外键引用自身的方法及on_delete参数的配置"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/15.django%20%E5%A4%96%E9%94%AE%E5%BC%95%E7%94%A8%E8%87%AA%E8%BA%AB%E5%92%8Con_delete%E5%8F%82%E6%95%B0.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django 外键引用自身和on_delete参数"},{property:"og:description",content:"django中使用外键引用自身的方法及on_delete参数的配置"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/15.django%20%E5%A4%96%E9%94%AE%E5%BC%95%E7%94%A8%E8%87%AA%E8%BA%AB%E5%92%8Con_delete%E5%8F%82%E6%95%B0.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django 外键引用自身和on_delete参数"},{itemprop:"description",content:"django中使用外键引用自身的方法及on_delete参数的配置"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/15.django%20%E5%A4%96%E9%94%AE%E5%BC%95%E7%94%A8%E8%87%AA%E8%BA%AB%E5%92%8Con_delete%E5%8F%82%E6%95%B0.html",relativePath:"04.编程/01.python/06.django/15.django 外键引用自身和on_delete参数.md",key:"v-e8f812b8",path:"/pages/b422bd/",headersStr:null,content:"案例. 该模型使用外键引用自己本身。\n\nfrom django.db import models\n\nclass Category(models.Model):\n    name = models.TextField()\n    parent_cat = models.ForeignKey('self',on_delete=models.CASCADE)\n\n\n1\n2\n3\n4\n5\n\n\non_delete参数如下:\n\n 1. CASCADE：级联操作。如果外键对应的那条数据被删除了，那么这条数据也会被删除。\n\n 2. PROTECT：受保护。即只要这条数据引用了外键的那条数据，那么就不能删除外键的那条数据。如果我们强行删除，Django就会报错。\n\n 3. SET_NULL：设置为空。如果外键的那条数据被删除了，那么在本条数据上就将这个字段设置为空。如果设置这个选项，前提是要指定这个字段可以为空。\n\n 4. SET_DEFAULT：设置默认值。如果外键的那条数据被删除了，那么本条数据上就将这个字段设置为默认值。如果设置这个选项，== 前提是要指定这个字段一个默认值 ==。\n\n 5. SET()：如果外键的那条数据被删除了。那么将会获取SET函数中的值来作为这个外键的值。SET函数可以接收一个可以调用的对象（比如函数或者方法），如果是可以调用的对象，那么会将这个对象调用后的结果作为值返回回去。== 可以不用指定默认值 ==\n\n 6. DO_NOTHING：不采取任何行为。一切全看数据库级别的约束。\n\n注意:以上的配置都是django级别的，在数据库中的级别依旧是RESTRICT\n\n数据库层面的约束有:\n\n 1. RESTRICT：默认的选项，如果想要删除父表的记录时，而在子表中有关联该父表的记录，则不允许删除父表中的记录；\n\n 2. NOACTION：同 RESTRICT效果一样，也是首先先检查外键;\n\n 3. CASCADE：父表delete、update的时候，子表会delete、update掉关联记录；\n\n 4. SET NULL:父表delete、update的时候，子表会将关联记录的外键字段所在列设为null，所以注意在设计子表时外键不能设为not null；\n\n为什么在django中可以是用不同的约束去操作数据库呢。\n\n> 比如 django 中 on_delete=CASCADE, 但是数据库的外键约束是RESTRICT. 在进行删除A表数据时，发现被外键约束着，使数据不能被删除，则django会先去删除约束的B表数据，然后再来删除A表数据。",normalizedContent:"案例. 该模型使用外键引用自己本身。\n\nfrom django.db import models\n\nclass category(models.model):\n    name = models.textfield()\n    parent_cat = models.foreignkey('self',on_delete=models.cascade)\n\n\n1\n2\n3\n4\n5\n\n\non_delete参数如下:\n\n 1. cascade：级联操作。如果外键对应的那条数据被删除了，那么这条数据也会被删除。\n\n 2. protect：受保护。即只要这条数据引用了外键的那条数据，那么就不能删除外键的那条数据。如果我们强行删除，django就会报错。\n\n 3. set_null：设置为空。如果外键的那条数据被删除了，那么在本条数据上就将这个字段设置为空。如果设置这个选项，前提是要指定这个字段可以为空。\n\n 4. set_default：设置默认值。如果外键的那条数据被删除了，那么本条数据上就将这个字段设置为默认值。如果设置这个选项，== 前提是要指定这个字段一个默认值 ==。\n\n 5. set()：如果外键的那条数据被删除了。那么将会获取set函数中的值来作为这个外键的值。set函数可以接收一个可以调用的对象（比如函数或者方法），如果是可以调用的对象，那么会将这个对象调用后的结果作为值返回回去。== 可以不用指定默认值 ==\n\n 6. do_nothing：不采取任何行为。一切全看数据库级别的约束。\n\n注意:以上的配置都是django级别的，在数据库中的级别依旧是restrict\n\n数据库层面的约束有:\n\n 1. restrict：默认的选项，如果想要删除父表的记录时，而在子表中有关联该父表的记录，则不允许删除父表中的记录；\n\n 2. noaction：同 restrict效果一样，也是首先先检查外键;\n\n 3. cascade：父表delete、update的时候，子表会delete、update掉关联记录；\n\n 4. set null:父表delete、update的时候，子表会将关联记录的外键字段所在列设为null，所以注意在设计子表时外键不能设为not null；\n\n为什么在django中可以是用不同的约束去操作数据库呢。\n\n> 比如 django 中 on_delete=cascade, 但是数据库的外键约束是restrict. 在进行删除a表数据时，发现被外键约束着，使数据不能被删除，则django会先去删除约束的b表数据，然后再来删除a表数据。",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django 警告 while time zone support is active",frontmatter:{title:"django 警告 while time zone support is active",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/f0d816/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"django中的时区问题",feed:{enable:!0},tags:["python","django"],categories:["编程","python","django"],comment:!0,meta:[{name:"twitter:title",content:"django 警告 while time zone support is active"},{name:"twitter:description",content:"django中的时区问题"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/16.django%20%E8%AD%A6%E5%91%8A%20while%20time%20zone%20support%20is%20active.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django 警告 while time zone support is active"},{property:"og:description",content:"django中的时区问题"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/16.django%20%E8%AD%A6%E5%91%8A%20while%20time%20zone%20support%20is%20active.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django 警告 while time zone support is active"},{itemprop:"description",content:"django中的时区问题"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/16.django%20%E8%AD%A6%E5%91%8A%20while%20time%20zone%20support%20is%20active.html",relativePath:"04.编程/01.python/06.django/16.django 警告 while time zone support is active.md",key:"v-35d0167d",path:"/pages/f0d816/",headersStr:null,content:"告警错误如下。\n\n> DateTimeField Customer.updated received a naive datetime (2016-06-19 07:18:21.118000) while time zone support is active\n\n在 settings.py 中设置的 USE_TZ=True，所以需要使用 active datetime, 但是却得到了 naive datetime.\n\n> naive datetime 是通过 datetime 输出不带时区的时间. active time 是使用django.utils.timezone.now() 输出的是带时区utc时间。\n\n解决办法\n\n 1. 使用带时区的时间, django中使用 django.utils.timezone.now() , settings.py 中 USE_TZ=True\n\n 2. 使用不带时区的时间, django中使用 datetime.now(), settings.py 中 USE_TZ=False",normalizedContent:"告警错误如下。\n\n> datetimefield customer.updated received a naive datetime (2016-06-19 07:18:21.118000) while time zone support is active\n\n在 settings.py 中设置的 use_tz=true，所以需要使用 active datetime, 但是却得到了 naive datetime.\n\n> naive datetime 是通过 datetime 输出不带时区的时间. active time 是使用django.utils.timezone.now() 输出的是带时区utc时间。\n\n解决办法\n\n 1. 使用带时区的时间, django中使用 django.utils.timezone.now() , settings.py 中 use_tz=true\n\n 2. 使用不带时区的时间, django中使用 datetime.now(), settings.py 中 use_tz=false",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"django rest_framework 分页",frontmatter:{title:"django rest_framework 分页",date:"2023-03-20T11:32:52.000Z",permalink:"/pages/cb262f/",categories:["编程","python","django"],tags:[null],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档",comment:!0,meta:[{name:"twitter:title",content:"django rest_framework 分页"},{name:"twitter:description",content:"本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/17.django%20rest_framework%20%E5%88%86%E9%A1%B5.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework 分页"},{property:"og:description",content:"本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/17.django%20rest_framework%20%E5%88%86%E9%A1%B5.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-03-20T11:32:52.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"django rest_framework 分页"},{itemprop:"description",content:"本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/17.django%20rest_framework%20%E5%88%86%E9%A1%B5.html",relativePath:"04.编程/01.python/06.django/17.django rest_framework 分页.md",key:"v-788c4982",path:"/pages/cb262f/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"内置分页方式",slug:"内置分页方式",normalizedTitle:"内置分页方式",charIndex:84},{level:2,title:"自定义分页",slug:"自定义分页",normalizedTitle:"自定义分页",charIndex:375},{level:2,title:"自定义分页响应数据",slug:"自定义分页响应数据",normalizedTitle:"自定义分页响应数据",charIndex:906},{level:2,title:"配置",slug:"配置",normalizedTitle:"配置",charIndex:1513},{level:3,title:"全局",slug:"全局",normalizedTitle:"全局",charIndex:1520},{level:3,title:"局部",slug:"局部",normalizedTitle:"局部",charIndex:1862}],headersStr:"简介 内置分页方式 自定义分页 自定义分页响应数据 配置 全局 局部",content:"# 简介\n\n本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档\n\n\n# 内置分页方式\n\ndrf框架中默认提供几种分页方式，并封装成了模块提供给开发者调用，主要是以下几种：\n\n * PageNumberPagination，主要是提供page 和page_size 进行分页。\n   * page，当前页数\n   * page_size，每页展示的数量\n * LimitOffsetPagination，提供limit 和offset 进行分页\n   * limit，当前分页展示的数量\n   * offset，当前数据是从第几行开始。\n * CursorPagination，对结果集中提供前进与后退的链接来进行操作，不允许随意跳动到任意位置。\n\n\n# 自定义分页\n\n框架本身提供了分类的模块，但在实际工作中并不适用，所以我们可以通过继承的方式对内置的分页模块中的部分属性进行覆盖，以符合自身业务。\n\nclass LargeResultsSetPagination(PageNumberPagination):\n    page_size = 1000\n    page_size_query_param = 'page_size'\n    max_page_size = 10000\n\nclass StandardResultsSetPagination(PageNumberPagination):\n    page_size = 100   \n    page_size_query_param = 'page_size'\n    max_page_size = 1000\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n参数：\n\n * page_size：请求接口未指明时，默认使用该值来查询数据量\n * max_page_size：这个是限制一页最大能展示的数量。\n * page_size_query_param：前端请求分页数量的字段\n\n上面是部分常用的字段，如果有特殊业务可以看源码再进行修改。\n\n\n# 自定义分页响应数据\n\n在内置的分页类PageNumberPagination 中响应的数据格式如下：\n\n{\n    \"count\": 总数,\n    \"next\": 下一页的链接,\n    \"previous\": 上一页的链接,\n    \"results\": 分页后的数据\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n但实我们在业务中可能并不需要next 和previous ，只需要保留count 和results 两个字段，这个时候我们可以通过重写get_paginated_response 方法需要对响应的数据进行裁剪。\n\nclass LargeResultsSetPagination(PageNumberPagination):\n    page_size = 1000\n    page_size_query_param = 'page_size'\n    max_page_size = 10000\n\n    def get_paginated_response(self, data):\n        return Response(OrderedDict([\n            ('count', self.page.paginator.count),\n            ('results', data)\n        ]))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 配置\n\n\n# 全局\n\n在settings.py 中可以设置全局的分页模式，在REST_FRAMEWORK 中设置DEFAULT_PAGINATION_CLASS ，该key是指定分页模式使用哪个分页类，而这里使用的是drf框架中内置的分页类LimitOffsetPagination，并设置参数PAGE_SIZE指定每页默认展示的数量。\n\nREST_FRAMEWORK = {\n    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.LimitOffsetPagination',\n    'PAGE_SIZE': 100\n}\n\n\n1\n2\n3\n4\n\n\n该项配置会对全局生效，也就是每一个view的List查询都会走该分页模式。\n\n\n# 局部\n\n在某些业务场景是不需要分页的，或者不同的接口需要使用的分页模式不同，那么上面的全局配置方法就不适用的了，这个时候就需要使用局部配置的方式。\n\n首先不进行全局模式，在需要分页的View中添加pagination_class 并设置对应的分页模式类，这里使用的是自定义的分页类，该配置只会在本View中生效。\n\nclass BillingRecordsView(generics.ListAPIView):\n    queryset = Billing.objects.all()\n    serializer_class = BillingRecordsSerializer\n    pagination_class = LargeResultsSetPagination\n\n\n1\n2\n3\n4\n",normalizedContent:"# 简介\n\n本文主要介绍在drf框架中如何对查询的数据进行分页，在drf框架中有提供该基础功能的使用案例和文档，详情参考drf-pagination-官网文档\n\n\n# 内置分页方式\n\ndrf框架中默认提供几种分页方式，并封装成了模块提供给开发者调用，主要是以下几种：\n\n * pagenumberpagination，主要是提供page 和page_size 进行分页。\n   * page，当前页数\n   * page_size，每页展示的数量\n * limitoffsetpagination，提供limit 和offset 进行分页\n   * limit，当前分页展示的数量\n   * offset，当前数据是从第几行开始。\n * cursorpagination，对结果集中提供前进与后退的链接来进行操作，不允许随意跳动到任意位置。\n\n\n# 自定义分页\n\n框架本身提供了分类的模块，但在实际工作中并不适用，所以我们可以通过继承的方式对内置的分页模块中的部分属性进行覆盖，以符合自身业务。\n\nclass largeresultssetpagination(pagenumberpagination):\n    page_size = 1000\n    page_size_query_param = 'page_size'\n    max_page_size = 10000\n\nclass standardresultssetpagination(pagenumberpagination):\n    page_size = 100   \n    page_size_query_param = 'page_size'\n    max_page_size = 1000\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n参数：\n\n * page_size：请求接口未指明时，默认使用该值来查询数据量\n * max_page_size：这个是限制一页最大能展示的数量。\n * page_size_query_param：前端请求分页数量的字段\n\n上面是部分常用的字段，如果有特殊业务可以看源码再进行修改。\n\n\n# 自定义分页响应数据\n\n在内置的分页类pagenumberpagination 中响应的数据格式如下：\n\n{\n    \"count\": 总数,\n    \"next\": 下一页的链接,\n    \"previous\": 上一页的链接,\n    \"results\": 分页后的数据\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n但实我们在业务中可能并不需要next 和previous ，只需要保留count 和results 两个字段，这个时候我们可以通过重写get_paginated_response 方法需要对响应的数据进行裁剪。\n\nclass largeresultssetpagination(pagenumberpagination):\n    page_size = 1000\n    page_size_query_param = 'page_size'\n    max_page_size = 10000\n\n    def get_paginated_response(self, data):\n        return response(ordereddict([\n            ('count', self.page.paginator.count),\n            ('results', data)\n        ]))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 配置\n\n\n# 全局\n\n在settings.py 中可以设置全局的分页模式，在rest_framework 中设置default_pagination_class ，该key是指定分页模式使用哪个分页类，而这里使用的是drf框架中内置的分页类limitoffsetpagination，并设置参数page_size指定每页默认展示的数量。\n\nrest_framework = {\n    'default_pagination_class': 'rest_framework.pagination.limitoffsetpagination',\n    'page_size': 100\n}\n\n\n1\n2\n3\n4\n\n\n该项配置会对全局生效，也就是每一个view的list查询都会走该分页模式。\n\n\n# 局部\n\n在某些业务场景是不需要分页的，或者不同的接口需要使用的分页模式不同，那么上面的全局配置方法就不适用的了，这个时候就需要使用局部配置的方式。\n\n首先不进行全局模式，在需要分页的view中添加pagination_class 并设置对应的分页模式类，这里使用的是自定义的分页类，该配置只会在本view中生效。\n\nclass billingrecordsview(generics.listapiview):\n    queryset = billing.objects.all()\n    serializer_class = billingrecordsserializer\n    pagination_class = largeresultssetpagination\n\n\n1\n2\n3\n4\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"Flask使用flask_socketio实现websocket",frontmatter:{author:{name:"msqfx",link:"https://github.com/msqfx"},title:"Flask使用flask_socketio实现websocket",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/b71dc2/",description:"在flask中使用flask_socketio来实现websocket的功能。",feed:{enable:!0},tags:["python","flask"],categories:["编程","python","flask"],comment:!0,meta:[{name:"twitter:title",content:"Flask使用flask_socketio实现websocket"},{name:"twitter:description",content:"在flask中使用flask_socketio来实现websocket的功能。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/01.Flask%E4%BD%BF%E7%94%A8flask_socketio%E5%AE%9E%E7%8E%B0websocket.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Flask使用flask_socketio实现websocket"},{property:"og:description",content:"在flask中使用flask_socketio来实现websocket的功能。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/01.Flask%E4%BD%BF%E7%94%A8flask_socketio%E5%AE%9E%E7%8E%B0websocket.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"flask"},{itemprop:"name",content:"Flask使用flask_socketio实现websocket"},{itemprop:"description",content:"在flask中使用flask_socketio来实现websocket的功能。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/01.Flask%E4%BD%BF%E7%94%A8flask_socketio%E5%AE%9E%E7%8E%B0websocket.html",relativePath:"04.编程/01.python/07.flask/01.Flask使用flask_socketio实现websocket.md",key:"v-f7e64afe",path:"/pages/b71dc2/",headers:[{level:2,title:"前端实现",slug:"前端实现",normalizedTitle:"前端实现",charIndex:105},{level:2,title:"后端实现",slug:"后端实现",normalizedTitle:"后端实现",charIndex:1556},{level:3,title:"安装",slug:"安装",normalizedTitle:"安装",charIndex:1615},{level:3,title:"send 和 emit区别",slug:"send-和-emit区别",normalizedTitle:"send 和 emit区别",charIndex:1652},{level:3,title:"简单使用",slug:"简单使用",normalizedTitle:"简单使用",charIndex:1711},{level:3,title:"基于类的使用",slug:"基于类的使用",normalizedTitle:"基于类的使用",charIndex:2613}],excerpt:'<h1 id="flask使用flask-socketio实现websocket"><a class="header-anchor" href="#flask使用flask-socketio实现websocket">#</a> Flask使用flask_socketio实现websocket</h1>\n<p>下面是案例，是我自己用来测试使用的，可以直接运行的。详细的使用请看<a href="https://flask-socketio.readthedocs.io/en/latest/" target="_blank" rel="noopener noreferrer">官网<OutboundLink/></a></p>\n<p>websocket主要应用于客户端和服务端双向通信的。</p>\n',headersStr:"前端实现 后端实现 安装 send 和 emit区别 简单使用 基于类的使用",content:"# Flask使用flask_socketio实现websocket\n\n下面是案例，是我自己用来测试使用的，可以直接运行的。详细的使用请看官网\n\nwebsocket主要应用于客户端和服务端双向通信的。\n\n\n# 前端实现\n\n使用socket.io.min.js是node.js的一个websocket库，首先创建socket. emit是向后端发送消息, message是该条消息的名称，后面是发送消息的数据。on是注册接受消息的事件,获取后端传过来的数据. namespace是指一类的消息。当连接成功时，会触发connect事件，连接关闭时，触发disconnect事件。\n\n\n<html>\n    <head>\n        <script type=\"text/javascript\"\n        src=\"https://code.jquery.com/jquery-3.4.0.min.js\"><\/script>\n        <script type=\"text/javascript\"\n        src=\"//cdnjs.cloudflare.com/ajax/libs/socket.io/1.3.6/socket.io.min.js\"><\/script>\n        \n        <script type=\"text/javascript\" charset=\"utf-8\">\n            $(document).ready(function () {\n                namespace = \"/wechat\"\n                var socket = io.connect('http://' + document.domain + ':' + location.port + namespace);\n                \n                socket.emit(\"message\", { \"data\": \"zhangsan\" })\n                \n                socket.on('connect', function (data) {\n                    socket.emit('message', { 'data': 'I\\'m connected!' });\n                });\n                \n                socket.on('disconnect', function(data){\n                    socket.emit('message', { 'data': 'I\\'m disconnected!' });\n                });\n                    \n                socket.on('response', function (data) {\n                    console.log(data.age)\n                });\n            });\n        <\/script>\n    </head>\n    \n    <body>\n        <h1>德玛西亚</h1>\n    </body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n\n\n\n# 后端实现\n\n> Flask-SocketIO使Flask应用程序可以访问客户端和服务器之间的低延迟双向通信。\n\n\n# 安装\n\n> pip install flask-socketio\n\n\n# send 和 emit区别\n\nsend发送的是无命名的数据，而emit是发送有命名的数据，个人建议是emit\n\n\n# 简单使用\n\non是注册接收前端消息的方法，message是指接收的信息的名称，和前端对应。namespace是指一类的消息，和前端对应。emit是指向前端发送消息，对应的消息的名称、数据和namespace。\n\n默认的两个事件，connect和disconnect，当websocket连接成功和失败时，自动触发这两个事件。\n\n\nfrom flask import Flask, render_template\nfrom flask_socketio import SocketIO\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = 'secret!'\nsocketio = SocketIO(app)\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@socketio.on('message', namespace=\"/wechat\")\ndef handle_message(message):\n    print('received message: ' + message['data'])\n    socketio.emit(\"response\", {'age': 18}, namespace=\"/wechat\")\n\n@socketio.on('connect', namespace=\"/wechat\")\ndef connect():\n    print(\"connect..\")\n\n@socketio.on('disconnect', namespace=\"/wechat\")\ndef connect():\n    print(\"disconnect...\")\n\nif __name__ == '__main__':\n    socketio.run(app, port=8080)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n\n# 基于类的使用\n\n上面都是基于方法使用，个人感觉如果操作较多的情况，比较凌乱，使用类去管理会整齐和方便很多。\n\n服务器收到的任何事件都会被分配到一个名为带有on_前缀的事件名称的方法。\n\n这个案例和上面基于方法是一样的，但是更加方便管理了，每个class管理一个namespace。\n\n\nclass MyCustomNamespace(Namespace):\n\n    def on_connect(self):\n        print(\"连接..\")\n        \n    def on_disconnect(self):\n        print(\"关闭连接\")\n        \n    def on_message(self, data):\n        print('received message: ' + data['data'])\n        self.emit(\"response\", {'age': 18})\n    \nsocketio.on_namespace(MyCustomNamespace(\"/wechat\"))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",normalizedContent:"# flask使用flask_socketio实现websocket\n\n下面是案例，是我自己用来测试使用的，可以直接运行的。详细的使用请看官网\n\nwebsocket主要应用于客户端和服务端双向通信的。\n\n\n# 前端实现\n\n使用socket.io.min.js是node.js的一个websocket库，首先创建socket. emit是向后端发送消息, message是该条消息的名称，后面是发送消息的数据。on是注册接受消息的事件,获取后端传过来的数据. namespace是指一类的消息。当连接成功时，会触发connect事件，连接关闭时，触发disconnect事件。\n\n\n<html>\n    <head>\n        <script type=\"text/javascript\"\n        src=\"https://code.jquery.com/jquery-3.4.0.min.js\"><\/script>\n        <script type=\"text/javascript\"\n        src=\"//cdnjs.cloudflare.com/ajax/libs/socket.io/1.3.6/socket.io.min.js\"><\/script>\n        \n        <script type=\"text/javascript\" charset=\"utf-8\">\n            $(document).ready(function () {\n                namespace = \"/wechat\"\n                var socket = io.connect('http://' + document.domain + ':' + location.port + namespace);\n                \n                socket.emit(\"message\", { \"data\": \"zhangsan\" })\n                \n                socket.on('connect', function (data) {\n                    socket.emit('message', { 'data': 'i\\'m connected!' });\n                });\n                \n                socket.on('disconnect', function(data){\n                    socket.emit('message', { 'data': 'i\\'m disconnected!' });\n                });\n                    \n                socket.on('response', function (data) {\n                    console.log(data.age)\n                });\n            });\n        <\/script>\n    </head>\n    \n    <body>\n        <h1>德玛西亚</h1>\n    </body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n\n\n\n# 后端实现\n\n> flask-socketio使flask应用程序可以访问客户端和服务器之间的低延迟双向通信。\n\n\n# 安装\n\n> pip install flask-socketio\n\n\n# send 和 emit区别\n\nsend发送的是无命名的数据，而emit是发送有命名的数据，个人建议是emit\n\n\n# 简单使用\n\non是注册接收前端消息的方法，message是指接收的信息的名称，和前端对应。namespace是指一类的消息，和前端对应。emit是指向前端发送消息，对应的消息的名称、数据和namespace。\n\n默认的两个事件，connect和disconnect，当websocket连接成功和失败时，自动触发这两个事件。\n\n\nfrom flask import flask, render_template\nfrom flask_socketio import socketio\n\napp = flask(__name__)\napp.config['secret_key'] = 'secret!'\nsocketio = socketio(app)\n\n@app.route('/')\ndef index():\n    return render_template('index.html')\n\n@socketio.on('message', namespace=\"/wechat\")\ndef handle_message(message):\n    print('received message: ' + message['data'])\n    socketio.emit(\"response\", {'age': 18}, namespace=\"/wechat\")\n\n@socketio.on('connect', namespace=\"/wechat\")\ndef connect():\n    print(\"connect..\")\n\n@socketio.on('disconnect', namespace=\"/wechat\")\ndef connect():\n    print(\"disconnect...\")\n\nif __name__ == '__main__':\n    socketio.run(app, port=8080)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n\n# 基于类的使用\n\n上面都是基于方法使用，个人感觉如果操作较多的情况，比较凌乱，使用类去管理会整齐和方便很多。\n\n服务器收到的任何事件都会被分配到一个名为带有on_前缀的事件名称的方法。\n\n这个案例和上面基于方法是一样的，但是更加方便管理了，每个class管理一个namespace。\n\n\nclass mycustomnamespace(namespace):\n\n    def on_connect(self):\n        print(\"连接..\")\n        \n    def on_disconnect(self):\n        print(\"关闭连接\")\n        \n    def on_message(self, data):\n        print('received message: ' + data['data'])\n        self.emit(\"response\", {'age': 18})\n    \nsocketio.on_namespace(mycustomnamespace(\"/wechat\"))\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"flask结合mongo",frontmatter:{tags:["python","flask"],title:"flask结合mongo",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/c59edf/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"在flask中集成第三方库flask-mongoengine来通过ORM操作mongo数据库",feed:{enable:!0},categories:["编程","python","flask"],comment:!0,meta:[{name:"twitter:title",content:"flask结合mongo"},{name:"twitter:description",content:"在flask中集成第三方库flask-mongoengine来通过ORM操作mongo数据库"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/02.flask%E7%BB%93%E5%90%88mongo.html"},{property:"og:type",content:"article"},{property:"og:title",content:"flask结合mongo"},{property:"og:description",content:"在flask中集成第三方库flask-mongoengine来通过ORM操作mongo数据库"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/02.flask%E7%BB%93%E5%90%88mongo.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"flask"},{itemprop:"name",content:"flask结合mongo"},{itemprop:"description",content:"在flask中集成第三方库flask-mongoengine来通过ORM操作mongo数据库"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/07.flask/02.flask%E7%BB%93%E5%90%88mongo.html",relativePath:"04.编程/01.python/07.flask/02.flask结合mongo.md",key:"v-3c157da4",path:"/pages/c59edf/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:83},{level:2,title:"使用",slug:"使用",normalizedTitle:"使用",charIndex:26},{level:2,title:"解決问题",slug:"解決问题",normalizedTitle:"解決问题",charIndex:857}],headersStr:"简介 相关链接 使用 解決问题",content:'# 简介\n\n本文是flask中对mongo的操作. 使用Flask-MongoEngine集成了mongo的操作，使用的是类似于django中的orm操作。\n\n\n# 相关链接\n\nFlask-MongoEngine文档\n\nMongoEngine文档\n\n\n# 使用\n\nmongo的配置. flask将这个配置加载进来即可.\n\nMONGODB_SETTINGS = {\n    "db": "lifeAssistant",\n    "host": "192.168.0.206",\n    "port": 27017\n}\n\n\n1\n2\n3\n4\n5\n\n\n创建mongo引擎.\n\nfrom flask_mongoengine import MongoEngine\nmongodb = MongoEngine()\n\n\n1\n2\n\n\n创建Document，类似于django的model.\n\nfrom lifeAssistant.extension import mongodb\n\nclass Article(mongodb.Document):\n    category = mongodb.StringField()\n    category2 = mongodb.StringField()\n    title = mongodb.StringField()\n    content = mongodb.StringField()\n    publisher = mongodb.StringField()\n    publisher_time = mongodb.StringField()\n    create_time = mongodb.StringField()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n使用Document进行操作. 其他操作请看官方文档\n\n\n# 通过id获取数据.  \ninstance = Article.objects.get_or_404(id=id)\n\n\n1\n2\n3\n\n\n\n# 解決问题\n\nmongo数据转json\n\n问题: mongo转json时，会输出ObjectId这对象，而不是直接的id值，这个时候需要转换.\n\n\n# 这个是将mongo Document对象转换成json的编码器\nclass MongoEncoder(JSONEncoder):\n    def default(self, o):\n\n        # 转换日期\n        if isinstance(o, (datetime, date)):\n            pass\n\n        # 转换Document\n        if isinstance(o, BaseDocument):\n            return o.to_mongo()\n\n        # 转换id\n        if isinstance(o, ObjectId):\n            return str(o)\n\n        return JSONEncoder.default(self, o)\n\n\n\n# 在蓝图上添加mongo解码器.  jsonify会自动将Document对象转成json\nbp = Blueprint("article", __name__, url_prefix="/article")\nbp.json_encoder = MongoEncoder\n\n\n@bp.route("/<id>/", methods=("GET",))\ndef article(id: str):\n    instance = Article.objects.get_or_404(id=id)\n\n    return jsonify({\n        "code": 0,\n        "msg": "success",\n        "data": instance\n    })\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n',normalizedContent:'# 简介\n\n本文是flask中对mongo的操作. 使用flask-mongoengine集成了mongo的操作，使用的是类似于django中的orm操作。\n\n\n# 相关链接\n\nflask-mongoengine文档\n\nmongoengine文档\n\n\n# 使用\n\nmongo的配置. flask将这个配置加载进来即可.\n\nmongodb_settings = {\n    "db": "lifeassistant",\n    "host": "192.168.0.206",\n    "port": 27017\n}\n\n\n1\n2\n3\n4\n5\n\n\n创建mongo引擎.\n\nfrom flask_mongoengine import mongoengine\nmongodb = mongoengine()\n\n\n1\n2\n\n\n创建document，类似于django的model.\n\nfrom lifeassistant.extension import mongodb\n\nclass article(mongodb.document):\n    category = mongodb.stringfield()\n    category2 = mongodb.stringfield()\n    title = mongodb.stringfield()\n    content = mongodb.stringfield()\n    publisher = mongodb.stringfield()\n    publisher_time = mongodb.stringfield()\n    create_time = mongodb.stringfield()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n使用document进行操作. 其他操作请看官方文档\n\n\n# 通过id获取数据.  \ninstance = article.objects.get_or_404(id=id)\n\n\n1\n2\n3\n\n\n\n# 解決问题\n\nmongo数据转json\n\n问题: mongo转json时，会输出objectid这对象，而不是直接的id值，这个时候需要转换.\n\n\n# 这个是将mongo document对象转换成json的编码器\nclass mongoencoder(jsonencoder):\n    def default(self, o):\n\n        # 转换日期\n        if isinstance(o, (datetime, date)):\n            pass\n\n        # 转换document\n        if isinstance(o, basedocument):\n            return o.to_mongo()\n\n        # 转换id\n        if isinstance(o, objectid):\n            return str(o)\n\n        return jsonencoder.default(self, o)\n\n\n\n# 在蓝图上添加mongo解码器.  jsonify会自动将document对象转成json\nbp = blueprint("article", __name__, url_prefix="/article")\nbp.json_encoder = mongoencoder\n\n\n@bp.route("/<id>/", methods=("get",))\ndef article(id: str):\n    instance = article.objects.get_or_404(id=id)\n\n    return jsonify({\n        "code": 0,\n        "msg": "success",\n        "data": instance\n    })\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado 文件上传",frontmatter:{title:"tornado 文件上传",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/4c38f5/",tags:["python","tornado"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"tornado实现的文件上传功能",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado 文件上传"},{name:"twitter:description",content:"tornado实现的文件上传功能"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/01.tornado%20%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado 文件上传"},{property:"og:description",content:"tornado实现的文件上传功能"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/01.tornado%20%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado 文件上传"},{itemprop:"description",content:"tornado实现的文件上传功能"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/01.tornado%20%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0.html",relativePath:"04.编程/01.python/08.tornado/01.tornado 文件上传.md",key:"v-069fea3d",path:"/pages/4c38f5/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"栗子",slug:"栗子",normalizedTitle:"栗子",charIndex:71}],headersStr:"简介 栗子",content:'# 简介\n\n文章介绍的是使用tornado完成文件的上传功能\n\n该项目的github地址: tornado_learning.git\n\n\n# 栗子\n\n设置文件上传的路径\n\n代码: tornado_learning/settings.py\n\nBASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsettings = {\n    "MEDIA_ROOT": os.path.join(BASE_DIR, "media"),\n}\n\n\n1\n2\n3\n4\n\n\n保存上传文件\n\n获取前端传送过来的front_image文件，然后再使用aiofiles完成上传文件的二进制异步写入。\n\n代码: /apps/hello/uploadHandler.py\n\n\nfrom tornado_learning.handler import BaseHandler\nimport os\nimport uuid\nimport aiofiles\n\nclass UploadHandler(BaseHandler):\n\n    async def post(self):\n        ret_data = {}\n\n        files_meta = self.request.files.get("front_image", None)\n        if not files_meta:\n            self.set_status(400)\n            ret_data["front_image"] = "请上传图片"\n        else:\n            for meta in files_meta:\n                filename = meta["filename"]\n                new_filename = "{uuid}_{filename}".format(uuid=uuid.uuid1(), filename=filename)\n                file_path = os.path.join(self.settings["MEDIA_ROOT"], new_filename)\n\n                async with aiofiles.open(file_path, "wb") as f:\n                    await f.write(meta["body"])\n\n                ret_data[\'file_path\'] = file_path\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n',normalizedContent:'# 简介\n\n文章介绍的是使用tornado完成文件的上传功能\n\n该项目的github地址: tornado_learning.git\n\n\n# 栗子\n\n设置文件上传的路径\n\n代码: tornado_learning/settings.py\n\nbase_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsettings = {\n    "media_root": os.path.join(base_dir, "media"),\n}\n\n\n1\n2\n3\n4\n\n\n保存上传文件\n\n获取前端传送过来的front_image文件，然后再使用aiofiles完成上传文件的二进制异步写入。\n\n代码: /apps/hello/uploadhandler.py\n\n\nfrom tornado_learning.handler import basehandler\nimport os\nimport uuid\nimport aiofiles\n\nclass uploadhandler(basehandler):\n\n    async def post(self):\n        ret_data = {}\n\n        files_meta = self.request.files.get("front_image", none)\n        if not files_meta:\n            self.set_status(400)\n            ret_data["front_image"] = "请上传图片"\n        else:\n            for meta in files_meta:\n                filename = meta["filename"]\n                new_filename = "{uuid}_{filename}".format(uuid=uuid.uuid1(), filename=filename)\n                file_path = os.path.join(self.settings["media_root"], new_filename)\n\n                async with aiofiles.open(file_path, "wb") as f:\n                    await f.write(meta["body"])\n\n                ret_data[\'file_path\'] = file_path\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado 使用jwt完成用户异步认证",frontmatter:{tags:["python","tornado"],title:"tornado 使用jwt完成用户异步认证",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/c24905/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"tornado使用jwt实现用户的异步认证",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado 使用jwt完成用户异步认证"},{name:"twitter:description",content:"tornado使用jwt实现用户的异步认证"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/02.tornado%20%E4%BD%BF%E7%94%A8jwt%E5%AE%8C%E6%88%90%E7%94%A8%E6%88%B7%E5%BC%82%E6%AD%A5%E8%AE%A4%E8%AF%81.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado 使用jwt完成用户异步认证"},{property:"og:description",content:"tornado使用jwt实现用户的异步认证"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/02.tornado%20%E4%BD%BF%E7%94%A8jwt%E5%AE%8C%E6%88%90%E7%94%A8%E6%88%B7%E5%BC%82%E6%AD%A5%E8%AE%A4%E8%AF%81.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado 使用jwt完成用户异步认证"},{itemprop:"description",content:"tornado使用jwt实现用户的异步认证"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/02.tornado%20%E4%BD%BF%E7%94%A8jwt%E5%AE%8C%E6%88%90%E7%94%A8%E6%88%B7%E5%BC%82%E6%AD%A5%E8%AE%A4%E8%AF%81.html",relativePath:"04.编程/01.python/08.tornado/02.tornado 使用jwt完成用户异步认证.md",key:"v-2e6d253f",path:"/pages/c24905/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"栗子",slug:"栗子",normalizedTitle:"栗子",charIndex:156}],headersStr:"简介 栗子",content:'# 简介\n\n在使用特定功能时，需要验证用户是否登录。使用jwt将用户不敏感的信息保存在客户端上，然后访问时，将加密的信息发送给服务端验证。\n\n和session的不同之处在于，session需要在两端都存储，而jwt仅在客户端存储。\n\n该项目的github地址: tornado_learning.git\n\n\n# 栗子\n\n创建异步验证的装饰器\n\n从header中获取tsessionid的jwt token信息，然后从token获取用户id，从数据库中查找用户信息，再验证token是否过期。\n\n代码: utils/authenticated_async.py\n\ndef authenticated_async(method):\n    async def wrapper(self, *args, **kwargs):\n\n        # ret_data = {}\n\n        tsessionid = self.request.headers.get("tsessionid", None)\n        if tsessionid:\n\n            try:\n                payload = jwt.decode(tsessionid, self.settings["secret_key"], leeway=self.settings["jwt_expire"],\n                                     options={"verify_exp": True})\n\n                user_id = payload["id"]\n                try:\n                    user = await self.application.objects.get(User, id=user_id)\n                    self._current_user = user\n                    await method(self, *args, **kwargs)\n                except User.DoesNotExist as e:\n                    self.set_status(401)\n            except jwt.ExpiredSignatureError as e:\n                self.set_status(401)\n\n    return wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n在请求上添加用户认证\n\n每次在请求该接口时，都需要对进行用户认证，认证通过才能访问该接口。\n\n代码: apps/school/handle.py\n\n\nfrom utils.authenticated_async import authenticated_async\n\nclass StudentHandler(BaseHandler):\n\n    @authenticated_async\n    async def get(self):\n        id = self.get_argument("id", None)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(Student, id=id)\n\n        try:\n            self.write({\n                "id": student.id,\n                "name": student.name\n            })\n        except Student.DoesNotExist:\n            raise tornado.webHttpError(404, "Object not found")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n',normalizedContent:'# 简介\n\n在使用特定功能时，需要验证用户是否登录。使用jwt将用户不敏感的信息保存在客户端上，然后访问时，将加密的信息发送给服务端验证。\n\n和session的不同之处在于，session需要在两端都存储，而jwt仅在客户端存储。\n\n该项目的github地址: tornado_learning.git\n\n\n# 栗子\n\n创建异步验证的装饰器\n\n从header中获取tsessionid的jwt token信息，然后从token获取用户id，从数据库中查找用户信息，再验证token是否过期。\n\n代码: utils/authenticated_async.py\n\ndef authenticated_async(method):\n    async def wrapper(self, *args, **kwargs):\n\n        # ret_data = {}\n\n        tsessionid = self.request.headers.get("tsessionid", none)\n        if tsessionid:\n\n            try:\n                payload = jwt.decode(tsessionid, self.settings["secret_key"], leeway=self.settings["jwt_expire"],\n                                     options={"verify_exp": true})\n\n                user_id = payload["id"]\n                try:\n                    user = await self.application.objects.get(user, id=user_id)\n                    self._current_user = user\n                    await method(self, *args, **kwargs)\n                except user.doesnotexist as e:\n                    self.set_status(401)\n            except jwt.expiredsignatureerror as e:\n                self.set_status(401)\n\n    return wrapper\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n在请求上添加用户认证\n\n每次在请求该接口时，都需要对进行用户认证，认证通过才能访问该接口。\n\n代码: apps/school/handle.py\n\n\nfrom utils.authenticated_async import authenticated_async\n\nclass studenthandler(basehandler):\n\n    @authenticated_async\n    async def get(self):\n        id = self.get_argument("id", none)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(student, id=id)\n\n        try:\n            self.write({\n                "id": student.id,\n                "name": student.name\n            })\n        except student.doesnotexist:\n            raise tornado.webhttperror(404, "object not found")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado 结合wtforms使用表单操作",frontmatter:{tags:["python","tornado"],title:"tornado 结合wtforms使用表单操作",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/7ac01f/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"tornado使用wtforms来对表单进行验证与操作。",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado 结合wtforms使用表单操作"},{name:"twitter:description",content:"tornado使用wtforms来对表单进行验证与操作。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/04.tornado%20%E7%BB%93%E5%90%88wtforms%E4%BD%BF%E7%94%A8%E8%A1%A8%E5%8D%95%E6%93%8D%E4%BD%9C.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado 结合wtforms使用表单操作"},{property:"og:description",content:"tornado使用wtforms来对表单进行验证与操作。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/04.tornado%20%E7%BB%93%E5%90%88wtforms%E4%BD%BF%E7%94%A8%E8%A1%A8%E5%8D%95%E6%93%8D%E4%BD%9C.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado 结合wtforms使用表单操作"},{itemprop:"description",content:"tornado使用wtforms来对表单进行验证与操作。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/04.tornado%20%E7%BB%93%E5%90%88wtforms%E4%BD%BF%E7%94%A8%E8%A1%A8%E5%8D%95%E6%93%8D%E4%BD%9C.html",relativePath:"04.编程/01.python/08.tornado/04.tornado 结合wtforms使用表单操作.md",key:"v-573b59b6",path:"/pages/7ac01f/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"例子",slug:"例子",normalizedTitle:"例子",charIndex:110},{level:2,title:"html表单",slug:"html表单",normalizedTitle:"html表单",charIndex:1458},{level:2,title:"wtforms 读取json",slug:"wtforms-读取json",normalizedTitle:"wtforms 读取json",charIndex:2568}],headersStr:"简介 例子 html表单 wtforms 读取json",content:'# 简介\n\n在获取请求时，需要将请求的参数进行验证。\n使用wtforms和tornado的结合，可以获取到请求的参数，并且对参数进行验证。\n\n该项目的github地址: tornado_learning.git\n\n\n# 例子\n\n创建student的form\n\n代码: apps/shchool/forms.py\n\n\nfrom wtforms_tornado import Form\nfrom wtforms import StringField, IntegerField, TextAreaField\nfrom wtforms.validators import DataRequired, Length\n\nclass StudentForm(Form):\n    """\n    可以作为student的 post 和 put 的表单使用。\n    """\n\n    id = IntegerField("id", null=True)\n    name = StringField("姓名", validators=[DataRequired("请输入姓名")])\n    age = IntegerField("年龄", validators=[DataRequired("请输入年龄")])\n    desc = TextAreaField("个人简介", validators=[DataRequired("请输入个人简介")])\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后通过form接收参数，对参数进行验证，验证通过则操作model，对数据库进行保存操作\n\n通过遍历student_from.errors得到校验失败的字段，然后再返回到前端提示。\n\n代码: apps/school/handler.py\n\n\nimport tornado\n\nfrom apps.school.forms import StudentForm\nfrom apps.school.models import Student\nfrom tornado_learning.handler import BaseHandler\n\nclass StudentHandler(BaseHandler):\n\n        async def post(self):\n\n        ret_data = {}\n\n        student_form = StudentForm(self.request.arguments)\n        if student_form.validate():\n            await self.application.objects.create(Student, **student_form.data)\n\n            ret_data["ret"] = "success"\n        else:\n            for field in student_form.errors:\n                ret_data[field] = ret_data.errors[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# html表单\n\n还可以通过wtforms创建对应的model模板表单。\n\n个人不是很推荐使用，因为前后端耦合性太强。\n\n获取表单\n\n代码: apps/school/forms.py\n\nclass StudentFormHandler(BaseHandler):\n\n    def get(self):\n        studentForm = StudentForm()\n        return self.render("student.html", studentForm=studentForm)\n\n\n1\n2\n3\n4\n5\n\n\n表单的html模板\n将该文件放在templates路径下\n\n代码: templates/student.html\n\n<form action="/student" , method="post">\n    {% autoescape None %}\n    {% for field in studentForm %}\n        <span>{{ field.label.text }} :</span>\n        {{ field(placeholder="请输入"+field.label.text) }}\n\n        {% if field.errors %}\n            {% for error_msg in field.errors %}\n                <div class="error-msg">{{ error_msg }}</div>\n                {% end %}\n                {% else %}\n                <div class="error-msg"></div>\n            {% end %}\n    {% end %}\n\n    <label>\n        <span>&nbsp;</span>\n        <input type="submit" class="button" value="提交"/>\n    </label>\n</form>\n</body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n需要在设置项中设置模板路径\n代码:tornado_learning/settings.py\n\nsettings = {\n    "template_path": "templates"\n}\n\n\n1\n2\n3\n\n\n\n# wtforms 读取json\n\n使用wtforms_json可以使表单直接对json参数的读取。\n\n初始化wtforms_json\n\n首选需要对wtforms_json初始化。\n代码: server.py\n\nimport wtforms_json\nwtforms_json.init()\n\n\n1\n2\n\n\n在handler中获取json参数，然后读入到form中\n\n代码: apps/school/handler.py\n\nclass TeacherHandler(BaseHandler):\n   \n    async def post(self):\n\n        ret_data = {}\n\n        param = self.request.body.decode("utf8")\n        param = json.loads(param)\n\n        teacherForm = TeacherForm.from_json(param)\n        print(teacherForm.data)\n        if teacherForm.validate():\n            teacher = await self.application.objects.create(Teacher, **teacherForm.data)\n\n            ret_data["ret"] = "success"\n        else:\n            for field in teacherForm.errors:\n                ret_data[field] = teacherForm.errors[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n',normalizedContent:'# 简介\n\n在获取请求时，需要将请求的参数进行验证。\n使用wtforms和tornado的结合，可以获取到请求的参数，并且对参数进行验证。\n\n该项目的github地址: tornado_learning.git\n\n\n# 例子\n\n创建student的form\n\n代码: apps/shchool/forms.py\n\n\nfrom wtforms_tornado import form\nfrom wtforms import stringfield, integerfield, textareafield\nfrom wtforms.validators import datarequired, length\n\nclass studentform(form):\n    """\n    可以作为student的 post 和 put 的表单使用。\n    """\n\n    id = integerfield("id", null=true)\n    name = stringfield("姓名", validators=[datarequired("请输入姓名")])\n    age = integerfield("年龄", validators=[datarequired("请输入年龄")])\n    desc = textareafield("个人简介", validators=[datarequired("请输入个人简介")])\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n然后通过form接收参数，对参数进行验证，验证通过则操作model，对数据库进行保存操作\n\n通过遍历student_from.errors得到校验失败的字段，然后再返回到前端提示。\n\n代码: apps/school/handler.py\n\n\nimport tornado\n\nfrom apps.school.forms import studentform\nfrom apps.school.models import student\nfrom tornado_learning.handler import basehandler\n\nclass studenthandler(basehandler):\n\n        async def post(self):\n\n        ret_data = {}\n\n        student_form = studentform(self.request.arguments)\n        if student_form.validate():\n            await self.application.objects.create(student, **student_form.data)\n\n            ret_data["ret"] = "success"\n        else:\n            for field in student_form.errors:\n                ret_data[field] = ret_data.errors[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# html表单\n\n还可以通过wtforms创建对应的model模板表单。\n\n个人不是很推荐使用，因为前后端耦合性太强。\n\n获取表单\n\n代码: apps/school/forms.py\n\nclass studentformhandler(basehandler):\n\n    def get(self):\n        studentform = studentform()\n        return self.render("student.html", studentform=studentform)\n\n\n1\n2\n3\n4\n5\n\n\n表单的html模板\n将该文件放在templates路径下\n\n代码: templates/student.html\n\n<form action="/student" , method="post">\n    {% autoescape none %}\n    {% for field in studentform %}\n        <span>{{ field.label.text }} :</span>\n        {{ field(placeholder="请输入"+field.label.text) }}\n\n        {% if field.errors %}\n            {% for error_msg in field.errors %}\n                <div class="error-msg">{{ error_msg }}</div>\n                {% end %}\n                {% else %}\n                <div class="error-msg"></div>\n            {% end %}\n    {% end %}\n\n    <label>\n        <span>&nbsp;</span>\n        <input type="submit" class="button" value="提交"/>\n    </label>\n</form>\n</body>\n</html>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n需要在设置项中设置模板路径\n代码:tornado_learning/settings.py\n\nsettings = {\n    "template_path": "templates"\n}\n\n\n1\n2\n3\n\n\n\n# wtforms 读取json\n\n使用wtforms_json可以使表单直接对json参数的读取。\n\n初始化wtforms_json\n\n首选需要对wtforms_json初始化。\n代码: server.py\n\nimport wtforms_json\nwtforms_json.init()\n\n\n1\n2\n\n\n在handler中获取json参数，然后读入到form中\n\n代码: apps/school/handler.py\n\nclass teacherhandler(basehandler):\n   \n    async def post(self):\n\n        ret_data = {}\n\n        param = self.request.body.decode("utf8")\n        param = json.loads(param)\n\n        teacherform = teacherform.from_json(param)\n        print(teacherform.data)\n        if teacherform.validate():\n            teacher = await self.application.objects.create(teacher, **teacherform.data)\n\n            ret_data["ret"] = "success"\n        else:\n            for field in teacherform.errors:\n                ret_data[field] = teacherform.errors[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado finish和write区别",frontmatter:{tags:["python","tornado"],title:"tornado finish和write区别",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/d18657/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍tornado中finish和write的区别",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado finish和write区别"},{name:"twitter:description",content:"介绍tornado中finish和write的区别"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/05.tornado%20finish%E5%92%8Cwrite%E5%8C%BA%E5%88%AB.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado finish和write区别"},{property:"og:description",content:"介绍tornado中finish和write的区别"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/05.tornado%20finish%E5%92%8Cwrite%E5%8C%BA%E5%88%AB.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado finish和write区别"},{itemprop:"description",content:"介绍tornado中finish和write的区别"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/05.tornado%20finish%E5%92%8Cwrite%E5%8C%BA%E5%88%AB.html",relativePath:"04.编程/01.python/08.tornado/05.tornado finish和write区别.md",key:"v-0056c406",path:"/pages/d18657/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"例子",slug:"例子",normalizedTitle:"例子",charIndex:82},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:556}],headersStr:"简介 例子 总结",content:'# 简介\n\nfinish和write都可以将后端的数据传输到前端。他们有啥差别嘞。\n\n该项目的github地址: tornado_learning.git\n\n\n# 例子\n\n代码apps/hello/write_finish_handler.py\n\nfrom tornado_learning.handler import BaseHandler\nimport time\n\nclass Write_Finish_Handler(BaseHandler):\n\n    def get(self):\n        self.write("hello")\n        time.sleep(4)\n        self.finish("world")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在等待4秒后，同时输出： hello world\n\nclass Finish_Write_Handler(BaseHandler):\n\n    def get(self):\n        self.finish("hello")\n        self.write("world")\n\n\n1\n2\n3\n4\n5\n\n\n输出: hello\n并且报错: Cannot write() after finish()\n\n\n# 总结\n\nself.finish()代表回应到前端的终结。并且可以在finsh后做一些与回应给前端无关的操作，缩短响应时间。\nself.write()并不会马上将数据返回前端，必须在self.finsh()或者return后才会响应，类似以缓存吧。',normalizedContent:'# 简介\n\nfinish和write都可以将后端的数据传输到前端。他们有啥差别嘞。\n\n该项目的github地址: tornado_learning.git\n\n\n# 例子\n\n代码apps/hello/write_finish_handler.py\n\nfrom tornado_learning.handler import basehandler\nimport time\n\nclass write_finish_handler(basehandler):\n\n    def get(self):\n        self.write("hello")\n        time.sleep(4)\n        self.finish("world")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在等待4秒后，同时输出： hello world\n\nclass finish_write_handler(basehandler):\n\n    def get(self):\n        self.finish("hello")\n        self.write("world")\n\n\n1\n2\n3\n4\n5\n\n\n输出: hello\n并且报错: cannot write() after finish()\n\n\n# 总结\n\nself.finish()代表回应到前端的终结。并且可以在finsh后做一些与回应给前端无关的操作，缩短响应时间。\nself.write()并不会马上将数据返回前端，必须在self.finsh()或者return后才会响应，类似以缓存吧。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado 用户密码 bcrypt加密",frontmatter:{tags:["python","tornado"],title:"tornado 用户密码 bcrypt加密",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/22f35b/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"使用bcrypt来实现对用户密码进行加密",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado 用户密码 bcrypt加密"},{name:"twitter:description",content:"使用bcrypt来实现对用户密码进行加密"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/03.tornado%20%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%20bcrypt%E5%8A%A0%E5%AF%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado 用户密码 bcrypt加密"},{property:"og:description",content:"使用bcrypt来实现对用户密码进行加密"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/03.tornado%20%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%20bcrypt%E5%8A%A0%E5%AF%86.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado 用户密码 bcrypt加密"},{itemprop:"description",content:"使用bcrypt来实现对用户密码进行加密"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/03.tornado%20%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%20bcrypt%E5%8A%A0%E5%AF%86.html",relativePath:"04.编程/01.python/08.tornado/03.tornado 用户密码 bcrypt加密.md",key:"v-fc3c6860",path:"/pages/22f35b/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"python 如何使用bcrypt 栗子",slug:"python-如何使用bcrypt-栗子",normalizedTitle:"python 如何使用bcrypt 栗子",charIndex:175},{level:2,title:"tornado 使用 bcrypt 加密密码栗子。",slug:"tornado-使用-bcrypt-加密密码栗子。",normalizedTitle:"tornado 使用 bcrypt 加密密码栗子。",charIndex:437},{level:3,title:"创建user model",slug:"创建user-model",normalizedTitle:"创建user model",charIndex:467},{level:3,title:"注册的handler",slug:"注册的handler",normalizedTitle:"注册的handler",charIndex:2218}],headersStr:"简介 python 如何使用bcrypt 栗子 tornado 使用 bcrypt 加密密码栗子。 创建user model 注册的handler",content:'# 简介\n\nbcrypt 可以通过加盐的方式对密码进行加密，更加的安全可靠。\n\n该项目的github地址: tornado_learning.git\n\n优点\n\nmd5加密，每个对应的明文密码，对应的是一样的加密的密文，比较容易的进行解密。而bcrypt每一次的明文密码得到的是不同的加密的密文，因为密文是通过随机的盐结合加密，所以更加安全。\n\n\n# python 如何使用bcrypt 栗子\n\nfrom bcrypt import hashpw, gensalt\n\n# 这个是随机生成的盐\nsalt = gensalt(12)\n\n# 这个是通过盐去加密\npasswd = hashpw("123456".encode(\'utf8\'), salt)\n\n# 将输入的明文密码与密文密码进行加密，是否等于密文密码。\nhashpw(input_passwd.encode(\'utf8\'), passwd) == passwd\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# tornado 使用 bcrypt 加密密码栗子。\n\n\n# 创建user model\n\n在user model中的密码字段使用自定义的PasswordField.\n\n代码/apps/user/models.py\n\nclass PasswordHash(bytes):\n    def check_password(self, password):\n        """\n        比较传入的密码和数据库中的密码是否匹配\n        :param password:\n        :return:\n        """\n        password = password.encode(\'utf-8\')\n        return hashpw(password, self) == self\n\nclass PasswordField(BlobField):\n    def __init__(self, iterations=12, *args, **kwargs):\n        if None in (hashpw, gensalt):\n            raise ValueError(\'Missing library required for PasswordField: bcrypt\')\n        self.bcrypt_iterations = iterations\n        self.raw_password = None\n        super(PasswordField, self).__init__(*args, **kwargs)\n\n    def db_value(self, value):\n        """\n        将python的值转换成存入数据库的值\n        存入数据库的值，是通过bcrypt加密后的密文。\n        :param value:\n        :return:\n        """\n        if isinstance(value, PasswordHash):\n            return bytes(value)\n\n        if isinstance(value, str):\n            value = value.encode(\'utf-8\')\n        salt = gensalt(self.bcrypt_iterations)\n        return value if value is None else hashpw(value, salt)\n\n    def python_value(self, value):\n        """\n        将数据库中的值转换成python中的值\n        这个值是一个PasswordHash对象。该对象提供比较密码的方法。\n        :param value:\n        :return:\n        """\n        if isinstance(value, str):\n            value = value.encode(\'utf-8\')\n\n        return PasswordHash(value)\n\nclass User(BaseModel):\n    username = CharField(max_length=16, verbose_name="用户名", index=True, unique=True)\n    password = PasswordField(verbose_name="密码")\n    address = CharField(max_length=200, null=True, verbose_name="地址")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n\n\n\n# 注册的handler\n\n注册的接口\n\n代码: /apps/user/handler.py\n\nclass RegisterHandler(BaseHandler):\n\n    async def post(self):\n\n        ret_data = {}\n\n        registerForm = RegisterForm(self.request.arguments)\n        if registerForm.validate():\n            username = registerForm.username.data\n\n            try:\n                exist_user = await self.application.objects.get(User, username=username)\n                ret_data["username"] = "用户名已经存在"\n            except User.DoesNotExist as e:\n                user = await self.application.objects.create(User, **registerForm.data)\n                ret_data["id"] = user.id\n        else:\n            self.set_status(400)\n            for field in registerForm.erros:\n                ret_data[field] = registerForm[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n',normalizedContent:'# 简介\n\nbcrypt 可以通过加盐的方式对密码进行加密，更加的安全可靠。\n\n该项目的github地址: tornado_learning.git\n\n优点\n\nmd5加密，每个对应的明文密码，对应的是一样的加密的密文，比较容易的进行解密。而bcrypt每一次的明文密码得到的是不同的加密的密文，因为密文是通过随机的盐结合加密，所以更加安全。\n\n\n# python 如何使用bcrypt 栗子\n\nfrom bcrypt import hashpw, gensalt\n\n# 这个是随机生成的盐\nsalt = gensalt(12)\n\n# 这个是通过盐去加密\npasswd = hashpw("123456".encode(\'utf8\'), salt)\n\n# 将输入的明文密码与密文密码进行加密，是否等于密文密码。\nhashpw(input_passwd.encode(\'utf8\'), passwd) == passwd\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# tornado 使用 bcrypt 加密密码栗子。\n\n\n# 创建user model\n\n在user model中的密码字段使用自定义的passwordfield.\n\n代码/apps/user/models.py\n\nclass passwordhash(bytes):\n    def check_password(self, password):\n        """\n        比较传入的密码和数据库中的密码是否匹配\n        :param password:\n        :return:\n        """\n        password = password.encode(\'utf-8\')\n        return hashpw(password, self) == self\n\nclass passwordfield(blobfield):\n    def __init__(self, iterations=12, *args, **kwargs):\n        if none in (hashpw, gensalt):\n            raise valueerror(\'missing library required for passwordfield: bcrypt\')\n        self.bcrypt_iterations = iterations\n        self.raw_password = none\n        super(passwordfield, self).__init__(*args, **kwargs)\n\n    def db_value(self, value):\n        """\n        将python的值转换成存入数据库的值\n        存入数据库的值，是通过bcrypt加密后的密文。\n        :param value:\n        :return:\n        """\n        if isinstance(value, passwordhash):\n            return bytes(value)\n\n        if isinstance(value, str):\n            value = value.encode(\'utf-8\')\n        salt = gensalt(self.bcrypt_iterations)\n        return value if value is none else hashpw(value, salt)\n\n    def python_value(self, value):\n        """\n        将数据库中的值转换成python中的值\n        这个值是一个passwordhash对象。该对象提供比较密码的方法。\n        :param value:\n        :return:\n        """\n        if isinstance(value, str):\n            value = value.encode(\'utf-8\')\n\n        return passwordhash(value)\n\nclass user(basemodel):\n    username = charfield(max_length=16, verbose_name="用户名", index=true, unique=true)\n    password = passwordfield(verbose_name="密码")\n    address = charfield(max_length=200, null=true, verbose_name="地址")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n\n\n\n# 注册的handler\n\n注册的接口\n\n代码: /apps/user/handler.py\n\nclass registerhandler(basehandler):\n\n    async def post(self):\n\n        ret_data = {}\n\n        registerform = registerform(self.request.arguments)\n        if registerform.validate():\n            username = registerform.username.data\n\n            try:\n                exist_user = await self.application.objects.get(user, username=username)\n                ret_data["username"] = "用户名已经存在"\n            except user.doesnotexist as e:\n                user = await self.application.objects.create(user, **registerform.data)\n                ret_data["id"] = user.id\n        else:\n            self.set_status(400)\n            for field in registerform.erros:\n                ret_data[field] = registerform[field][0]\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"python简单使用grpc",frontmatter:{title:"python简单使用grpc",date:"2022-09-06T19:45:31.000Z",permalink:"/pages/f9d78c/",tags:["python"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"简单介绍Python如何使用grpc",feed:{enable:!0},categories:["编程","python","其他"],comment:!0,meta:[{name:"twitter:title",content:"python简单使用grpc"},{name:"twitter:description",content:"简单介绍Python如何使用grpc"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/01.python%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html"},{property:"og:type",content:"article"},{property:"og:title",content:"python简单使用grpc"},{property:"og:description",content:"简单介绍Python如何使用grpc"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/01.python%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-09-06T19:45:31.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"python简单使用grpc"},{itemprop:"description",content:"简单介绍Python如何使用grpc"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/01.python%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html",relativePath:"04.编程/01.python/09.其他/01.python简单使用grpc.md",key:"v-3b941cbe",path:"/pages/f9d78c/",headers:[{level:2,title:"0. 相关链接",slug:"_0-相关链接",normalizedTitle:"0. 相关链接",charIndex:2},{level:2,title:"1. 创建protobuf文件",slug:"_1-创建protobuf文件",normalizedTitle:"1. 创建protobuf文件",charIndex:116},{level:2,title:"2. 编译proto文件",slug:"_2-编译proto文件",normalizedTitle:"2. 编译proto文件",charIndex:826},{level:2,title:"3. 简单测试protobuf数据结构的序列化与反序列化",slug:"_3-简单测试protobuf数据结构的序列化与反序列化",normalizedTitle:"3. 简单测试protobuf数据结构的序列化与反序列化",charIndex:1418},{level:2,title:"4. 创建grpc服务端",slug:"_4-创建grpc服务端",normalizedTitle:"4. 创建grpc服务端",charIndex:1899},{level:2,title:"5. 创建grpc客户端",slug:"_5-创建grpc客户端",normalizedTitle:"5. 创建grpc客户端",charIndex:2901}],headersStr:"0. 相关链接 1. 创建protobuf文件 2. 编译proto文件 3. 简单测试protobuf数据结构的序列化与反序列化 4. 创建grpc服务端 5. 创建grpc客户端",content:"# 0. 相关链接\n\n源码案例：https://github.com/msqfx/python-examples\n\n官方文档：https://grpc.io/docs/languages/python/quickstart\n\n\n# 1. 创建protobuf文件\n\n在目录proto目录下创建user.proto文件，创建User的rpc服务定义，该服务中包含AddUser和GetUser两个调用，并使用下面创建的对应的结构体作为请求体和响应体。 注意：需要添加package proto，否则下面编译生成的python文件引用路径则不正确。\n\nsyntax = \"proto3\";\n\n// 包名\npackage proto;\n\n// 定义User rpc服务\nservice User {\n  // 定义rpc服务的方法\n  rpc AddUser (UserRequest) returns (UserResponse);\n  rpc GetUser (GetUserRequest) returns (GetUserResponse);\n}\n\n// 请求的结构体\nmessage UserRequest {\n  string name = 1;\n  uint32 age = 2;\n}\n\n// 响应的结构体\nmessage UserResponse {\n  string msg = 1;\n  int32 code = 2;\n}\n\nmessage GetUserRequest {\n  string name = 1;\n}\n\nmessage GetUserResponse {\n  string name = 1;\n  string age = 2;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2. 编译proto文件\n\n首选需要安装grpc的库和工具\n\npython -m pip install grpcio #安装grpc\npython -m pip install grpcio-tools #安装grpc tools\n\n\n1\n2\n\n\n然后，运行命令对proto文件进行编译，会根据上面的proto文件生成对应的python文件，你会发现在proto目录下创建了user_pb2.py和user_pb2_grpc.py两个文件\n\npython -m grpc_tools.protoc --python_out=. --grpc_python_out=. -I. ./proto/user.proto\n\n\n1\n\n * --python_out=.，protobuf相关代码文件生成在这里\n * --grpc_python_out=.，grpc相关代码生成在这里\n * -I. ./proto/user.proto，proto文件路径\n\n编译后：\n\n * user_pb2.py，用来和 protobuf 数据进行交互，这个就是根据proto文件定义好的数据结构类型生成的python化的数据结构文件\n * user_pb2_grpc.py: 用来和 grpc 进行交互，这个就是定义了rpc方法的类，包含了类的请求参数和响应等等，可用python直接实例化调用\n\n\n# 3. 简单测试protobuf数据结构的序列化与反序列化\n\n我们创建proto_test.py文件，创建User对象，填充值，并将该对象序列化成字符串输出\n\nfrom proto import user_pb2\n\n# 创建Student对象，将该对象序列化成字符串\ns = user_pb2.UserRequest()\ns.name = \"zhangsan\"\ns.age = 12\nreq_str = s.SerializeToString()\nprint(req_str)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n输出：\n\nb'\\n\\x08zhangsan\\x10\\x0c'\n\n\n1\n\n\n然后我们再创建User对象将将上面的输出的序列化字符串反序列化进来。\n\n# 将上面的输出的序列化字符串反序列化成对象\ns2 = user_pb2.UserRequest()\ns2.ParseFromString(req_str)\nprint(s2.name)\nprint(s2.age)\n\n\n1\n2\n3\n4\n5\n\n\n输出：\n\nzhangsan\n12\n\n\n1\n2\n\n\n\n# 4. 创建grpc服务端\n\n下面是使用之前创建的protobuf和grpc文件来构建grpc服务端代码。\n\nimport logging\nfrom concurrent import futures\n\nimport grpc\n\nfrom proto import user_pb2, user_pb2_grpc\n\n\nclass UserService(user_pb2_grpc.UserServicer):\n\n    # 实现proto文件中rpc的调用\n    def AddUser(self, request: user_pb2.UserRequest, context):\n        return user_pb2.UserResponse(msg='add user(name={},age={}) success'.format(request.name, request.age), code=0)\n\n    def GetUser(self, request: user_pb2.GetUserRequest, context):\n        return user_pb2.GetUserResponse(name=request.name, age=\"1888\")\n\n\ndef serve():\n    # 使用线程池来完成grpc的请求\n    server = grpc.server(futures.ThreadPoolExecutor(max_workers=5))\n    user_pb2_grpc.add_UserServicer_to_server(UserService(), server)\n    server.add_insecure_port('[::]:50051')  # 绑定端口\n    server.start()\n    server.wait_for_termination()\n\n\nif __name__ == '__main__':\n    logging.basicConfig()\n    serve()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n运行该服务端，会阻塞等待客户端的请求。\n\n\n# 5. 创建grpc客户端\n\nimport logging\n\nimport grpc\n\nfrom proto import user_pb2, user_pb2_grpc\n\n\ndef run():\n    # 连接rpc服务\n    with grpc.insecure_channel('localhost:50051') as channel:\n        stub = user_pb2_grpc.UserStub(channel)\n\n        # 调用rpc服务的AddUser方法\n        response: user_pb2.UserResponse = stub.AddUser(user_pb2.UserRequest(name=\"zhangsan\", age=18))\n        print(\"add user, response is 'msg={}, code={}'\".format(response.msg, response.code))\n\n        # 调用rpc服务的GetUser方法\n        response: user_pb2.GetUserResponse = stub.GetUser(user_pb2.GetUserRequest(name=\"lisi\"))\n        print(\"get user[name={}, age={}]\".format(response.name, response.age))\n\n\nif __name__ == '__main__':\n    logging.basicConfig()\n    run()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n运行客户端，调用rpc服务，输出：\n\nadd user, response is 'msg=add user(name=zhangsan,age=18) success, code=0'\nget user[name=lisi, age=1888]\n\n\n1\n2\n",normalizedContent:"# 0. 相关链接\n\n源码案例：https://github.com/msqfx/python-examples\n\n官方文档：https://grpc.io/docs/languages/python/quickstart\n\n\n# 1. 创建protobuf文件\n\n在目录proto目录下创建user.proto文件，创建user的rpc服务定义，该服务中包含adduser和getuser两个调用，并使用下面创建的对应的结构体作为请求体和响应体。 注意：需要添加package proto，否则下面编译生成的python文件引用路径则不正确。\n\nsyntax = \"proto3\";\n\n// 包名\npackage proto;\n\n// 定义user rpc服务\nservice user {\n  // 定义rpc服务的方法\n  rpc adduser (userrequest) returns (userresponse);\n  rpc getuser (getuserrequest) returns (getuserresponse);\n}\n\n// 请求的结构体\nmessage userrequest {\n  string name = 1;\n  uint32 age = 2;\n}\n\n// 响应的结构体\nmessage userresponse {\n  string msg = 1;\n  int32 code = 2;\n}\n\nmessage getuserrequest {\n  string name = 1;\n}\n\nmessage getuserresponse {\n  string name = 1;\n  string age = 2;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2. 编译proto文件\n\n首选需要安装grpc的库和工具\n\npython -m pip install grpcio #安装grpc\npython -m pip install grpcio-tools #安装grpc tools\n\n\n1\n2\n\n\n然后，运行命令对proto文件进行编译，会根据上面的proto文件生成对应的python文件，你会发现在proto目录下创建了user_pb2.py和user_pb2_grpc.py两个文件\n\npython -m grpc_tools.protoc --python_out=. --grpc_python_out=. -i. ./proto/user.proto\n\n\n1\n\n * --python_out=.，protobuf相关代码文件生成在这里\n * --grpc_python_out=.，grpc相关代码生成在这里\n * -i. ./proto/user.proto，proto文件路径\n\n编译后：\n\n * user_pb2.py，用来和 protobuf 数据进行交互，这个就是根据proto文件定义好的数据结构类型生成的python化的数据结构文件\n * user_pb2_grpc.py: 用来和 grpc 进行交互，这个就是定义了rpc方法的类，包含了类的请求参数和响应等等，可用python直接实例化调用\n\n\n# 3. 简单测试protobuf数据结构的序列化与反序列化\n\n我们创建proto_test.py文件，创建user对象，填充值，并将该对象序列化成字符串输出\n\nfrom proto import user_pb2\n\n# 创建student对象，将该对象序列化成字符串\ns = user_pb2.userrequest()\ns.name = \"zhangsan\"\ns.age = 12\nreq_str = s.serializetostring()\nprint(req_str)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n输出：\n\nb'\\n\\x08zhangsan\\x10\\x0c'\n\n\n1\n\n\n然后我们再创建user对象将将上面的输出的序列化字符串反序列化进来。\n\n# 将上面的输出的序列化字符串反序列化成对象\ns2 = user_pb2.userrequest()\ns2.parsefromstring(req_str)\nprint(s2.name)\nprint(s2.age)\n\n\n1\n2\n3\n4\n5\n\n\n输出：\n\nzhangsan\n12\n\n\n1\n2\n\n\n\n# 4. 创建grpc服务端\n\n下面是使用之前创建的protobuf和grpc文件来构建grpc服务端代码。\n\nimport logging\nfrom concurrent import futures\n\nimport grpc\n\nfrom proto import user_pb2, user_pb2_grpc\n\n\nclass userservice(user_pb2_grpc.userservicer):\n\n    # 实现proto文件中rpc的调用\n    def adduser(self, request: user_pb2.userrequest, context):\n        return user_pb2.userresponse(msg='add user(name={},age={}) success'.format(request.name, request.age), code=0)\n\n    def getuser(self, request: user_pb2.getuserrequest, context):\n        return user_pb2.getuserresponse(name=request.name, age=\"1888\")\n\n\ndef serve():\n    # 使用线程池来完成grpc的请求\n    server = grpc.server(futures.threadpoolexecutor(max_workers=5))\n    user_pb2_grpc.add_userservicer_to_server(userservice(), server)\n    server.add_insecure_port('[::]:50051')  # 绑定端口\n    server.start()\n    server.wait_for_termination()\n\n\nif __name__ == '__main__':\n    logging.basicconfig()\n    serve()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n运行该服务端，会阻塞等待客户端的请求。\n\n\n# 5. 创建grpc客户端\n\nimport logging\n\nimport grpc\n\nfrom proto import user_pb2, user_pb2_grpc\n\n\ndef run():\n    # 连接rpc服务\n    with grpc.insecure_channel('localhost:50051') as channel:\n        stub = user_pb2_grpc.userstub(channel)\n\n        # 调用rpc服务的adduser方法\n        response: user_pb2.userresponse = stub.adduser(user_pb2.userrequest(name=\"zhangsan\", age=18))\n        print(\"add user, response is 'msg={}, code={}'\".format(response.msg, response.code))\n\n        # 调用rpc服务的getuser方法\n        response: user_pb2.getuserresponse = stub.getuser(user_pb2.getuserrequest(name=\"lisi\"))\n        print(\"get user[name={}, age={}]\".format(response.name, response.age))\n\n\nif __name__ == '__main__':\n    logging.basicconfig()\n    run()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n运行客户端，调用rpc服务，输出：\n\nadd user, response is 'msg=add user(name=zhangsan,age=18) success, code=0'\nget user[name=lisi, age=1888]\n\n\n1\n2\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"tornado 使用peewee-async 完成异步orm数据库操作",frontmatter:{tags:["python","tornado"],title:"tornado 使用peewee-async 完成异步orm数据库操作",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/113ab1/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"tornado中使用peewee-async来完成异步orm数据库操作",feed:{enable:!0},categories:["编程","python","tornado"],comment:!0,meta:[{name:"twitter:title",content:"tornado 使用peewee-async 完成异步orm数据库操作"},{name:"twitter:description",content:"tornado中使用peewee-async来完成异步orm数据库操作"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/06.tornado%20%E4%BD%BF%E7%94%A8peewee-async%20%E5%AE%8C%E6%88%90%E5%BC%82%E6%AD%A5orm%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tornado 使用peewee-async 完成异步orm数据库操作"},{property:"og:description",content:"tornado中使用peewee-async来完成异步orm数据库操作"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/06.tornado%20%E4%BD%BF%E7%94%A8peewee-async%20%E5%AE%8C%E6%88%90%E5%BC%82%E6%AD%A5orm%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"tornado"},{itemprop:"name",content:"tornado 使用peewee-async 完成异步orm数据库操作"},{itemprop:"description",content:"tornado中使用peewee-async来完成异步orm数据库操作"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/08.tornado/06.tornado%20%E4%BD%BF%E7%94%A8peewee-async%20%E5%AE%8C%E6%88%90%E5%BC%82%E6%AD%A5orm%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C.html",relativePath:"04.编程/01.python/08.tornado/06.tornado 使用peewee-async 完成异步orm数据库操作.md",key:"v-05407dda",path:"/pages/113ab1/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"配置",slug:"配置",normalizedTitle:"配置",charIndex:169},{level:2,title:"创建model",slug:"创建model",normalizedTitle:"创建model",charIndex:1026},{level:2,title:"增删改查",slug:"增删改查",normalizedTitle:"增删改查",charIndex:2523},{level:2,title:"连表查询",slug:"连表查询",normalizedTitle:"连表查询",charIndex:4290}],headersStr:"简介 配置 创建model 增删改查 连表查询",content:'# 简介\n\ntornado是一个异步web框架，其中不能使用阻塞的操作，不然会导致整个程序的阻塞。数据库操作时不可避免的需要使用，这里采用的是peewee-async去解决。\n\npeewee-async 是一个为 peewee orm框架提供异步接口的库。\n\n该项目的github地址: tornado_learning.git\n\n\n# 配置\n\n在settings.py文件中创建连接数据库\n代码: server.py\n\nimport peewee_async\n\ndatabase = peewee_async.MySQLDatabase("tornado_learning", "127.0.0.1", port=3306, user="root", password="root1234")\n\n\n1\n2\n3\n\n\n在server.py中引用数据库连接，并加入到app中\n\nfrom peewee_async import Manager\nfrom tornado import web, ioloop\n\nfrom tornado_learning.settings import database\nfrom tornado_learning.settings import settings\nfrom tornado_learning.urls import urlpattern\n\n\ndef make_app():    \n    app = web.Application(urlpattern, debug=True, **settings)    \n    \n    # 就在这里添加数据库连接\n    objects = Manager(database)    \n    \n    # 禁止使用同步操作\n    database.set_allow_sync(False)    \n    app.objects = objects    \n    return app\n\nif __name__ == \'__main__\':   \n    app = make_app()   \n    app.listen(8888)    \n    ioloop.IOLoop.current().start()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 创建model\n\n创建通用的BaseModel类\ncreate_time是每个model都需要的字段，将两个字段提取到BaseModel中。\nid字段在peewee中会为每个model自动创建。\n为每一个model指定database\n在配置目录tornado_learning中创建model.py\n\n代码: tornado_learning/models\n\nfrom datetime import datetime\n\nfrom peewee import Model, DateTimeField\n\nfrom tornado_learning.settings import database\n\nclass BaseModel(Model):   \n    create_time = DateTimeField(default=datetime.now, verbose_name="创建时间")    \n    class Meta:        \n        database = database\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n创建model类\n\n> 这里的student和teacher的关系是1对多。\n\n创建student的模型类。\n代码: apps/school/models.py\n\nfrom peewee import CharField, IntegerField, TextField\nfrom tornado_learning.models import BaseModel\n\nclass Student(BaseModel):    \n    name = CharField(max_length=100, null=False, verbose_name="学生名")    \n    age = IntegerField(null=False, verbose_name="年龄")    \n    desc = TextField(verbose_name="个人简介")\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n创建teacher的模型类\n\nclass Teacher(BaseModel):    \n    student = ForeignKeyField(rel_model=Student, related_name="teachers")    \n    name = CharField(max_length=100, null=False, verbose_name="老师名")   \n    age = IntegerField(null=False, verbose_name="年龄")   \n    subject = CharField(max_length=100, null=False, verbose_name="学科")\n\n\n1\n2\n3\n4\n5\n\n\n使用工具类创建表\n在tools/init_db.py中初始化表。\n运行该文件即可在数据库中创建表\n\nfrom tornado_learning.settings import database\nfrom apps.school.models import Student\n\ndef init_db():    \n    database.create_tables([Student, student])\n\nif __name__ == \'__main__\':    \n    init_db()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 增删改查\n\n下面是增删改查的例子。\n\n> form表单的使用可以参考我的文章<<tornado 结合wtforms使用表单操作\n\n代码: apps/school/handler.py\n\n\nimport tornado\n\nfrom apps.school.forms import StudentForm\nfrom apps.school.models import Student\nfrom tornado_learning.handler import BaseHandler\n\nclass StudentHandler(BaseHandler):\n\n    async def get(self):\n        id = self.get_argument("id", None)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(Student, id=id)\n\n        try:\n            self.write({\n                "id": student.id,\n                "name": student.name\n            })\n        except Student.DoesNotExist:\n            raise tornado.webHttpError(404, "Object not found")\n\n    async def post(self):\n\n        student_form = StudentForm(self.request.arguments)\n        if student_form.validate():\n            await self.application.objects.create(Student, **student_form.data)\n\n            self.write("创建成功")\n        else:\n            self.write("校验失败")\n\n    async def delete(self):\n        id = self.get_argument("id", None)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(Student, id=id)\n        await self.application.objects.delete(student)\n\n        self.write("删除成功")\n\n    async def put(self):\n        studentForm = StudentForm(self.request.arguments)\n\n        student = Student(**studentForm.data)\n\n        if studentForm.validate():\n            await self.application.objects.update(student)\n            self.write("更新成功")\n        else:\n            print(studentForm.errors)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n\n\n\n# 连表查询\n\n在teacher model中添加extend方法，拼凑连表查询的方法，方便使用。\n代码: apps/school/model.py\n\nclass Teacher(BaseModel):\n    student = ForeignKeyField(rel_model=Student, related_name="teachers")\n    name = CharField(max_length=100, null=False, verbose_name="老师名")\n    age = IntegerField(null=False, verbose_name="年龄")\n    subject = CharField(max_length=100, null=False, verbose_name="学科")\n\n    @classmethod\n    def extend(cls):\n        return cls.select(cls, Student.name, Student.age).join(Student)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n使用peewee拼凑出查询，然后通过异步执行得到结果\n代码: apps/school/handler.py\n\nclass TeacherHandler(BaseHandler):\n\n    async def get(self):\n        ret_data = {"data": []}\n\n        teacher_query = Teacher.extend()\n        teacher_query = teacher_query.filter(Teacher.age > 20)\n        teachers = await self.application.objects.execute(teacher_query)\n\n        for teacher in teachers:\n            item_dict = {\n                "teacher_name": teacher.name,\n                "teacher_age": teacher.age,\n                "student_name": teacher.student.name,\n                "student_age": teacher.student.age\n            }\n            ret_data[\'data\'].append(item_dict)\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n',normalizedContent:'# 简介\n\ntornado是一个异步web框架，其中不能使用阻塞的操作，不然会导致整个程序的阻塞。数据库操作时不可避免的需要使用，这里采用的是peewee-async去解决。\n\npeewee-async 是一个为 peewee orm框架提供异步接口的库。\n\n该项目的github地址: tornado_learning.git\n\n\n# 配置\n\n在settings.py文件中创建连接数据库\n代码: server.py\n\nimport peewee_async\n\ndatabase = peewee_async.mysqldatabase("tornado_learning", "127.0.0.1", port=3306, user="root", password="root1234")\n\n\n1\n2\n3\n\n\n在server.py中引用数据库连接，并加入到app中\n\nfrom peewee_async import manager\nfrom tornado import web, ioloop\n\nfrom tornado_learning.settings import database\nfrom tornado_learning.settings import settings\nfrom tornado_learning.urls import urlpattern\n\n\ndef make_app():    \n    app = web.application(urlpattern, debug=true, **settings)    \n    \n    # 就在这里添加数据库连接\n    objects = manager(database)    \n    \n    # 禁止使用同步操作\n    database.set_allow_sync(false)    \n    app.objects = objects    \n    return app\n\nif __name__ == \'__main__\':   \n    app = make_app()   \n    app.listen(8888)    \n    ioloop.ioloop.current().start()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n\n# 创建model\n\n创建通用的basemodel类\ncreate_time是每个model都需要的字段，将两个字段提取到basemodel中。\nid字段在peewee中会为每个model自动创建。\n为每一个model指定database\n在配置目录tornado_learning中创建model.py\n\n代码: tornado_learning/models\n\nfrom datetime import datetime\n\nfrom peewee import model, datetimefield\n\nfrom tornado_learning.settings import database\n\nclass basemodel(model):   \n    create_time = datetimefield(default=datetime.now, verbose_name="创建时间")    \n    class meta:        \n        database = database\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n创建model类\n\n> 这里的student和teacher的关系是1对多。\n\n创建student的模型类。\n代码: apps/school/models.py\n\nfrom peewee import charfield, integerfield, textfield\nfrom tornado_learning.models import basemodel\n\nclass student(basemodel):    \n    name = charfield(max_length=100, null=false, verbose_name="学生名")    \n    age = integerfield(null=false, verbose_name="年龄")    \n    desc = textfield(verbose_name="个人简介")\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n创建teacher的模型类\n\nclass teacher(basemodel):    \n    student = foreignkeyfield(rel_model=student, related_name="teachers")    \n    name = charfield(max_length=100, null=false, verbose_name="老师名")   \n    age = integerfield(null=false, verbose_name="年龄")   \n    subject = charfield(max_length=100, null=false, verbose_name="学科")\n\n\n1\n2\n3\n4\n5\n\n\n使用工具类创建表\n在tools/init_db.py中初始化表。\n运行该文件即可在数据库中创建表\n\nfrom tornado_learning.settings import database\nfrom apps.school.models import student\n\ndef init_db():    \n    database.create_tables([student, student])\n\nif __name__ == \'__main__\':    \n    init_db()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 增删改查\n\n下面是增删改查的例子。\n\n> form表单的使用可以参考我的文章<<tornado 结合wtforms使用表单操作\n\n代码: apps/school/handler.py\n\n\nimport tornado\n\nfrom apps.school.forms import studentform\nfrom apps.school.models import student\nfrom tornado_learning.handler import basehandler\n\nclass studenthandler(basehandler):\n\n    async def get(self):\n        id = self.get_argument("id", none)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(student, id=id)\n\n        try:\n            self.write({\n                "id": student.id,\n                "name": student.name\n            })\n        except student.doesnotexist:\n            raise tornado.webhttperror(404, "object not found")\n\n    async def post(self):\n\n        student_form = studentform(self.request.arguments)\n        if student_form.validate():\n            await self.application.objects.create(student, **student_form.data)\n\n            self.write("创建成功")\n        else:\n            self.write("校验失败")\n\n    async def delete(self):\n        id = self.get_argument("id", none)\n        if not id:\n            return self.write("please provide the \'id\'")\n\n        student = await self.application.objects.get(student, id=id)\n        await self.application.objects.delete(student)\n\n        self.write("删除成功")\n\n    async def put(self):\n        studentform = studentform(self.request.arguments)\n\n        student = student(**studentform.data)\n\n        if studentform.validate():\n            await self.application.objects.update(student)\n            self.write("更新成功")\n        else:\n            print(studentform.errors)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n\n\n\n# 连表查询\n\n在teacher model中添加extend方法，拼凑连表查询的方法，方便使用。\n代码: apps/school/model.py\n\nclass teacher(basemodel):\n    student = foreignkeyfield(rel_model=student, related_name="teachers")\n    name = charfield(max_length=100, null=false, verbose_name="老师名")\n    age = integerfield(null=false, verbose_name="年龄")\n    subject = charfield(max_length=100, null=false, verbose_name="学科")\n\n    @classmethod\n    def extend(cls):\n        return cls.select(cls, student.name, student.age).join(student)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n使用peewee拼凑出查询，然后通过异步执行得到结果\n代码: apps/school/handler.py\n\nclass teacherhandler(basehandler):\n\n    async def get(self):\n        ret_data = {"data": []}\n\n        teacher_query = teacher.extend()\n        teacher_query = teacher_query.filter(teacher.age > 20)\n        teachers = await self.application.objects.execute(teacher_query)\n\n        for teacher in teachers:\n            item_dict = {\n                "teacher_name": teacher.name,\n                "teacher_age": teacher.age,\n                "student_name": teacher.student.name,\n                "student_age": teacher.student.age\n            }\n            ret_data[\'data\'].append(item_dict)\n\n        return self.finish(ret_data)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"pyspark streaming简介 和 消费 kafka示例",frontmatter:{tags:["python"],title:"pyspark streaming简介 和 消费 kafka示例",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/72664a/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"简单介绍pyspark streaming以及消费kafka的示例",feed:{enable:!0},categories:["编程","python","其他"],comment:!0,meta:[{name:"image",content:"https://img-blog.csdnimg.cn/20190416164155495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIyOTE4MjQz,size_16,color_FFFFFF,t_70"},{name:"twitter:title",content:"pyspark streaming简介 和 消费 kafka示例"},{name:"twitter:description",content:"简单介绍pyspark streaming以及消费kafka的示例"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://img-blog.csdnimg.cn/20190416164155495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIyOTE4MjQz,size_16,color_FFFFFF,t_70"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/02.pyspark%20streaming%E7%AE%80%E4%BB%8B%20%E5%92%8C%20%E6%B6%88%E8%B4%B9%20kafka%E7%A4%BA%E4%BE%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"pyspark streaming简介 和 消费 kafka示例"},{property:"og:description",content:"简单介绍pyspark streaming以及消费kafka的示例"},{property:"og:image",content:"https://img-blog.csdnimg.cn/20190416164155495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIyOTE4MjQz,size_16,color_FFFFFF,t_70"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/02.pyspark%20streaming%E7%AE%80%E4%BB%8B%20%E5%92%8C%20%E6%B6%88%E8%B4%B9%20kafka%E7%A4%BA%E4%BE%8B.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{itemprop:"name",content:"pyspark streaming简介 和 消费 kafka示例"},{itemprop:"description",content:"简单介绍pyspark streaming以及消费kafka的示例"},{itemprop:"image",content:"https://img-blog.csdnimg.cn/20190416164155495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIyOTE4MjQz,size_16,color_FFFFFF,t_70"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/09.%E5%85%B6%E4%BB%96/02.pyspark%20streaming%E7%AE%80%E4%BB%8B%20%E5%92%8C%20%E6%B6%88%E8%B4%B9%20kafka%E7%A4%BA%E4%BE%8B.html",relativePath:"04.编程/01.python/09.其他/02.pyspark streaming简介 和 消费 kafka示例.md",key:"v-a1f03dba",path:"/pages/72664a/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"基础数据源",slug:"基础数据源",normalizedTitle:"基础数据源",charIndex:314},{level:2,title:"高级数据源",slug:"高级数据源",normalizedTitle:"高级数据源",charIndex:1431},{level:3,title:"Spark Streaming 和 kafka 整合",slug:"spark-streaming-和-kafka-整合",normalizedTitle:"spark streaming 和 kafka 整合",charIndex:1441}],headersStr:"简介 基础数据源 高级数据源 Spark Streaming 和 kafka 整合",content:'# 简介\n\n> 并不是真正的实时处理框架，只是按照时间进行微批处理进行，时间可以设置的尽可能的小。\n\n> 将不同的额数据源的数据经过SparkStreaming 处理之后将结果输出到外部文件系统\n\n * 特点\n\n> 低延时 能从错误中搞笑的恢复: fault-tolerant 能够运行在成百上千的节点 能够将批处理、机器学习、图计算等自框架和Spark Streaming 综合起来使用\n\n * 粗粒度\n\n> Spark Streaming接收到实时数据流，把数据按照指定的时间段切成一片片小的数据块，然后把小的数据块传给Spark Engine处理。\n\n * 细粒度\n\n * 数据源 kafka提供了两种数据源。\n\n 1. 基础数据源，可以直接通过streamingContext API实现。如文件系统和socket连接\n 2. 高级的数据源，如Kafka, Flume, Kinesis等等. 可以通过额外的类库去实现。\n\n\n# 基础数据源\n\n 1. 使用官方的案例\n\n/spark/examples/src/main/python/streaming\n\nnc -lk 6789\n\n 2. 处理socket数据\n\n示例代码如下: 读取socket中的数据进行流处理\n\nfrom pyspark import SparkContext\nfrom pyspark.streaming import StreamingContext\n\n# local 必须设为2\nsc = SparkContext("local[2]", "NetworkWordCount")\nssc = StreamingContext(sc, 1)\n\nlines = ssc.socketTextStream("localhost", 9999)\n\nwords = lines.flatMap(lambda line: line.split(" "))\n\npairs = words.map(lambda word: (word, 1))\nwordCounts = pairs.reduceByKey(lambda x, y: x + y)\n\nwordCounts.pprint()\n\nssc.start()\nssc.awaitTermination()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n测试\n\n> nc -lk 9999\n\n 3. 处理文件系统数据\n\n> 文件系统(fileStream(that is, HDFSM S3, NFS))暂不支持python，python仅支持文本文件(textFileStream)\n\n示例如下，但未成功，找不到该文件。\n\n\nlines = ssc.textFileStream("hdfs://txz-data0:9820/user/jim/workflow/crash/python/crash_2_hdfs.py")\n\n\n\n1\n2\n3\n\n\n * streaming context\n\n * DStreams\n\n> 持续化的数据流 对DStream操作算子， 比如map/flatMap,其实底层会被翻译为对DStream中的每个RDD都做相同的操作，因为一个DStream是由不同批次的RDD所\n\n * Input DStreams and Receivers\n\n\n# 高级数据源\n\n\n# Spark Streaming 和 kafka 整合\n\n两种模式\n\n * receiver 模式\n\nfrom pyspark.streaming.kafka import KafkaUtils\nfrom pyspark import SparkContext\nfrom pyspark.streaming import StreamingContext\n\nsc = SparkContext("local[2]", "NetworkWordCount")\nsc.setLogLevel("OFF")\nssc = StreamingContext(sc, 1)\n\n# 创建Kafka streaming\nline = KafkaUtils.createStream(ssc, "192.168.0.208:2181", \'test\', {"jim_test": 1})\n\n# 分词\nwords = line.flatMap(lambda line: line.split(" "))\npairs = words.map(lambda word: (word, 1))\nwordCounts = pairs.reduceByKey(lambda x, y: x + y)\nwordCounts.pprint()\n\nssc.start()\nssc.awaitTermination()\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n * no receiver\n\n根据上面的代码替换掉createStream即可。\n\nline = KafkaUtils.createDirectStream(ssc, ["jim_test"], {"metadata.broker.list": "192.168.0.208:9092"})\n\n\n1\n\n\n运行:\n\n> spark-submit --jars spark-streaming-kafka-0-8-assembly_2.11-2.4.0.jar test_spark_stream.py\n\n需要下载相应的jar包.下载地址如下，搜索。 https://search.maven.org\n\njar版本会在运行程序时报错提醒。',normalizedContent:'# 简介\n\n> 并不是真正的实时处理框架，只是按照时间进行微批处理进行，时间可以设置的尽可能的小。\n\n> 将不同的额数据源的数据经过sparkstreaming 处理之后将结果输出到外部文件系统\n\n * 特点\n\n> 低延时 能从错误中搞笑的恢复: fault-tolerant 能够运行在成百上千的节点 能够将批处理、机器学习、图计算等自框架和spark streaming 综合起来使用\n\n * 粗粒度\n\n> spark streaming接收到实时数据流，把数据按照指定的时间段切成一片片小的数据块，然后把小的数据块传给spark engine处理。\n\n * 细粒度\n\n * 数据源 kafka提供了两种数据源。\n\n 1. 基础数据源，可以直接通过streamingcontext api实现。如文件系统和socket连接\n 2. 高级的数据源，如kafka, flume, kinesis等等. 可以通过额外的类库去实现。\n\n\n# 基础数据源\n\n 1. 使用官方的案例\n\n/spark/examples/src/main/python/streaming\n\nnc -lk 6789\n\n 2. 处理socket数据\n\n示例代码如下: 读取socket中的数据进行流处理\n\nfrom pyspark import sparkcontext\nfrom pyspark.streaming import streamingcontext\n\n# local 必须设为2\nsc = sparkcontext("local[2]", "networkwordcount")\nssc = streamingcontext(sc, 1)\n\nlines = ssc.sockettextstream("localhost", 9999)\n\nwords = lines.flatmap(lambda line: line.split(" "))\n\npairs = words.map(lambda word: (word, 1))\nwordcounts = pairs.reducebykey(lambda x, y: x + y)\n\nwordcounts.pprint()\n\nssc.start()\nssc.awaittermination()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n测试\n\n> nc -lk 9999\n\n 3. 处理文件系统数据\n\n> 文件系统(filestream(that is, hdfsm s3, nfs))暂不支持python，python仅支持文本文件(textfilestream)\n\n示例如下，但未成功，找不到该文件。\n\n\nlines = ssc.textfilestream("hdfs://txz-data0:9820/user/jim/workflow/crash/python/crash_2_hdfs.py")\n\n\n\n1\n2\n3\n\n\n * streaming context\n\n * dstreams\n\n> 持续化的数据流 对dstream操作算子， 比如map/flatmap,其实底层会被翻译为对dstream中的每个rdd都做相同的操作，因为一个dstream是由不同批次的rdd所\n\n * input dstreams and receivers\n\n\n# 高级数据源\n\n\n# spark streaming 和 kafka 整合\n\n两种模式\n\n * receiver 模式\n\nfrom pyspark.streaming.kafka import kafkautils\nfrom pyspark import sparkcontext\nfrom pyspark.streaming import streamingcontext\n\nsc = sparkcontext("local[2]", "networkwordcount")\nsc.setloglevel("off")\nssc = streamingcontext(sc, 1)\n\n# 创建kafka streaming\nline = kafkautils.createstream(ssc, "192.168.0.208:2181", \'test\', {"jim_test": 1})\n\n# 分词\nwords = line.flatmap(lambda line: line.split(" "))\npairs = words.map(lambda word: (word, 1))\nwordcounts = pairs.reducebykey(lambda x, y: x + y)\nwordcounts.pprint()\n\nssc.start()\nssc.awaittermination()\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n * no receiver\n\n根据上面的代码替换掉createstream即可。\n\nline = kafkautils.createdirectstream(ssc, ["jim_test"], {"metadata.broker.list": "192.168.0.208:9092"})\n\n\n1\n\n\n运行:\n\n> spark-submit --jars spark-streaming-kafka-0-8-assembly_2.11-2.4.0.jar test_spark_stream.py\n\n需要下载相应的jar包.下载地址如下，搜索。 https://search.maven.org\n\njar版本会在运行程序时报错提醒。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"go简单使用grpc",frontmatter:{tags:["golang"],title:"go简单使用grpc",date:"2022-09-07T20:10:13.000Z",permalink:"/pages/87014e/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍go是如何使用grpc的",feed:{enable:!0},categories:["编程","go"],comment:!0,meta:[{name:"twitter:title",content:"go简单使用grpc"},{name:"twitter:description",content:"介绍go是如何使用grpc的"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/02.go/01.go%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html"},{property:"og:type",content:"article"},{property:"og:title",content:"go简单使用grpc"},{property:"og:description",content:"介绍go是如何使用grpc的"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/02.go/01.go%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-09-07T20:10:13.000Z"},{property:"article:tag",content:"golang"},{itemprop:"name",content:"go简单使用grpc"},{itemprop:"description",content:"介绍go是如何使用grpc的"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go/01.go%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8grpc.html",relativePath:"04.编程/02.go/01.go简单使用grpc.md",key:"v-ec68963a",path:"/pages/87014e/",headers:[{level:2,title:"0.相关链接",slug:"_0-相关链接",normalizedTitle:"0.相关链接",charIndex:2},{level:2,title:"1. 定义proto文件",slug:"_1-定义proto文件",normalizedTitle:"1. 定义proto文件",charIndex:142},{level:2,title:"2. 编译proto文件",slug:"_2-编译proto文件",normalizedTitle:"2. 编译proto文件",charIndex:799},{level:2,title:"3. 创建grpc服务端",slug:"_3-创建grpc服务端",normalizedTitle:"3. 创建grpc服务端",charIndex:1377},{level:2,title:"4. 创建grpc客户端",slug:"_4-创建grpc客户端",normalizedTitle:"4. 创建grpc客户端",charIndex:2873},{level:2,title:"5. 运行结果",slug:"_5-运行结果",normalizedTitle:"5. 运行结果",charIndex:4042}],headersStr:"0.相关链接 1. 定义proto文件 2. 编译proto文件 3. 创建grpc服务端 4. 创建grpc客户端 5. 运行结果",content:'# 0.相关链接\n\ngrpc github：https://github.com/grpc/grpc-go\n\n官方文档：https://grpc.io/docs/languages/go/\n\n案例代码：https://github.com/msqfx/go-examples\n\n\n# 1. 定义proto文件\n\nproto文件是用来预先定义的消息格式。数据包会按照proto文件所定义的消息格式完成二进制码流的编码和解码。\n\nsyntax = "proto3";\n\n// 指定生成的 go 文件存放位置及其包名\noption go_package = "./;proto";\n\n// 定义User rpc服务\nservice User {\n  // 定义rpc服务的方法\n  rpc AddUser (UserRequest) returns (UserResponse);\n  rpc GetUser (GetUserRequest) returns (GetUserResponse);\n}\n\n// 请求的结构体\nmessage UserRequest {\n  string name = 1;\n  uint32 age = 2;\n}\n\n// 响应的结构体\nmessage UserResponse {\n  string msg = 1;\n  int32 code = 2;\n}\n\nmessage GetUserRequest {\n  string name = 1;\n}\n\nmessage GetUserResponse {\n  string name = 1;\n  string age = 2;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2. 编译proto文件\n\n首先需要安装protoc的二进制文件，是用来编译proto的。\n\n下载地址：https://github.com/protocolbuffers/protobuf/releases\n\n然后再下载安装编译proto文件的插件\n\n$ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28\n$ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2\n\n\n1\n2\n\n\n进入proto目录下使用以下命令对proto文件进行编译，会生成两个文件user.pb.go和user_grpc.pb.go两个文件\n\nprotoc --go_out=. --go-grpc_out=. user.proto\n\n\n1\n\n * --go_out=. protobuf相关代码文件生成在该目录下\n * --go-grpc_out=. grpc相关代码文件生成在该目录下\n\n编译后:\n\n * user.pb.go：主要是请求与相应数据包的结构体定义，客户端和服务端都可以通过该结构体进行序列化与反序列化。\n * user_grpc.pb.go：主要是grpc的服务端和客户端代码，通过实现及调用接口来互相沟通。\n\n\n# 3. 创建grpc服务端\n\n我们首先要实现user_grpc.pb.go中的UserServer接口，该接口中的方法是我们在proto文件中定义的rpc服务AddUser和GetUser。\n\n不过，你会发现其中还多了个mustEmbedUnimplementedUserServer方法，但是我们proto文件中并没有定义，这个是用来兼容使用的。你看可以文件中UnimplementedUserServer结构体实现了UserServer接口，自己定义UserService包含UnimplementedUserServer，即使没有实现UserServer所有接口，也不会报错。\n\npackage main\n\nimport (\n\t"context"\n\t"fmt"\n\t"google.golang.org/grpc"\n\t"log"\n\t"net"\n\t"simple_example/proto"\n)\n\n// UserService 定义结构体，实现UserServer\ntype UserService struct {\n\tproto.UnimplementedUserServer\n}\n\nfunc NewUserService() *UserService {\n\treturn &UserService{}\n}\n\n// AddUser 实现rpc方法\nfunc (us *UserService) AddUser(ctx context.Context, request *proto.UserRequest) (*proto.UserResponse, error) {\n\tfmt.Printf("add user success. name = %s, age = %d\\n", request.GetName(), request.GetAge())\n\treturn &proto.UserResponse{Msg: "success", Code: 0}, nil\n}\n\nfunc (us *UserService) GetUser(ctx context.Context, request *proto.GetUserRequest) (*proto.GetUserResponse, error) {\n\tfmt.Printf("get user. name = %s\\n", request.GetName())\n\treturn &proto.GetUserResponse{Name: request.GetName(), Age: 1999}, nil\n}\n\nfunc main() {\n\t// 监听端口\n\tlis, err := net.Listen("tcp", fmt.Sprintf("localhost:%d", 8000))\n\tif err != nil {\n\t\tlog.Fatalf("failed to listen: %v", err)\n\t}\n\tgrpcServer := grpc.NewServer()\n\n\t// 注册rpc服务\n\tproto.RegisterUserServer(grpcServer, NewUserService())\n\tgrpcServer.Serve(lis)\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n\n\n\n# 4. 创建grpc客户端\n\n调用user_grpc.pb.go文件中的NewUserClient方法来创建调用rpc服务的客户端，调用rpc方法时使用user.pb.go中的结构体作为输入与输出。\n\npackage main\n\nimport (\n\t"context"\n\t"fmt"\n\t"google.golang.org/grpc"\n\t"google.golang.org/grpc/credentials/insecure"\n\t"log"\n\t"simple_example/proto"\n)\n\nfunc main() {\n\tvar opts []grpc.DialOption\n\topts = append(opts, grpc.WithTransportCredentials(insecure.NewCredentials()))\n\n\tconn, err := grpc.Dial("localhost:8000", opts...)\n\tif err != nil {\n\t\tlog.Fatalf("fail to dial: %v", err)\n\t}\n\tdefer conn.Close()\n\n\tclient := proto.NewUserClient(conn)\n\n\t// 调用rpc服务AddUser方法\n\tresp, err := client.AddUser(context.Background(), &proto.UserRequest{Name: "zhengwenfeng", Age: 18})\n\tif err != nil {\n\t\tlog.Fatalf("fail to AddUser: %v", err)\n\t}\n\tfmt.Printf("AddUser, msg = %s, code = %d\\n", resp.Msg, resp.Code)\n\n\t// 调用rpc服务GetUser方法\n\tgetuserResp, err := client.GetUser(context.Background(), &proto.GetUserRequest{Name: "zhangsan"})\n\tif err != nil {\n\t\tlog.Fatalf("fail to GetUser: %v", err)\n\t}\n\tfmt.Printf("GetUser, Name = %s, Age = %d", getuserResp.Name, getuserResp.Age)\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# 5. 运行结果\n\n首先运行服务端监听rpc服务 然后再运行客户端调用服务。 服务端输出：\n\nadd user success. name = zhengwenfeng, age = 18\nget user success. name = zhangsan\n\n\n1\n2\n\n\n客户端输出：\n\nAddUser, msg = success, code = 0\nGetUser, Name = zhangsan, Age = 1999\n\n\n1\n2\n',normalizedContent:'# 0.相关链接\n\ngrpc github：https://github.com/grpc/grpc-go\n\n官方文档：https://grpc.io/docs/languages/go/\n\n案例代码：https://github.com/msqfx/go-examples\n\n\n# 1. 定义proto文件\n\nproto文件是用来预先定义的消息格式。数据包会按照proto文件所定义的消息格式完成二进制码流的编码和解码。\n\nsyntax = "proto3";\n\n// 指定生成的 go 文件存放位置及其包名\noption go_package = "./;proto";\n\n// 定义user rpc服务\nservice user {\n  // 定义rpc服务的方法\n  rpc adduser (userrequest) returns (userresponse);\n  rpc getuser (getuserrequest) returns (getuserresponse);\n}\n\n// 请求的结构体\nmessage userrequest {\n  string name = 1;\n  uint32 age = 2;\n}\n\n// 响应的结构体\nmessage userresponse {\n  string msg = 1;\n  int32 code = 2;\n}\n\nmessage getuserrequest {\n  string name = 1;\n}\n\nmessage getuserresponse {\n  string name = 1;\n  string age = 2;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n\n\n\n# 2. 编译proto文件\n\n首先需要安装protoc的二进制文件，是用来编译proto的。\n\n下载地址：https://github.com/protocolbuffers/protobuf/releases\n\n然后再下载安装编译proto文件的插件\n\n$ go install google.golang.org/protobuf/cmd/protoc-gen-go@v1.28\n$ go install google.golang.org/grpc/cmd/protoc-gen-go-grpc@v1.2\n\n\n1\n2\n\n\n进入proto目录下使用以下命令对proto文件进行编译，会生成两个文件user.pb.go和user_grpc.pb.go两个文件\n\nprotoc --go_out=. --go-grpc_out=. user.proto\n\n\n1\n\n * --go_out=. protobuf相关代码文件生成在该目录下\n * --go-grpc_out=. grpc相关代码文件生成在该目录下\n\n编译后:\n\n * user.pb.go：主要是请求与相应数据包的结构体定义，客户端和服务端都可以通过该结构体进行序列化与反序列化。\n * user_grpc.pb.go：主要是grpc的服务端和客户端代码，通过实现及调用接口来互相沟通。\n\n\n# 3. 创建grpc服务端\n\n我们首先要实现user_grpc.pb.go中的userserver接口，该接口中的方法是我们在proto文件中定义的rpc服务adduser和getuser。\n\n不过，你会发现其中还多了个mustembedunimplementeduserserver方法，但是我们proto文件中并没有定义，这个是用来兼容使用的。你看可以文件中unimplementeduserserver结构体实现了userserver接口，自己定义userservice包含unimplementeduserserver，即使没有实现userserver所有接口，也不会报错。\n\npackage main\n\nimport (\n\t"context"\n\t"fmt"\n\t"google.golang.org/grpc"\n\t"log"\n\t"net"\n\t"simple_example/proto"\n)\n\n// userservice 定义结构体，实现userserver\ntype userservice struct {\n\tproto.unimplementeduserserver\n}\n\nfunc newuserservice() *userservice {\n\treturn &userservice{}\n}\n\n// adduser 实现rpc方法\nfunc (us *userservice) adduser(ctx context.context, request *proto.userrequest) (*proto.userresponse, error) {\n\tfmt.printf("add user success. name = %s, age = %d\\n", request.getname(), request.getage())\n\treturn &proto.userresponse{msg: "success", code: 0}, nil\n}\n\nfunc (us *userservice) getuser(ctx context.context, request *proto.getuserrequest) (*proto.getuserresponse, error) {\n\tfmt.printf("get user. name = %s\\n", request.getname())\n\treturn &proto.getuserresponse{name: request.getname(), age: 1999}, nil\n}\n\nfunc main() {\n\t// 监听端口\n\tlis, err := net.listen("tcp", fmt.sprintf("localhost:%d", 8000))\n\tif err != nil {\n\t\tlog.fatalf("failed to listen: %v", err)\n\t}\n\tgrpcserver := grpc.newserver()\n\n\t// 注册rpc服务\n\tproto.registeruserserver(grpcserver, newuserservice())\n\tgrpcserver.serve(lis)\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n\n\n\n# 4. 创建grpc客户端\n\n调用user_grpc.pb.go文件中的newuserclient方法来创建调用rpc服务的客户端，调用rpc方法时使用user.pb.go中的结构体作为输入与输出。\n\npackage main\n\nimport (\n\t"context"\n\t"fmt"\n\t"google.golang.org/grpc"\n\t"google.golang.org/grpc/credentials/insecure"\n\t"log"\n\t"simple_example/proto"\n)\n\nfunc main() {\n\tvar opts []grpc.dialoption\n\topts = append(opts, grpc.withtransportcredentials(insecure.newcredentials()))\n\n\tconn, err := grpc.dial("localhost:8000", opts...)\n\tif err != nil {\n\t\tlog.fatalf("fail to dial: %v", err)\n\t}\n\tdefer conn.close()\n\n\tclient := proto.newuserclient(conn)\n\n\t// 调用rpc服务adduser方法\n\tresp, err := client.adduser(context.background(), &proto.userrequest{name: "zhengwenfeng", age: 18})\n\tif err != nil {\n\t\tlog.fatalf("fail to adduser: %v", err)\n\t}\n\tfmt.printf("adduser, msg = %s, code = %d\\n", resp.msg, resp.code)\n\n\t// 调用rpc服务getuser方法\n\tgetuserresp, err := client.getuser(context.background(), &proto.getuserrequest{name: "zhangsan"})\n\tif err != nil {\n\t\tlog.fatalf("fail to getuser: %v", err)\n\t}\n\tfmt.printf("getuser, name = %s, age = %d", getuserresp.name, getuserresp.age)\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# 5. 运行结果\n\n首先运行服务端监听rpc服务 然后再运行客户端调用服务。 服务端输出：\n\nadd user success. name = zhengwenfeng, age = 18\nget user success. name = zhangsan\n\n\n1\n2\n\n\n客户端输出：\n\nadduser, msg = success, code = 0\ngetuser, name = zhangsan, age = 1999\n\n\n1\n2\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"gin中validator模块的源码分析",frontmatter:{tags:["golang","gin"],title:"gin中validator模块的源码分析",date:"2022-09-11T16:23:04.000Z",permalink:"/pages/c41003/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"在gin中使用的是validator模块来对表单进行校验的，本文主要是对该模块的源码分析与学习",feed:{enable:!0},categories:["编程","go"],comment:!0,meta:[{name:"twitter:title",content:"gin中validator模块的源码分析"},{name:"twitter:description",content:"在gin中使用的是validator模块来对表单进行校验的，本文主要是对该模块的源码分析与学习"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/02.go/02.%20gin%E4%B8%ADvalidator%E6%A8%A1%E5%9D%97%E7%9A%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"gin中validator模块的源码分析"},{property:"og:description",content:"在gin中使用的是validator模块来对表单进行校验的，本文主要是对该模块的源码分析与学习"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/02.go/02.%20gin%E4%B8%ADvalidator%E6%A8%A1%E5%9D%97%E7%9A%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-09-11T16:23:04.000Z"},{property:"article:tag",content:"golang"},{property:"article:tag",content:"gin"},{itemprop:"name",content:"gin中validator模块的源码分析"},{itemprop:"description",content:"在gin中使用的是validator模块来对表单进行校验的，本文主要是对该模块的源码分析与学习"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go/02.%20gin%E4%B8%ADvalidator%E6%A8%A1%E5%9D%97%E7%9A%84%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90.html",relativePath:"04.编程/02.go/02. gin中validator模块的源码分析.md",key:"v-37dbc27d",path:"/pages/c41003/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"懒加载validate对象",slug:"懒加载validate对象",normalizedTitle:"懒加载validate对象",charIndex:62},{level:2,title:"多种请求参数的校验",slug:"多种请求参数的校验",normalizedTitle:"多种请求参数的校验",charIndex:1555},{level:2,title:"钩子方法",slug:"钩子方法",normalizedTitle:"钩子方法",charIndex:3621},{level:2,title:"对象池的应用",slug:"对象池的应用",normalizedTitle:"对象池的应用",charIndex:4816},{level:2,title:"根据标签校验过程",slug:"根据标签校验过程",normalizedTitle:"根据标签校验过程",charIndex:6027},{level:2,title:"错误提示信息翻译",slug:"错误提示信息翻译",normalizedTitle:"错误提示信息翻译",charIndex:9749}],headersStr:"简介 懒加载validate对象 多种请求参数的校验 钩子方法 对象池的应用 根据标签校验过程 错误提示信息翻译",content:'# 简介\n\n在gin中使用的是validator模块来对表单进行校验的。\n\nvalidator模块github地址\n\n\n# 懒加载validate对象\n\n众所周知，在api层需要使用gin.Context中的ShouldBindJSON方法来对request中的json字段进行校验，例子如下:\n\nfunc login(c *gin.Context) {\n\n\tvar user User\n\tif err := c.ShouldBindJSON(&user); err != nil {\n\n\t\terrs, ok := err.(validator.ValidationErrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.JSON(http.StatusOK, gin.H{"msg": err.Error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.JSON(http.StatusOK, gin.H{"msg": errs.Translate(global.Trans)})\n\t\treturn\n\t}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在c.ShourdBindJSON中，一直往下跳转，跟到路径binding/default_validator.go下，可以看到代码如下，对表单的校验是调用v.validate.Struct(obj)来完成的，这里的validate是validator库中Validate对象，所以在之前使用v.lazyinit()来创建该对象。\n\n// validateStruct receives struct type\nfunc (v *defaultValidator) validateStruct(obj any) error {\n\tv.lazyinit()\n\treturn v.validate.Struct(obj)\n}\n\n\n1\n2\n3\n4\n5\n\n\n再看v.lazyinit()方法，这里使用了once.Do方法，该once是sync.Onec对象，Do中的方法只会执行一次，也就是只会创建一次Validate对象，保持该对象的单例。\n\ntype defaultValidator struct {\n\tonce     sync.Once\n\tvalidate *validator.Validate\n}\n\nfunc (v *defaultValidator) lazyinit() {\n\tv.once.Do(func() {\n\t\tv.validate = validator.New()\n\t\tv.validate.SetTagName("binding")\n\t})\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n那么有这么一种场景，如果我想要对validator中的validate对象进行配置，该怎么办呢？因为上面都是在使用时懒加载才加载的，我们需要提前拿到validate对象并进行配置，该如何处理？\n\n在代码binding/default_validator.go中，提供了Engine方法，我们可以使用该方法给使用这调用提前加载validate对象，并返回该对象，就可以进行配置了。\n\nfunc (v *defaultValidator) Engine() any {\n\tv.lazyinit()\n\treturn v.validate\n}\n\n\n1\n2\n3\n4\n\n\n结论：\n\n * 结构体中的对象可以使用懒加载的方式，在使用的时候再进行创建。\n\n * 可以使用once.Do的方法创建对象保持单例。\n\n * 可以提供方法提前加载对象，然后返回出来进行使用配置\n\n\n# 多种请求参数的校验\n\n我们使用c.ShouldBindJSON(&user)可以对json格式的请求参数进行校验，也可以使用c.ShouldBindXML对xml格式的请求参数进行校验。\n\n在代码binding/binding.go中可以看到定义了多种对request进行校验的全局对象。\n\nvar (\n\tJSON          = jsonBinding{}\n\tXML           = xmlBinding{}\n\tForm          = formBinding{}\n\tQuery         = queryBinding{}\n\tFormPost      = formPostBinding{}\n\tFormMultipart = formMultipartBinding{}\n\tProtoBuf      = protobufBinding{}\n\tMsgPack       = msgpackBinding{}\n\tYAML          = yamlBinding{}\n\tUri           = uriBinding{}\n\tHeader        = headerBinding{}\n\tTOML          = tomlBinding{}\n)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n进入c.ShouldBindJSON方法，可以看到调用了c.ShouldBindWith方法并将表单对象和全局的JSON对象传入其中。\n\n// ShouldBindJSON is a shortcut for c.ShouldBindWith(obj, binding.JSON).\nfunc (c *Context) ShouldBindJSON(obj any) error {\n\treturn c.ShouldBindWith(obj, binding.JSON)\n}\n\n\n1\n2\n3\n4\n\n\n在c.ShouldBindWith中，是直接使用上面的JSON全局对象的bind方法，将requets和表单对象传入其中。\n\n// ShouldBindWith binds the passed struct pointer using the specified binding engine.\n// See the binding package.\nfunc (c *Context) ShouldBindWith(obj any, b binding.Binding) error {\n\treturn b.Bind(c.Request, obj)\n}\n\n\n1\n2\n3\n4\n5\n\n\n再看b.Bind方法，你会发现，它做的事情是：校验请求参数是否为json格式，然后再调用validate方法，该方法就是去创建go-palyground模块中Validate对象，然后调用其struct方法进行参数验证。\n\nfunc (jsonBinding) Bind(req *http.Request, obj any) error {\n\tif req == nil || req.Body == nil {\n\t\treturn errors.New("invalid request")\n\t}\n\treturn decodeJSON(req.Body, obj)\n}\n\nfunc decodeJSON(r io.Reader, obj any) error {\n\tdecoder := json.NewDecoder(r)\n\tif EnableDecoderUseNumber {\n\t\tdecoder.UseNumber()\n\t}\n\tif EnableDecoderDisallowUnknownFields {\n\t\tdecoder.DisallowUnknownFields()\n\t}\n\tif err := decoder.Decode(obj); err != nil {\n\t\treturn err\n\t}\n\treturn validate(obj)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n你再看看ShouldBindXML方法，就会发现是和上面一样的过程，调用的是全局对象XML中的bind方法，然后再校验请求参数是否为xml格式，最终调用validate方法。\n\n总结：\n\n在binding/binding.go中的全局对象都实现了一个bind方法，该方法是对请求参数的格式进行检验，然后最终会调用validate方法，去创建go-palyground模块中Validate对象，再调用其struct对象进行请求参数的内容校验。\n\n创建多个ShouldBindXXX，在不同的方法中使用不同的全局对象，这些对象都有一个相同的方法bind，然后再统一调用bind方法进行校验。\n\n\n# 钩子方法\n\nvalidator库中Validate结构体提供了一系列的钩子方法，在校验中的过程中，提供给使用者来修改其中的部分内容。\n\n我们看一下validator_instance.go文件中Validate结构体，该结构体中包含了hasTagNameFunc和tagNameFunc两个变量，tagNameFunc代表着钩子方法，使用者可以自定方法来赋值给它，hasTagNameFunc是bool类型代表是否配置了钩子方法.\n\ntype Validate struct {\n\ttagName          string\n\tpool             *sync.Pool\n\thasCustomFuncs   bool\n\thasTagNameFunc   bool\n\ttagNameFunc      TagNameFunc\n\tstructLevelFuncs map[reflect.Type]StructLevelFuncCtx\n\tcustomFuncs      map[reflect.Type]CustomTypeFunc\n\taliases          map[string]string\n\tvalidations      map[string]internalValidationFuncWrapper\n\ttransTagFunc     map[ut.Translator]map[string]TranslationFunc // map[<locale>]map[<tag>]TranslationFunc\n\ttagCache         *tagCache\n\tstructCache      *structCache\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n使用者可以调用RegisterTagNameFunc方法来注册自己写的方法\n\nfunc (v *Validate) RegisterTagNameFunc(fn TagNameFunc) {\n\tv.tagNameFunc = fn\n\tv.hasTagNameFunc = true\n}\n\n\n1\n2\n3\n4\n\n\n在代码cache.go中extractStructCache方法中有下面一段代码，通过调用hasTagNameFunc方法来判断是否设置了钩子方法，如果设置了，则调用tagNameFunc来执行使用者自定的方法。\n\n\t\tif v.hasTagNameFunc {\n\t\t\tname := v.tagNameFunc(fld)\n\t\t\tif len(name) > 0 {\n\t\t\t\tcustomName = name\n\t\t\t}\n\t\t}\n\n\n1\n2\n3\n4\n5\n6\n\n\n总结：\n\n * 可以提供钩子方法暴露给使用者参与到执行过程中来。\n\n\n# 对象池的应用\n\n看文件validator_instance.go中的Struct方法，这个方法就是表单的校验的入口方法，可以看到它又调用了StructCtx方法。\n\nfunc (v *Validate) Struct(s interface{}) error {\n\treturn v.StructCtx(context.Background(), s)\n}\n\n\n1\n2\n3\n\n\n再来看看StructCtx方法，其中pool是*sync.Pool类型，调用Get方法获取validate对象，然后再调用其validateStruct方法，其中会进行请求参数的校验，然后如果校验有误，会将错误信息保存在errs中。valudate使用完成后，再put回pool中。\n\n因为每一次校验都需要创建validate对象，所以这里使用了sync.Pool可以复用临时对象，减少内存的分配，降低GC压力。\n\nfunc (v *Validate) StructCtx(ctx context.Context, s interface{}) (err error) {\n\n\tval := reflect.ValueOf(s)\n\ttop := val\n\n\tif val.Kind() == reflect.Ptr && !val.IsNil() {\n\t\tval = val.Elem()\n\t}\n\n\tif val.Kind() != reflect.Struct || val.Type() == timeType {\n\t\treturn &InvalidValidationError{Type: reflect.TypeOf(s)}\n\t}\n\n\t// good to validate\n\tvd := v.pool.Get().(*validate)\n\tvd.top = top\n\tvd.isPartial = false\n\t// vd.hasExcludes = false // only need to reset in StructPartial and StructExcept\n\n\tvd.validateStruct(ctx, top, val, val.Type(), vd.ns[0:0], vd.actualNs[0:0], nil)\n\n\tif len(vd.errs) > 0 {\n\t\terr = vd.errs\n\t\tvd.errs = nil\n\t}\n\n\tv.pool.Put(vd)\n\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n总结：\n\n * 当需要频繁创建相同对象，并且该对象是无状态时，可以使用sync.Pool来提高复用临时对象，减少内存的分配，降低GC压力。\n\n\n# 根据标签校验过程\n\n在懒加载创建validator的Validate对象时，是调用validator_instance.go中New方法来创建该对象，在该方法中初始化所有标签及标签对应的校验方法并保存在Validate对象中的validations变量中\n\nfor k, val := range bakedInValidators {\n\tswitch k {\n\t// these require that even if the value is nil that the validation should run, omitempty still overrides this behaviour\n\tcase requiredIfTag, requiredUnlessTag, requiredWithTag, requiredWithAllTag, requiredWithoutTag, requiredWithoutAllTag,\n\t\texcludedWithTag, excludedWithAllTag, excludedWithoutTag, excludedWithoutAllTag:\n\t\t_ = v.registerValidation(k, wrapFunc(val), true, true)\n\tdefault:\n\t\t// no need to error check here, baked in will always be valid\n\t\t_ = v.registerValidation(k, wrapFunc(val), true, false)\n\t}\n}\n\n\nfunc (v *Validate) registerValidation(tag string, fn FuncCtx, bakedIn bool, nilCheckable bool) error {\n\tif len(tag) == 0 {\n\t\treturn errors.New("function Key cannot be empty")\n\t}\n\n\tif fn == nil {\n\t\treturn errors.New("function cannot be empty")\n\t}\n\n\t_, ok := restrictedTags[tag]\n\tif !bakedIn && (ok || strings.ContainsAny(tag, restrictedTagChars)) {\n\t\tpanic(fmt.Sprintf(restrictedTagErr, tag))\n\t}\n\tv.validations[tag] = internalValidationFuncWrapper{fn: fn, runValidatinOnNil: nilCheckable}\n\treturn nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n我们可以在baked_in.go文件中看到有定义以标签为key，校验方法为value的map对象。\n\nbakedInValidators = map[string]Func{\n\t\t"required":                      hasValue,\n\t\t"required_if":                   requiredIf,\n\t\t"required_unless":               requiredUnless,\n\t\t"required_with":                 requiredWith,\n\t\t"required_with_all":             requiredWithAll,\n\t\t"required_without":              requiredWithout,\n\t\t"required_without_all":          requiredWithoutAll,\n......\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在代码cache.go中extractStructCache方法中，会遍历请求参数的每一个字段，然后根据该字段的tag创建对应的ctag对象，再创建该字段的cField对象，并将ctag传入。\n\n\t\tif len(tag) > 0 {\n\t\t\tctag, _ = v.parseFieldTagsRecursive(tag, fld.Name, "", false)\n\t\t} else {\n\t\t\t// even if field doesn\'t have validations need cTag for traversing to potential inner/nested\n\t\t\t// elements of the field.\n\t\t\tctag = new(cTag)\n\t\t}\n\n\t\tcs.fields = append(cs.fields, &cField{\n\t\t\tidx:        i,\n\t\t\tname:       fld.Name,\n\t\t\taltName:    customName,\n\t\t\tcTags:      ctag,\n\t\t\tnamesEqual: fld.Name == customName,\n\t\t})\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在上面的v.parseFieldTagsRecursive方法中会将从之前缓存的validatetions集合中找到该ctag的校验方法，然后赋值ctag.fn方法。\n\nif wrapper, ok := v.validations[current.tag]; ok {\n\tcurrent.fn = wrapper.fn\n\tcurrent.runValidationWhenNil = wrapper.runValidatinOnNil\n} else {\n\tpanic(strings.TrimSpace(fmt.Sprintf(undefinedValidation, current.tag, fieldName)))\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n在文件validator.go中traverseField方法校验字段中会调用上面传递的fn方法，返回值为false时，会创建fieldError对象保存在validate的errs中\n\nif !ct.fn(ctx, v) {\n\n\tv.str1 = string(append(ns, cf.altName...))\n\n\tif v.v.hasTagNameFunc {\n\t\tv.str2 = string(append(structNs, cf.name...))\n\t} else {\n\t\tv.str2 = v.str1\n\t}\n\n\tv.errs = append(v.errs,\n\t\t&fieldError{\n\t\t\tv:              v.v,\n\t\t\ttag:            ct.aliasTag,\n\t\t\tactualTag:      ct.tag,\n\t\t\tns:             v.str1,\n\t\t\tstructNs:       v.str2,\n\t\t\tfieldLen:       uint8(len(cf.altName)),\n\t\t\tstructfieldLen: uint8(len(cf.name)),\n\t\t\tvalue:          current.Interface(),\n\t\t\tparam:          ct.param,\n\t\t\tkind:           kind,\n\t\t\ttyp:            typ,\n\t\t},\n)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n最终将这个error在validator_instance.go中的StructCtx方法中返回出去。\n\nvd.validateStruct(ctx, top, val, val.Type(), vd.ns[0:0], vd.actualNs[0:0], nil)\n\nif len(vd.errs) > 0 {\n\terr = vd.errs\n\tvd.errs = nil\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n结论：\n\n * error并不是调用validateStruct返回出来的，而是通过在结构体中创建了一个error，在过程中如果发生了错误则将该错误信息保存在结构体的error变量中，也是一种error的返回方式。\n\n * 先初始化所有的校验方法，然后再根据每个字段选择校验方法进行执行。逻辑非常清晰。\n\n\n# 错误提示信息翻译\n\n从上面的过程可以发现，仅能够发现哪个字段再哪个tag中发生了错误，如下所示：\n\n{\'msg\': "Key: \'User.password\' Error:Field validation for \'password\' failed on the \'required\' tag"}\n\n\n1\n\n\n但是我们需要的时候人性化的错误提示。\n\n在代码translations/zh/zh.go的RegisterDefaultTranslations方法中可以看到定义了每个tag及对应中文提示信息。这些信息会注册到validator的Validate.transTagFunc变量中。\n\nfunc RegisterDefaultTranslations(v *validator.Validate, trans ut.Translator) (err error) {\n\n\ttranslations := []struct {\n\t\ttag             string\n\t\ttranslation     string\n\t\toverride        bool\n\t\tcustomRegisFunc validator.RegisterTranslationsFunc\n\t\tcustomTransFunc validator.TranslationFunc\n\t}{\n\t\t{\n\t\t\ttag:         "required",\n\t\t\ttranslation: "{0}为必填字段",\n\t\t\toverride:    false,\n\t\t},\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n每个字段的错误对象都有Translate方法，当调用方法时，会遍历当前所有错误的字段，然后再找到每个Tag对应的提示信息输出。\n\nfunc (ve ValidationErrors) Translate(ut ut.Translator) ValidationErrorsTranslations {\n\n\ttrans := make(ValidationErrorsTranslations)\n\n\tvar fe *fieldError\n\n\tfor i := 0; i < len(ve); i++ {\n\t\tfe = ve[i].(*fieldError)\n\n\t\t// // in case an Anonymous struct was used, ensure that the key\n\t\t// // would be \'Username\' instead of ".Username"\n\t\t// if len(fe.ns) > 0 && fe.ns[:1] == "." {\n\t\t// \ttrans[fe.ns[1:]] = fe.Translate(ut)\n\t\t// \tcontinue\n\t\t// }\n\n\t\ttrans[fe.ns] = fe.Translate(ut)\n\t}\n\n\treturn trans\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n这个是每一个字段通过tag获取提示信息。\n\nfunc (fe *fieldError) Translate(ut ut.Translator) string {\n\n\tm, ok := fe.v.transTagFunc[ut]\n\tif !ok {\n\t\treturn fe.Error()\n\t}\n\n\tfn, ok := m[fe.tag]\n\tif !ok {\n\t\treturn fe.Error()\n\t}\n\n\treturn fn(ut, fe)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n',normalizedContent:'# 简介\n\n在gin中使用的是validator模块来对表单进行校验的。\n\nvalidator模块github地址\n\n\n# 懒加载validate对象\n\n众所周知，在api层需要使用gin.context中的shouldbindjson方法来对request中的json字段进行校验，例子如下:\n\nfunc login(c *gin.context) {\n\n\tvar user user\n\tif err := c.shouldbindjson(&user); err != nil {\n\n\t\terrs, ok := err.(validator.validationerrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.json(http.statusok, gin.h{"msg": err.error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.json(http.statusok, gin.h{"msg": errs.translate(global.trans)})\n\t\treturn\n\t}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在c.shourdbindjson中，一直往下跳转，跟到路径binding/default_validator.go下，可以看到代码如下，对表单的校验是调用v.validate.struct(obj)来完成的，这里的validate是validator库中validate对象，所以在之前使用v.lazyinit()来创建该对象。\n\n// validatestruct receives struct type\nfunc (v *defaultvalidator) validatestruct(obj any) error {\n\tv.lazyinit()\n\treturn v.validate.struct(obj)\n}\n\n\n1\n2\n3\n4\n5\n\n\n再看v.lazyinit()方法，这里使用了once.do方法，该once是sync.onec对象，do中的方法只会执行一次，也就是只会创建一次validate对象，保持该对象的单例。\n\ntype defaultvalidator struct {\n\tonce     sync.once\n\tvalidate *validator.validate\n}\n\nfunc (v *defaultvalidator) lazyinit() {\n\tv.once.do(func() {\n\t\tv.validate = validator.new()\n\t\tv.validate.settagname("binding")\n\t})\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n那么有这么一种场景，如果我想要对validator中的validate对象进行配置，该怎么办呢？因为上面都是在使用时懒加载才加载的，我们需要提前拿到validate对象并进行配置，该如何处理？\n\n在代码binding/default_validator.go中，提供了engine方法，我们可以使用该方法给使用这调用提前加载validate对象，并返回该对象，就可以进行配置了。\n\nfunc (v *defaultvalidator) engine() any {\n\tv.lazyinit()\n\treturn v.validate\n}\n\n\n1\n2\n3\n4\n\n\n结论：\n\n * 结构体中的对象可以使用懒加载的方式，在使用的时候再进行创建。\n\n * 可以使用once.do的方法创建对象保持单例。\n\n * 可以提供方法提前加载对象，然后返回出来进行使用配置\n\n\n# 多种请求参数的校验\n\n我们使用c.shouldbindjson(&user)可以对json格式的请求参数进行校验，也可以使用c.shouldbindxml对xml格式的请求参数进行校验。\n\n在代码binding/binding.go中可以看到定义了多种对request进行校验的全局对象。\n\nvar (\n\tjson          = jsonbinding{}\n\txml           = xmlbinding{}\n\tform          = formbinding{}\n\tquery         = querybinding{}\n\tformpost      = formpostbinding{}\n\tformmultipart = formmultipartbinding{}\n\tprotobuf      = protobufbinding{}\n\tmsgpack       = msgpackbinding{}\n\tyaml          = yamlbinding{}\n\turi           = uribinding{}\n\theader        = headerbinding{}\n\ttoml          = tomlbinding{}\n)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n进入c.shouldbindjson方法，可以看到调用了c.shouldbindwith方法并将表单对象和全局的json对象传入其中。\n\n// shouldbindjson is a shortcut for c.shouldbindwith(obj, binding.json).\nfunc (c *context) shouldbindjson(obj any) error {\n\treturn c.shouldbindwith(obj, binding.json)\n}\n\n\n1\n2\n3\n4\n\n\n在c.shouldbindwith中，是直接使用上面的json全局对象的bind方法，将requets和表单对象传入其中。\n\n// shouldbindwith binds the passed struct pointer using the specified binding engine.\n// see the binding package.\nfunc (c *context) shouldbindwith(obj any, b binding.binding) error {\n\treturn b.bind(c.request, obj)\n}\n\n\n1\n2\n3\n4\n5\n\n\n再看b.bind方法，你会发现，它做的事情是：校验请求参数是否为json格式，然后再调用validate方法，该方法就是去创建go-palyground模块中validate对象，然后调用其struct方法进行参数验证。\n\nfunc (jsonbinding) bind(req *http.request, obj any) error {\n\tif req == nil || req.body == nil {\n\t\treturn errors.new("invalid request")\n\t}\n\treturn decodejson(req.body, obj)\n}\n\nfunc decodejson(r io.reader, obj any) error {\n\tdecoder := json.newdecoder(r)\n\tif enabledecoderusenumber {\n\t\tdecoder.usenumber()\n\t}\n\tif enabledecoderdisallowunknownfields {\n\t\tdecoder.disallowunknownfields()\n\t}\n\tif err := decoder.decode(obj); err != nil {\n\t\treturn err\n\t}\n\treturn validate(obj)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n你再看看shouldbindxml方法，就会发现是和上面一样的过程，调用的是全局对象xml中的bind方法，然后再校验请求参数是否为xml格式，最终调用validate方法。\n\n总结：\n\n在binding/binding.go中的全局对象都实现了一个bind方法，该方法是对请求参数的格式进行检验，然后最终会调用validate方法，去创建go-palyground模块中validate对象，再调用其struct对象进行请求参数的内容校验。\n\n创建多个shouldbindxxx，在不同的方法中使用不同的全局对象，这些对象都有一个相同的方法bind，然后再统一调用bind方法进行校验。\n\n\n# 钩子方法\n\nvalidator库中validate结构体提供了一系列的钩子方法，在校验中的过程中，提供给使用者来修改其中的部分内容。\n\n我们看一下validator_instance.go文件中validate结构体，该结构体中包含了hastagnamefunc和tagnamefunc两个变量，tagnamefunc代表着钩子方法，使用者可以自定方法来赋值给它，hastagnamefunc是bool类型代表是否配置了钩子方法.\n\ntype validate struct {\n\ttagname          string\n\tpool             *sync.pool\n\thascustomfuncs   bool\n\thastagnamefunc   bool\n\ttagnamefunc      tagnamefunc\n\tstructlevelfuncs map[reflect.type]structlevelfuncctx\n\tcustomfuncs      map[reflect.type]customtypefunc\n\taliases          map[string]string\n\tvalidations      map[string]internalvalidationfuncwrapper\n\ttranstagfunc     map[ut.translator]map[string]translationfunc // map[<locale>]map[<tag>]translationfunc\n\ttagcache         *tagcache\n\tstructcache      *structcache\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n使用者可以调用registertagnamefunc方法来注册自己写的方法\n\nfunc (v *validate) registertagnamefunc(fn tagnamefunc) {\n\tv.tagnamefunc = fn\n\tv.hastagnamefunc = true\n}\n\n\n1\n2\n3\n4\n\n\n在代码cache.go中extractstructcache方法中有下面一段代码，通过调用hastagnamefunc方法来判断是否设置了钩子方法，如果设置了，则调用tagnamefunc来执行使用者自定的方法。\n\n\t\tif v.hastagnamefunc {\n\t\t\tname := v.tagnamefunc(fld)\n\t\t\tif len(name) > 0 {\n\t\t\t\tcustomname = name\n\t\t\t}\n\t\t}\n\n\n1\n2\n3\n4\n5\n6\n\n\n总结：\n\n * 可以提供钩子方法暴露给使用者参与到执行过程中来。\n\n\n# 对象池的应用\n\n看文件validator_instance.go中的struct方法，这个方法就是表单的校验的入口方法，可以看到它又调用了structctx方法。\n\nfunc (v *validate) struct(s interface{}) error {\n\treturn v.structctx(context.background(), s)\n}\n\n\n1\n2\n3\n\n\n再来看看structctx方法，其中pool是*sync.pool类型，调用get方法获取validate对象，然后再调用其validatestruct方法，其中会进行请求参数的校验，然后如果校验有误，会将错误信息保存在errs中。valudate使用完成后，再put回pool中。\n\n因为每一次校验都需要创建validate对象，所以这里使用了sync.pool可以复用临时对象，减少内存的分配，降低gc压力。\n\nfunc (v *validate) structctx(ctx context.context, s interface{}) (err error) {\n\n\tval := reflect.valueof(s)\n\ttop := val\n\n\tif val.kind() == reflect.ptr && !val.isnil() {\n\t\tval = val.elem()\n\t}\n\n\tif val.kind() != reflect.struct || val.type() == timetype {\n\t\treturn &invalidvalidationerror{type: reflect.typeof(s)}\n\t}\n\n\t// good to validate\n\tvd := v.pool.get().(*validate)\n\tvd.top = top\n\tvd.ispartial = false\n\t// vd.hasexcludes = false // only need to reset in structpartial and structexcept\n\n\tvd.validatestruct(ctx, top, val, val.type(), vd.ns[0:0], vd.actualns[0:0], nil)\n\n\tif len(vd.errs) > 0 {\n\t\terr = vd.errs\n\t\tvd.errs = nil\n\t}\n\n\tv.pool.put(vd)\n\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n总结：\n\n * 当需要频繁创建相同对象，并且该对象是无状态时，可以使用sync.pool来提高复用临时对象，减少内存的分配，降低gc压力。\n\n\n# 根据标签校验过程\n\n在懒加载创建validator的validate对象时，是调用validator_instance.go中new方法来创建该对象，在该方法中初始化所有标签及标签对应的校验方法并保存在validate对象中的validations变量中\n\nfor k, val := range bakedinvalidators {\n\tswitch k {\n\t// these require that even if the value is nil that the validation should run, omitempty still overrides this behaviour\n\tcase requirediftag, requiredunlesstag, requiredwithtag, requiredwithalltag, requiredwithouttag, requiredwithoutalltag,\n\t\texcludedwithtag, excludedwithalltag, excludedwithouttag, excludedwithoutalltag:\n\t\t_ = v.registervalidation(k, wrapfunc(val), true, true)\n\tdefault:\n\t\t// no need to error check here, baked in will always be valid\n\t\t_ = v.registervalidation(k, wrapfunc(val), true, false)\n\t}\n}\n\n\nfunc (v *validate) registervalidation(tag string, fn funcctx, bakedin bool, nilcheckable bool) error {\n\tif len(tag) == 0 {\n\t\treturn errors.new("function key cannot be empty")\n\t}\n\n\tif fn == nil {\n\t\treturn errors.new("function cannot be empty")\n\t}\n\n\t_, ok := restrictedtags[tag]\n\tif !bakedin && (ok || strings.containsany(tag, restrictedtagchars)) {\n\t\tpanic(fmt.sprintf(restrictedtagerr, tag))\n\t}\n\tv.validations[tag] = internalvalidationfuncwrapper{fn: fn, runvalidatinonnil: nilcheckable}\n\treturn nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n我们可以在baked_in.go文件中看到有定义以标签为key，校验方法为value的map对象。\n\nbakedinvalidators = map[string]func{\n\t\t"required":                      hasvalue,\n\t\t"required_if":                   requiredif,\n\t\t"required_unless":               requiredunless,\n\t\t"required_with":                 requiredwith,\n\t\t"required_with_all":             requiredwithall,\n\t\t"required_without":              requiredwithout,\n\t\t"required_without_all":          requiredwithoutall,\n......\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n在代码cache.go中extractstructcache方法中，会遍历请求参数的每一个字段，然后根据该字段的tag创建对应的ctag对象，再创建该字段的cfield对象，并将ctag传入。\n\n\t\tif len(tag) > 0 {\n\t\t\tctag, _ = v.parsefieldtagsrecursive(tag, fld.name, "", false)\n\t\t} else {\n\t\t\t// even if field doesn\'t have validations need ctag for traversing to potential inner/nested\n\t\t\t// elements of the field.\n\t\t\tctag = new(ctag)\n\t\t}\n\n\t\tcs.fields = append(cs.fields, &cfield{\n\t\t\tidx:        i,\n\t\t\tname:       fld.name,\n\t\t\taltname:    customname,\n\t\t\tctags:      ctag,\n\t\t\tnamesequal: fld.name == customname,\n\t\t})\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在上面的v.parsefieldtagsrecursive方法中会将从之前缓存的validatetions集合中找到该ctag的校验方法，然后赋值ctag.fn方法。\n\nif wrapper, ok := v.validations[current.tag]; ok {\n\tcurrent.fn = wrapper.fn\n\tcurrent.runvalidationwhennil = wrapper.runvalidatinonnil\n} else {\n\tpanic(strings.trimspace(fmt.sprintf(undefinedvalidation, current.tag, fieldname)))\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n在文件validator.go中traversefield方法校验字段中会调用上面传递的fn方法，返回值为false时，会创建fielderror对象保存在validate的errs中\n\nif !ct.fn(ctx, v) {\n\n\tv.str1 = string(append(ns, cf.altname...))\n\n\tif v.v.hastagnamefunc {\n\t\tv.str2 = string(append(structns, cf.name...))\n\t} else {\n\t\tv.str2 = v.str1\n\t}\n\n\tv.errs = append(v.errs,\n\t\t&fielderror{\n\t\t\tv:              v.v,\n\t\t\ttag:            ct.aliastag,\n\t\t\tactualtag:      ct.tag,\n\t\t\tns:             v.str1,\n\t\t\tstructns:       v.str2,\n\t\t\tfieldlen:       uint8(len(cf.altname)),\n\t\t\tstructfieldlen: uint8(len(cf.name)),\n\t\t\tvalue:          current.interface(),\n\t\t\tparam:          ct.param,\n\t\t\tkind:           kind,\n\t\t\ttyp:            typ,\n\t\t},\n)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n最终将这个error在validator_instance.go中的structctx方法中返回出去。\n\nvd.validatestruct(ctx, top, val, val.type(), vd.ns[0:0], vd.actualns[0:0], nil)\n\nif len(vd.errs) > 0 {\n\terr = vd.errs\n\tvd.errs = nil\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n结论：\n\n * error并不是调用validatestruct返回出来的，而是通过在结构体中创建了一个error，在过程中如果发生了错误则将该错误信息保存在结构体的error变量中，也是一种error的返回方式。\n\n * 先初始化所有的校验方法，然后再根据每个字段选择校验方法进行执行。逻辑非常清晰。\n\n\n# 错误提示信息翻译\n\n从上面的过程可以发现，仅能够发现哪个字段再哪个tag中发生了错误，如下所示：\n\n{\'msg\': "key: \'user.password\' error:field validation for \'password\' failed on the \'required\' tag"}\n\n\n1\n\n\n但是我们需要的时候人性化的错误提示。\n\n在代码translations/zh/zh.go的registerdefaulttranslations方法中可以看到定义了每个tag及对应中文提示信息。这些信息会注册到validator的validate.transtagfunc变量中。\n\nfunc registerdefaulttranslations(v *validator.validate, trans ut.translator) (err error) {\n\n\ttranslations := []struct {\n\t\ttag             string\n\t\ttranslation     string\n\t\toverride        bool\n\t\tcustomregisfunc validator.registertranslationsfunc\n\t\tcustomtransfunc validator.translationfunc\n\t}{\n\t\t{\n\t\t\ttag:         "required",\n\t\t\ttranslation: "{0}为必填字段",\n\t\t\toverride:    false,\n\t\t},\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n每个字段的错误对象都有translate方法，当调用方法时，会遍历当前所有错误的字段，然后再找到每个tag对应的提示信息输出。\n\nfunc (ve validationerrors) translate(ut ut.translator) validationerrorstranslations {\n\n\ttrans := make(validationerrorstranslations)\n\n\tvar fe *fielderror\n\n\tfor i := 0; i < len(ve); i++ {\n\t\tfe = ve[i].(*fielderror)\n\n\t\t// // in case an anonymous struct was used, ensure that the key\n\t\t// // would be \'username\' instead of ".username"\n\t\t// if len(fe.ns) > 0 && fe.ns[:1] == "." {\n\t\t// \ttrans[fe.ns[1:]] = fe.translate(ut)\n\t\t// \tcontinue\n\t\t// }\n\n\t\ttrans[fe.ns] = fe.translate(ut)\n\t}\n\n\treturn trans\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n这个是每一个字段通过tag获取提示信息。\n\nfunc (fe *fielderror) translate(ut ut.translator) string {\n\n\tm, ok := fe.v.transtagfunc[ut]\n\tif !ok {\n\t\treturn fe.error()\n\t}\n\n\tfn, ok := m[fe.tag]\n\tif !ok {\n\t\treturn fe.error()\n\t}\n\n\treturn fn(ut, fe)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"优化gin表单的错误提示信息",frontmatter:{tags:["golang","gin"],title:"优化gin表单的错误提示信息",date:"2022-09-11T16:53:33.000Z",permalink:"/pages/cf9a4d/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"如何优化gin框架中表单的错误提示信息",feed:{enable:!0},categories:["编程","go"],comment:!0,meta:[{name:"twitter:title",content:"优化gin表单的错误提示信息"},{name:"twitter:description",content:"如何优化gin框架中表单的错误提示信息"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/02.go/03.%E4%BC%98%E5%8C%96gin%E8%A1%A8%E5%8D%95%E7%9A%84%E9%94%99%E8%AF%AF%E6%8F%90%E7%A4%BA%E4%BF%A1%E6%81%AF.html"},{property:"og:type",content:"article"},{property:"og:title",content:"优化gin表单的错误提示信息"},{property:"og:description",content:"如何优化gin框架中表单的错误提示信息"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/02.go/03.%E4%BC%98%E5%8C%96gin%E8%A1%A8%E5%8D%95%E7%9A%84%E9%94%99%E8%AF%AF%E6%8F%90%E7%A4%BA%E4%BF%A1%E6%81%AF.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-09-11T16:53:33.000Z"},{property:"article:tag",content:"golang"},{property:"article:tag",content:"gin"},{itemprop:"name",content:"优化gin表单的错误提示信息"},{itemprop:"description",content:"如何优化gin框架中表单的错误提示信息"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go/03.%E4%BC%98%E5%8C%96gin%E8%A1%A8%E5%8D%95%E7%9A%84%E9%94%99%E8%AF%AF%E6%8F%90%E7%A4%BA%E4%BF%A1%E6%81%AF.html",relativePath:"04.编程/02.go/03.优化gin表单的错误提示信息.md",key:"v-118bdc85",path:"/pages/cf9a4d/",headers:[{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:2},{level:2,title:"简单使用表单检验请求参数",slug:"简单使用表单检验请求参数",normalizedTitle:"简单使用表单检验请求参数",charIndex:27},{level:2,title:"翻译",slug:"翻译",normalizedTitle:"翻译",charIndex:970},{level:2,title:"优化返回字段的key",slug:"优化返回字段的key",normalizedTitle:"优化返回字段的key",charIndex:3105},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:5184}],headersStr:"相关链接 简单使用表单检验请求参数 翻译 优化返回字段的key 总结",content:'# 相关链接\n\ngin官方例子\n\n文章的代码\n\n\n# 简单使用表单检验请求参数\n\n创建一个简单的登录例子，我们对username和password绑定了required标签，代表着请求login接口的参数中必须包含这两个字段。\n\ntype User struct {\n\tUserName string `json:"username" binding:"required"`\n\tPassword string `json:"password" binding:"required"`\n}\n\nfunc login(c *gin.Context) {\n\n\tvar user User\n\tif err := c.ShouldBindJSON(&user); err != nil {\n\t\tc.JSON(http.StatusOK, gin.H{"msg": err.Error()})\n\t\treturn\n\t}\n\n\tif user.UserName != "admin" || user.Password != "123456" {\n\t\tc.JSON(http.StatusUnauthorized, gin.H{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.JSON(http.StatusOK, gin.H{"msg": "you are logged in"})\n}\n\nfunc main() {\n\tr := gin.Default()\n\tr.POST("/login", login)\n\tr.Run() // 监听并在 0.0.0.0:8080 上启动服务\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n我们使用仅带有username去请求login接口，会输出如下，提示我们Password校验失败了，因为required的标签导致的。但是这个提示并不友好，我们需要进行优化展示。\n\n{\'msg\': "Key: \'User.Password\' Error:Field validation for \'Password\' failed on the \'required\' tag"}\n\n\n1\n\n\n\n# 翻译\n\n我们需要对上面的提示信息进行一个翻译，并且可以支持各种语言的友好性提示。\n\n我们在global/global.go文件中创建一个全局变量，该全局变量在后面的表单翻译中需要使用到\n\nimport ut "github.com/go-playground/universal-translator"\n\nvar (\n\tTrans ut.Translator\n)\n\n\n1\n2\n3\n4\n5\n\n\n在initialize/validator.go文件中编写内容如下，获取gin中的validate对象，然后给该对象绑定中文和英文的友好提示信息，我们可以通过locale来设置我们需要使用中文还是英文的信息。\n\nfunc InitTrans(locale string) (err error) {\n\n\tif v, ok := binding.Validator.Engine().(*validator.Validate); ok {\n\n\t\t// 翻译\n\t\tzhT := zh.New()\n\t\tenT := en.New()\n\t\tuni := ut.New(enT, zhT, enT)\n\n\t\tglobal.Trans, ok = uni.GetTranslator(locale)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf("uni.GetTranslator(%s) error", locale)\n\t\t}\n\n\t\tswitch locale {\n\t\tcase "zh":\n\t\t\tzh_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\tcase "en":\n\t\t\ten_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\tdefault:\n\t\t\ten_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\t}\n\n\t\treturn\n\t}\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n最后在main.go中的main方法下调用上面的InitTrans方法来初始化翻译内容。\n\n再将login方法中ShouldBindJSON返回的error转成validator.ValidationErrors类型，该类型包含一个Translate方法，调用该方法，再将之前的全局变量Trans传入。\n\nfunc login(c *gin.Context) {\n\n\tvar user User\n\tif err := c.ShouldBindJSON(&user); err != nil {\n\n\t\terrs, ok := err.(validator.ValidationErrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.JSON(http.StatusOK, gin.H{"msg": err.Error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.JSON(http.StatusOK, gin.H{"msg": errs.Translate(global.Trans)})\n\t\treturn\n\t}\n\n\tif user.UserName != "admin" || user.Password != "123456" {\n\t\tc.JSON(http.StatusUnauthorized, gin.H{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.JSON(http.StatusOK, gin.H{"msg": "you are logged in"})\n}\n\nfunc main() {\n\terr := initialize.InitTrans("zh")\n\tif err != nil {\n\t\tfmt.Printf("初始化翻译器错误, err = %s", err.Error())\n\t\treturn\n\t}\n\n\tr := gin.Default()\n\tr.POST("/login", login)\n\tr.Run() // 监听并在 0.0.0.0:8080 上启动服务\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n我们再使用仅带有username字段去请求login接口，输出内容如下。\n\n{\'msg\': {\'User.Password\': \'Password为必填字段\'}}\n\n\n1\n\n\n但是，发现提示信息的key是User.Password，是表单对象和其字段名称，我们应该想要的是：\n\n{\'msg\': {\'password\': \'Password为必填字段\'}}\n\n\n1\n\n\n\n# 优化返回字段的key\n\n我们修改InitTrans方法，通过go-playground提供的方法RegisterTagNameFunc来将我们自定义的方法注册进去，该自定义方法的目的是修改上面的Password改为json中的password，可以改成json标签中的值作为返回。\n\nfunc InitTrans(locale string) (err error) {\n\n\tif v, ok := binding.Validator.Engine().(*validator.Validate); ok {\n\n\t\t//修改返回字段key的格式\n\t\tv.RegisterTagNameFunc(func(fld reflect.StructField) string {\n\t\t\tname := strings.SplitN(fld.Tag.Get("json"), ",", 2)[0]\n\t\t\tif name == "-" {\n\t\t\t\treturn ""\n\t\t\t}\n\t\t\treturn name\n\t\t})\n\n\t\t// 翻译\n\t\tzhT := zh.New()\n\t\tenT := en.New()\n\t\tuni := ut.New(enT, zhT, enT)\n\n\t\tglobal.Trans, ok = uni.GetTranslator(locale)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf("uni.GetTranslator(%s) error", locale)\n\t\t}\n\n\t\tswitch locale {\n\t\tcase "zh":\n\t\t\tzh_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\tcase "en":\n\t\t\ten_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\tdefault:\n\t\t\ten_translations.RegisterDefaultTranslations(v, global.Trans)\n\t\t}\n\n\t\treturn\n\t}\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n再请求，响应如下，发现password已经改好了，但是User也想删除。\n\n{\'msg\': {\'User.password\': \'password为必填字段\'}}\n\n\n1\n\n\n我们在utils/validator.go文件中编写代码如下，该方法是用来删除User的。\n\nfunc RemoveTopStruct(fields map[string]string) map[string]string {\n\tres := map[string]string{}\n\tfor field, err := range fields {\n\t\tres[field[strings.Index(field, ".")+1:]] = err\n\t}\n\treturn res\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n再在翻译返回的错误信息包上该方法。\n\nfunc login(c *gin.Context) {\n\n\tvar user User\n\tif err := c.ShouldBindJSON(&user); err != nil {\n\n\t\terrs, ok := err.(validator.ValidationErrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.JSON(http.StatusOK, gin.H{"msg": err.Error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.JSON(http.StatusOK, gin.H{"msg": utils.RemoveTopStruct(errs.Translate(global.Trans))})\n\t\treturn\n\t}\n\n\tif user.UserName != "admin" || user.Password != "123456" {\n\t\tc.JSON(http.StatusUnauthorized, gin.H{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.JSON(http.StatusOK, gin.H{"msg": "you are logged in"})\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再执行，相应结果如下，这个就是我们想要的信息。\n\n{\'msg\': {\'password\': \'password为必填字段\'}}\n\n\n1\n\n\n\n# 总结\n\n个人觉的虽然gin灵活小巧，但是功能真的很不完善。每次一次输出友好信息，我们都要手动调用Translate来翻译，并且还需要通过RemoveTopStruct方法来修改返回的信息，按简单的来说，应该由框架来做，我们只需要通过配置，就能自动输出我们想要的友好提示信息才对。',normalizedContent:'# 相关链接\n\ngin官方例子\n\n文章的代码\n\n\n# 简单使用表单检验请求参数\n\n创建一个简单的登录例子，我们对username和password绑定了required标签，代表着请求login接口的参数中必须包含这两个字段。\n\ntype user struct {\n\tusername string `json:"username" binding:"required"`\n\tpassword string `json:"password" binding:"required"`\n}\n\nfunc login(c *gin.context) {\n\n\tvar user user\n\tif err := c.shouldbindjson(&user); err != nil {\n\t\tc.json(http.statusok, gin.h{"msg": err.error()})\n\t\treturn\n\t}\n\n\tif user.username != "admin" || user.password != "123456" {\n\t\tc.json(http.statusunauthorized, gin.h{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.json(http.statusok, gin.h{"msg": "you are logged in"})\n}\n\nfunc main() {\n\tr := gin.default()\n\tr.post("/login", login)\n\tr.run() // 监听并在 0.0.0.0:8080 上启动服务\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n\n\n我们使用仅带有username去请求login接口，会输出如下，提示我们password校验失败了，因为required的标签导致的。但是这个提示并不友好，我们需要进行优化展示。\n\n{\'msg\': "key: \'user.password\' error:field validation for \'password\' failed on the \'required\' tag"}\n\n\n1\n\n\n\n# 翻译\n\n我们需要对上面的提示信息进行一个翻译，并且可以支持各种语言的友好性提示。\n\n我们在global/global.go文件中创建一个全局变量，该全局变量在后面的表单翻译中需要使用到\n\nimport ut "github.com/go-playground/universal-translator"\n\nvar (\n\ttrans ut.translator\n)\n\n\n1\n2\n3\n4\n5\n\n\n在initialize/validator.go文件中编写内容如下，获取gin中的validate对象，然后给该对象绑定中文和英文的友好提示信息，我们可以通过locale来设置我们需要使用中文还是英文的信息。\n\nfunc inittrans(locale string) (err error) {\n\n\tif v, ok := binding.validator.engine().(*validator.validate); ok {\n\n\t\t// 翻译\n\t\tzht := zh.new()\n\t\tent := en.new()\n\t\tuni := ut.new(ent, zht, ent)\n\n\t\tglobal.trans, ok = uni.gettranslator(locale)\n\t\tif !ok {\n\t\t\treturn fmt.errorf("uni.gettranslator(%s) error", locale)\n\t\t}\n\n\t\tswitch locale {\n\t\tcase "zh":\n\t\t\tzh_translations.registerdefaulttranslations(v, global.trans)\n\t\tcase "en":\n\t\t\ten_translations.registerdefaulttranslations(v, global.trans)\n\t\tdefault:\n\t\t\ten_translations.registerdefaulttranslations(v, global.trans)\n\t\t}\n\n\t\treturn\n\t}\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n最后在main.go中的main方法下调用上面的inittrans方法来初始化翻译内容。\n\n再将login方法中shouldbindjson返回的error转成validator.validationerrors类型，该类型包含一个translate方法，调用该方法，再将之前的全局变量trans传入。\n\nfunc login(c *gin.context) {\n\n\tvar user user\n\tif err := c.shouldbindjson(&user); err != nil {\n\n\t\terrs, ok := err.(validator.validationerrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.json(http.statusok, gin.h{"msg": err.error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.json(http.statusok, gin.h{"msg": errs.translate(global.trans)})\n\t\treturn\n\t}\n\n\tif user.username != "admin" || user.password != "123456" {\n\t\tc.json(http.statusunauthorized, gin.h{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.json(http.statusok, gin.h{"msg": "you are logged in"})\n}\n\nfunc main() {\n\terr := initialize.inittrans("zh")\n\tif err != nil {\n\t\tfmt.printf("初始化翻译器错误, err = %s", err.error())\n\t\treturn\n\t}\n\n\tr := gin.default()\n\tr.post("/login", login)\n\tr.run() // 监听并在 0.0.0.0:8080 上启动服务\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n\n\n我们再使用仅带有username字段去请求login接口，输出内容如下。\n\n{\'msg\': {\'user.password\': \'password为必填字段\'}}\n\n\n1\n\n\n但是，发现提示信息的key是user.password，是表单对象和其字段名称，我们应该想要的是：\n\n{\'msg\': {\'password\': \'password为必填字段\'}}\n\n\n1\n\n\n\n# 优化返回字段的key\n\n我们修改inittrans方法，通过go-playground提供的方法registertagnamefunc来将我们自定义的方法注册进去，该自定义方法的目的是修改上面的password改为json中的password，可以改成json标签中的值作为返回。\n\nfunc inittrans(locale string) (err error) {\n\n\tif v, ok := binding.validator.engine().(*validator.validate); ok {\n\n\t\t//修改返回字段key的格式\n\t\tv.registertagnamefunc(func(fld reflect.structfield) string {\n\t\t\tname := strings.splitn(fld.tag.get("json"), ",", 2)[0]\n\t\t\tif name == "-" {\n\t\t\t\treturn ""\n\t\t\t}\n\t\t\treturn name\n\t\t})\n\n\t\t// 翻译\n\t\tzht := zh.new()\n\t\tent := en.new()\n\t\tuni := ut.new(ent, zht, ent)\n\n\t\tglobal.trans, ok = uni.gettranslator(locale)\n\t\tif !ok {\n\t\t\treturn fmt.errorf("uni.gettranslator(%s) error", locale)\n\t\t}\n\n\t\tswitch locale {\n\t\tcase "zh":\n\t\t\tzh_translations.registerdefaulttranslations(v, global.trans)\n\t\tcase "en":\n\t\t\ten_translations.registerdefaulttranslations(v, global.trans)\n\t\tdefault:\n\t\t\ten_translations.registerdefaulttranslations(v, global.trans)\n\t\t}\n\n\t\treturn\n\t}\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n再请求，响应如下，发现password已经改好了，但是user也想删除。\n\n{\'msg\': {\'user.password\': \'password为必填字段\'}}\n\n\n1\n\n\n我们在utils/validator.go文件中编写代码如下，该方法是用来删除user的。\n\nfunc removetopstruct(fields map[string]string) map[string]string {\n\tres := map[string]string{}\n\tfor field, err := range fields {\n\t\tres[field[strings.index(field, ".")+1:]] = err\n\t}\n\treturn res\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n再在翻译返回的错误信息包上该方法。\n\nfunc login(c *gin.context) {\n\n\tvar user user\n\tif err := c.shouldbindjson(&user); err != nil {\n\n\t\terrs, ok := err.(validator.validationerrors)\n\t\tif !ok {\n\t\t\t// 非校验错误，其他错误直接返回\n\t\t\tc.json(http.statusok, gin.h{"msg": err.error()})\n\t\t\treturn\n\t\t}\n\n\t\tc.json(http.statusok, gin.h{"msg": utils.removetopstruct(errs.translate(global.trans))})\n\t\treturn\n\t}\n\n\tif user.username != "admin" || user.password != "123456" {\n\t\tc.json(http.statusunauthorized, gin.h{"msg": "unauthorized"})\n\t\treturn\n\t}\n\n\tc.json(http.statusok, gin.h{"msg": "you are logged in"})\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n再执行，相应结果如下，这个就是我们想要的信息。\n\n{\'msg\': {\'password\': \'password为必填字段\'}}\n\n\n1\n\n\n\n# 总结\n\n个人觉的虽然gin灵活小巧，但是功能真的很不完善。每次一次输出友好信息，我们都要手动调用translate来翻译，并且还需要通过removetopstruct方法来修改返回的信息，按简单的来说，应该由框架来做，我们只需要通过配置，就能自动输出我们想要的友好提示信息才对。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"go中如何处理error",frontmatter:{title:"go中如何处理error",date:"2022-11-14T10:11:11.000Z",permalink:"/pages/d93df5/",tags:["go"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。",categories:["编程","go"],comment:!0,feed:{enable:!0},meta:[{name:"twitter:title",content:"go中如何处理error"},{name:"twitter:description",content:"在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/02.go/04.go%E4%B8%AD%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86error.html"},{property:"og:type",content:"article"},{property:"og:title",content:"go中如何处理error"},{property:"og:description",content:"在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/02.go/04.go%E4%B8%AD%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86error.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-11-14T10:11:11.000Z"},{property:"article:tag",content:"go"},{itemprop:"name",content:"go中如何处理error"},{itemprop:"description",content:"在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go/04.go%E4%B8%AD%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86error.html",relativePath:"04.编程/02.go/04.go中如何处理error.md",key:"v-fdcf4762",path:"/pages/d93df5/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. error 是什么？",slug:"_1-error-是什么",normalizedTitle:"1. error 是什么？",charIndex:195},{level:2,title:"2. 错误类型",slug:"_2-错误类型",normalizedTitle:"2. 错误类型",charIndex:1465},{level:3,title:"2.1 Sentinel Error(预定义错误)",slug:"_2-1-sentinel-error-预定义错误",normalizedTitle:"2.1 sentinel error(预定义错误)",charIndex:1477},{level:3,title:"2.2 Error types(自定义错类型)",slug:"_2-2-error-types-自定义错类型",normalizedTitle:"2.2 error types(自定义错类型)",charIndex:2033},{level:3,title:"2.3 Opaque errors(不透明的错误)",slug:"_2-3-opaque-errors-不透明的错误",normalizedTitle:"2.3 opaque errors(不透明的错误)",charIndex:3015},{level:2,title:"3. 优雅的处理错误",slug:"_3-优雅的处理错误",normalizedTitle:"3. 优雅的处理错误",charIndex:3513},{level:3,title:"3.1 无错误的正常流程代码",slug:"_3-1-无错误的正常流程代码",normalizedTitle:"3.1 无错误的正常流程代码",charIndex:3528},{level:3,title:"3.2 减少不必要的判断",slug:"_3-2-减少不必要的判断",normalizedTitle:"3.2 减少不必要的判断",charIndex:3794},{level:3,title:"3.3 将 error 内部存储起来",slug:"_3-3-将-error-内部存储起来",normalizedTitle:"3.3 将 error 内部存储起来",charIndex:4059},{level:3,title:"3.4 将重复操作抽离出来",slug:"_3-4-将重复操作抽离出来",normalizedTitle:"3.4 将重复操作抽离出来",charIndex:4865},{level:2,title:"4. Wrap erros",slug:"_4-wrap-erros",normalizedTitle:"4. wrap erros",charIndex:6248},{level:2,title:"5. pkg/errors",slug:"_5-pkg-errors",normalizedTitle:"5. pkg/errors",charIndex:8186},{level:2,title:"6. error 的最佳实践",slug:"_6-error-的最佳实践",normalizedTitle:"6. error 的最佳实践",charIndex:9741},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:10492}],headersStr:"0. 前言 1. error 是什么？ 2. 错误类型 2.1 Sentinel Error(预定义错误) 2.2 Error types(自定义错类型) 2.3 Opaque errors(不透明的错误) 3. 优雅的处理错误 3.1 无错误的正常流程代码 3.2 减少不必要的判断 3.3 将 error 内部存储起来 3.4 将重复操作抽离出来 4. Wrap erros 5. pkg/errors 6. error 的最佳实践 参考资料",content:'# 0. 前言\n\ngo 中的异常处理和其他语言大不相同，像 Java、C++、python 等语言都是通过抛出 Exception 来处理异常，而 go 是通过返回 error 来判定异常，并进行处理。\n\n在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。\n\n\n# 1. error 是什么？\n\n举个例子，使用 Open 来打开文件，但是可能该路径的文件不存在，出现异常，在 go 是通过判断 err 是否为 nil 来判定打开文件是否成功。\n\nf, err := os.Open(path)\nif err != nil {\n    // handle error\n}\n\n// do stuff\n\n\n1\n2\n3\n4\n5\n6\n\n\n问题来了，error 是什么？\n\n查看源码会发现，error 是一个包含 Error 方法的接口，返回的是实现了该接口的对象。\n\ntype error interface {  \n   Error() string  \n}\n\n\n1\n2\n3\n\n\n我们一般使用是通过 errors.New()来返回一个实现了 error 接口的对象。这个对象是一个包含了字符串的结构体，然后可以通过 Error 方法来获取字符串。\n\nfunc New(text string) error {  \n   return &errorString{text}  \n}  \n  \n// errorString is a trivial implementation of error.\ntype errorString struct {  \n   s string  \n}  \n  \nfunc (e *errorString) Error() string {  \n   return e.s  \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n我们可以注意到 New 方法返回的是 errorString 的地址，也就是说，在我们将两个 error 比较相等时，比较是地址，是两个 error 是否为同一个对象，而不是其中的错误字符串。\n\nimport (\n\t"errors"\n\t"fmt"\n)\n\ntype errorString string\n\nfunc (e errorString) Error() string {\n\treturn string(e)\n}\n\nfunc New(text string) error {\n\treturn errorString(text)\n}\n\nvar ErrNamedType = New("EOF")\nvar ErrStructType = errors.New("EOF")\n\nfunc main() {\n\n\tif ErrNamedType == New("EOF") {\n\t\tfmt.Println("Named Type Error")\n\t}\n\n\tif ErrStructType == errors.New("EOF") {\n\t\tfmt.Println("Struct Type Error")\n\t}\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n输出：\n\nNamed Type Error\n\n\n1\n\n\n\n# 2. 错误类型\n\n\n# 2.1 Sentinel Error(预定义错误)\n\n其实就是先预定义一些可以预料中的错误，在使用过程中，通过判断 error 是属于哪一种 error 并进行对应的处理。\n\n举个栗子，在 io.EOF 就是一个预定义的错误，它是表示输入流中的结尾。\n\nvar EOF = errors.New("EOF")\n\n\n1\n\n\n在从流中读取字符的时候，会通过判断 error 是否等于 io.EOF 来判定是否读完。注意这里是判断 error 的指针是否相等。\n\nn, err := reader.Read(p)  \nif err != nil {  \n   if err == io.EOF {  \n      fmt.Println("The resource is read!")  \n      break  \n   }  \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n这种方式不建议使用，原因是：\n\n * 它会成为你 API 的公共部分\n\n因为公共函数需要返回一个固定的 error，那么这个 error 就必须是公开的，那么就需要文档记录，这会增加 API 的表面积。\n\n * 增加调用者的耦合性\n\n调用者必须要知道 io.EOF 这个 error ，并在调用的地方使用该 error 判断是否结束。\n\n\n# 2.2 Error types(自定义错类型)\n\n通过实现 error 接口来创建自定义错误类型。和 Sentinel Error 相比，是通过判断类型来知道是哪种错误，并且可以输出更多的上下文错误信息。\n\n通过自定义 MyError，并实现 error 接口中的 Error 的方法。\n\ntype MyError struct {\n\tMsg  string\n\tFile string\n\tLine int\n}\n\nfunc (e *MyError) Error() string {\n\treturn fmt.Sprintf("%s:%d: %s", e.File, e.Line, e.Msg)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ntest 方法中返回的是自定义的 error，我们通过断言转换 error 成 MyError 类型，然后再输出更多的上下文信息。\n\nfunc test() error {\n\treturn &MyError{"Something happened", "server.go", 42}\n}\n\nfunc main() {\n\terr := test()\n\tswitch err := err.(type) {\n\tcase nil:\n\t\t// success\n\tcase *MyError:\n\t\tfmt.Println("error occured on line:", err.Line)\n\tdefault:\n\t\t// unknown error\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在标准库 os.PathError 中，自定义了 PathError ，也是相同的用法。\n\ntype PathError struct {\n\tOp   string\n\tPath string\n\tErr  error\n}\n\nfunc (e *PathError) Error() string { return e.Op + " " + e.Path + ": " + e.Err.Error() }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n我们也尽可能避免使用 Error types，因为它和 Sentinel Erorr 一样会和调用者产生耦合，会作为 API 的一部分。\n\n\n# 2.3 Opaque errors(不透明的错误)\n\nError types 是通过判断 error 的类型来走不同的逻辑，而 Opaque errors 是通过判断 error 的行为来走不同的逻辑。\n\n在 net.Error 中定义如下，除了包含 error 外，还包含 Timeout 和 Temporary 方法。\n\ntype Error interface {\n\terror\n\tTimeout() bool \n\tTemporary() bool\n}\n\n\n1\n2\n3\n4\n5\n\n\n除了判断是否有 error 之外，还可以通过方法来判断是哪种类型的 error 然后进行对应的处理。\n\nif netErr, ok := err.(net.Error); ok && netErr.Timeout() {\n\treturn false\n}\n\nif netErr, ok := err.(net.Error); ok && netErr.Temporary() {\n\treturn false\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n它不是扩展 error 更多的信息，而是扩展其方法。\n\n\n# 3. 优雅的处理错误\n\n\n# 3.1 无错误的正常流程代码\n\n无错误的正常流程代码，将成为一条直线，而不是缩进的代码。\n\n错误的写法：\n\n// no\nf, err := os.Open(path)\nif err == nil {\n    // do stuff\n}\n\n// handle error\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n正确的写法：\n\n// ok\nf, err := os.Open(path)\nif err != nil {\n    // handle error\n}\n\n// do stuff\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 3.2 减少不必要的判断\n\nfunc AuthenticateRequest(r *Request) error {\n    err := authenticate(r.User)\n    err != nil {\n        return err\n    }\n    return nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n改为：\n\nfunc AuthenticateRequest(r *Request) error {\n    return authenticate(r.User)\n}\n\n\n1\n2\n3\n\n\n\n# 3.3 将 error 内部存储起来\n\nerr 在内部临时储存，在最后在返回出来。\n\n下面例子中，通过循环读 reader 每一行的数据，每次判断 err 是不是 nil 来判断是否读完，如果是则退出循环，再返回。\n\nfunc CountLines(r io.Reader)  (int, error) {\n\tvar (\n\t\tbr = bufio.NewReader(r)\n\t\tlines int\n\t\terr error\n\t)\n\n\tfor {\n\t\t_, err = br.ReadString(\'\\n\')\n\t\tlines++\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif err != io.EOF {\n\t\treturn 0, err\n\t}\n\n\treturn lines, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n改进版本：\n\ntype Scanner struct {\n\terr          error     // Sticky error.\n\t...\n}\n\nfunc CountLines(r io.Reader)  (int, error) {\n\tsc := bufio.NewScanner(r)\n\tlines := 0\n\n\tfor sc.Scan() {\n\t\tlines++\n\t}\n\n\treturn lines, sc.Err()\n}\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n每次循环都会判断 Scan 的返回值，当无内容返回时，则会返回 False，则结束循环，并返回结果。循环中出现的 error 会在 Scan 中通过 s.setErr(err) 保存在对象的 err 属性中。\n\n代码明显简洁了许多。\n\n\n# 3.4 将重复操作抽离出来\n\n看看下面的代码，里面多次使用 fmt.Fprintf()并判断其返回值是否为 err\n\ntype Header struct {\n\tKey, Value string\n}\n\ntype Status struct {\n\tCode   int\n\tReason string\n}\n\nfunc WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error {\n\t_, err := fmt.Fprintf(w, "HTTP/1.1 %d %s\\r\\n", st.Code, st.Reason)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, h := range headers {\n\t\t_, err := fmt.Fprintf(w, "%s: %s\\r\\n", h.Key, h.Value)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif _, err := fmt.Fprintf(w, "\\r\\n"); err != nil {\n\t\treturn err\n\t}\n\n\t_, err = io.Copy(w, body)\n\treturn err\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n我们创建一个 errWrite 结构体并实现 Write 方法，也就是在原来的 write 方法中包了一层并做好错误判断，然后在每一个 fmt.Fprintf 使用我们定义的 errWrite 进行写入，这样就达到了复用的效果，代码也好看了许多。\n\ntype errWrite struct {\n\tio.Writer\n\terr error\n}\n\nfunc (e *errWrite) Write(buf []byte) (int, error) {\n\tif e.err != nil {\n\t\treturn 0, e.err\n\t}\n\n\tvar n int\n\tn, e.err = e.Writer.Write(buf)\n\treturn n, e.err\n}\n\nfunc WriteResponse(w io.Writer, st Status, headers []Header, body io.Reader) error {\n\tew := &errWrite{Writer: w}\n\tfmt.Fprintf(ew, "HTTP/1.1 %d %s\\r\\n", st.Code, st.Reason)\n\n\tfor _, h := range headers {\n\t\tfmt.Fprintf(ew, "%s: %s\\r\\n", h.Key, h.Value)\n\t}\n\n\tfmt.Fprintf(w, "\\r\\n")\n\n\tio.Copy(ew, body)\n\treturn ew.err\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 4. Wrap erros\n\n在我们开发中，常常会在错误处理中，记录了日志，并且将错误给返回了。\n\n在 os.Open 找不到文件时会返回 error，处理 error 时，将 error 的信息打上日志，并且将 err 进行返回，在 main 函数中，拿到 error 后再次打上 error 的日志，这个日志和上面有部分是重复的日志。\n\n在代码调用链多的时候，会打上更多的重复日志，日志中出现非常多的噪音，非常影响排查错误。\n\nfunc ReadFile(path string) ([]byte, error) {\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\tlog.Printf("could not open file: %v", err)\n\t\treturn nil, err\n\t}\n\tdefer f.Close()\n\n\tread := bufio.NewReader(f)\n\n\tline, _, err := read.ReadLine()\n\treturn line, err\n}\n\nfunc main() {\n\t_, err := ReadFile("test.txt")\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行输出：\n\n2022/11/05 17:03:16 could not open file: open test.txt: The system cannot find t\nhe file specified.\n2022/11/05 17:03:16 open test.txt: The system cannot find the file specified.\n\n\n1\n2\n3\n\n\n可以使用 fmt.Errorf 来对原始错误进行包装，除了原始错误信息之外，在添加额外得信息并返回。\n\nf, err := os.Open(path)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf("open file failed: %w", err)\n\t}\n\n\n1\n2\n3\n4\n\n\n输出：\n\n2022/11/05 17:04:43 open file failed: open test.txt: The system cannot find the\nfile specified.\n\n\n1\n2\n\n\nfmt.Errorf 返回的是一个新的被包装的 error，errors.Is 可以一层一层的剥开包装来判断是否为原始错误，但是它是做指针判断的，这里 os.Open 返回的原始错误是 os.PathError 但是因为返回的是地址，所以无法用 errors.Is 判断。\n\nfunc main() {\n\n\t_, err := ReadFile("test.txt")\n\tvar pathError *os.PathError\n\n\tif errors.Is(err, pathError) {\n\t\tfmt.Println("is PathError")\n\t} else {\n\t\tfmt.Println("no PathError")\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n输出：\n\nno PathError\n\n\n1\n\n\n这里可以用 errors.As 来判断 err 是否为 os.PathError 类型，即使 err 是地址。\n\n这里判断了是否为 os.PathError 错误，并且将返回的 err 转换成了该错误，我们可以调用其中的属性来获取更多的信息。\n\nfunc main() {\n\n\t_, err := ReadFile("test.txt")\n\tvar pathError *os.PathError\n\n\tif errors.As(err, &pathError) {\n\t\tfmt.Println(pathError.Path)\n\t}\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n输出：\n\ntest.txt\n\n\n1\n\n\n还可以通过 errors.UnWrap 来获取底层错误，将原始错误给解析出来。\n\nfunc main() {\n\t_, err := ReadFile("test.txt")\n\terr = errors.Unwrap(err)\n\tfmt.Printf("ori err: %v", err)\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 5. pkg/errors\n\n上面介绍的都是原生的 errors 处理模块，现在介绍 pkg/errors 模块，完全兼容原生 errors，并且对其进行增强，主要是添加了保存堆栈的能力。\n\n可以使用 errors.Wrap 进行对 error 的包装，并添加额外的信息。\n\nfunc ReadFile(path string) ([]byte, error) {\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn nil, errors.Wrap(err, "could not open file")\n\t}\n\tdefer f.Close()\n\n\tread := bufio.NewReader(f)\n\n\tline, _, err := read.ReadLine()\n\treturn line, err\n}\n\nfunc main() {\n\t_, err := ReadFile("test.txt")\n\tif err != nil {\n\t\tfmt.Println(err)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n输出：\n\ncould not open file: open test.txt: The system cannot find the file specified.\n\n\n1\n\n\n但它还有一个更强的功能是会保存当前的堆栈信息，使用%+v 可以打印出来。\n\nfunc main() {\n\t_, err := ReadFile("test.txt")\n\tif err != nil {\n\t\tfmt.Printf("stack track: \\n%+v", err)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n输出：\n\nstack track:\nopen test.txt: The system cannot find the file specified.\ncould not open file\nmain.ReadFile\n        D:/code/go_demo/main3.go:13\nmain.main\n        D:/code/go_demo/main3.go:24\nruntime.main\n        D:/install/go18.3/src/runtime/proc.go:250\nruntime.goexit\n        D:/install/go18.3/src/runtime/asm_amd64.s:1571\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n如果不想保存堆栈信息，只添加额外的信息，可以使用 errors.WithMessage 添加。\n\n\tf, err := os.Open(path)\n\tif err != nil {\n\t\treturn nil, errors.WithMessage(err, "could not open file")\n\t}\n\n\n1\n2\n3\n4\n\n\n输出：\n\ncould not open file: open test.txt: The system cannot find the file specified.\n\n\n1\n\n\n还有几个常见的方法\n\n// 生成错误的同时带上堆栈信息\nfunc New(message string) error\n\n// 只附加调用堆栈信息\nfunc WithStack(err error) error\n\n// 获得最根本的错误原因\nfunc Cause(err error) error\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 6. error 的最佳实践\n\n处理 error 的方式这么多，我们该如何最优的使用它们呢？有以下几个方法：\n\n * 在自己的应用代码中，使用 errors.New 或者 errors.Errorf 来返回错误\n\nfunc parseArgs(args []string) error {\n\tif len(args) < 3 {\n\t\treturn errors.Errorf("not enough arguments")\n\t}\n\n\treturn nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * 如果调用其他包内的函数，通常简单的直接返回。\n\nif err != nil {\n\treturn err\n}\n\n\n1\n2\n3\n\n * 如果和其他库进行协作，考虑使用 errors.Wrap 或者 errors.Wrapf 保存堆栈信息。同样适用于和标准库协作的时候。\n\nf, err := os.Open(path)\nif err != nil {\n\treturn errors.Wrapf(err, "failed to open %q", path)\n\n\n1\n2\n3\n\n\n * 直接返回错误，而不是每个错误产生的地方到处打日志。\n\n * 在程序的顶部或者是工作的 goroutine 顶部（请求入口），使用 %+v 把堆栈详情记录。\n\nfunc main() {\n\terr := app.Run()\n\tif err != nil {\n\t\tfmt.Printf("FATAL: %+V\\n", err)\n\t\tos.Exit(1)\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * 使用 errors.Cause 获取 root error，再进行和 sentinel error 判定。\n\n\n# 参考资料\n\n * io.EOF 设计的缺陷',normalizedContent:'# 0. 前言\n\ngo 中的异常处理和其他语言大不相同，像 java、c++、python 等语言都是通过抛出 exception 来处理异常，而 go 是通过返回 error 来判定异常，并进行处理。\n\n在 go 中有 panic 的机制，但 panic 意味着程序终止，代码不能继续运行了，不能期望调用者来解决它。而 error 是预期中的异常，希望调用者可以对其进行处理的。\n\n\n# 1. error 是什么？\n\n举个例子，使用 open 来打开文件，但是可能该路径的文件不存在，出现异常，在 go 是通过判断 err 是否为 nil 来判定打开文件是否成功。\n\nf, err := os.open(path)\nif err != nil {\n    // handle error\n}\n\n// do stuff\n\n\n1\n2\n3\n4\n5\n6\n\n\n问题来了，error 是什么？\n\n查看源码会发现，error 是一个包含 error 方法的接口，返回的是实现了该接口的对象。\n\ntype error interface {  \n   error() string  \n}\n\n\n1\n2\n3\n\n\n我们一般使用是通过 errors.new()来返回一个实现了 error 接口的对象。这个对象是一个包含了字符串的结构体，然后可以通过 error 方法来获取字符串。\n\nfunc new(text string) error {  \n   return &errorstring{text}  \n}  \n  \n// errorstring is a trivial implementation of error.\ntype errorstring struct {  \n   s string  \n}  \n  \nfunc (e *errorstring) error() string {  \n   return e.s  \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n我们可以注意到 new 方法返回的是 errorstring 的地址，也就是说，在我们将两个 error 比较相等时，比较是地址，是两个 error 是否为同一个对象，而不是其中的错误字符串。\n\nimport (\n\t"errors"\n\t"fmt"\n)\n\ntype errorstring string\n\nfunc (e errorstring) error() string {\n\treturn string(e)\n}\n\nfunc new(text string) error {\n\treturn errorstring(text)\n}\n\nvar errnamedtype = new("eof")\nvar errstructtype = errors.new("eof")\n\nfunc main() {\n\n\tif errnamedtype == new("eof") {\n\t\tfmt.println("named type error")\n\t}\n\n\tif errstructtype == errors.new("eof") {\n\t\tfmt.println("struct type error")\n\t}\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n输出：\n\nnamed type error\n\n\n1\n\n\n\n# 2. 错误类型\n\n\n# 2.1 sentinel error(预定义错误)\n\n其实就是先预定义一些可以预料中的错误，在使用过程中，通过判断 error 是属于哪一种 error 并进行对应的处理。\n\n举个栗子，在 io.eof 就是一个预定义的错误，它是表示输入流中的结尾。\n\nvar eof = errors.new("eof")\n\n\n1\n\n\n在从流中读取字符的时候，会通过判断 error 是否等于 io.eof 来判定是否读完。注意这里是判断 error 的指针是否相等。\n\nn, err := reader.read(p)  \nif err != nil {  \n   if err == io.eof {  \n      fmt.println("the resource is read!")  \n      break  \n   }  \n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n这种方式不建议使用，原因是：\n\n * 它会成为你 api 的公共部分\n\n因为公共函数需要返回一个固定的 error，那么这个 error 就必须是公开的，那么就需要文档记录，这会增加 api 的表面积。\n\n * 增加调用者的耦合性\n\n调用者必须要知道 io.eof 这个 error ，并在调用的地方使用该 error 判断是否结束。\n\n\n# 2.2 error types(自定义错类型)\n\n通过实现 error 接口来创建自定义错误类型。和 sentinel error 相比，是通过判断类型来知道是哪种错误，并且可以输出更多的上下文错误信息。\n\n通过自定义 myerror，并实现 error 接口中的 error 的方法。\n\ntype myerror struct {\n\tmsg  string\n\tfile string\n\tline int\n}\n\nfunc (e *myerror) error() string {\n\treturn fmt.sprintf("%s:%d: %s", e.file, e.line, e.msg)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\ntest 方法中返回的是自定义的 error，我们通过断言转换 error 成 myerror 类型，然后再输出更多的上下文信息。\n\nfunc test() error {\n\treturn &myerror{"something happened", "server.go", 42}\n}\n\nfunc main() {\n\terr := test()\n\tswitch err := err.(type) {\n\tcase nil:\n\t\t// success\n\tcase *myerror:\n\t\tfmt.println("error occured on line:", err.line)\n\tdefault:\n\t\t// unknown error\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n在标准库 os.patherror 中，自定义了 patherror ，也是相同的用法。\n\ntype patherror struct {\n\top   string\n\tpath string\n\terr  error\n}\n\nfunc (e *patherror) error() string { return e.op + " " + e.path + ": " + e.err.error() }\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n我们也尽可能避免使用 error types，因为它和 sentinel erorr 一样会和调用者产生耦合，会作为 api 的一部分。\n\n\n# 2.3 opaque errors(不透明的错误)\n\nerror types 是通过判断 error 的类型来走不同的逻辑，而 opaque errors 是通过判断 error 的行为来走不同的逻辑。\n\n在 net.error 中定义如下，除了包含 error 外，还包含 timeout 和 temporary 方法。\n\ntype error interface {\n\terror\n\ttimeout() bool \n\ttemporary() bool\n}\n\n\n1\n2\n3\n4\n5\n\n\n除了判断是否有 error 之外，还可以通过方法来判断是哪种类型的 error 然后进行对应的处理。\n\nif neterr, ok := err.(net.error); ok && neterr.timeout() {\n\treturn false\n}\n\nif neterr, ok := err.(net.error); ok && neterr.temporary() {\n\treturn false\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n它不是扩展 error 更多的信息，而是扩展其方法。\n\n\n# 3. 优雅的处理错误\n\n\n# 3.1 无错误的正常流程代码\n\n无错误的正常流程代码，将成为一条直线，而不是缩进的代码。\n\n错误的写法：\n\n// no\nf, err := os.open(path)\nif err == nil {\n    // do stuff\n}\n\n// handle error\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n正确的写法：\n\n// ok\nf, err := os.open(path)\nif err != nil {\n    // handle error\n}\n\n// do stuff\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 3.2 减少不必要的判断\n\nfunc authenticaterequest(r *request) error {\n    err := authenticate(r.user)\n    err != nil {\n        return err\n    }\n    return nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n改为：\n\nfunc authenticaterequest(r *request) error {\n    return authenticate(r.user)\n}\n\n\n1\n2\n3\n\n\n\n# 3.3 将 error 内部存储起来\n\nerr 在内部临时储存，在最后在返回出来。\n\n下面例子中，通过循环读 reader 每一行的数据，每次判断 err 是不是 nil 来判断是否读完，如果是则退出循环，再返回。\n\nfunc countlines(r io.reader)  (int, error) {\n\tvar (\n\t\tbr = bufio.newreader(r)\n\t\tlines int\n\t\terr error\n\t)\n\n\tfor {\n\t\t_, err = br.readstring(\'\\n\')\n\t\tlines++\n\t\tif err != nil {\n\t\t\tbreak\n\t\t}\n\t}\n\n\tif err != io.eof {\n\t\treturn 0, err\n\t}\n\n\treturn lines, nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n改进版本：\n\ntype scanner struct {\n\terr          error     // sticky error.\n\t...\n}\n\nfunc countlines(r io.reader)  (int, error) {\n\tsc := bufio.newscanner(r)\n\tlines := 0\n\n\tfor sc.scan() {\n\t\tlines++\n\t}\n\n\treturn lines, sc.err()\n}\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n每次循环都会判断 scan 的返回值，当无内容返回时，则会返回 false，则结束循环，并返回结果。循环中出现的 error 会在 scan 中通过 s.seterr(err) 保存在对象的 err 属性中。\n\n代码明显简洁了许多。\n\n\n# 3.4 将重复操作抽离出来\n\n看看下面的代码，里面多次使用 fmt.fprintf()并判断其返回值是否为 err\n\ntype header struct {\n\tkey, value string\n}\n\ntype status struct {\n\tcode   int\n\treason string\n}\n\nfunc writeresponse(w io.writer, st status, headers []header, body io.reader) error {\n\t_, err := fmt.fprintf(w, "http/1.1 %d %s\\r\\n", st.code, st.reason)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tfor _, h := range headers {\n\t\t_, err := fmt.fprintf(w, "%s: %s\\r\\n", h.key, h.value)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tif _, err := fmt.fprintf(w, "\\r\\n"); err != nil {\n\t\treturn err\n\t}\n\n\t_, err = io.copy(w, body)\n\treturn err\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n\n\n我们创建一个 errwrite 结构体并实现 write 方法，也就是在原来的 write 方法中包了一层并做好错误判断，然后在每一个 fmt.fprintf 使用我们定义的 errwrite 进行写入，这样就达到了复用的效果，代码也好看了许多。\n\ntype errwrite struct {\n\tio.writer\n\terr error\n}\n\nfunc (e *errwrite) write(buf []byte) (int, error) {\n\tif e.err != nil {\n\t\treturn 0, e.err\n\t}\n\n\tvar n int\n\tn, e.err = e.writer.write(buf)\n\treturn n, e.err\n}\n\nfunc writeresponse(w io.writer, st status, headers []header, body io.reader) error {\n\tew := &errwrite{writer: w}\n\tfmt.fprintf(ew, "http/1.1 %d %s\\r\\n", st.code, st.reason)\n\n\tfor _, h := range headers {\n\t\tfmt.fprintf(ew, "%s: %s\\r\\n", h.key, h.value)\n\t}\n\n\tfmt.fprintf(w, "\\r\\n")\n\n\tio.copy(ew, body)\n\treturn ew.err\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 4. wrap erros\n\n在我们开发中，常常会在错误处理中，记录了日志，并且将错误给返回了。\n\n在 os.open 找不到文件时会返回 error，处理 error 时，将 error 的信息打上日志，并且将 err 进行返回，在 main 函数中，拿到 error 后再次打上 error 的日志，这个日志和上面有部分是重复的日志。\n\n在代码调用链多的时候，会打上更多的重复日志，日志中出现非常多的噪音，非常影响排查错误。\n\nfunc readfile(path string) ([]byte, error) {\n\tf, err := os.open(path)\n\tif err != nil {\n\t\tlog.printf("could not open file: %v", err)\n\t\treturn nil, err\n\t}\n\tdefer f.close()\n\n\tread := bufio.newreader(f)\n\n\tline, _, err := read.readline()\n\treturn line, err\n}\n\nfunc main() {\n\t_, err := readfile("test.txt")\n\tif err != nil {\n\t\tfmt.println(err)\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行输出：\n\n2022/11/05 17:03:16 could not open file: open test.txt: the system cannot find t\nhe file specified.\n2022/11/05 17:03:16 open test.txt: the system cannot find the file specified.\n\n\n1\n2\n3\n\n\n可以使用 fmt.errorf 来对原始错误进行包装，除了原始错误信息之外，在添加额外得信息并返回。\n\nf, err := os.open(path)\n\tif err != nil {\n\t\treturn nil, fmt.errorf("open file failed: %w", err)\n\t}\n\n\n1\n2\n3\n4\n\n\n输出：\n\n2022/11/05 17:04:43 open file failed: open test.txt: the system cannot find the\nfile specified.\n\n\n1\n2\n\n\nfmt.errorf 返回的是一个新的被包装的 error，errors.is 可以一层一层的剥开包装来判断是否为原始错误，但是它是做指针判断的，这里 os.open 返回的原始错误是 os.patherror 但是因为返回的是地址，所以无法用 errors.is 判断。\n\nfunc main() {\n\n\t_, err := readfile("test.txt")\n\tvar patherror *os.patherror\n\n\tif errors.is(err, patherror) {\n\t\tfmt.println("is patherror")\n\t} else {\n\t\tfmt.println("no patherror")\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n输出：\n\nno patherror\n\n\n1\n\n\n这里可以用 errors.as 来判断 err 是否为 os.patherror 类型，即使 err 是地址。\n\n这里判断了是否为 os.patherror 错误，并且将返回的 err 转换成了该错误，我们可以调用其中的属性来获取更多的信息。\n\nfunc main() {\n\n\t_, err := readfile("test.txt")\n\tvar patherror *os.patherror\n\n\tif errors.as(err, &patherror) {\n\t\tfmt.println(patherror.path)\n\t}\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n输出：\n\ntest.txt\n\n\n1\n\n\n还可以通过 errors.unwrap 来获取底层错误，将原始错误给解析出来。\n\nfunc main() {\n\t_, err := readfile("test.txt")\n\terr = errors.unwrap(err)\n\tfmt.printf("ori err: %v", err)\n}\n\n\n1\n2\n3\n4\n5\n\n\n\n# 5. pkg/errors\n\n上面介绍的都是原生的 errors 处理模块，现在介绍 pkg/errors 模块，完全兼容原生 errors，并且对其进行增强，主要是添加了保存堆栈的能力。\n\n可以使用 errors.wrap 进行对 error 的包装，并添加额外的信息。\n\nfunc readfile(path string) ([]byte, error) {\n\tf, err := os.open(path)\n\tif err != nil {\n\t\treturn nil, errors.wrap(err, "could not open file")\n\t}\n\tdefer f.close()\n\n\tread := bufio.newreader(f)\n\n\tline, _, err := read.readline()\n\treturn line, err\n}\n\nfunc main() {\n\t_, err := readfile("test.txt")\n\tif err != nil {\n\t\tfmt.println(err)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n输出：\n\ncould not open file: open test.txt: the system cannot find the file specified.\n\n\n1\n\n\n但它还有一个更强的功能是会保存当前的堆栈信息，使用%+v 可以打印出来。\n\nfunc main() {\n\t_, err := readfile("test.txt")\n\tif err != nil {\n\t\tfmt.printf("stack track: \\n%+v", err)\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n\n\n输出：\n\nstack track:\nopen test.txt: the system cannot find the file specified.\ncould not open file\nmain.readfile\n        d:/code/go_demo/main3.go:13\nmain.main\n        d:/code/go_demo/main3.go:24\nruntime.main\n        d:/install/go18.3/src/runtime/proc.go:250\nruntime.goexit\n        d:/install/go18.3/src/runtime/asm_amd64.s:1571\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n如果不想保存堆栈信息，只添加额外的信息，可以使用 errors.withmessage 添加。\n\n\tf, err := os.open(path)\n\tif err != nil {\n\t\treturn nil, errors.withmessage(err, "could not open file")\n\t}\n\n\n1\n2\n3\n4\n\n\n输出：\n\ncould not open file: open test.txt: the system cannot find the file specified.\n\n\n1\n\n\n还有几个常见的方法\n\n// 生成错误的同时带上堆栈信息\nfunc new(message string) error\n\n// 只附加调用堆栈信息\nfunc withstack(err error) error\n\n// 获得最根本的错误原因\nfunc cause(err error) error\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 6. error 的最佳实践\n\n处理 error 的方式这么多，我们该如何最优的使用它们呢？有以下几个方法：\n\n * 在自己的应用代码中，使用 errors.new 或者 errors.errorf 来返回错误\n\nfunc parseargs(args []string) error {\n\tif len(args) < 3 {\n\t\treturn errors.errorf("not enough arguments")\n\t}\n\n\treturn nil\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * 如果调用其他包内的函数，通常简单的直接返回。\n\nif err != nil {\n\treturn err\n}\n\n\n1\n2\n3\n\n * 如果和其他库进行协作，考虑使用 errors.wrap 或者 errors.wrapf 保存堆栈信息。同样适用于和标准库协作的时候。\n\nf, err := os.open(path)\nif err != nil {\n\treturn errors.wrapf(err, "failed to open %q", path)\n\n\n1\n2\n3\n\n\n * 直接返回错误，而不是每个错误产生的地方到处打日志。\n\n * 在程序的顶部或者是工作的 goroutine 顶部（请求入口），使用 %+v 把堆栈详情记录。\n\nfunc main() {\n\terr := app.run()\n\tif err != nil {\n\t\tfmt.printf("fatal: %+v\\n", err)\n\t\tos.exit(1)\n\t}\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n * 使用 errors.cause 获取 root error，再进行和 sentinel error 判定。\n\n\n# 参考资料\n\n * io.eof 设计的缺陷',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"快速了解iptables",frontmatter:{title:"快速了解iptables",date:"2023-05-15T19:19:11.000Z",permalink:"/pages/72ba9a/",categories:["编程","linux"],tags:["linux","计算机网络","linux网络虚拟化"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"iptables是一个在Linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/2023-04-13-2330-20230514151755-we6q131.png"},{name:"twitter:title",content:"快速了解iptables"},{name:"twitter:description",content:"iptables是一个在Linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/2023-04-13-2330-20230514151755-we6q131.png"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/03.linux/01.%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A3iptables.html"},{property:"og:type",content:"article"},{property:"og:title",content:"快速了解iptables"},{property:"og:description",content:"iptables是一个在Linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/2023-04-13-2330-20230514151755-we6q131.png"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/03.linux/01.%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A3iptables.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-05-15T19:19:11.000Z"},{property:"article:tag",content:"linux"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"linux网络虚拟化"},{itemprop:"name",content:"快速了解iptables"},{itemprop:"description",content:"iptables是一个在Linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/2023-04-13-2330-20230514151755-we6q131.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/03.linux/01.%E5%BF%AB%E9%80%9F%E4%BA%86%E8%A7%A3iptables.html",relativePath:"04.编程/03.linux/01.快速了解iptables.md",key:"v-21216af8",path:"/pages/72ba9a/",headers:[{level:2,title:"初识",slug:"初识",normalizedTitle:"初识",charIndex:2},{level:3,title:"iptables是什么？",slug:"iptables是什么",normalizedTitle:"iptables是什么？",charIndex:9},{level:3,title:"Netfilter是什么？",slug:"netfilter是什么",normalizedTitle:"netfilter是什么？",charIndex:267},{level:3,title:"iptables实现",slug:"iptables实现",normalizedTitle:"iptables实现",charIndex:1020},{level:2,title:"iptables三板斧：table、chain和rule",slug:"iptables三板斧-table、chain和rule",normalizedTitle:"iptables三板斧：table、chain和rule",charIndex:1140},{level:3,title:"chain",slug:"chain",normalizedTitle:"chain",charIndex:1158},{level:3,title:"table",slug:"table",normalizedTitle:"table",charIndex:11},{level:3,title:"rule",slug:"rule",normalizedTitle:"rule",charIndex:1164},{level:2,title:"iptables命令使用",slug:"iptables命令使用",normalizedTitle:"iptables命令使用",charIndex:2402},{level:3,title:"参数",slug:"参数",normalizedTitle:"参数",charIndex:2419},{level:3,title:"常规武器",slug:"常规武器",normalizedTitle:"常规武器",charIndex:3390},{level:2,title:"巨人的肩膀",slug:"巨人的肩膀",normalizedTitle:"巨人的肩膀",charIndex:4926}],headersStr:"初识 iptables是什么？ Netfilter是什么？ iptables实现 iptables三板斧：table、chain和rule chain table rule iptables命令使用 参数 常规武器 巨人的肩膀",content:"# 初识\n\n\n# iptables是什么？\n\niptables是一个在Linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。\n\n 1. 过滤数据包：iptables可以根据不同的规则过滤网络数据包，例如根据源IP地址、目标IP地址、端口号等进行过滤。\n\n 2. 转发数据包：iptables可以将网络数据包从一个接口转发到另一个接口，实现网络数据的转发功能。\n\n 3. 修改数据包：iptables可以修改网络数据包的源IP地址、目标IP地址、端口号等信息，实现网络数据的伪装和欺骗。\n\n\n# Netfilter是什么？\n\nNetfilter是Linux内核中的一个网络数据包过滤框架，它可以在数据包进入和离开网络接口时进行拦截和处理。iptables就是基于Netfilter框架实现的一个用户空间工具，它可以通过调用Netfilter提供的API来实现网络数据包的过滤、转发和修改等操作。\n\nnetfilter的架构就是在整个网络流程的若干位置放置一些钩子，并在每个钩子上挂载一些处理函数进行处理。\n\nIP层的5个钩子点的位置，分别是PREROUTING、POSTROUTING、INPUT、OUTPUT和FORWARD。原理图如下：\n\n‍\n\n‍\n\n当网卡上收到一个包送达协议栈时，最先经过的netfilter钩子是PREROUTING，如果确实有用户埋了这个钩子函数，那么内核将在这里对数据包进行目的地址转换（DNAT）。不管在PREROUTING有没有做过DNAT，内核都会通过查本地路由表决定这个数据包是发送给本地进程还是发送给其他机器。如果是发送给其他机器（或其他network namespace），就相当于把本地当作路由器，就会经过netfilter的FORWARD钩子，用户可以在此处设置包过滤钩子函数，例如iptables的reject函数。所有马上要发到协议栈外的包都会经过POSTROUTING钩子，用户可以在这里埋下源地址转换（SNAT）或源地址伪装（Masquerade，简称Masq）的钩子函数。如果经过上面的路由决策，内核决定把包发给本地进程，就会经过INPUT钩子。本地进程收到数据包后，回程报文会先经过OUTPUT钩子，然后经过一次路由决策（例如，决定从机器的哪块网卡出去，下一跳地址是多少等），最后出协议栈的网络包同样会经过POSTROUTING钩子。\n\n\n# iptables实现\n\niptables的底层实现是通过Linux内核中的Netfilter框架来实现的。iptables是用户空间的一个程序，通过netlink和内核的netfilter框架打交道，负责往钩子上配置回调函数。\n\n\n\n\n# iptables三板斧：table、chain和rule\n\n\n# chain\n\niptables有5条内置链分别对应着netfilter的5个钩子：\n\n * INPUT链：一般用于处理输入本地进程的数据包。\n * OUTPUT链：一般用于处理本地进程的输出数据包。\n * FORWARD链：一般用于处理转发到其他机器/network namespace的数\n   据包。\n * PREROUTING链：可以在此处进行DNAT。\n * POSTROUTING链：可以在此处进行SNAT。\n\n\n# table\n\n除了5条内置链之外，还可以在表中定义自己的链：\n\n * filter 表：用于过滤数据包，是默认的表。它包含 INPUT、OUTPUT 和 FORWARD 三个链，分别用于处理进入本机的数据包、从本机发出的数据包和转发的数据包。\n\n * nat 表：用于网络地址转换（NAT）。它包含 PREROUTING、POSTROUTING 和 OUTPUT 三个链，分别用于处理进入本机前的数据包、从本机发出的数据包和本机生成的数据包。\n\n * mangle 表：用于修改数据包的特定字段。如 TTL、TOS 等。它包含 PREROUTING、INPUT、FORWARD、OUTPUT 和 POSTROUTING 五个链，分别用于处理进入本机前的数据包、进入本机的数据包、转发的数据包、从本机发出的数据包和本机生成的数据包。\n\n * raw 表：用于配置连接追踪系统。它包含 PREROUTING 和 OUTPUT 两个链，分别用于处理进入本机前的数据包和从本机发出的数据包。\n\n这5张表的优先级从高到低是：raw、mangle、nat、filter、security。\n\niptables表与链的对应关系图如下：\n\n‍\n\n\n\n不同的表挂不同的链，这是为了分类管理iptables规则（rule）的，系统所有的iptables规则都被划分到不同的表集合中。\n\n\n# rule\n\niptables的规则就是挂载netfilter钩子上的函数，用来修改数据包的内容或者过滤数据包等操作，iptables的表就是所有规则的5个逻辑集合。\n\niptables规则如何编写？\n\n一条iptables规则包含两部分信息：匹配条件和动作。\n\n匹配条件即为匹配数据包被这条iptables规则“捕获”的条件，例如协议类型、源IP、目的IP、源端口、目的端口、连接状态等。每条iptables规则允许多个匹配条件任意组合，从而实现多条件的匹配，多条件之间是逻辑与（&&）关系。\n\n常见动作如下：\n\n * ACCEPT：允许数据包通过。\n\n * DROP：丢弃数据包，不给出任何响应。\n\n * REJECT：拒绝数据包，给出响应告知发送方被拒绝。\n\n * SNAT：源地址转换，用于网络地址转换（NAT）。\n\n * DNAT：目标地址转换，用于网络地址转换（NAT）。\n\n * REDIRECT：重定向数据包到指定端口或 IP 地址。\n\n\n# iptables命令使用\n\n\n# 参数\n\n * -A：添加规则到指定链的末尾。\n   例如：iptables -A INPUT -s 192.168.1.0/24 -j DROP\n\n * -D：删除指定链中的规则。\n   例如：iptables -D INPUT -s 192.168.1.0/24 -j DROP\n\n * -I：插入规则到指定链的开头或指定位置。\n   例如：iptables -I INPUT 2 -s 192.168.1.0/24 -j DROP\n\n * -R：替换指定链中的规则。\n   例如：iptables -R INPUT 2 -s 192.168.1.0/24 -j DROP\n\n * -L：列出指定链中的规则。\n   例如：iptables -L INPUT\n\n * -F：清空指定链中的规则。\n   例如：iptables -F INPUT\n\n * -N：创建新的自定义链。\n   例如：iptables -N MYCHAIN\n\n * -X：删除指定的自定义链。\n   例如：iptables -X MYCHAIN\n\n * -P：设置指定链的默认策略。\n   例如：iptables -P INPUT DROP\n\n * -s：指定源 IP 地址或地址段。\n   例如：iptables -A INPUT -s 192.168.1.0/24 -j DROP\n\n * -d：指定目标 IP 地址或地址段。\n   例如：iptables -A OUTPUT -d 192.168.1.0/24 -j DROP\n\n * -p：指定协议类型。\n   例如：iptables -A INPUT -p tcp -j DROP\n\n * -m：指定匹配模块。\n   例如：iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n\n * -j：指定动作。\n   例如：iptables -A INPUT -s 192.168.1.0/24 -j DROP\n\n * -i：指定进入接口。\n   例如：iptables -A INPUT -i eth0 -j DROP\n\n * -o：指定输出接口。\n   例如：iptables -A OUTPUT -o eth0 -j DROP\n\n\n# 常规武器\n\n 1. 查看所有iptables规则\n\niptables -L -n\n\n\n1\n\n 2. 配置防火墙规则策略\n\n * 配置允许SSH连接\n\niptables -A INPUT -s 10.20.30.40/24 -p tcp --dport 22 -j ACCECT\n\n\n1\n\n\n-A INPUT 是以追加的方式增加该规则在INPUT链上，-s 10.20.30.40/24 -p tcp --dport 22 是匹配上源地址为10.20.30.40/24网段，tcp协议和目的端口22的数据包，-j ACCET 表示允许该数据包进行连接。这里没有指定表默认是filter表。\n\n * 阻止来自某个IP/网段的所有连接\n\niptables -A INPUT -s 10.10.10.10 -j DROP\n\n\n1\n\n\n-j DROP 会发送给源地址为10.10.10.10一个连接拒绝的回程报文。\n\n * 封锁端口\n\niptables -A OUTPUT -p tcp --dport 1234 -j DROP\n\n\n1\n\n\n禁止本地进程访问外部1234端口。因为是在挂载OUTPUT链上该条规则，所以是屏蔽本地进程对外的连接。如果想要禁止外部连接访问本地1234端口，则需要在INPUT链上新增规则。\n\niptables -A INPUT -p tcp --dport 1234 -j DROP\n\n\n1\n\n * 端口转发\n\niptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 8080\n\n\n1\n\n\n该条规则添加到PREROUTING链下的nat表中，匹配上eth0网卡上所有目的端口为80的tcp数据包，匹配上则将转发到8080端口上。因为将目的端口改变了，则需要写到nat表中。\n\n * 禁ping\n\niptables -A INPUT -p icmp -j DROP\n\n\n1\n\n\n在INPUT链filter表中新增禁止icmp协议数据包的规则。\n\n 3. DNAT\n\niptables -t nat -A PREROUTING -d 1.2.3.4 -p tcp --dport 80 -j DNAT --to-destination 10.20.30.40:8080\n\n\n1\n\n\n和端口转发原理差不多，区别在于，端口转发不修改IP地址，而这里修改了目的IP地址。在nat表PREROUTING中新增目的地址为1.2.3.4，目的端口80的tcp数据包的DNAT动作，将目的地址改为了10.20.30.40:8080。\n\nDNAT仅发生在nat表的PREROUTING链中，并且该操作需要确保开启ipforward功能。\n\n 4. SNAT\n\niptables -t nat -A POSTROUTING -s 192.168.1.2 -j SNAT --to-source 10.172.16.1\n\n\n1\n\n\n在nat表POSTROUTING链中新增将源地址192.168.1.2的数据包进行SNAT操作，改为源地址10.172.16.1.\n\nSNAT操作仅可发生在nat表的POSTROUTING链中。\n\n 5. 保存与恢复\n\niptables规则修改仅是临时的，重启则丢失，执行以下命令永久保存。\n\niptables-save\n\n\n1\n\n\n也可将规则保存在文件中\n\niptables-save > iptables.bak\n\n\n1\n\n\n后续可以通过以下命令进行恢复\n\niptables-restore < iptables.bak\n\n\n1\n\n\n\n# 巨人的肩膀\n\n * 《kubernetes网络权威指南》\n\n‍",normalizedContent:"# 初识\n\n\n# iptables是什么？\n\niptables是一个在linux操作系统上使用的防火墙工具，它可以用于配置和管理网络数据包的过滤、转发和修改等操作。\n\n 1. 过滤数据包：iptables可以根据不同的规则过滤网络数据包，例如根据源ip地址、目标ip地址、端口号等进行过滤。\n\n 2. 转发数据包：iptables可以将网络数据包从一个接口转发到另一个接口，实现网络数据的转发功能。\n\n 3. 修改数据包：iptables可以修改网络数据包的源ip地址、目标ip地址、端口号等信息，实现网络数据的伪装和欺骗。\n\n\n# netfilter是什么？\n\nnetfilter是linux内核中的一个网络数据包过滤框架，它可以在数据包进入和离开网络接口时进行拦截和处理。iptables就是基于netfilter框架实现的一个用户空间工具，它可以通过调用netfilter提供的api来实现网络数据包的过滤、转发和修改等操作。\n\nnetfilter的架构就是在整个网络流程的若干位置放置一些钩子，并在每个钩子上挂载一些处理函数进行处理。\n\nip层的5个钩子点的位置，分别是prerouting、postrouting、input、output和forward。原理图如下：\n\n‍\n\n‍\n\n当网卡上收到一个包送达协议栈时，最先经过的netfilter钩子是prerouting，如果确实有用户埋了这个钩子函数，那么内核将在这里对数据包进行目的地址转换（dnat）。不管在prerouting有没有做过dnat，内核都会通过查本地路由表决定这个数据包是发送给本地进程还是发送给其他机器。如果是发送给其他机器（或其他network namespace），就相当于把本地当作路由器，就会经过netfilter的forward钩子，用户可以在此处设置包过滤钩子函数，例如iptables的reject函数。所有马上要发到协议栈外的包都会经过postrouting钩子，用户可以在这里埋下源地址转换（snat）或源地址伪装（masquerade，简称masq）的钩子函数。如果经过上面的路由决策，内核决定把包发给本地进程，就会经过input钩子。本地进程收到数据包后，回程报文会先经过output钩子，然后经过一次路由决策（例如，决定从机器的哪块网卡出去，下一跳地址是多少等），最后出协议栈的网络包同样会经过postrouting钩子。\n\n\n# iptables实现\n\niptables的底层实现是通过linux内核中的netfilter框架来实现的。iptables是用户空间的一个程序，通过netlink和内核的netfilter框架打交道，负责往钩子上配置回调函数。\n\n\n\n\n# iptables三板斧：table、chain和rule\n\n\n# chain\n\niptables有5条内置链分别对应着netfilter的5个钩子：\n\n * input链：一般用于处理输入本地进程的数据包。\n * output链：一般用于处理本地进程的输出数据包。\n * forward链：一般用于处理转发到其他机器/network namespace的数\n   据包。\n * prerouting链：可以在此处进行dnat。\n * postrouting链：可以在此处进行snat。\n\n\n# table\n\n除了5条内置链之外，还可以在表中定义自己的链：\n\n * filter 表：用于过滤数据包，是默认的表。它包含 input、output 和 forward 三个链，分别用于处理进入本机的数据包、从本机发出的数据包和转发的数据包。\n\n * nat 表：用于网络地址转换（nat）。它包含 prerouting、postrouting 和 output 三个链，分别用于处理进入本机前的数据包、从本机发出的数据包和本机生成的数据包。\n\n * mangle 表：用于修改数据包的特定字段。如 ttl、tos 等。它包含 prerouting、input、forward、output 和 postrouting 五个链，分别用于处理进入本机前的数据包、进入本机的数据包、转发的数据包、从本机发出的数据包和本机生成的数据包。\n\n * raw 表：用于配置连接追踪系统。它包含 prerouting 和 output 两个链，分别用于处理进入本机前的数据包和从本机发出的数据包。\n\n这5张表的优先级从高到低是：raw、mangle、nat、filter、security。\n\niptables表与链的对应关系图如下：\n\n‍\n\n\n\n不同的表挂不同的链，这是为了分类管理iptables规则（rule）的，系统所有的iptables规则都被划分到不同的表集合中。\n\n\n# rule\n\niptables的规则就是挂载netfilter钩子上的函数，用来修改数据包的内容或者过滤数据包等操作，iptables的表就是所有规则的5个逻辑集合。\n\niptables规则如何编写？\n\n一条iptables规则包含两部分信息：匹配条件和动作。\n\n匹配条件即为匹配数据包被这条iptables规则“捕获”的条件，例如协议类型、源ip、目的ip、源端口、目的端口、连接状态等。每条iptables规则允许多个匹配条件任意组合，从而实现多条件的匹配，多条件之间是逻辑与（&&）关系。\n\n常见动作如下：\n\n * accept：允许数据包通过。\n\n * drop：丢弃数据包，不给出任何响应。\n\n * reject：拒绝数据包，给出响应告知发送方被拒绝。\n\n * snat：源地址转换，用于网络地址转换（nat）。\n\n * dnat：目标地址转换，用于网络地址转换（nat）。\n\n * redirect：重定向数据包到指定端口或 ip 地址。\n\n\n# iptables命令使用\n\n\n# 参数\n\n * -a：添加规则到指定链的末尾。\n   例如：iptables -a input -s 192.168.1.0/24 -j drop\n\n * -d：删除指定链中的规则。\n   例如：iptables -d input -s 192.168.1.0/24 -j drop\n\n * -i：插入规则到指定链的开头或指定位置。\n   例如：iptables -i input 2 -s 192.168.1.0/24 -j drop\n\n * -r：替换指定链中的规则。\n   例如：iptables -r input 2 -s 192.168.1.0/24 -j drop\n\n * -l：列出指定链中的规则。\n   例如：iptables -l input\n\n * -f：清空指定链中的规则。\n   例如：iptables -f input\n\n * -n：创建新的自定义链。\n   例如：iptables -n mychain\n\n * -x：删除指定的自定义链。\n   例如：iptables -x mychain\n\n * -p：设置指定链的默认策略。\n   例如：iptables -p input drop\n\n * -s：指定源 ip 地址或地址段。\n   例如：iptables -a input -s 192.168.1.0/24 -j drop\n\n * -d：指定目标 ip 地址或地址段。\n   例如：iptables -a output -d 192.168.1.0/24 -j drop\n\n * -p：指定协议类型。\n   例如：iptables -a input -p tcp -j drop\n\n * -m：指定匹配模块。\n   例如：iptables -a input -m state --state established,related -j accept\n\n * -j：指定动作。\n   例如：iptables -a input -s 192.168.1.0/24 -j drop\n\n * -i：指定进入接口。\n   例如：iptables -a input -i eth0 -j drop\n\n * -o：指定输出接口。\n   例如：iptables -a output -o eth0 -j drop\n\n\n# 常规武器\n\n 1. 查看所有iptables规则\n\niptables -l -n\n\n\n1\n\n 2. 配置防火墙规则策略\n\n * 配置允许ssh连接\n\niptables -a input -s 10.20.30.40/24 -p tcp --dport 22 -j accect\n\n\n1\n\n\n-a input 是以追加的方式增加该规则在input链上，-s 10.20.30.40/24 -p tcp --dport 22 是匹配上源地址为10.20.30.40/24网段，tcp协议和目的端口22的数据包，-j accet 表示允许该数据包进行连接。这里没有指定表默认是filter表。\n\n * 阻止来自某个ip/网段的所有连接\n\niptables -a input -s 10.10.10.10 -j drop\n\n\n1\n\n\n-j drop 会发送给源地址为10.10.10.10一个连接拒绝的回程报文。\n\n * 封锁端口\n\niptables -a output -p tcp --dport 1234 -j drop\n\n\n1\n\n\n禁止本地进程访问外部1234端口。因为是在挂载output链上该条规则，所以是屏蔽本地进程对外的连接。如果想要禁止外部连接访问本地1234端口，则需要在input链上新增规则。\n\niptables -a input -p tcp --dport 1234 -j drop\n\n\n1\n\n * 端口转发\n\niptables -t nat -a prerouting -i eth0 -p tcp --dport 80 -j redirect --to-port 8080\n\n\n1\n\n\n该条规则添加到prerouting链下的nat表中，匹配上eth0网卡上所有目的端口为80的tcp数据包，匹配上则将转发到8080端口上。因为将目的端口改变了，则需要写到nat表中。\n\n * 禁ping\n\niptables -a input -p icmp -j drop\n\n\n1\n\n\n在input链filter表中新增禁止icmp协议数据包的规则。\n\n 3. dnat\n\niptables -t nat -a prerouting -d 1.2.3.4 -p tcp --dport 80 -j dnat --to-destination 10.20.30.40:8080\n\n\n1\n\n\n和端口转发原理差不多，区别在于，端口转发不修改ip地址，而这里修改了目的ip地址。在nat表prerouting中新增目的地址为1.2.3.4，目的端口80的tcp数据包的dnat动作，将目的地址改为了10.20.30.40:8080。\n\ndnat仅发生在nat表的prerouting链中，并且该操作需要确保开启ipforward功能。\n\n 4. snat\n\niptables -t nat -a postrouting -s 192.168.1.2 -j snat --to-source 10.172.16.1\n\n\n1\n\n\n在nat表postrouting链中新增将源地址192.168.1.2的数据包进行snat操作，改为源地址10.172.16.1.\n\nsnat操作仅可发生在nat表的postrouting链中。\n\n 5. 保存与恢复\n\niptables规则修改仅是临时的，重启则丢失，执行以下命令永久保存。\n\niptables-save\n\n\n1\n\n\n也可将规则保存在文件中\n\niptables-save > iptables.bak\n\n\n1\n\n\n后续可以通过以下命令进行恢复\n\niptables-restore < iptables.bak\n\n\n1\n\n\n\n# 巨人的肩膀\n\n * 《kubernetes网络权威指南》\n\n‍",charsets:{cjk:!0},lastUpdated:"2023/05/26, 12:48:43",lastUpdatedTimestamp:1685076523e3},{title:"理解Linux TunTap设备",frontmatter:{title:"理解Linux TunTap设备",date:"2023-05-26T10:20:08.000Z",permalink:"/pages/143447/",categories:["编程","linux"],tags:["linux","计算机网络","linux网络虚拟化"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"TUN/TAP是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/2023-04-13-2330-20230507110448-2vjzt36.png"},{name:"twitter:title",content:"理解Linux TunTap设备"},{name:"twitter:description",content:"TUN/TAP是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/2023-04-13-2330-20230507110448-2vjzt36.png"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/03.linux/02.%E7%90%86%E8%A7%A3Linux%20TunTap%E8%AE%BE%E5%A4%87.html"},{property:"og:type",content:"article"},{property:"og:title",content:"理解Linux TunTap设备"},{property:"og:description",content:"TUN/TAP是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/2023-04-13-2330-20230507110448-2vjzt36.png"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/03.linux/02.%E7%90%86%E8%A7%A3Linux%20TunTap%E8%AE%BE%E5%A4%87.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-05-26T10:20:08.000Z"},{property:"article:tag",content:"linux"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"linux网络虚拟化"},{itemprop:"name",content:"理解Linux TunTap设备"},{itemprop:"description",content:"TUN/TAP是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/2023-04-13-2330-20230507110448-2vjzt36.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/03.linux/02.%E7%90%86%E8%A7%A3Linux%20TunTap%E8%AE%BE%E5%A4%87.html",relativePath:"04.编程/03.linux/02.理解Linux TunTap设备.md",key:"v-325b46da",path:"/pages/143447/",headers:[{level:2,title:"入门",slug:"入门",normalizedTitle:"入门",charIndex:2},{level:2,title:"应用程序通过tun设备获取ping数据包",slug:"应用程序通过tun设备获取ping数据包",normalizedTitle:"应用程序通过tun设备获取ping数据包",charIndex:293},{level:2,title:"使用tun设备完成基于UDP的容器跨节点通信",slug:"使用tun设备完成基于udp的容器跨节点通信",normalizedTitle:"使用tun设备完成基于udp的容器跨节点通信",charIndex:3535},{level:2,title:"巨人的肩膀",slug:"巨人的肩膀",normalizedTitle:"巨人的肩膀",charIndex:8804}],headersStr:"入门 应用程序通过tun设备获取ping数据包 使用tun设备完成基于UDP的容器跨节点通信 巨人的肩膀",content:'# 入门\n\nTUN/TAP是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。\n\nTUN模拟的是三层设备，操作三层的数据包，而TAP模拟的二层设备，操作二层的数据包。\n\n> 物理网卡与虚拟网卡的区别是，物理网卡是外界与内核空间的网络协议栈数据交互的门户，而虚拟网卡是用户空间和内核空间交互的门户。\n\n/dev/net/tun 是linux提供的字符设备，写入该设备的数据会发送到虚拟网卡中，而发送到虚拟网卡中的数据也会出现在字符设备中。\n\n\n\n‍\n\n\n# 应用程序通过tun设备获取ping数据包\n\n\n\napp程序通过打开tun字符设备创建出tun虚拟网卡。然后通过ping命令发送ICMP数据包到网络协议栈中，这个过程是从用户空间到内核空间，再通过路由将数据包转发到tun虚拟网卡中，因为tun网卡特性，会进入到打开该tun设备用户空间app程序中。\n\napp程序代码如下：\n\nimport os\nimport struct\nfrom fcntl import ioctl\n\nBUFFER_SIZE = 4096\n\n# 完成虚拟网卡的注册\nTUNSETIFF = 0x400454ca\n\n# 设备模式\nIFF_TUN = 0x0001\nIFF_TAP = 0x0002\n\n\ndef create_tunnel(tun_name=\'tun%d\', tun_mode=IFF_TUN):\n    # 以读写的方式打开字符设备tun，获取到设备描述符\n    tun_fd = os.open("/dev/net/tun", os.O_RDWR)\n\n    # 对该设备进行配置，设备名称和设备模式。\n    ifn = ioctl(tun_fd, TUNSETIFF, struct.pack(b"16sH", tun_name.encode(), tun_mode))\n\n    # 获取到设备名称\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef main():\n    tun_fd, tun_name = create_tunnel()\n\n    while True:\n        data = os.read(tun_fd, BUFFER_SIZE)\n        print(f"get data from tun. data size = {len(data)}")\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n运行后输出：\n\n# python3 tun_demo.py\nOpen tun/tap device: tun0 for reading...\n\n\n1\n2\n\n\n通过ip a 命令发现tun设备已经创建，但其状态为DOWN\n\n# ip a | grep -C tun\n45: tun0: <POINTOPOINT,MULTICAST,NOARP> mtu 1500 qdisc noop state DOWN group default qlen 500\n    link/none\n\n\n1\n2\n3\n\n\n对其设置一个ip并将它状态设置为UP\n\nip a add 192.37.1.2/24 dev tun0\nip link set tun0 up\n\n\n1\n2\n\n\n配置好ip后，会发现自动配置了如下路由:\n\n...\n192.37.1.0/24 dev tun0 proto kernel scope link src 192.37.1.2 \n...\n\n\n1\n2\n3\n\n\n再次查看tun设备，发现已经配置好\n\n# ip a | grep tun0\n45: tun0: <POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 500\n    inet 192.37.1.1/24 scope global tun0\n\n\n1\n2\n3\n\n\n并且这时会发现tun0已经接收到了3个数据包\n\n# python3 tun_demo.py\nOpen tun/tap device: tun0 for reading...\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\n\n\n1\n2\n3\n4\n5\n\n\n这时候使用tcpdump监听tun0，执行ping 192.37.1.2，是有回包的，但是tcpdump却没有抓到任何包。\n\n> ping命令会根据目标IP地址和子网掩码来判断数据包的目的地，如果目的地在本地网络中，ping命令会直接将数据包发送到本地网络，而不是通过TUN设备发送。\n\n# tcpdump -i tun0 -n\n...\n\n# ping 192.37.1.2 -c 3\nPING 192.37.1.2 (192.37.1.2) 56(84) bytes of data.\n64 bytes from 192.37.1.2: icmp_seq=1 ttl=64 time=0.148 ms\n64 bytes from 192.37.1.2: icmp_seq=2 ttl=64 time=0.114 ms\n64 bytes from 192.37.1.2: icmp_seq=3 ttl=64 time=0.316 ms\n\n--- 192.37.1.2 ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 1999ms\nrtt min/avg/max/mdev = 0.114/0.192/0.316/0.089 ms\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n改为ping 192.37.1.3，可以看到程序收到了收到了数据包，tcpdump也抓到了包，但是因为没有做任何的处理也没有回包，所以ping命令看到不到回包。\n\n# python3 tun_demo.py\nOpen tun/tap device: tun0 for reading...\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\n\nget data from tun. data size = 88\nget data from tun. data size = 88\nget data from tun. data size = 88\n\n# tcpdump -i tun0 -n\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on tun0, link-type RAW (Raw IP), capture size 262144 bytes\n22:56:41.018149 IP 192.37.1.2 > 192.37.1.3: ICMP echo request, id 22559, seq 1, length 64\n22:56:42.018871 IP 192.37.1.2 > 192.37.1.3: ICMP echo request, id 22559, seq 2, length 64\n22:56:43.022732 IP 192.37.1.2 > 192.37.1.3: ICMP echo request, id 22559, seq 3, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n‍\n\n\n# 使用tun设备完成基于UDP的容器跨节点通信\n\n使用tun设备基于UDP完成容器跨节点通信。如下图所示：\n\n‍\n\n\n\n通信流程是，在Node1中的NS1进行ping Node2中NS2的veth0网卡的IP，ICMP的IP包会通过veth0到达veth1中，并进入到宿主机的网络协议栈，通过路由配置达到tun设备，这时app服务从tun设备中读取到IP包数据，然后将其封装在UDP包中，并通过eth0网卡发送到Node2的eth0网卡上，通过网络协议栈解包达到app程序中，拿到里面的IP包，将其写入到tun设备中，进入到网络协议栈中，通过路由达到veth1中，然后到达net ns1的veth0网卡。\n\napp程序简单实现如下：\n\nimport os\nimport socket\nimport struct\nimport threading\nfrom fcntl import ioctl\nimport click\n\nBIND_ADDRESS = (\'0.0.0.0\', 7000)\nBUFFER_SIZE = 4096\n\nTUNSETIFF = 0x400454ca\nIFF_TUN = 0x0001\nIFF_TAP = 0x0002\n\n\ndef create_tunnel(tun_name=\'tun%d\', tun_mode=IFF_TUN):\n    tun_fd = os.open("/dev/net/tun", os.O_RDWR)\n    ifn = ioctl(tun_fd, TUNSETIFF, struct.pack(b"16sH", tun_name.encode(), tun_mode))\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef start_tunnel(tun_name):\n    os.popen(f"ip link set {tun_name} up")\n\n\ndef udp_server(udp_socket, tun_fd):\n    while True:\n        data, addr = udp_socket.recvfrom(2048)\n        print("get data from udp.")\n        if not data:\n            break\n\n        os.write(tun_fd, data)\n\n\n@click.command()\n@click.option("--peer_node_ip", "-p", required=True, help="对端节点IP")\ndef main(peer_node_ip):\n    peer_node_addr = (peer_node_ip, 7000)\n\n    tun_fd, tun_name = create_tunnel()\n    start_tunnel(tun_name)\n\n    udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n    udp_socket.bind(BIND_ADDRESS)\n\n    t = threading.Thread(target=udp_server, args=(udp_socket, tun_fd))\n    t.daemon = True\n    t.start()\n\n    while True:\n        data = os.read(tun_fd, BUFFER_SIZE)\n        print(f"get data from tun. data size = {len(data)}")\n        udp_socket.sendto(data, peer_node_addr)\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n在Node1中运行该程序，设置Node2 IP\n\npython3 tun_app.py -p 10.65.132.187\n\n\n1\n\n\n可以看到已经创建了tun设备\n\n# ip link show tun0\n...\n109: tun0: <POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UNKNOWN group default qlen 500\n    link/none \n    inet6 fe80::8e98:91a4:6537:d77a/64 scope link flags 800 \n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在Node1中创建Network Namespace命名为net1，使用它来完成模拟容器网络。\n\nip netns add net1\n\n\n1\n\n\n然后创建veth pair，它们是一对网卡，分别为命名为veth0和veth1\n\nip link add veth0 type veth peer name veth1\n\n\n1\n\n\n将其一端接入到net1中，并设置好其IP地址为10.1.1.2/24\n\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 10.1.1.2/24 dev veth0\nip netns exec net1 ip link set dev veth0 up\n\n\n1\n2\n3\n\n\n开启在宿主机上的veth1网卡，并设置其IP为10.1.1.1/24\n\nip a add 10.1.1.1/24 dev veth1\nip link set dev veth1 up\n\n\n1\n2\n\n\n再将net1中的默认路由设置成都走veth0，这样，ping Node2中net2的网络包可以到veth1中，也就进入到了宿主机的网络协议栈中。\n\nip netns exec net1 ip r add default via 10.1.1.1 dev veth0\n\n\n1\n\n\n在宿主机上还需要添加路由，访问Node2中net2时都路由到tun0设备\n\nip r add 10.1.2.0/24 dev tun0\n\n\n1\n\n\n这时，在Node1 net1中ping Node2 net2时，正常来说是可以在app中看到从tun收到IP包的，虽然没有回包，那是因为app程序收到包后没有做任何回包操作。\n\n# ip netns exec net1 ping 10.1.2.2 -c 3\nPING 10.1.2.2 (10.1.2.2) 56(84) bytes of data.\n--- 10.1.2.2 ping statistics ---\n3 packets transmitted, 0 received, 100% packet loss, time 2001ms\n\n\n1\n2\n3\n4\n\n\n我们通过tcpdump抓取veth1网卡，可以看到收到了ARP请求，想要获取10.1.2.2的MAC地址，但是一直获取不到，所以导致IP包无法通过路由达到TUN设备\n\n# tcpdump -i veth1 -n\n00:45:13.988076 ARP, Request who-has 10.1.2.2 tell 10.1.1.2, length 28\n\n\n1\n2\n\n\n这个时候需要开启veth1的arp代理，将veth1的MAC地址作为ARP的回复。\n\necho 1 >  /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n\n\n再次ping Node2 net2时，可以看到tcpdump看到ARP中回复的MAC地址为veth1的地址。\n\n# tcpdump -i veth1 -n\n00:45:13.988076 ARP, Request who-has 10.1.2.2 tell 10.1.1.2, length 28\n00:45:13.988100 ARP, Reply 10.1.2.2 is-at 4e:7c:bf:fe:4d:0f, length 28\n\n# ip a | grep -C 3 veth1\n...\n107: veth1@if108: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000\n    link/ether 4e:7c:bf:fe:4d:0f brd ff:ff:ff:ff:ff:ff link-netnsid 3\n    inet 10.1.1.1/24 scope global veth1\n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n并且app程序中也从tun设备中获取到了IP包。\n\n# python3 tun_app.py -p 10.65.132.187\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 88\nget data from tun. data size = 88\nget data from tun. data size = 88\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n到这一步，Node1的基本配置完成，接下来配置Node2，配置的方法与Node1一致，在Node2执行命令如下:\n\n# 开启app程序\npython3 tun_app.py -p 10.61.74.37\n\n# 新增network namespace net2\nip netns add net2\n\n# 新增veth pair设备\nip link add veth0 type veth peer name veth1\n\n# 配置veth pair设备\nip link set dev veth0 netns net2\nip netns exec net2 ip addr add 10.1.2.2/24 dev veth0\nip netns exec net2 ip link set dev veth0 up\n\nip a add 10.1.2.1/24 dev veth1\nip link set dev veth1 up\n\n# 添加默认路由\nip netns exec net2 ip r add default via 10.1.2.1 dev veth0\n\n# 添加tun0设备路由\nip r add 10.1.1.0/24 dev tun0\n\n# 开启arp代理\necho 1 >  /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n配置完成后，在Node1的net1中ping Node2的net2，可以ping通有回包。\n\n# ip netns exec net1 ping 10.1.2.2 \nPING 10.1.2.2 (10.1.2.2) 56(84) bytes of data.\n64 bytes from 10.1.2.2: icmp_seq=1 ttl=62 time=5.46 ms\n64 bytes from 10.1.2.2: icmp_seq=2 ttl=62 time=4.67 ms\n64 bytes from 10.1.2.2: icmp_seq=3 ttl=62 time=5.52 ms\n\n\n1\n2\n3\n4\n5\n\n\n\n# 巨人的肩膀\n\n * Linux Tun/Tap 介绍\n\n * 理解 Linux 虚拟网卡设备 tun/tap 的一切\n\n * 基于tun设备实现在用户空间可以ping通外部节点(golang版本)\n\n * 一起动手写一个VPN\n\n‍',normalizedContent:'# 入门\n\ntun/tap是操作系统内核中的虚拟网络设备，可以完成用户空间与内核空间的数据的交互。网络协议栈中的数据通过该设备可以进入到用户空间中，而用户空间中的程序通过该设备空间进入到内核空间的网络协议栈。\n\ntun模拟的是三层设备，操作三层的数据包，而tap模拟的二层设备，操作二层的数据包。\n\n> 物理网卡与虚拟网卡的区别是，物理网卡是外界与内核空间的网络协议栈数据交互的门户，而虚拟网卡是用户空间和内核空间交互的门户。\n\n/dev/net/tun 是linux提供的字符设备，写入该设备的数据会发送到虚拟网卡中，而发送到虚拟网卡中的数据也会出现在字符设备中。\n\n\n\n‍\n\n\n# 应用程序通过tun设备获取ping数据包\n\n\n\napp程序通过打开tun字符设备创建出tun虚拟网卡。然后通过ping命令发送icmp数据包到网络协议栈中，这个过程是从用户空间到内核空间，再通过路由将数据包转发到tun虚拟网卡中，因为tun网卡特性，会进入到打开该tun设备用户空间app程序中。\n\napp程序代码如下：\n\nimport os\nimport struct\nfrom fcntl import ioctl\n\nbuffer_size = 4096\n\n# 完成虚拟网卡的注册\ntunsetiff = 0x400454ca\n\n# 设备模式\niff_tun = 0x0001\niff_tap = 0x0002\n\n\ndef create_tunnel(tun_name=\'tun%d\', tun_mode=iff_tun):\n    # 以读写的方式打开字符设备tun，获取到设备描述符\n    tun_fd = os.open("/dev/net/tun", os.o_rdwr)\n\n    # 对该设备进行配置，设备名称和设备模式。\n    ifn = ioctl(tun_fd, tunsetiff, struct.pack(b"16sh", tun_name.encode(), tun_mode))\n\n    # 获取到设备名称\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef main():\n    tun_fd, tun_name = create_tunnel()\n\n    while true:\n        data = os.read(tun_fd, buffer_size)\n        print(f"get data from tun. data size = {len(data)}")\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n运行后输出：\n\n# python3 tun_demo.py\nopen tun/tap device: tun0 for reading...\n\n\n1\n2\n\n\n通过ip a 命令发现tun设备已经创建，但其状态为down\n\n# ip a | grep -c tun\n45: tun0: <pointopoint,multicast,noarp> mtu 1500 qdisc noop state down group default qlen 500\n    link/none\n\n\n1\n2\n3\n\n\n对其设置一个ip并将它状态设置为up\n\nip a add 192.37.1.2/24 dev tun0\nip link set tun0 up\n\n\n1\n2\n\n\n配置好ip后，会发现自动配置了如下路由:\n\n...\n192.37.1.0/24 dev tun0 proto kernel scope link src 192.37.1.2 \n...\n\n\n1\n2\n3\n\n\n再次查看tun设备，发现已经配置好\n\n# ip a | grep tun0\n45: tun0: <pointopoint,multicast,noarp,up,lower_up> mtu 1500 qdisc pfifo_fast state unknown group default qlen 500\n    inet 192.37.1.1/24 scope global tun0\n\n\n1\n2\n3\n\n\n并且这时会发现tun0已经接收到了3个数据包\n\n# python3 tun_demo.py\nopen tun/tap device: tun0 for reading...\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\n\n\n1\n2\n3\n4\n5\n\n\n这时候使用tcpdump监听tun0，执行ping 192.37.1.2，是有回包的，但是tcpdump却没有抓到任何包。\n\n> ping命令会根据目标ip地址和子网掩码来判断数据包的目的地，如果目的地在本地网络中，ping命令会直接将数据包发送到本地网络，而不是通过tun设备发送。\n\n# tcpdump -i tun0 -n\n...\n\n# ping 192.37.1.2 -c 3\nping 192.37.1.2 (192.37.1.2) 56(84) bytes of data.\n64 bytes from 192.37.1.2: icmp_seq=1 ttl=64 time=0.148 ms\n64 bytes from 192.37.1.2: icmp_seq=2 ttl=64 time=0.114 ms\n64 bytes from 192.37.1.2: icmp_seq=3 ttl=64 time=0.316 ms\n\n--- 192.37.1.2 ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 1999ms\nrtt min/avg/max/mdev = 0.114/0.192/0.316/0.089 ms\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n改为ping 192.37.1.3，可以看到程序收到了收到了数据包，tcpdump也抓到了包，但是因为没有做任何的处理也没有回包，所以ping命令看到不到回包。\n\n# python3 tun_demo.py\nopen tun/tap device: tun0 for reading...\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\n\nget data from tun. data size = 88\nget data from tun. data size = 88\nget data from tun. data size = 88\n\n# tcpdump -i tun0 -n\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on tun0, link-type raw (raw ip), capture size 262144 bytes\n22:56:41.018149 ip 192.37.1.2 > 192.37.1.3: icmp echo request, id 22559, seq 1, length 64\n22:56:42.018871 ip 192.37.1.2 > 192.37.1.3: icmp echo request, id 22559, seq 2, length 64\n22:56:43.022732 ip 192.37.1.2 > 192.37.1.3: icmp echo request, id 22559, seq 3, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n\n\n‍\n\n\n# 使用tun设备完成基于udp的容器跨节点通信\n\n使用tun设备基于udp完成容器跨节点通信。如下图所示：\n\n‍\n\n\n\n通信流程是，在node1中的ns1进行ping node2中ns2的veth0网卡的ip，icmp的ip包会通过veth0到达veth1中，并进入到宿主机的网络协议栈，通过路由配置达到tun设备，这时app服务从tun设备中读取到ip包数据，然后将其封装在udp包中，并通过eth0网卡发送到node2的eth0网卡上，通过网络协议栈解包达到app程序中，拿到里面的ip包，将其写入到tun设备中，进入到网络协议栈中，通过路由达到veth1中，然后到达net ns1的veth0网卡。\n\napp程序简单实现如下：\n\nimport os\nimport socket\nimport struct\nimport threading\nfrom fcntl import ioctl\nimport click\n\nbind_address = (\'0.0.0.0\', 7000)\nbuffer_size = 4096\n\ntunsetiff = 0x400454ca\niff_tun = 0x0001\niff_tap = 0x0002\n\n\ndef create_tunnel(tun_name=\'tun%d\', tun_mode=iff_tun):\n    tun_fd = os.open("/dev/net/tun", os.o_rdwr)\n    ifn = ioctl(tun_fd, tunsetiff, struct.pack(b"16sh", tun_name.encode(), tun_mode))\n    tun_name = ifn[:16].decode().strip("\\x00")\n    return tun_fd, tun_name\n\n\ndef start_tunnel(tun_name):\n    os.popen(f"ip link set {tun_name} up")\n\n\ndef udp_server(udp_socket, tun_fd):\n    while true:\n        data, addr = udp_socket.recvfrom(2048)\n        print("get data from udp.")\n        if not data:\n            break\n\n        os.write(tun_fd, data)\n\n\n@click.command()\n@click.option("--peer_node_ip", "-p", required=true, help="对端节点ip")\ndef main(peer_node_ip):\n    peer_node_addr = (peer_node_ip, 7000)\n\n    tun_fd, tun_name = create_tunnel()\n    start_tunnel(tun_name)\n\n    udp_socket = socket.socket(socket.af_inet, socket.sock_dgram)\n    udp_socket.bind(bind_address)\n\n    t = threading.thread(target=udp_server, args=(udp_socket, tun_fd))\n    t.daemon = true\n    t.start()\n\n    while true:\n        data = os.read(tun_fd, buffer_size)\n        print(f"get data from tun. data size = {len(data)}")\n        udp_socket.sendto(data, peer_node_addr)\n\n\nif __name__ == \'__main__\':\n    main()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n\n\n在node1中运行该程序，设置node2 ip\n\npython3 tun_app.py -p 10.65.132.187\n\n\n1\n\n\n可以看到已经创建了tun设备\n\n# ip link show tun0\n...\n109: tun0: <pointopoint,multicast,noarp,up,lower_up> mtu 1500 qdisc pfifo_fast state unknown group default qlen 500\n    link/none \n    inet6 fe80::8e98:91a4:6537:d77a/64 scope link flags 800 \n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n在node1中创建network namespace命名为net1，使用它来完成模拟容器网络。\n\nip netns add net1\n\n\n1\n\n\n然后创建veth pair，它们是一对网卡，分别为命名为veth0和veth1\n\nip link add veth0 type veth peer name veth1\n\n\n1\n\n\n将其一端接入到net1中，并设置好其ip地址为10.1.1.2/24\n\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 10.1.1.2/24 dev veth0\nip netns exec net1 ip link set dev veth0 up\n\n\n1\n2\n3\n\n\n开启在宿主机上的veth1网卡，并设置其ip为10.1.1.1/24\n\nip a add 10.1.1.1/24 dev veth1\nip link set dev veth1 up\n\n\n1\n2\n\n\n再将net1中的默认路由设置成都走veth0，这样，ping node2中net2的网络包可以到veth1中，也就进入到了宿主机的网络协议栈中。\n\nip netns exec net1 ip r add default via 10.1.1.1 dev veth0\n\n\n1\n\n\n在宿主机上还需要添加路由，访问node2中net2时都路由到tun0设备\n\nip r add 10.1.2.0/24 dev tun0\n\n\n1\n\n\n这时，在node1 net1中ping node2 net2时，正常来说是可以在app中看到从tun收到ip包的，虽然没有回包，那是因为app程序收到包后没有做任何回包操作。\n\n# ip netns exec net1 ping 10.1.2.2 -c 3\nping 10.1.2.2 (10.1.2.2) 56(84) bytes of data.\n--- 10.1.2.2 ping statistics ---\n3 packets transmitted, 0 received, 100% packet loss, time 2001ms\n\n\n1\n2\n3\n4\n\n\n我们通过tcpdump抓取veth1网卡，可以看到收到了arp请求，想要获取10.1.2.2的mac地址，但是一直获取不到，所以导致ip包无法通过路由达到tun设备\n\n# tcpdump -i veth1 -n\n00:45:13.988076 arp, request who-has 10.1.2.2 tell 10.1.1.2, length 28\n\n\n1\n2\n\n\n这个时候需要开启veth1的arp代理，将veth1的mac地址作为arp的回复。\n\necho 1 >  /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n\n\n再次ping node2 net2时，可以看到tcpdump看到arp中回复的mac地址为veth1的地址。\n\n# tcpdump -i veth1 -n\n00:45:13.988076 arp, request who-has 10.1.2.2 tell 10.1.1.2, length 28\n00:45:13.988100 arp, reply 10.1.2.2 is-at 4e:7c:bf:fe:4d:0f, length 28\n\n# ip a | grep -c 3 veth1\n...\n107: veth1@if108: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up group default qlen 1000\n    link/ether 4e:7c:bf:fe:4d:0f brd ff:ff:ff:ff:ff:ff link-netnsid 3\n    inet 10.1.1.1/24 scope global veth1\n       valid_lft forever preferred_lft forever\n...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n并且app程序中也从tun设备中获取到了ip包。\n\n# python3 tun_app.py -p 10.65.132.187\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 52\nget data from tun. data size = 88\nget data from tun. data size = 88\nget data from tun. data size = 88\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n到这一步，node1的基本配置完成，接下来配置node2，配置的方法与node1一致，在node2执行命令如下:\n\n# 开启app程序\npython3 tun_app.py -p 10.61.74.37\n\n# 新增network namespace net2\nip netns add net2\n\n# 新增veth pair设备\nip link add veth0 type veth peer name veth1\n\n# 配置veth pair设备\nip link set dev veth0 netns net2\nip netns exec net2 ip addr add 10.1.2.2/24 dev veth0\nip netns exec net2 ip link set dev veth0 up\n\nip a add 10.1.2.1/24 dev veth1\nip link set dev veth1 up\n\n# 添加默认路由\nip netns exec net2 ip r add default via 10.1.2.1 dev veth0\n\n# 添加tun0设备路由\nip r add 10.1.1.0/24 dev tun0\n\n# 开启arp代理\necho 1 >  /proc/sys/net/ipv4/conf/veth1/proxy_arp\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n配置完成后，在node1的net1中ping node2的net2，可以ping通有回包。\n\n# ip netns exec net1 ping 10.1.2.2 \nping 10.1.2.2 (10.1.2.2) 56(84) bytes of data.\n64 bytes from 10.1.2.2: icmp_seq=1 ttl=62 time=5.46 ms\n64 bytes from 10.1.2.2: icmp_seq=2 ttl=62 time=4.67 ms\n64 bytes from 10.1.2.2: icmp_seq=3 ttl=62 time=5.52 ms\n\n\n1\n2\n3\n4\n5\n\n\n\n# 巨人的肩膀\n\n * linux tun/tap 介绍\n\n * 理解 linux 虚拟网卡设备 tun/tap 的一切\n\n * 基于tun设备实现在用户空间可以ping通外部节点(golang版本)\n\n * 一起动手写一个vpn\n\n‍',charsets:{cjk:!0},lastUpdated:"2023/05/26, 12:48:43",lastUpdatedTimestamp:1685076523e3},{title:"理解VXLAN网络",frontmatter:{title:"理解VXLAN网络",date:"2023-05-26T11:38:14.000Z",permalink:"/pages/8a4b28/",categories:["编程","linux"],tags:["linux","计算机网络","linux网络虚拟化"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"在三层可达的网络中部署VXLAN，在每个VXLAN网络端点中都有一个VTEP设备，负责将VXLAN协议的数据包进行UDP数据包的封包和解包，可以将其理解为隧道，将VXLAN数据包从逻辑网络转发到物理网络",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230526124522.png"},{name:"twitter:title",content:"理解VXLAN网络"},{name:"twitter:description",content:"在三层可达的网络中部署VXLAN，在每个VXLAN网络端点中都有一个VTEP设备，负责将VXLAN协议的数据包进行UDP数据包的封包和解包，可以将其理解为隧道，将VXLAN数据包从逻辑网络转发到物理网络"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230526124522.png"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/03.linux/03.%E7%90%86%E8%A7%A3VXLAN%E7%BD%91%E7%BB%9C.html"},{property:"og:type",content:"article"},{property:"og:title",content:"理解VXLAN网络"},{property:"og:description",content:"在三层可达的网络中部署VXLAN，在每个VXLAN网络端点中都有一个VTEP设备，负责将VXLAN协议的数据包进行UDP数据包的封包和解包，可以将其理解为隧道，将VXLAN数据包从逻辑网络转发到物理网络"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230526124522.png"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/03.linux/03.%E7%90%86%E8%A7%A3VXLAN%E7%BD%91%E7%BB%9C.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-05-26T11:38:14.000Z"},{property:"article:tag",content:"linux"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"linux网络虚拟化"},{itemprop:"name",content:"理解VXLAN网络"},{itemprop:"description",content:"在三层可达的网络中部署VXLAN，在每个VXLAN网络端点中都有一个VTEP设备，负责将VXLAN协议的数据包进行UDP数据包的封包和解包，可以将其理解为隧道，将VXLAN数据包从逻辑网络转发到物理网络"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20230526124522.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/03.linux/03.%E7%90%86%E8%A7%A3VXLAN%E7%BD%91%E7%BB%9C.html",relativePath:"04.编程/03.linux/03.理解VXLAN网络.md",key:"v-3e69314c",path:"/pages/8a4b28/",headers:[{level:2,title:"什么是VXLAN?",slug:"什么是vxlan",normalizedTitle:"什么是vxlan?",charIndex:2},{level:2,title:"点对点的VXLAN",slug:"点对点的vxlan",normalizedTitle:"点对点的vxlan",charIndex:159},{level:3,title:"实操",slug:"实操",normalizedTitle:"实操",charIndex:205},{level:3,title:"开测",slug:"开测",normalizedTitle:"开测",charIndex:2072},{level:2,title:"VXLAN的多播模式",slug:"vxlan的多播模式",normalizedTitle:"vxlan的多播模式",charIndex:4578},{level:3,title:"通信过程",slug:"通信过程",normalizedTitle:"通信过程",charIndex:4633},{level:3,title:"环境准备",slug:"环境准备",normalizedTitle:"环境准备",charIndex:5250},{level:3,title:"开始分析",slug:"开始分析",normalizedTitle:"开始分析",charIndex:6883},{level:2,title:"VXLAN多播模式+桥接",slug:"vxlan多播模式-桥接",normalizedTitle:"vxlan多播模式+桥接",charIndex:9655},{level:3,title:"通信过程",slug:"通信过程-2",normalizedTitle:"通信过程",charIndex:4633},{level:3,title:"环境准备",slug:"环境准备-2",normalizedTitle:"环境准备",charIndex:5250},{level:3,title:"开始分析",slug:"开始分析-2",normalizedTitle:"开始分析",charIndex:6883},{level:2,title:"巨人的肩膀",slug:"巨人的肩膀",normalizedTitle:"巨人的肩膀",charIndex:13468}],headersStr:"什么是VXLAN? 点对点的VXLAN 实操 开测 VXLAN的多播模式 通信过程 环境准备 开始分析 VXLAN多播模式+桥接 通信过程 环境准备 开始分析 巨人的肩膀",content:"# 什么是VXLAN?\n\n在三层可达的网络中部署VXLAN，在每个VXLAN网络端点中都有一个VTEP设备，负责将VXLAN协议的数据包进行UDP数据包的封包和解包，可以将其理解为隧道，将VXLAN数据包从逻辑网络转发到物理网络\n\nVXLAN使用24位的VXLAN网络标识符（VNI）来标识不同的虚拟网络\n\n\n\n\n# 点对点的VXLAN\n\n在已经知道对端VTEP所在节点，是如何进行跨节点通信的。\n\n\n\n\n# 实操\n\n在Node上新增VTEP设备vxlan0，创建命令如下：\n\nip link add vxlan0 type vxlan id 42 dstport 4789 remote 10.65.132.188 local 10.65.132.187 dev ens18\n\n\n1\n\n * remote是对端节点的IP\n * local是本节点IP\n * id是VNI的值\n * dstport 是VTEP设备的端口\n\n创建好后，需要给它配置IP并启用\n\nip a add 172.17.1.2/24 dev vxlan0\nip link set vxlan0 up\n\n\n1\n2\n\n\nvxlan0详情如下：\n\n# ip -d link show dev vxlan0\n114: vxlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/ether 86:45:5c:56:49:42 brd ff:ff:ff:ff:ff:ff promiscuity 0 \n    vxlan id 42 remote 10.65.132.187 local 10.61.74.37 dev ens18 srcport 0 0 dstport 4789 ageing 300 noudpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n并且可以看到路由中新增一条记录，所有目的地址是172.17.1.0/24网段的包都要走vxlan0转发。\n\n# ip r\n...\n172.17.1.0/24 dev vxlan0 proto kernel scope link src 172.17.1.2\n...\n\n\n1\n2\n3\n4\n\n\n同时fdb表中新增以下记录，代表着，所有进过vxlan0包的外部UDP目的地址都会设置为10.65.132.187，并从ens18网卡出去。\n\n]# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 10.65.132.187 via ens18 self permanent\n\n\n1\n2\n\n\n到这里，Node1已经配置好了，我们重复上面操作设置Node2，只需要将部分IP修改即可。\n\n# 将Node1中remote和local反过来即可.\nip link add vxlan0 type vxlan id 42 dstport 4789 remote 10.65.132.187 dev ens18 local 10.65.132.188 dev ens18\n\n# vxlan0 地址设置为172.17.1.3/24\nip a add 172.17.1.3/24 dev vxlan0\nip link set vxlan0 up\n\n# ip -d link show vxlan0\n20: vxlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/ether 12:09:3d:c0:97:32 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 remote 10.65.132.187 local 10.65.132.188 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 开测\n\n在Node2上监听Node1的udp数据包\n\ntcpdump -i ens18 udp and host 10.65.132.187 -n\n\n\n1\n\n\n然后在Node1中ping Node2的VTEP设备地址172.17.1.3\n\n[root@k8s-master-07rf9 ~]# ping 172.17.1.3 -c 3\nPING 172.17.1.3 (172.17.1.3) 56(84) bytes of data.\n64 bytes from 172.17.1.3: icmp_seq=1 ttl=64 time=0.841 ms\n64 bytes from 172.17.1.3: icmp_seq=2 ttl=64 time=0.382 ms\n64 bytes from 172.17.1.3: icmp_seq=3 ttl=64 time=0.377 ms\n\n\n1\n2\n3\n4\n5\n\n\n可以看到tcpdump抓到的数据包如下，先收到了Node1的发过来封装了ARP数据包的数据包，想要知道Node2中VTEP设备的MAC地址，然后回给了Node1，Node1收到后，将MAC地址填充，再将封装了ICMP的VXLAN数据包发送到Node2，Node2中VTEP收到包并解包，最后回包给Node1\n\n[root@k8s-work01-1zapn ~]# tcpdump -i ens18 udp and host 10.65.132.187 -n\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n19:23:36.705418 IP 10.65.132.187.34062 > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Request who-has 172.17.1.3 tell 172.17.1.2, length 28\n19:23:36.705574 IP 10.65.132.188.20835 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Reply 172.17.1.3 is-at 3a:84:39:cc:05:93, length 28\n19:23:36.705880 IP 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.2 > 172.17.1.3: ICMP echo request, id 25707, seq 1, length 64\n19:23:36.705986 IP 10.65.132.188.62793 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.3 > 172.17.1.2: ICMP echo reply, id 25707, seq 1, length 64\n19:23:37.708701 IP 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.2 > 172.17.1.3: ICMP echo request, id 25707, seq 2, length 64\n19:23:37.708846 IP 10.65.132.188.62793 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.3 > 172.17.1.2: ICMP echo reply, id 25707, seq 2, length 64\n19:23:38.732737 IP 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.2 > 172.17.1.3: ICMP echo request, id 25707, seq 3, length 64\n19:23:38.732846 IP 10.65.132.188.62793 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.3 > 172.17.1.2: ICMP echo reply, id 25707, seq 3, length 64\n19:23:41.804637 IP 10.65.132.188.20835 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Request who-has 172.17.1.2 tell 172.17.1.3, length 28\n19:23:41.804917 IP 10.65.132.187.34062 > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Reply 172.17.1.2 is-at c2:a1:4e:56:7d:eb, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# VXLAN的多播模式\n\n在我们不知道VTEP所在节点的情况下，并且需要使用多个VTEP组建逻辑网络。\n\n\n# 通信过程\n\n\n\n 1. 在Node1上通过ping Node2上vxlan0设备ip，数据包通过路由到达vxlan0，vxlan0发现目的IP和源IP属于同一网段，需要知道对方的MAC地址，因此需要发送ARP查询报文。\n 2. ARP报文中，源MAC地址为Node1上vxlan0的mac地址，目的mac地址为255.255.255.255也就是广播地址，并且添加VXLAN头部VNI=42\n 3. 因为不知道对端的VTEP设备在哪台节点上，所以vxlan0会向多播地址224.1.1.1发送多播报文。\n 4. 多播组中所有的主机都会收到报文，并且内核会判断该数据包为VXLAN报文，根据VNI发送给VTEP设备。\n 5. Node2中vxlan0收到报文后，解包拿到ARP报文，然后通过ARP报文学习到了将Node1的vxlan0的mac地址与Node1 IP的映射关系记录到FDB表中，并且生成ARP应答报文。\n 6. ARP应答报文中，目的主机Node1的MAC地址和目的主机Node1中vxlan0的MAC地址都通过发过来的ARP报文中学习到，所以可以直接通过单播进行回复。\n 7. Node1收到ARP回复的报文后，通过报文内容，将Node2的主机地址和vxlan0的MAC地址的映射关系缓存到FDB表中。\n 8. 现在双方都已经通过ARP报文获得了双方的建立ICMP通信的所有信息，可以直接通过通过单播进行通信。\n\n\n# 环境准备\n\n首先在Node1中新增VTEP设备vxlan0，VNI为42，通信端口4789，主机地址为10.65.132.187，设置多播地址为224.1.1.1，数据包通过ens18真实网卡出去。\n\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.187 group 224.1.1.1 dev ens18\n\n\n1\n\n\n给vxlan0添加地址172.17.1.2/24，并把它拉起\n\nip addr add 172.17.1.2/24 dev vxlan0\nip link set vxlan0 up\n\n\n1\n2\n\n\n查看vxlan0的详细信息\n\n# ip -d link  show vxlan0\n22: vxlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/ether 4e:92:72:79:59:ed brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 group 224.1.1.1 local 10.65.132.187 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535\n\n\n1\n2\n3\n4\n\n\n再看看fdb表，意思是，vxlan0封包的时候，默认会使用224.1.1.1作为VXLAN包也就是外部UDP的目的IP。\n\n# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 224.1.1.1 via ens18 self permanent\n\n\n1\n2\n\n\n在Node2上重复上述操作\n\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.188 group 224.1.1.1 dev ens18\n\nip addr add 172.17.1.3/24 dev vxlan0\nip link set vxlan0 up\n\n# ip -d link show vxlan0\n11: vxlan0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/ether ba:d8:43:67:8d:fb brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 group 224.1.1.1 local 10.65.132.188 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 开始分析\n\n先使用tcpdump来监听Node2中ens18网卡中来自Node1的UDP数据包，然后在Node1上ping Node2中vxlan0设备。\n\n可以看到是可以ping通的。\n\n# ping 172.17.1.3 -c 1\nPING 172.17.1.3 (172.17.1.3) 56(84) bytes of data.\n64 bytes from 172.17.1.3: icmp_seq=1 ttl=64 time=0.807 ms\n\n--- 172.17.1.3 ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\nrtt min/avg/max/mdev = 0.807/0.807/0.807/0.000 ms\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n再来看看抓到的包：\n\n 1. 第一个数据包，可以看到Node2收到了来自Node1的 VXLAN数据包，vni为42，目的地址是多播IP224.1.1.1，因为我们创建的VTEP设备设置了该多播IP，所以会接收该数据包。且里面封装了ARP数据包，需要将172.17.1.3的MAC地址告诉172.17.1.2。\n 2. 第二个数据包可以看到回复了一个VXLAN数据包，里面包含了ARP应答包，将172.17.1.3的mac地址也就是vxlan0的地址回复过去。\n 3. 第三个数据包是Node1 vxlan0根据对方的MAC地址和Node2的IP地址，直接单播发送包含了ICMP数据包的VXLAN数据包到Node2\n 4. 第四个数据包时Node2 vxlan0进行回复ICMP，也是包裹在一个VXLAN数据包中，发送到Node1中。\n\n# tcpdump -i ens18 udp and host 10.65.132.187 -n\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type EN10MB (Ethernet), capture size 262144 bytes\n\n10:31:34.560469 IP 10.65.132.187.34062 > 224.1.1.1.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Request who-has 172.17.1.3 tell 172.17.1.2, length 28\n10:31:34.560616 IP 10.65.132.188.20835 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Reply 172.17.1.3 is-at ba:d8:43:67:8d:fb, length 28\n10:31:34.560819 IP 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.2 > 172.17.1.3: ICMP echo request, id 46810, seq 1, length 64\n10:31:34.560935 IP 10.65.132.188.62793 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.3 > 172.17.1.2: ICMP echo reply, id 46810, seq 1, length 64\n10:31:39.661990 IP 10.65.132.188.20835 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Request who-has 172.17.1.2 tell 172.17.1.3, length 28\n10:31:39.662329 IP 10.65.132.187.34062 > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Reply 172.17.1.2 is-at 4e:92:72:79:59:ed, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n再次ping Node2的vxlan0设备，通过抓包可以看到，不需要发送ARP报文了，是因为Node1已经缓存了ARP。\n\n第一个数据包目的IP不再是224.1.1.1多播地址了，而是Node2的地址。是因为vxlan0也已经缓存到fdb表中。\n\n10:49:36.712777 IP 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.2 > 172.17.1.3: ICMP echo request, id 41695, seq 1, length 64\n10:49:36.712973 IP 10.65.132.188.62793 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.17.1.3 > 172.17.1.2: ICMP echo reply, id 41695, seq 1, length 64\n\n\n1\n2\n3\n4\n\n\n查看arp缓存\n\n# arp | grep vxlan0\n172.17.1.3               ether   ba:d8:43:67:8d:fb   C                     vxlan0\n\n\n1\n2\n\n\n查看fdb表，添加了Node2中vxlan0的MAC地址和Node2地址的映射表项。\n\n# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 224.1.1.1 via ens18 self permanent\nba:d8:43:67:8d:fb dev vxlan0 dst 10.65.132.188 self\n\n\n1\n2\n3\n\n\n\n# VXLAN多播模式+桥接\n\n在VXLAN的多播的基础上再加上桥接网络。\n\n\n# 通信过程\n\n桥接网络模拟及通信到宿主机过程可以参考手动实现docker容器bridge网络模型\n\n数据包达到网桥后，然后再转发到vxlan0中，接下来的流程也与上面将的多播是一致的。\n\n\n\n\n# 环境准备\n\n在Node1上运行如下命令准备环境\n\n# 添加VTEP设备\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.187 group 224.1.1.1 dev ens18\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set vxlan0 master bridge0\nip link set vxlan0 up\nip link set bridge0 up\n\n# 添加net1模拟容器\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n在Node2中重复上面操作，将172.19.1.3/24绑定到另一个Network Namespace net3中\n\n# 添加VTEP设备\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.188 group 224.1.1.1 dev ens18\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set vxlan0 master bridge0\nip link set vxlan0 up\nip link set bridge0 up\n\n# 添加net1模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 设置net1中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.1.3/24 dev veth0\nip netns exec net3 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n\n# 开始分析\n\n在Node1的net1中ping Node2中的net3，可以看到有回包，说明网络是通的。\n\n# ip netns exec net1 ping 172.19.1.3 -c 2\nPING 172.19.1.3 (172.19.1.3) 56(84) bytes of data.\n64 bytes from 172.19.1.3: icmp_seq=1 ttl=64 time=0.992 ms\n64 bytes from 172.19.1.3: icmp_seq=2 ttl=64 time=0.605 ms\n\n\n1\n2\n3\n4\n\n\n通过监听Node2的网卡ens18，抓到以下的包：\n\n 1. 首先是Node1发送包含ARP的UDP包到多播地址224.1.1.1，因为Node2是属于该多播地址，所以会接收该包，并通过vxlan0进行解包，最终拿到ARP包，然后发送vxlan0的mac地址进行arp回包，也是通过封装到UDP包中发送Node1中，然后再通过vxlan0->bridge进入到net1中，net1中收到ARP后，将Node2的容器IP地址和mac地址缓存到ARP中。\n\n 2. 并且在fdb表中添加一项，net3的的mac地址与Node2的IP地址映射关系\n\n 3. 接下来是通过ARP缓存找到MAC地址并添加到ICMP的IP包上，然后再将其封装到UDP包中，UDP的源IP是通过查询fdb表得到的，可以直接通过单播发送。\n\n7:15:47.595683 IP 10.65.132.187.34062 > 224.1.1.1.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Request who-has 172.19.1.3 tell 172.19.1.2, length 28\n17:15:47.595863 IP 10.65.132.188.20835 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nARP, Reply 172.19.1.3 is-at 02:fd:f9:7f:61:a7, length 28\n17:15:47.596172 IP 10.65.132.187.42208 > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.19.1.2 > 172.19.1.3: ICMP echo request, id 51397, seq 1, length 64\n17:15:47.596295 IP 10.65.132.188.22080 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.19.1.3 > 172.19.1.2: ICMP echo reply, id 51397, seq 1, length 64\n17:15:48.596543 IP 10.65.132.187.42208 > 10.65.132.188.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.19.1.2 > 172.19.1.3: ICMP echo request, id 51397, seq 2, length 64\n17:15:48.596724 IP 10.65.132.188.22080 > 10.65.132.187.vxlan: VXLAN, flags [I] (0x08), vni 42\nIP 172.19.1.3 > 172.19.1.2: ICMP echo reply, id 51397, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n可以看到net1中已经缓存了net3的ip地址与mac地址\n\n# Node1\n# ip netns exec net1 arp \nAddress                  HWtype  HWaddress           Flags Mask            Iface\n172.19.1.3               ether   02:fd:f9:7f:61:a7   C                     veth0\n\n\n1\n2\n3\n4\n\n\nnet3中的mac地址和net1中的arp缓存是对应上的。\n\n# ip netns exec net3 ip -d link show veth0\n34: veth0@if33: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000\n    link/ether 02:fd:f9:7f:61:a7 brd ff:ff:ff:ff:ff:ff link-netnsid 0 promiscuity 0 minmtu 68 maxmtu 65535 \n    veth addrgenmode eui64 numtxqueues 8 numrxqueues 8 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n查看fdb表，新增了net3的mac地址和Node2的IP地址映射关系\n\n# bridge fdb | grep vxlan0\n02:fd:f9:7f:61:a7 dev vxlan0 dst 10.65.132.188 self\n\n\n1\n2\n\n\n\n# 巨人的肩膀\n\n * 《kubernetes网络权威指南》",normalizedContent:"# 什么是vxlan?\n\n在三层可达的网络中部署vxlan，在每个vxlan网络端点中都有一个vtep设备，负责将vxlan协议的数据包进行udp数据包的封包和解包，可以将其理解为隧道，将vxlan数据包从逻辑网络转发到物理网络\n\nvxlan使用24位的vxlan网络标识符（vni）来标识不同的虚拟网络\n\n\n\n\n# 点对点的vxlan\n\n在已经知道对端vtep所在节点，是如何进行跨节点通信的。\n\n\n\n\n# 实操\n\n在node上新增vtep设备vxlan0，创建命令如下：\n\nip link add vxlan0 type vxlan id 42 dstport 4789 remote 10.65.132.188 local 10.65.132.187 dev ens18\n\n\n1\n\n * remote是对端节点的ip\n * local是本节点ip\n * id是vni的值\n * dstport 是vtep设备的端口\n\n创建好后，需要给它配置ip并启用\n\nip a add 172.17.1.2/24 dev vxlan0\nip link set vxlan0 up\n\n\n1\n2\n\n\nvxlan0详情如下：\n\n# ip -d link show dev vxlan0\n114: vxlan0: <broadcast,multicast,up,lower_up> mtu 1450 qdisc noqueue state unknown mode default group default qlen 1000\n    link/ether 86:45:5c:56:49:42 brd ff:ff:ff:ff:ff:ff promiscuity 0 \n    vxlan id 42 remote 10.65.132.187 local 10.61.74.37 dev ens18 srcport 0 0 dstport 4789 ageing 300 noudpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n并且可以看到路由中新增一条记录，所有目的地址是172.17.1.0/24网段的包都要走vxlan0转发。\n\n# ip r\n...\n172.17.1.0/24 dev vxlan0 proto kernel scope link src 172.17.1.2\n...\n\n\n1\n2\n3\n4\n\n\n同时fdb表中新增以下记录，代表着，所有进过vxlan0包的外部udp目的地址都会设置为10.65.132.187，并从ens18网卡出去。\n\n]# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 10.65.132.187 via ens18 self permanent\n\n\n1\n2\n\n\n到这里，node1已经配置好了，我们重复上面操作设置node2，只需要将部分ip修改即可。\n\n# 将node1中remote和local反过来即可.\nip link add vxlan0 type vxlan id 42 dstport 4789 remote 10.65.132.187 dev ens18 local 10.65.132.188 dev ens18\n\n# vxlan0 地址设置为172.17.1.3/24\nip a add 172.17.1.3/24 dev vxlan0\nip link set vxlan0 up\n\n# ip -d link show vxlan0\n20: vxlan0: <broadcast,multicast,up,lower_up> mtu 1450 qdisc noqueue state unknown mode default group default qlen 1000\n    link/ether 12:09:3d:c0:97:32 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 remote 10.65.132.187 local 10.65.132.188 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 开测\n\n在node2上监听node1的udp数据包\n\ntcpdump -i ens18 udp and host 10.65.132.187 -n\n\n\n1\n\n\n然后在node1中ping node2的vtep设备地址172.17.1.3\n\n[root@k8s-master-07rf9 ~]# ping 172.17.1.3 -c 3\nping 172.17.1.3 (172.17.1.3) 56(84) bytes of data.\n64 bytes from 172.17.1.3: icmp_seq=1 ttl=64 time=0.841 ms\n64 bytes from 172.17.1.3: icmp_seq=2 ttl=64 time=0.382 ms\n64 bytes from 172.17.1.3: icmp_seq=3 ttl=64 time=0.377 ms\n\n\n1\n2\n3\n4\n5\n\n\n可以看到tcpdump抓到的数据包如下，先收到了node1的发过来封装了arp数据包的数据包，想要知道node2中vtep设备的mac地址，然后回给了node1，node1收到后，将mac地址填充，再将封装了icmp的vxlan数据包发送到node2，node2中vtep收到包并解包，最后回包给node1\n\n[root@k8s-work01-1zapn ~]# tcpdump -i ens18 udp and host 10.65.132.187 -n\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n19:23:36.705418 ip 10.65.132.187.34062 > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\narp, request who-has 172.17.1.3 tell 172.17.1.2, length 28\n19:23:36.705574 ip 10.65.132.188.20835 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\narp, reply 172.17.1.3 is-at 3a:84:39:cc:05:93, length 28\n19:23:36.705880 ip 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.2 > 172.17.1.3: icmp echo request, id 25707, seq 1, length 64\n19:23:36.705986 ip 10.65.132.188.62793 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.3 > 172.17.1.2: icmp echo reply, id 25707, seq 1, length 64\n19:23:37.708701 ip 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.2 > 172.17.1.3: icmp echo request, id 25707, seq 2, length 64\n19:23:37.708846 ip 10.65.132.188.62793 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.3 > 172.17.1.2: icmp echo reply, id 25707, seq 2, length 64\n19:23:38.732737 ip 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.2 > 172.17.1.3: icmp echo request, id 25707, seq 3, length 64\n19:23:38.732846 ip 10.65.132.188.62793 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.3 > 172.17.1.2: icmp echo reply, id 25707, seq 3, length 64\n19:23:41.804637 ip 10.65.132.188.20835 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\narp, request who-has 172.17.1.2 tell 172.17.1.3, length 28\n19:23:41.804917 ip 10.65.132.187.34062 > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\narp, reply 172.17.1.2 is-at c2:a1:4e:56:7d:eb, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# vxlan的多播模式\n\n在我们不知道vtep所在节点的情况下，并且需要使用多个vtep组建逻辑网络。\n\n\n# 通信过程\n\n\n\n 1. 在node1上通过ping node2上vxlan0设备ip，数据包通过路由到达vxlan0，vxlan0发现目的ip和源ip属于同一网段，需要知道对方的mac地址，因此需要发送arp查询报文。\n 2. arp报文中，源mac地址为node1上vxlan0的mac地址，目的mac地址为255.255.255.255也就是广播地址，并且添加vxlan头部vni=42\n 3. 因为不知道对端的vtep设备在哪台节点上，所以vxlan0会向多播地址224.1.1.1发送多播报文。\n 4. 多播组中所有的主机都会收到报文，并且内核会判断该数据包为vxlan报文，根据vni发送给vtep设备。\n 5. node2中vxlan0收到报文后，解包拿到arp报文，然后通过arp报文学习到了将node1的vxlan0的mac地址与node1 ip的映射关系记录到fdb表中，并且生成arp应答报文。\n 6. arp应答报文中，目的主机node1的mac地址和目的主机node1中vxlan0的mac地址都通过发过来的arp报文中学习到，所以可以直接通过单播进行回复。\n 7. node1收到arp回复的报文后，通过报文内容，将node2的主机地址和vxlan0的mac地址的映射关系缓存到fdb表中。\n 8. 现在双方都已经通过arp报文获得了双方的建立icmp通信的所有信息，可以直接通过通过单播进行通信。\n\n\n# 环境准备\n\n首先在node1中新增vtep设备vxlan0，vni为42，通信端口4789，主机地址为10.65.132.187，设置多播地址为224.1.1.1，数据包通过ens18真实网卡出去。\n\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.187 group 224.1.1.1 dev ens18\n\n\n1\n\n\n给vxlan0添加地址172.17.1.2/24，并把它拉起\n\nip addr add 172.17.1.2/24 dev vxlan0\nip link set vxlan0 up\n\n\n1\n2\n\n\n查看vxlan0的详细信息\n\n# ip -d link  show vxlan0\n22: vxlan0: <broadcast,multicast,up,lower_up> mtu 1450 qdisc noqueue state unknown mode default group default qlen 1000\n    link/ether 4e:92:72:79:59:ed brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 group 224.1.1.1 local 10.65.132.187 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535\n\n\n1\n2\n3\n4\n\n\n再看看fdb表，意思是，vxlan0封包的时候，默认会使用224.1.1.1作为vxlan包也就是外部udp的目的ip。\n\n# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 224.1.1.1 via ens18 self permanent\n\n\n1\n2\n\n\n在node2上重复上述操作\n\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.188 group 224.1.1.1 dev ens18\n\nip addr add 172.17.1.3/24 dev vxlan0\nip link set vxlan0 up\n\n# ip -d link show vxlan0\n11: vxlan0: <broadcast,multicast,up,lower_up> mtu 1450 qdisc noqueue state unknown mode default group default qlen 1000\n    link/ether ba:d8:43:67:8d:fb brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65535 \n    vxlan id 42 group 224.1.1.1 local 10.65.132.188 dev ens18 srcport 0 0 dstport 4789 ttl auto ageing 300 udpcsum noudp6zerocsumtx noudp6zerocsumrx addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 开始分析\n\n先使用tcpdump来监听node2中ens18网卡中来自node1的udp数据包，然后在node1上ping node2中vxlan0设备。\n\n可以看到是可以ping通的。\n\n# ping 172.17.1.3 -c 1\nping 172.17.1.3 (172.17.1.3) 56(84) bytes of data.\n64 bytes from 172.17.1.3: icmp_seq=1 ttl=64 time=0.807 ms\n\n--- 172.17.1.3 ping statistics ---\n1 packets transmitted, 1 received, 0% packet loss, time 0ms\nrtt min/avg/max/mdev = 0.807/0.807/0.807/0.000 ms\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n再来看看抓到的包：\n\n 1. 第一个数据包，可以看到node2收到了来自node1的 vxlan数据包，vni为42，目的地址是多播ip224.1.1.1，因为我们创建的vtep设备设置了该多播ip，所以会接收该数据包。且里面封装了arp数据包，需要将172.17.1.3的mac地址告诉172.17.1.2。\n 2. 第二个数据包可以看到回复了一个vxlan数据包，里面包含了arp应答包，将172.17.1.3的mac地址也就是vxlan0的地址回复过去。\n 3. 第三个数据包是node1 vxlan0根据对方的mac地址和node2的ip地址，直接单播发送包含了icmp数据包的vxlan数据包到node2\n 4. 第四个数据包时node2 vxlan0进行回复icmp，也是包裹在一个vxlan数据包中，发送到node1中。\n\n# tcpdump -i ens18 udp and host 10.65.132.187 -n\ndropped privs to tcpdump\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on ens18, link-type en10mb (ethernet), capture size 262144 bytes\n\n10:31:34.560469 ip 10.65.132.187.34062 > 224.1.1.1.vxlan: vxlan, flags [i] (0x08), vni 42\narp, request who-has 172.17.1.3 tell 172.17.1.2, length 28\n10:31:34.560616 ip 10.65.132.188.20835 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\narp, reply 172.17.1.3 is-at ba:d8:43:67:8d:fb, length 28\n10:31:34.560819 ip 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.2 > 172.17.1.3: icmp echo request, id 46810, seq 1, length 64\n10:31:34.560935 ip 10.65.132.188.62793 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.3 > 172.17.1.2: icmp echo reply, id 46810, seq 1, length 64\n10:31:39.661990 ip 10.65.132.188.20835 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\narp, request who-has 172.17.1.2 tell 172.17.1.3, length 28\n10:31:39.662329 ip 10.65.132.187.34062 > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\narp, reply 172.17.1.2 is-at 4e:92:72:79:59:ed, length 28\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n再次ping node2的vxlan0设备，通过抓包可以看到，不需要发送arp报文了，是因为node1已经缓存了arp。\n\n第一个数据包目的ip不再是224.1.1.1多播地址了，而是node2的地址。是因为vxlan0也已经缓存到fdb表中。\n\n10:49:36.712777 ip 10.65.132.187.jboss-iiop > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.2 > 172.17.1.3: icmp echo request, id 41695, seq 1, length 64\n10:49:36.712973 ip 10.65.132.188.62793 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.17.1.3 > 172.17.1.2: icmp echo reply, id 41695, seq 1, length 64\n\n\n1\n2\n3\n4\n\n\n查看arp缓存\n\n# arp | grep vxlan0\n172.17.1.3               ether   ba:d8:43:67:8d:fb   c                     vxlan0\n\n\n1\n2\n\n\n查看fdb表，添加了node2中vxlan0的mac地址和node2地址的映射表项。\n\n# bridge fdb | grep vxlan0\n00:00:00:00:00:00 dev vxlan0 dst 224.1.1.1 via ens18 self permanent\nba:d8:43:67:8d:fb dev vxlan0 dst 10.65.132.188 self\n\n\n1\n2\n3\n\n\n\n# vxlan多播模式+桥接\n\n在vxlan的多播的基础上再加上桥接网络。\n\n\n# 通信过程\n\n桥接网络模拟及通信到宿主机过程可以参考手动实现docker容器bridge网络模型\n\n数据包达到网桥后，然后再转发到vxlan0中，接下来的流程也与上面将的多播是一致的。\n\n\n\n\n# 环境准备\n\n在node1上运行如下命令准备环境\n\n# 添加vtep设备\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.187 group 224.1.1.1 dev ens18\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set vxlan0 master bridge0\nip link set vxlan0 up\nip link set bridge0 up\n\n# 添加net1模拟容器\nip netns add net1\nip link add veth0 type veth peer name veth1\nip link set dev veth0 up\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n\n# 设置net1中网络配置\nip link set dev veth0 netns net1\nip netns exec net1 ip addr add 172.19.1.2/24 dev veth0\nip netns exec net1 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n在node2中重复上面操作，将172.19.1.3/24绑定到另一个network namespace net3中\n\n# 添加vtep设备\nip link add vxlan0 type vxlan id 42 dstport 4789 local 10.65.132.188 group 224.1.1.1 dev ens18\n\n# 添加网桥\nip link add bridge0 type bridge\nip link set vxlan0 master bridge0\nip link set vxlan0 up\nip link set bridge0 up\n\n# 添加net1模拟容器\nip netns add net3\nip link add veth0 type veth peer name veth1\n\n# 将另一端绑定在网桥上\nip link set dev veth1 up\nip link set dev veth1 master bridge0\n\n# 设置net1中网络配置\nip link set dev veth0 netns net3\nip netns exec net3 ip addr add 172.19.1.3/24 dev veth0\nip netns exec net3 ip link set veth0 up\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n\n# 开始分析\n\n在node1的net1中ping node2中的net3，可以看到有回包，说明网络是通的。\n\n# ip netns exec net1 ping 172.19.1.3 -c 2\nping 172.19.1.3 (172.19.1.3) 56(84) bytes of data.\n64 bytes from 172.19.1.3: icmp_seq=1 ttl=64 time=0.992 ms\n64 bytes from 172.19.1.3: icmp_seq=2 ttl=64 time=0.605 ms\n\n\n1\n2\n3\n4\n\n\n通过监听node2的网卡ens18，抓到以下的包：\n\n 1. 首先是node1发送包含arp的udp包到多播地址224.1.1.1，因为node2是属于该多播地址，所以会接收该包，并通过vxlan0进行解包，最终拿到arp包，然后发送vxlan0的mac地址进行arp回包，也是通过封装到udp包中发送node1中，然后再通过vxlan0->bridge进入到net1中，net1中收到arp后，将node2的容器ip地址和mac地址缓存到arp中。\n\n 2. 并且在fdb表中添加一项，net3的的mac地址与node2的ip地址映射关系\n\n 3. 接下来是通过arp缓存找到mac地址并添加到icmp的ip包上，然后再将其封装到udp包中，udp的源ip是通过查询fdb表得到的，可以直接通过单播发送。\n\n7:15:47.595683 ip 10.65.132.187.34062 > 224.1.1.1.vxlan: vxlan, flags [i] (0x08), vni 42\narp, request who-has 172.19.1.3 tell 172.19.1.2, length 28\n17:15:47.595863 ip 10.65.132.188.20835 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\narp, reply 172.19.1.3 is-at 02:fd:f9:7f:61:a7, length 28\n17:15:47.596172 ip 10.65.132.187.42208 > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.19.1.2 > 172.19.1.3: icmp echo request, id 51397, seq 1, length 64\n17:15:47.596295 ip 10.65.132.188.22080 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.19.1.3 > 172.19.1.2: icmp echo reply, id 51397, seq 1, length 64\n17:15:48.596543 ip 10.65.132.187.42208 > 10.65.132.188.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.19.1.2 > 172.19.1.3: icmp echo request, id 51397, seq 2, length 64\n17:15:48.596724 ip 10.65.132.188.22080 > 10.65.132.187.vxlan: vxlan, flags [i] (0x08), vni 42\nip 172.19.1.3 > 172.19.1.2: icmp echo reply, id 51397, seq 2, length 64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n可以看到net1中已经缓存了net3的ip地址与mac地址\n\n# node1\n# ip netns exec net1 arp \naddress                  hwtype  hwaddress           flags mask            iface\n172.19.1.3               ether   02:fd:f9:7f:61:a7   c                     veth0\n\n\n1\n2\n3\n4\n\n\nnet3中的mac地址和net1中的arp缓存是对应上的。\n\n# ip netns exec net3 ip -d link show veth0\n34: veth0@if33: <broadcast,multicast,up,lower_up> mtu 1500 qdisc noqueue state up mode default group default qlen 1000\n    link/ether 02:fd:f9:7f:61:a7 brd ff:ff:ff:ff:ff:ff link-netnsid 0 promiscuity 0 minmtu 68 maxmtu 65535 \n    veth addrgenmode eui64 numtxqueues 8 numrxqueues 8 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n查看fdb表，新增了net3的mac地址和node2的ip地址映射关系\n\n# bridge fdb | grep vxlan0\n02:fd:f9:7f:61:a7 dev vxlan0 dst 10.65.132.188 self\n\n\n1\n2\n\n\n\n# 巨人的肩膀\n\n * 《kubernetes网络权威指南》",charsets:{cjk:!0},lastUpdated:"2023/06/06, 18:33:56",lastUpdatedTimestamp:1686047636e3},{title:"tcp缓存引起的日志丢失",frontmatter:{title:"tcp缓存引起的日志丢失",date:"2023-11-09T15:49:47.000Z",permalink:"/pages/36b0b2/",tags:["go","logstash","编程"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"logstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。",comment:!0,categories:["编程","go"],feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20231109171607.png"},{name:"twitter:title",content:"tcp缓存引起的日志丢失"},{name:"twitter:description",content:"logstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20231109171607.png"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/02.go/05.tcp%E7%BC%93%E5%AD%98%E5%BC%95%E8%B5%B7%E7%9A%84%E6%97%A5%E5%BF%97%E4%B8%A2%E5%A4%B1.html"},{property:"og:type",content:"article"},{property:"og:title",content:"tcp缓存引起的日志丢失"},{property:"og:description",content:"logstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20231109171607.png"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/02.go/05.tcp%E7%BC%93%E5%AD%98%E5%BC%95%E8%B5%B7%E7%9A%84%E6%97%A5%E5%BF%97%E4%B8%A2%E5%A4%B1.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-11-09T15:49:47.000Z"},{property:"article:tag",content:"go"},{property:"article:tag",content:"logstash"},{property:"article:tag",content:"编程"},{itemprop:"name",content:"tcp缓存引起的日志丢失"},{itemprop:"description",content:"logstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20231109171607.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/02.go/05.tcp%E7%BC%93%E5%AD%98%E5%BC%95%E8%B5%B7%E7%9A%84%E6%97%A5%E5%BF%97%E4%B8%A2%E5%A4%B1.html",relativePath:"04.编程/02.go/05.tcp缓存引起的日志丢失.md",key:"v-31a5e395",path:"/pages/36b0b2/",headers:[{level:2,title:"背景",slug:"背景",normalizedTitle:"背景",charIndex:2},{level:2,title:"问题排查定位",slug:"问题排查定位",normalizedTitle:"问题排查定位",charIndex:78},{level:2,title:"代码排查",slug:"代码排查",normalizedTitle:"代码排查",charIndex:1167},{level:2,title:"解决方法",slug:"解决方法",normalizedTitle:"解决方法",charIndex:2432},{level:2,title:"总结",slug:"总结",normalizedTitle:"总结",charIndex:2749}],headersStr:"背景 问题排查定位 代码排查 解决方法 总结",content:'# 背景\n\nlogstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。\n\n\n\n\n# 问题排查定位\n\n首先从logstash侧开始检查。我们先看logstash的日志，没有明显的报错信息。\n\n然后再查看logstash管道的状态。可以很明显的看到，在output管道中，in远远大于out，也就是logstash拉取的日志已经到了output管道，但是无法输出出去，并且duration_in_millis时间很长，这个代表着发出去的速率很慢，这是什么原因呢？\n\ncurl -XGET \'localhost:9600/_node/stats/pipelines/azure_event_hubs?pretty\'\n\n{\n    ...\n"outputs" : [ {\n        "id" : "99b12e190d297be5d6113d04cf10089a3dccbaef7eed0cc41515e8e5af5f4595",\n        "name" : "tcp",\n        "events" : {\n        "in" : 341,\n        "out" : 69,\n        "duration_in_millis" : 519709\n        }\n    } \n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n要么是发送方的原因，要么是接收方的原因。我先从发送方进行排查，我在output管道中，除了tcp插件外，还添加了stdout插件，也就是日志来了除了会通过tcp发送外，还会打印在标准输出中。\n\noutput {\n\n    tcp {\n        ...\n    }\n\n    stdout {}\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n然后等待一段时间，然后再查看该管道的信息，stdout插件的in和out完全相等，但tcp插件in和out还是相差甚大，也就是output管道应该没问题。\n\n我再假设proxy端有问题。日志是可以从logstash端发送到proxy端的，只是很慢，并且还有其他数据源也在往proxy端发送日志，也没有这个问题，所以我突然想到，该数据源的日志很大，会不会是这个原因导致的呢？\n\n我从上面标准输出中抓了一条日志出来，134k大小，然后我手动的用nc命令将日志发送到proxy，因为日志很大，我是将日志写入到文件，然后再用管道的方式发送的\n\ncat test.txt | nc \n\n\n1\n\n\n通过查看proxy的日志发现，其根本没有收到该条日志。那么问题原因找到了，就是因为日志太大，导致日志发生了丢失。\n\n\n# 代码排查\n\nproxy服务的是golang写的，通过查看代码，这里使用了bufio.NewScanner来循环读取连接中的数据。\n\n\tscanner := bufio.NewScanner(conn)\n\n\tfor scanner.Scan() {\n\t\t// 处理数据\n\t\tmsg := scanner.Text()\n        ...\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看NewScanner方法可以看到有一个maxTokenSize参数，然后用的默认值MaxScanTokenSize\n\nfunc NewScanner(r io.Reader) *Scanner {\n\treturn &Scanner{\n\t\tr:            r,\n\t\tsplit:        ScanLines,\n\t\tmaxTokenSize: MaxScanTokenSize,\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n再跳转，有一个初始化缓存大小startBufSize为4k和最大的缓存大小MaxScanTokenSize为64k。但是我们的日志大小为134k，已经大于最大大小了，所以无法接收到该日志，也就是因为这个原因导致了日志发生了丢失。\n\nconst (\n\tMaxScanTokenSize = 64 * 1024\n\n\tstartBufSize = 4096\n)\n\n\n1\n2\n3\n4\n5\n\n\n我们再看下Scan方法，有一段代码如下，如果拿到的数据的大小大于maxTokenSize，则会使用s.setErr(ErrTooLong)记录错误，然后返回false\n\n\nfunc (s *Scanner) Scan() bool {\n\n    ..\n    const maxInt = int(^uint(0) >> 1)\n    if len(s.buf) >= s.maxTokenSize || len(s.buf) > maxInt/2 {\n        s.setErr(ErrTooLong)\n        return false\n    }\n    newSize := len(s.buf) * 2\n    if newSize == 0 {\n        newSize = startBufSize\n    }\n    if newSize > s.maxTokenSize {\n        newSize = s.maxTokenSize\n    }\n    newBuf := make([]byte, newSize)\n    copy(newBuf, s.buf[s.start:s.end])\n    ...\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n但是我们在业务代码中，并没有判断该错误，也就是如果Scan方法虽然返回了false，循环结束了，但是并没有任何错误信息。也就是无法发现该问题。\n\n\n# 解决方法\n\n 1. 将TCP的最大缓存大小修改为配置文件可配置的，这样如果日志很大，可以修改配置增大缓存上限。库中有提供Buffer方法来设置该上限。\n\n 2. 在Scan发生错误时，打印错误日志，代码如下：\n\n\nscanner := bufio.NewScanner(conn)\n\nfor scanner.Scan() {\n    // 处理数据\n    msg := scanner.Text()\n    ...\n\nif err := scanner.Err(); err != nil {\n    log.Errorf("扫描输入时发生错误：%s", err)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 总结\n\n 1. 要提高自己的排查的手段，熟悉组件提供的排查机制，让你事半功倍。\n 2. 每一个提供的参数都至关重要，所以我们都需要有一定的理解，可以减少BUG的发生',normalizedContent:'# 背景\n\nlogstash从数据源拉取日志，然后通过tcp插件发送到proxy进程中。在业务侧发现日志量明显少了，所以有了这一次的问题排查。\n\n\n\n\n# 问题排查定位\n\n首先从logstash侧开始检查。我们先看logstash的日志，没有明显的报错信息。\n\n然后再查看logstash管道的状态。可以很明显的看到，在output管道中，in远远大于out，也就是logstash拉取的日志已经到了output管道，但是无法输出出去，并且duration_in_millis时间很长，这个代表着发出去的速率很慢，这是什么原因呢？\n\ncurl -xget \'localhost:9600/_node/stats/pipelines/azure_event_hubs?pretty\'\n\n{\n    ...\n"outputs" : [ {\n        "id" : "99b12e190d297be5d6113d04cf10089a3dccbaef7eed0cc41515e8e5af5f4595",\n        "name" : "tcp",\n        "events" : {\n        "in" : 341,\n        "out" : 69,\n        "duration_in_millis" : 519709\n        }\n    } \n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n要么是发送方的原因，要么是接收方的原因。我先从发送方进行排查，我在output管道中，除了tcp插件外，还添加了stdout插件，也就是日志来了除了会通过tcp发送外，还会打印在标准输出中。\n\noutput {\n\n    tcp {\n        ...\n    }\n\n    stdout {}\n\n}\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n然后等待一段时间，然后再查看该管道的信息，stdout插件的in和out完全相等，但tcp插件in和out还是相差甚大，也就是output管道应该没问题。\n\n我再假设proxy端有问题。日志是可以从logstash端发送到proxy端的，只是很慢，并且还有其他数据源也在往proxy端发送日志，也没有这个问题，所以我突然想到，该数据源的日志很大，会不会是这个原因导致的呢？\n\n我从上面标准输出中抓了一条日志出来，134k大小，然后我手动的用nc命令将日志发送到proxy，因为日志很大，我是将日志写入到文件，然后再用管道的方式发送的\n\ncat test.txt | nc \n\n\n1\n\n\n通过查看proxy的日志发现，其根本没有收到该条日志。那么问题原因找到了，就是因为日志太大，导致日志发生了丢失。\n\n\n# 代码排查\n\nproxy服务的是golang写的，通过查看代码，这里使用了bufio.newscanner来循环读取连接中的数据。\n\n\tscanner := bufio.newscanner(conn)\n\n\tfor scanner.scan() {\n\t\t// 处理数据\n\t\tmsg := scanner.text()\n        ...\n\n\n1\n2\n3\n4\n5\n6\n\n\n查看newscanner方法可以看到有一个maxtokensize参数，然后用的默认值maxscantokensize\n\nfunc newscanner(r io.reader) *scanner {\n\treturn &scanner{\n\t\tr:            r,\n\t\tsplit:        scanlines,\n\t\tmaxtokensize: maxscantokensize,\n\t}\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n再跳转，有一个初始化缓存大小startbufsize为4k和最大的缓存大小maxscantokensize为64k。但是我们的日志大小为134k，已经大于最大大小了，所以无法接收到该日志，也就是因为这个原因导致了日志发生了丢失。\n\nconst (\n\tmaxscantokensize = 64 * 1024\n\n\tstartbufsize = 4096\n)\n\n\n1\n2\n3\n4\n5\n\n\n我们再看下scan方法，有一段代码如下，如果拿到的数据的大小大于maxtokensize，则会使用s.seterr(errtoolong)记录错误，然后返回false\n\n\nfunc (s *scanner) scan() bool {\n\n    ..\n    const maxint = int(^uint(0) >> 1)\n    if len(s.buf) >= s.maxtokensize || len(s.buf) > maxint/2 {\n        s.seterr(errtoolong)\n        return false\n    }\n    newsize := len(s.buf) * 2\n    if newsize == 0 {\n        newsize = startbufsize\n    }\n    if newsize > s.maxtokensize {\n        newsize = s.maxtokensize\n    }\n    newbuf := make([]byte, newsize)\n    copy(newbuf, s.buf[s.start:s.end])\n    ...\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n但是我们在业务代码中，并没有判断该错误，也就是如果scan方法虽然返回了false，循环结束了，但是并没有任何错误信息。也就是无法发现该问题。\n\n\n# 解决方法\n\n 1. 将tcp的最大缓存大小修改为配置文件可配置的，这样如果日志很大，可以修改配置增大缓存上限。库中有提供buffer方法来设置该上限。\n\n 2. 在scan发生错误时，打印错误日志，代码如下：\n\n\nscanner := bufio.newscanner(conn)\n\nfor scanner.scan() {\n    // 处理数据\n    msg := scanner.text()\n    ...\n\nif err := scanner.err(); err != nil {\n    log.errorf("扫描输入时发生错误：%s", err)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 总结\n\n 1. 要提高自己的排查的手段，熟悉组件提供的排查机制，让你事半功倍。\n 2. 每一个提供的参数都至关重要，所以我们都需要有一定的理解，可以减少bug的发生',charsets:{cjk:!0},lastUpdated:"2023/11/17, 16:03:58",lastUpdatedTimestamp:1700208238e3},{title:"使用java开发logstash的filter插件",frontmatter:{title:"使用java开发logstash的filter插件",date:"2022-12-20T15:37:33.000Z",permalink:"/pages/7f16f6/",categories:["计算机","组件","其他"],tags:["组件","logstash","java"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"主要记录使用java开发logstash的filter插件的过程。",feed:{enable:!0},comment:!0,meta:[{name:"twitter:title",content:"使用java开发logstash的filter插件"},{name:"twitter:description",content:"主要记录使用java开发logstash的filter插件的过程。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/03.%E4%BD%BF%E7%94%A8java%E5%BC%80%E5%8F%91logstash%E7%9A%84filter%E6%8F%92%E4%BB%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"使用java开发logstash的filter插件"},{property:"og:description",content:"主要记录使用java开发logstash的filter插件的过程。"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/03.%E4%BD%BF%E7%94%A8java%E5%BC%80%E5%8F%91logstash%E7%9A%84filter%E6%8F%92%E4%BB%B6.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-12-20T15:37:33.000Z"},{property:"article:tag",content:"组件"},{property:"article:tag",content:"logstash"},{property:"article:tag",content:"java"},{itemprop:"name",content:"使用java开发logstash的filter插件"},{itemprop:"description",content:"主要记录使用java开发logstash的filter插件的过程。"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/03.%E4%BD%BF%E7%94%A8java%E5%BC%80%E5%8F%91logstash%E7%9A%84filter%E6%8F%92%E4%BB%B6.html",relativePath:"04.编程/09.其他/03.使用java开发logstash的filter插件.md",key:"v-e9cb914e",path:"/pages/7f16f6/",headers:[{level:2,title:"0. 前言",slug:"_0-前言",normalizedTitle:"0. 前言",charIndex:2},{level:2,title:"1. 准备开发环境",slug:"_1-准备开发环境",normalizedTitle:"1. 准备开发环境",charIndex:111},{level:2,title:"2. 编写 logstash java filter 插件",slug:"_2-编写-logstash-java-filter-插件",normalizedTitle:"2. 编写 logstash java filter 插件",charIndex:518},{level:3,title:"2.1 准备官方 demo",slug:"_2-1-准备官方-demo",normalizedTitle:"2.1 准备官方 demo",charIndex:552},{level:3,title:"2.2 开发 Filter 代码",slug:"_2-2-开发-filter-代码",normalizedTitle:"2.2 开发 filter 代码",charIndex:835},{level:2,title:"3. 单元测试",slug:"_3-单元测试",normalizedTitle:"3. 单元测试",charIndex:2129},{level:2,title:"4. 打包部署 Filter 插件",slug:"_4-打包部署-filter-插件",normalizedTitle:"4. 打包部署 filter 插件",charIndex:2368},{level:3,title:"4.1 元数据信息",slug:"_4-1-元数据信息",normalizedTitle:"4.1 元数据信息",charIndex:2390},{level:3,title:"4.2 打包任务",slug:"_4-2-打包任务",normalizedTitle:"4.2 打包任务",charIndex:2588},{level:3,title:"4.3 安装",slug:"_4-3-安装",normalizedTitle:"4.3 安装",charIndex:2659},{level:2,title:"5. 验证",slug:"_5-验证",normalizedTitle:"5. 验证",charIndex:3043},{level:2,title:"6. 相关链接",slug:"_6-相关链接",normalizedTitle:"6. 相关链接",charIndex:3700}],headersStr:"0. 前言 1. 准备开发环境 2. 编写 logstash java filter 插件 2.1 准备官方 demo 2.2 开发 Filter 代码 3. 单元测试 4. 打包部署 Filter 插件 4.1 元数据信息 4.2 打包任务 4.3 安装 5. 验证 6. 相关链接",content:'# 0. 前言\n\n在工作中遇到，logstash 中的 filter 中写了大量的解析逻辑，解析性能遇到瓶颈，所以希望将该部分的逻辑转换成 java 开发的插件，以提高解析速度。\n\n本文主要记录我开发插件的过程。\n\n\n# 1. 准备开发环境\n\n下载 logstash 源码\n\n直接可以去 logstash github 中选择自己使用的版本进行下载即可。\n\n构建 logstash\n\n将下载的 logstash 压缩包解压出来，进入 logstash 根目录下，当前路径下有 gradlew 和 gradlew.bat 两个脚本文件，前者是在 linux 下执行的，后者是在 windows 执行的脚本。\n\n假设当前环境是 windows，执行 gradlew.bat assemble 命令可以对当前模块进行构建。在这个过程中会去下载所有的依赖包到本地。等待构建完成，直至输出 BUILD SUCCESSFUL 代表构建成功。\n\n> gradlew.bat 脚本是对 gradle 的封装，在执行该命令时，会主动根据 gradle/wrapper/ 下的配置去下载 gradle 工具，然后再调用 gradle 进行构建模块\n\n\n# 2. 编写 logstash java filter 插件\n\n\n# 2.1 准备官方 demo\n\n下载 java 插件官方模板\n\n将 logstash-filter-java_filter_example 下载到本地使用，自定义开发的插件是基于该 example 进行修改的。\n\n构建插件\n\n在该项目的根目录下，创建 gradle.properties 文件，需要添加变量指定 logstash 下的 logstash-core 目录路径，使用绝对路径即可。\n\nLOGSTASH_CORE_PATH=<target_folder>/logstash-core\n\n\n1\n\n\n该变量是给 build.gradle 文件中使用的。\n\n\n# 2.2 开发 Filter 代码\n\n首先来看官方提供的 demo Filter 代码，代码路径在：src\\main\\java\\org\\logstashplugins\\JavaFilterExample.java，我们开发的插件基本是按照这个例子进行修改实现的。\n\n * 设置 pipeline 中的插件名称\n\n首先可以看到有一个注解 @LogstashPlugin(name = "java_filter_example") name 的值是指我们在 pipeline 中填写的插件名称。\n\n * 在 pipeline 中传参到插件中\n\n通过 PluginConfigSpec.stringSetting 定义变量\n\npublic static final PluginConfigSpec<String> SOURCE_CONFIG = PluginConfigSpec.stringSetting("source", "message");\n\n\n1\n\n\n再通过在构造方法中调用 get 方法即可获取到传入的值\n\nthis.sourceField = config.get(SOURCE_CONFIG);\n\n\n1\n\n\n并且需要将新增的字段添加到 configSchema 方法中并返回出去。\n\n@Override\npublic Collection<PluginConfigSpec<?>> configSchema() {\n\t// should return a list of all configuration options for this plugin\n\treturn Collections.singletonList(SOURCE_CONFIG);\n}\n\n\n1\n2\n3\n4\n5\n\n * filter 主体编码\n\n该插件的主体是 filter 方法，也就是数据的过滤走的 filter 方法，我们将想要做的解析规则实现在该方法中即可。\n\n可以看到该方法中有一个对 events 遍历的处理，每一个 Event 都是进来的每一条数据，然后对该条数据进行处理转换，最后再将转换好的 events 传出去。\n\n可以看到官方的案例是将传入的 message 字符串翻转。\n\n@Override\npublic Collection<Event> filter(Collection<Event> events, FilterMatchListener matchListener) {\n\tfor (Event e : events) {\n\t\tObject f = e.getField(sourceField);\n\t\tif (f instanceof String) {\n\t\t\te.setField(sourceField, StringUtils.reverse((String)f));\n\t\t\tmatchListener.filterMatched(e);\n\t\t}\n\t}\n\n\treturn events;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 3. 单元测试\n\n单测对插件来说至关重要，插件的规则转换流程、判断逻辑都非常多，各种类型的数据都可能导致插件出错，而插件验证需要编译、打包、安装再测试，流程较长，所以我们可以通过单测来减少以上流程的进行，在单测中就把所有的可能性都验证到，节省大量的时间。并且在后续迭代修改中，可以减少改动引发。\n\n建议可以使用 junit 的参数化单测方式，可以提高单测的效率和数量。这个需要在 build.gradle 文件中的 dependencies 添加支持参数化的库来支持。\n\n\n# 4. 打包部署 Filter 插件\n\n\n# 4.1 元数据信息\n\n我们需要在 build.gradle 文件中修改部分的插件元数据信息，像 description、authors 和 email 等字段都可以随意填写，以下字段需要注意：\n\n * group，需要和包名相同\n * pluginClass，需要和插件 Filter 的类名相同\n * pluginName，需要和 @LogstashPlugin 中的 name 相同\n\n\n# 4.2 打包任务\n\n通过执行 gradlew.bat gem 进行插件打包任务，最后会在插件根目下生成 .gem 的插件安装包文件。\n\n\n# 4.3 安装\n\n安装有在线安装和离线安装两种方式。\n\n> 注意：我们需要去官网下载可以直接使用的 logstash，而不能使用上面自己下载的 logstash 源码。\n\n在线安装\n\n在线安装会去访问 Elastic 的官网，所以需要是在线的环境。\n\n通过执行 logstash/bin 路径下的 logstash-plugin 命令进行安装，等待片刻即可安装成功。\n\nlogstash-plugin install /path/javaPlugin.gem\n\n\n1\n\n\n离线安装\n\n在某些场景下，环境是不能连接外网的，所以需要使用离线安装的方式。\n\n将生成的 gem 插件压缩到 zip 包中，然后再使用 logstash-plugin 命令进行安装。\n\nlogstash-plugin install file:///tmp/plugin.zip\n\n\n1\n\n\n\n# 5. 验证\n\n官方的插件 example 的功能是翻转字符串的功能，所以我们只需要验证该功能即可。\n\n 1. 创建一个 pipeline.conf\n\ninput {\n    # 输入一个字符串\n    generator { message => "Hello world!" count => 1 }\n}\n\nfilter {\n\t# 在插件中@LogstashPlugin配置的插件名称\n    java_filter_example {}\n}\n\noutput {\n    # 直接打印到控制台\n    stdout { }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n 2. 启动 logstash 加载上面的 pipeline.conf\n\nlogstash -f pipeline.conf\n\n\n1\n\n\n输出如下，可以看到 message 字段中的 Hello world!被翻转了。\n\n{\n\t"host" => {\n\t\t"name" => "4-sip0060"\n\t},\n\t"event" => {\n\t\t"original" => "Hello world!",\n\t\t"sequence" => 0\n\t},\n\t"@timestamp" => 2022-12-20T07:27:46.634166300Z,\n\t"@version" => "1",\n\t"message" => "!dlrow olleH"\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 6. 相关链接\n\n * How to write a Java filter plugin',normalizedContent:'# 0. 前言\n\n在工作中遇到，logstash 中的 filter 中写了大量的解析逻辑，解析性能遇到瓶颈，所以希望将该部分的逻辑转换成 java 开发的插件，以提高解析速度。\n\n本文主要记录我开发插件的过程。\n\n\n# 1. 准备开发环境\n\n下载 logstash 源码\n\n直接可以去 logstash github 中选择自己使用的版本进行下载即可。\n\n构建 logstash\n\n将下载的 logstash 压缩包解压出来，进入 logstash 根目录下，当前路径下有 gradlew 和 gradlew.bat 两个脚本文件，前者是在 linux 下执行的，后者是在 windows 执行的脚本。\n\n假设当前环境是 windows，执行 gradlew.bat assemble 命令可以对当前模块进行构建。在这个过程中会去下载所有的依赖包到本地。等待构建完成，直至输出 build successful 代表构建成功。\n\n> gradlew.bat 脚本是对 gradle 的封装，在执行该命令时，会主动根据 gradle/wrapper/ 下的配置去下载 gradle 工具，然后再调用 gradle 进行构建模块\n\n\n# 2. 编写 logstash java filter 插件\n\n\n# 2.1 准备官方 demo\n\n下载 java 插件官方模板\n\n将 logstash-filter-java_filter_example 下载到本地使用，自定义开发的插件是基于该 example 进行修改的。\n\n构建插件\n\n在该项目的根目录下，创建 gradle.properties 文件，需要添加变量指定 logstash 下的 logstash-core 目录路径，使用绝对路径即可。\n\nlogstash_core_path=<target_folder>/logstash-core\n\n\n1\n\n\n该变量是给 build.gradle 文件中使用的。\n\n\n# 2.2 开发 filter 代码\n\n首先来看官方提供的 demo filter 代码，代码路径在：src\\main\\java\\org\\logstashplugins\\javafilterexample.java，我们开发的插件基本是按照这个例子进行修改实现的。\n\n * 设置 pipeline 中的插件名称\n\n首先可以看到有一个注解 @logstashplugin(name = "java_filter_example") name 的值是指我们在 pipeline 中填写的插件名称。\n\n * 在 pipeline 中传参到插件中\n\n通过 pluginconfigspec.stringsetting 定义变量\n\npublic static final pluginconfigspec<string> source_config = pluginconfigspec.stringsetting("source", "message");\n\n\n1\n\n\n再通过在构造方法中调用 get 方法即可获取到传入的值\n\nthis.sourcefield = config.get(source_config);\n\n\n1\n\n\n并且需要将新增的字段添加到 configschema 方法中并返回出去。\n\n@override\npublic collection<pluginconfigspec<?>> configschema() {\n\t// should return a list of all configuration options for this plugin\n\treturn collections.singletonlist(source_config);\n}\n\n\n1\n2\n3\n4\n5\n\n * filter 主体编码\n\n该插件的主体是 filter 方法，也就是数据的过滤走的 filter 方法，我们将想要做的解析规则实现在该方法中即可。\n\n可以看到该方法中有一个对 events 遍历的处理，每一个 event 都是进来的每一条数据，然后对该条数据进行处理转换，最后再将转换好的 events 传出去。\n\n可以看到官方的案例是将传入的 message 字符串翻转。\n\n@override\npublic collection<event> filter(collection<event> events, filtermatchlistener matchlistener) {\n\tfor (event e : events) {\n\t\tobject f = e.getfield(sourcefield);\n\t\tif (f instanceof string) {\n\t\t\te.setfield(sourcefield, stringutils.reverse((string)f));\n\t\t\tmatchlistener.filtermatched(e);\n\t\t}\n\t}\n\n\treturn events;\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 3. 单元测试\n\n单测对插件来说至关重要，插件的规则转换流程、判断逻辑都非常多，各种类型的数据都可能导致插件出错，而插件验证需要编译、打包、安装再测试，流程较长，所以我们可以通过单测来减少以上流程的进行，在单测中就把所有的可能性都验证到，节省大量的时间。并且在后续迭代修改中，可以减少改动引发。\n\n建议可以使用 junit 的参数化单测方式，可以提高单测的效率和数量。这个需要在 build.gradle 文件中的 dependencies 添加支持参数化的库来支持。\n\n\n# 4. 打包部署 filter 插件\n\n\n# 4.1 元数据信息\n\n我们需要在 build.gradle 文件中修改部分的插件元数据信息，像 description、authors 和 email 等字段都可以随意填写，以下字段需要注意：\n\n * group，需要和包名相同\n * pluginclass，需要和插件 filter 的类名相同\n * pluginname，需要和 @logstashplugin 中的 name 相同\n\n\n# 4.2 打包任务\n\n通过执行 gradlew.bat gem 进行插件打包任务，最后会在插件根目下生成 .gem 的插件安装包文件。\n\n\n# 4.3 安装\n\n安装有在线安装和离线安装两种方式。\n\n> 注意：我们需要去官网下载可以直接使用的 logstash，而不能使用上面自己下载的 logstash 源码。\n\n在线安装\n\n在线安装会去访问 elastic 的官网，所以需要是在线的环境。\n\n通过执行 logstash/bin 路径下的 logstash-plugin 命令进行安装，等待片刻即可安装成功。\n\nlogstash-plugin install /path/javaplugin.gem\n\n\n1\n\n\n离线安装\n\n在某些场景下，环境是不能连接外网的，所以需要使用离线安装的方式。\n\n将生成的 gem 插件压缩到 zip 包中，然后再使用 logstash-plugin 命令进行安装。\n\nlogstash-plugin install file:///tmp/plugin.zip\n\n\n1\n\n\n\n# 5. 验证\n\n官方的插件 example 的功能是翻转字符串的功能，所以我们只需要验证该功能即可。\n\n 1. 创建一个 pipeline.conf\n\ninput {\n    # 输入一个字符串\n    generator { message => "hello world!" count => 1 }\n}\n\nfilter {\n\t# 在插件中@logstashplugin配置的插件名称\n    java_filter_example {}\n}\n\noutput {\n    # 直接打印到控制台\n    stdout { }\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n 2. 启动 logstash 加载上面的 pipeline.conf\n\nlogstash -f pipeline.conf\n\n\n1\n\n\n输出如下，可以看到 message 字段中的 hello world!被翻转了。\n\n{\n\t"host" => {\n\t\t"name" => "4-sip0060"\n\t},\n\t"event" => {\n\t\t"original" => "hello world!",\n\t\t"sequence" => 0\n\t},\n\t"@timestamp" => 2022-12-20t07:27:46.634166300z,\n\t"@version" => "1",\n\t"message" => "!dlrow olleh"\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 6. 相关链接\n\n * how to write a java filter plugin',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"分布式锁",frontmatter:{tags:["分布式","锁","python"],title:"分布式锁",date:"2022-09-21T10:09:01.000Z",permalink:"/pages/d91dfb/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文介绍了分布式锁遇到的问题及对应的解决方案",feed:{enable:!0},categories:["编程","其他"],comment:!0,meta:[{name:"twitter:title",content:"分布式锁"},{name:"twitter:description",content:"本文介绍了分布式锁遇到的问题及对应的解决方案"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/01.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.html"},{property:"og:type",content:"article"},{property:"og:title",content:"分布式锁"},{property:"og:description",content:"本文介绍了分布式锁遇到的问题及对应的解决方案"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/01.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-09-21T10:09:01.000Z"},{property:"article:tag",content:"分布式"},{property:"article:tag",content:"锁"},{property:"article:tag",content:"python"},{itemprop:"name",content:"分布式锁"},{itemprop:"description",content:"本文介绍了分布式锁遇到的问题及对应的解决方案"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/01.%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81.html",relativePath:"04.编程/09.其他/01.分布式锁.md",key:"v-087ac98a",path:"/pages/d91dfb/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"数据库更新问题",slug:"数据库更新问题",normalizedTitle:"数据库更新问题",charIndex:34},{level:2,title:"超卖问题",slug:"超卖问题",normalizedTitle:"超卖问题",charIndex:1789},{level:2,title:"基于mysql的乐观锁机制实现",slug:"基于mysql的乐观锁机制实现",normalizedTitle:"基于mysql的乐观锁机制实现",charIndex:3022},{level:2,title:"基于mysql的悲观锁机制实现",slug:"基于mysql的悲观锁机制实现",normalizedTitle:"基于mysql的悲观锁机制实现",charIndex:4436},{level:2,title:"redis分布式锁",slug:"redis分布式锁",normalizedTitle:"redis分布式锁",charIndex:4593},{level:3,title:"分布式锁需要解决的问题",slug:"分布式锁需要解决的问题",normalizedTitle:"分布式锁需要解决的问题",charIndex:4607},{level:3,title:"抛出问题",slug:"抛出问题",normalizedTitle:"抛出问题",charIndex:4804},{level:3,title:"redis中原子操作setnx",slug:"redis中原子操作setnx",normalizedTitle:"redis中原子操作setnx",charIndex:7150},{level:3,title:"死锁问题",slug:"死锁问题",normalizedTitle:"死锁问题",charIndex:7832},{level:3,title:"py-redis-lock和redis-py",slug:"py-redis-lock和redis-py",normalizedTitle:"py-redis-lock和redis-py",charIndex:10238},{level:3,title:"redis的分布式锁优缺点",slug:"redis的分布式锁优缺点",normalizedTitle:"redis的分布式锁优缺点",charIndex:10307}],headersStr:"前言 数据库更新问题 超卖问题 基于mysql的乐观锁机制实现 基于mysql的悲观锁机制实现 redis分布式锁 分布式锁需要解决的问题 抛出问题 redis中原子操作setnx 死锁问题 py-redis-lock和redis-py redis的分布式锁优缺点",content:'# 前言\n\n本文介绍了分布式锁遇到的问题及对应的解决方案。\n\n\n# 数据库更新问题\n\n在数据库中创建一个商品表，包含id、name、count字段，这里使用的peewee来操作数据库。\n\nfrom peewee import *\n\ndb = SqliteDatabase(\'people.db\')\n\n\nclass Goods(Model):\n    id = IntegerField()\n    count = IntegerField()\n    name = CharField()\n\n    class Meta:\n        database = db  # This model uses the "people.db" database.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n初始化数据表中数据。给id=1的商品初始化商品数量为100\n\nID   NAME      COUNT\n1    clothes   100\n\n使用两个线程消费商品卖出的场景，每次消费数量为10，当商品数量充足时，商品数量减少10。因为程序可能会在任何地方暂停运行，我们使用time.Sleep来构造程序暂停的场景。\n\nimport time\n\ndef main():\n    # 卖出的数量\n    num = 10\n\n    goods = Goods.get(Goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        goods.count -= num\n        goods.save()\n\nif __name__ == \'__main__\':\n    import threading\n\n    t1 = threading.Thread(target=main)\n    t2 = threading.Thread(target=main)\n\n    t1.start()\n    t2.start()\n    t1.join()\n    t2.join()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n运行后会发现，商品数量变成了90，这明显不符合我们的预期。两个线程都消费了10个，预期结果应该是80才对。\n\nID   NAME      COUNT\n1    clothes   90\n\n执行过程\n\n在t1线程查询到的goods的商品数量为100，保存在变量中，停止，然后t2线程开始查询，查询到的数量也是100，然后往下执行时，t1减10，调用save时是告诉数据库保存的数量为90，结束。t2线程也是100-10，save时，也是保存90。\n\n解决方案\n\n应该让数据库根据自己当前的值更新，而不是使用变量中的值进行更新。\n\n我们恢复商品的数量到100，然后修改代码如下，使用update来让数据库根据当前的值进行更新。\n\ndef main():\n    # 卖出的数量\n    num = 10\n\n    goods = Goods.get(Goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = Goods.update(count=Goods.count - num).where(Goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n运行结果符合我们的预期，商品数量变成了80。\n\nID   NAME      COUNT\n1    clothes   80\n\n\n# 超卖问题\n\n虽然解决了更新数量不一致的问题，依然没有解决商品超卖问题。商品数量依然是100，但是我们两个线程都想买99件。\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    goods = Goods.get(Goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = Goods.update(count=Goods.count - num).where(Goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n运行结果是，两个线程都成功买入，数据库表中的数量变成了-98。我们肯定期望一个线程买入成功，而另一个线程执行失败。\n\nID   NAME      COUNT\n1    clothes   -98\n\n加锁解决\n\n我们在买入之前，加一个锁，这样同时只能有一个用户在执行买入。\n\nimport threading\nR = threading.Lock()\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    R.acquire()\n    goods = Goods.get(Goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = Goods.update(count=Goods.count - num).where(Goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n    R.release()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行之后，可以看到库存为1件，只有一个线程更新成功，另一个更新失败。\n\n当前是同一个服务的两个线程中，可以拿到通一把锁，但是如果在微服务中，每一次请求因为负载均衡可能请求在不同的服务中，这两个服务甚至不在同一台服务器上，那么这个锁就失效了。\n\n这个时候需要使用分布式锁来解决该问题。 ‍\n\n\n# 基于mysql的乐观锁机制实现\n\n什么是乐观锁？\n\n乐观锁，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制，乐观锁适用于多读的应用类型，这样可以提高吞吐量\n\n实现\n\n从业务中实现乐观锁机制。\n\n在之前的Goods表中添加version字段\n\nclass Goods(Model):\n    id = IntegerField()\n    count = IntegerField()\n    name = CharField()\n    version = IntegerField()\n\n    class Meta:\n        database = db  # This model uses the "people.db" database.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n数据表如下：\n\nID   NAME      COUNT   VERSION\n1    clothes   100     1\n\n在更新条件中添加版本的判断，确认在更新库存数量时，是否有其他服务更改了该条记录，如果没有则进行更新。并且在更新库存时，给版本号+1，代表着该记录已被修改。\n\n如果没有更新成功，则一直重试，直至成功为止。\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    while True:\n        goods = Goods.get(Goods.id == 1)\n        time.sleep(random.randint(1, 3))\n        if goods.count < num:\n            print("商品数量不足")\n            break\n        else:\n            query = Goods.update(count=Goods.count - num, version=Goods.version + 1).where(Goods.id == 1,\n                                                                                           Goods.version == goods.version)\n            ok = query.execute()\n            if ok:\n                print("更新成功")\n                break\n            else:\n                print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n运行结果：\n\n更新成功\n更新失败\n商品数量不足\n\n\n1\n2\n3\n\n\n库存剩下1件，版本号更新为2，符合我们的预期。\n\nID   NAME      COUNT   VERSION\n1    clothes   1       2\n\n‍ 优点：\n\n 1. 简单\n 2. 不需要额外的组件\n\n缺点：\n\n并发高时，不断的对数据库进行查询，一样会增加数据库的压力。性能差。\n\n‍\n\n\n# 基于mysql的悲观锁机制实现\n\n悲观锁,就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。\n\n缺点：并发性不高，不建议使用\n\n\n# redis分布式锁\n\n\n# 分布式锁需要解决的问题\n\n 1. 互斥性，任何时刻只能有一个客户拥有锁，不能同时多个客户获取\n\n 2. 安全性，只有被持有该锁的用户删除，而不能被其他用户删除\n\n 3. 死锁，获取锁的客户单因为某些原因而宕机，而未能释放锁，其他客户端无法获取锁，需要有机制来避免该类问题的发生\n    \n    1. 代码异常，导致无法运行到release\n    2. 你的当前服务器网络问题-脑裂\n\n\n# 抛出问题\n\n我创建一个redis锁的类，使用acquire加锁，release解锁。\n\nclass Lock:\n    def __init__(self, name):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if not self.redis_client.get(self.name):\n            self.redis_client.set(self.name, 1)\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.get(self.name):\n                    self.redis_client.set(self.name, 1)\n                    return True\n\n    def release(self):\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n在入口处加锁，在出口处释放锁，这样同时只有一个服务能够执行更新操作。\n\ndef main():\n    # 卖出的数量\n    num = 99\n    # 商品ID\n    goods_id = 1\n\n    lock = Lock("lock:goods_{}".format(goods_id))\n    lock.acquire()\n    goods = Goods.get(Goods.id == goods_id)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = Goods.update(count=Goods.count - num).where(Goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n    lock.release()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n运行之后，发现库存的数量是-98，没有达到预期的效果。\n\nID   NAME      COUNT\n1    clothes   -98\n\n我通过打日志的方式，在redis_client.get之后和release中打日志。\n\nclass Lock:\n    def __init__(self, name):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n\n        if not self.redis_client.get(self.name):\n            print("acquire\\n")\n            self.redis_client.set(self.name, 1)\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.get(self.name):\n                    self.redis_client.set(self.name, 1)\n                    return True\n\n    def release(self):\n        print("release")\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n运行结果如下：\n\nacquireacquire\n\n更新成功\nrelease\n更新成功\nrelease\n\n\n1\n2\n3\n4\n5\n6\n\n\n在没有释放锁的时候，两个线程竟然都拿到锁了？\n\n因为，线程t1在执行redis_client.get(self.name)之后还没有redis_client.set(self.name, 1)时，线程t2也进来到这一步了，也就是两个线程同时在self.redis_client.get(self.name)和self.redis_client.set(self.name, 1)之间。\n\n我们需要保证get和set是原子性的，才能解决该问题。\n\n\n# redis中原子操作setnx\n\nredis中自带了一个原子性操作setnx，可以进行查询并更新。\n\nclass Lock:\n    def __init__(self, name):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n#       # 如果不存在，设置值为1，返回1. 否则返回0. 原子操作。\n        if self.redis_client.setnx(self.name, 1):\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.setnx(self.name, 1):\n                    return True\n\n    def release(self):\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n运行后，库存数量为1，符合我们的预期。\n\nID   NAME      COUNT\n1    clothes   1\n\n\n# 死锁问题\n\n获取锁的客户单因为某些原因而宕机，而未能释放锁，其他客户端无法获取锁，需要有机制来避免该类问题的发生\n\n 1. 代码异常，导致无法运行到release\n 2. 断点\n\n‍ 解决方案：\n\n通过设置过期时间来解决，每次在拿锁时，给redis中对应的key设置一个过期时间，即使出现上面的问题，key也能自动被删除，解决死锁问题。\n\nclass Lock:\n    def __init__(self, name):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if self.redis_client.set(self.name, 1, nx=True, ex=15):\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, 1, nx=True, ex=15):\n                    return True\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n但是会有新问题：\n\n * 当前线程如果在一段时间后没有执行完，当前的程序没有执行完，然后key过期\n * 不安全，另一个线程进来以后会将当前的key给删掉，另一个线程删掉了本该属于我设置的值。\n\n解决方案：\n\n如果当前线程没有执行完，那我的这个线程还应该在适当的时候去续租，将过期时间重新设置。一般是在快要过期的2/3的时候去续租。定时程序可以使用另一个线程去完成。\n\nclass Lock:\n    def __init__(self, name):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if self.redis_client.set(self.name, 1, nx=True, ex=15):\n            # 启动一个线程然后去定时的刷新这个过期，这个操作最好也是使用lua脚本来完成。\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, 1, nx=True, ex=15):\n                    return True\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n‍ 如何防止我设置的值被其他的线程给删除掉?\n\n解决方法\n\n可以拿锁的时候生成一个ID，并将其设置redis中键对应的值，在删除的时候，判断从redis中拿出的值是否为该程序设置的ID，如果不是，则删除失败。\n\nclass Lock:\n    def __init__(self, name, id=None):\n        self.redis_client = redis.Redis(host="10.61.74.37")\n        self.name = name\n        self.id = id if id else str(uuid.uuid4())\n\n    def acquire(self):\n        if self.redis_client.set(self.name, self.id, nx=True, ex=15):\n            # 启动一个线程然后去定时的刷新这个过期，这个操作最好也是使用lua脚本来完成。\n            return True\n        else:\n            while True:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, self.id, nx=True, ex=15):\n                    return True\n\n    def release(self):\n        val = str(self.redis_client.get(self.name), encoding="utf8")\n        if val == self.id:\n            self.redis_client.delete(self.name)\n        else:\n            print("不能删除自己的锁")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n‍ 但是还会有新的问题，上面的release方法，get和delete redis中key分成了两个步骤，还是有可能在两者之间中断，所以需要使用redis的lua脚本来实现两者的原子操作\n\n\n# py-redis-lock和redis-py\n\n该库是开源的分布式锁py实现库，解决了上面的问题。后面有空可以分析下该库的源码。\n\n\n# redis的分布式锁优缺点\n\n优点\n\n * 性能高\n * 简单\n * redis本身使用很频繁，不需要额外维护\n\n缺点\n\n * 依赖了第三方组件\n\n * 单机的redis挂掉的可能性相对较高，需要引入哨兵机制\n\n * redis的cluster的引入会导致刚才的redis的锁会有问题 - redlock\n\n‍\n\n‍',normalizedContent:'# 前言\n\n本文介绍了分布式锁遇到的问题及对应的解决方案。\n\n\n# 数据库更新问题\n\n在数据库中创建一个商品表，包含id、name、count字段，这里使用的peewee来操作数据库。\n\nfrom peewee import *\n\ndb = sqlitedatabase(\'people.db\')\n\n\nclass goods(model):\n    id = integerfield()\n    count = integerfield()\n    name = charfield()\n\n    class meta:\n        database = db  # this model uses the "people.db" database.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n初始化数据表中数据。给id=1的商品初始化商品数量为100\n\nid   name      count\n1    clothes   100\n\n使用两个线程消费商品卖出的场景，每次消费数量为10，当商品数量充足时，商品数量减少10。因为程序可能会在任何地方暂停运行，我们使用time.sleep来构造程序暂停的场景。\n\nimport time\n\ndef main():\n    # 卖出的数量\n    num = 10\n\n    goods = goods.get(goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        goods.count -= num\n        goods.save()\n\nif __name__ == \'__main__\':\n    import threading\n\n    t1 = threading.thread(target=main)\n    t2 = threading.thread(target=main)\n\n    t1.start()\n    t2.start()\n    t1.join()\n    t2.join()\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n运行后会发现，商品数量变成了90，这明显不符合我们的预期。两个线程都消费了10个，预期结果应该是80才对。\n\nid   name      count\n1    clothes   90\n\n执行过程\n\n在t1线程查询到的goods的商品数量为100，保存在变量中，停止，然后t2线程开始查询，查询到的数量也是100，然后往下执行时，t1减10，调用save时是告诉数据库保存的数量为90，结束。t2线程也是100-10，save时，也是保存90。\n\n解决方案\n\n应该让数据库根据自己当前的值更新，而不是使用变量中的值进行更新。\n\n我们恢复商品的数量到100，然后修改代码如下，使用update来让数据库根据当前的值进行更新。\n\ndef main():\n    # 卖出的数量\n    num = 10\n\n    goods = goods.get(goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = goods.update(count=goods.count - num).where(goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n运行结果符合我们的预期，商品数量变成了80。\n\nid   name      count\n1    clothes   80\n\n\n# 超卖问题\n\n虽然解决了更新数量不一致的问题，依然没有解决商品超卖问题。商品数量依然是100，但是我们两个线程都想买99件。\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    goods = goods.get(goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = goods.update(count=goods.count - num).where(goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n运行结果是，两个线程都成功买入，数据库表中的数量变成了-98。我们肯定期望一个线程买入成功，而另一个线程执行失败。\n\nid   name      count\n1    clothes   -98\n\n加锁解决\n\n我们在买入之前，加一个锁，这样同时只能有一个用户在执行买入。\n\nimport threading\nr = threading.lock()\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    r.acquire()\n    goods = goods.get(goods.id == 1)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = goods.update(count=goods.count - num).where(goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n\n    r.release()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n运行之后，可以看到库存为1件，只有一个线程更新成功，另一个更新失败。\n\n当前是同一个服务的两个线程中，可以拿到通一把锁，但是如果在微服务中，每一次请求因为负载均衡可能请求在不同的服务中，这两个服务甚至不在同一台服务器上，那么这个锁就失效了。\n\n这个时候需要使用分布式锁来解决该问题。 ‍\n\n\n# 基于mysql的乐观锁机制实现\n\n什么是乐观锁？\n\n乐观锁，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制，乐观锁适用于多读的应用类型，这样可以提高吞吐量\n\n实现\n\n从业务中实现乐观锁机制。\n\n在之前的goods表中添加version字段\n\nclass goods(model):\n    id = integerfield()\n    count = integerfield()\n    name = charfield()\n    version = integerfield()\n\n    class meta:\n        database = db  # this model uses the "people.db" database.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n数据表如下：\n\nid   name      count   version\n1    clothes   100     1\n\n在更新条件中添加版本的判断，确认在更新库存数量时，是否有其他服务更改了该条记录，如果没有则进行更新。并且在更新库存时，给版本号+1，代表着该记录已被修改。\n\n如果没有更新成功，则一直重试，直至成功为止。\n\ndef main():\n    # 卖出的数量\n    num = 99\n\n    while true:\n        goods = goods.get(goods.id == 1)\n        time.sleep(random.randint(1, 3))\n        if goods.count < num:\n            print("商品数量不足")\n            break\n        else:\n            query = goods.update(count=goods.count - num, version=goods.version + 1).where(goods.id == 1,\n                                                                                           goods.version == goods.version)\n            ok = query.execute()\n            if ok:\n                print("更新成功")\n                break\n            else:\n                print("更新失败")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n运行结果：\n\n更新成功\n更新失败\n商品数量不足\n\n\n1\n2\n3\n\n\n库存剩下1件，版本号更新为2，符合我们的预期。\n\nid   name      count   version\n1    clothes   1       2\n\n‍ 优点：\n\n 1. 简单\n 2. 不需要额外的组件\n\n缺点：\n\n并发高时，不断的对数据库进行查询，一样会增加数据库的压力。性能差。\n\n‍\n\n\n# 基于mysql的悲观锁机制实现\n\n悲观锁,就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。\n\n缺点：并发性不高，不建议使用\n\n\n# redis分布式锁\n\n\n# 分布式锁需要解决的问题\n\n 1. 互斥性，任何时刻只能有一个客户拥有锁，不能同时多个客户获取\n\n 2. 安全性，只有被持有该锁的用户删除，而不能被其他用户删除\n\n 3. 死锁，获取锁的客户单因为某些原因而宕机，而未能释放锁，其他客户端无法获取锁，需要有机制来避免该类问题的发生\n    \n    1. 代码异常，导致无法运行到release\n    2. 你的当前服务器网络问题-脑裂\n\n\n# 抛出问题\n\n我创建一个redis锁的类，使用acquire加锁，release解锁。\n\nclass lock:\n    def __init__(self, name):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if not self.redis_client.get(self.name):\n            self.redis_client.set(self.name, 1)\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.get(self.name):\n                    self.redis_client.set(self.name, 1)\n                    return true\n\n    def release(self):\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n在入口处加锁，在出口处释放锁，这样同时只有一个服务能够执行更新操作。\n\ndef main():\n    # 卖出的数量\n    num = 99\n    # 商品id\n    goods_id = 1\n\n    lock = lock("lock:goods_{}".format(goods_id))\n    lock.acquire()\n    goods = goods.get(goods.id == goods_id)\n    time.sleep(random.randint(1, 3))\n    if goods.count < num:\n        print("商品数量不足")\n    else:\n        query = goods.update(count=goods.count - num).where(goods.id == 1)\n        ok = query.execute()\n        if ok:\n            print("更新成功")\n        else:\n            print("更新失败")\n    lock.release()\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n运行之后，发现库存的数量是-98，没有达到预期的效果。\n\nid   name      count\n1    clothes   -98\n\n我通过打日志的方式，在redis_client.get之后和release中打日志。\n\nclass lock:\n    def __init__(self, name):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n\n        if not self.redis_client.get(self.name):\n            print("acquire\\n")\n            self.redis_client.set(self.name, 1)\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.get(self.name):\n                    self.redis_client.set(self.name, 1)\n                    return true\n\n    def release(self):\n        print("release")\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n\n\n运行结果如下：\n\nacquireacquire\n\n更新成功\nrelease\n更新成功\nrelease\n\n\n1\n2\n3\n4\n5\n6\n\n\n在没有释放锁的时候，两个线程竟然都拿到锁了？\n\n因为，线程t1在执行redis_client.get(self.name)之后还没有redis_client.set(self.name, 1)时，线程t2也进来到这一步了，也就是两个线程同时在self.redis_client.get(self.name)和self.redis_client.set(self.name, 1)之间。\n\n我们需要保证get和set是原子性的，才能解决该问题。\n\n\n# redis中原子操作setnx\n\nredis中自带了一个原子性操作setnx，可以进行查询并更新。\n\nclass lock:\n    def __init__(self, name):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n#       # 如果不存在，设置值为1，返回1. 否则返回0. 原子操作。\n        if self.redis_client.setnx(self.name, 1):\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.setnx(self.name, 1):\n                    return true\n\n    def release(self):\n        self.redis_client.delete(self.name)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n运行后，库存数量为1，符合我们的预期。\n\nid   name      count\n1    clothes   1\n\n\n# 死锁问题\n\n获取锁的客户单因为某些原因而宕机，而未能释放锁，其他客户端无法获取锁，需要有机制来避免该类问题的发生\n\n 1. 代码异常，导致无法运行到release\n 2. 断点\n\n‍ 解决方案：\n\n通过设置过期时间来解决，每次在拿锁时，给redis中对应的key设置一个过期时间，即使出现上面的问题，key也能自动被删除，解决死锁问题。\n\nclass lock:\n    def __init__(self, name):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if self.redis_client.set(self.name, 1, nx=true, ex=15):\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, 1, nx=true, ex=15):\n                    return true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n\n但是会有新问题：\n\n * 当前线程如果在一段时间后没有执行完，当前的程序没有执行完，然后key过期\n * 不安全，另一个线程进来以后会将当前的key给删掉，另一个线程删掉了本该属于我设置的值。\n\n解决方案：\n\n如果当前线程没有执行完，那我的这个线程还应该在适当的时候去续租，将过期时间重新设置。一般是在快要过期的2/3的时候去续租。定时程序可以使用另一个线程去完成。\n\nclass lock:\n    def __init__(self, name):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n\n    def acquire(self):\n        if self.redis_client.set(self.name, 1, nx=true, ex=15):\n            # 启动一个线程然后去定时的刷新这个过期，这个操作最好也是使用lua脚本来完成。\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, 1, nx=true, ex=15):\n                    return true\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n‍ 如何防止我设置的值被其他的线程给删除掉?\n\n解决方法\n\n可以拿锁的时候生成一个id，并将其设置redis中键对应的值，在删除的时候，判断从redis中拿出的值是否为该程序设置的id，如果不是，则删除失败。\n\nclass lock:\n    def __init__(self, name, id=none):\n        self.redis_client = redis.redis(host="10.61.74.37")\n        self.name = name\n        self.id = id if id else str(uuid.uuid4())\n\n    def acquire(self):\n        if self.redis_client.set(self.name, self.id, nx=true, ex=15):\n            # 启动一个线程然后去定时的刷新这个过期，这个操作最好也是使用lua脚本来完成。\n            return true\n        else:\n            while true:\n                import time\n                time.sleep(1)\n                if self.redis_client.set(self.name, self.id, nx=true, ex=15):\n                    return true\n\n    def release(self):\n        val = str(self.redis_client.get(self.name), encoding="utf8")\n        if val == self.id:\n            self.redis_client.delete(self.name)\n        else:\n            print("不能删除自己的锁")\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n\n\n‍ 但是还会有新的问题，上面的release方法，get和delete redis中key分成了两个步骤，还是有可能在两者之间中断，所以需要使用redis的lua脚本来实现两者的原子操作\n\n\n# py-redis-lock和redis-py\n\n该库是开源的分布式锁py实现库，解决了上面的问题。后面有空可以分析下该库的源码。\n\n\n# redis的分布式锁优缺点\n\n优点\n\n * 性能高\n * 简单\n * redis本身使用很频繁，不需要额外维护\n\n缺点\n\n * 依赖了第三方组件\n\n * 单机的redis挂掉的可能性相对较高，需要引入哨兵机制\n\n * redis的cluster的引入会导致刚才的redis的锁会有问题 - redlock\n\n‍\n\n‍',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"count的性能优化",frontmatter:{title:"count的性能优化",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/19cfb6/",tags:["性能问题","sql","clickhouse"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"遇到的sql查询语句中发现的count性能优化的问题",feed:{enable:!0},categories:["编程","其他"],comment:!0,meta:[{name:"twitter:title",content:"count的性能优化"},{name:"twitter:description",content:"遇到的sql查询语句中发现的count性能优化的问题"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/20.count%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.html"},{property:"og:type",content:"article"},{property:"og:title",content:"count的性能优化"},{property:"og:description",content:"遇到的sql查询语句中发现的count性能优化的问题"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/20.count%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"性能问题"},{property:"article:tag",content:"sql"},{property:"article:tag",content:"clickhouse"},{itemprop:"name",content:"count的性能优化"},{itemprop:"description",content:"遇到的sql查询语句中发现的count性能优化的问题"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/20.count%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96.html",relativePath:"04.编程/09.其他/20.count的性能优化.md",key:"v-05a28fa4",path:"/pages/19cfb6/",headers:[{level:2,title:"问题",slug:"问题",normalizedTitle:"问题",charIndex:2},{level:2,title:"定位问题",slug:"定位问题",normalizedTitle:"定位问题",charIndex:77},{level:2,title:"查询分析",slug:"查询分析",normalizedTitle:"查询分析",charIndex:227}],headersStr:"问题 定位问题 查询分析",content:"# 问题\n\n今天测试给我提了BUG，发现某个查询接口超时了，超时时间为1分钟。\n\n目前的用的数据库是clickhouse，数据量大概在20亿左右\n\n\n# 定位问题\n\n我通过调试将查询数据的语句打印出来，查询语句放在数据库中执行，发现几秒就查询完成了，这个时候我就奇了怪了，后面我再仔细看接口的代码，跟踪调试后发现，除了会查询数据之外，还会执行查询数据量的语句。\n\n我将查询数量的语句打印出来，执行该语句，发现是超过1分钟的，看来是定位到问题了。\n\n\n# 查询分析\n\n语句大概是下面这样的，大概有30多张表，也就是需要union30多张表\n\nselect\n    count(*)\nfrom\n    (\n        select\n            a_field,\n            b_field,\n            c_field,\n            d_field,\n            e_field,\n            f_field\n        from\n            A\n        union\n        all\n        select\n            a_field,\n            b_field,\n            c_field,\n            d_field,\n            e_field,\n            f_field\n        from\n            B\n    )\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n这条语句是通过将多个表union成一个大表，然后再count求数量。\n\n问题显而易见，为啥我们要构造一张这么大的表在内存中再count数量，直接count每张表的数量再相加不就是了。优化语句如下：\n\nselect\n    count(cnt)\nfrom\n    (\n        select\n            count() as cnt\n        from\n            A\n        union\n        all\n        select\n            count() as cnt\n        from\n            B\n    )\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n将该语句放在数据库查询，秒级返回，直接从1分钟优化到1秒钟",normalizedContent:"# 问题\n\n今天测试给我提了bug，发现某个查询接口超时了，超时时间为1分钟。\n\n目前的用的数据库是clickhouse，数据量大概在20亿左右\n\n\n# 定位问题\n\n我通过调试将查询数据的语句打印出来，查询语句放在数据库中执行，发现几秒就查询完成了，这个时候我就奇了怪了，后面我再仔细看接口的代码，跟踪调试后发现，除了会查询数据之外，还会执行查询数据量的语句。\n\n我将查询数量的语句打印出来，执行该语句，发现是超过1分钟的，看来是定位到问题了。\n\n\n# 查询分析\n\n语句大概是下面这样的，大概有30多张表，也就是需要union30多张表\n\nselect\n    count(*)\nfrom\n    (\n        select\n            a_field,\n            b_field,\n            c_field,\n            d_field,\n            e_field,\n            f_field\n        from\n            a\n        union\n        all\n        select\n            a_field,\n            b_field,\n            c_field,\n            d_field,\n            e_field,\n            f_field\n        from\n            b\n    )\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n这条语句是通过将多个表union成一个大表，然后再count求数量。\n\n问题显而易见，为啥我们要构造一张这么大的表在内存中再count数量，直接count每张表的数量再相加不就是了。优化语句如下：\n\nselect\n    count(cnt)\nfrom\n    (\n        select\n            count() as cnt\n        from\n            a\n        union\n        all\n        select\n            count() as cnt\n        from\n            b\n    )\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n将该语句放在数据库查询，秒级返回，直接从1分钟优化到1秒钟",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"使用hue创建ozzie的pyspark action workflow",frontmatter:{tags:["hue","python","大数据"],title:"使用hue创建ozzie的pyspark action workflow",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/aba491/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"介绍如何使用hue来创建ozzie来创建一个spark action的owrkflow",feed:{enable:!0},categories:["编程","其他"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220907215736.png"},{name:"twitter:title",content:"使用hue创建ozzie的pyspark action workflow"},{name:"twitter:description",content:"介绍如何使用hue来创建ozzie来创建一个spark action的owrkflow"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220907215736.png"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/02.%E4%BD%BF%E7%94%A8hue%E5%88%9B%E5%BB%BAozzie%E7%9A%84pyspark%20action%20workflow.html"},{property:"og:type",content:"article"},{property:"og:title",content:"使用hue创建ozzie的pyspark action workflow"},{property:"og:description",content:"介绍如何使用hue来创建ozzie来创建一个spark action的owrkflow"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220907215736.png"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/02.%E4%BD%BF%E7%94%A8hue%E5%88%9B%E5%BB%BAozzie%E7%9A%84pyspark%20action%20workflow.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"hue"},{property:"article:tag",content:"python"},{property:"article:tag",content:"大数据"},{itemprop:"name",content:"使用hue创建ozzie的pyspark action workflow"},{itemprop:"description",content:"介绍如何使用hue来创建ozzie来创建一个spark action的owrkflow"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/20220907215736.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/09.%E5%85%B6%E4%BB%96/02.%E4%BD%BF%E7%94%A8hue%E5%88%9B%E5%BB%BAozzie%E7%9A%84pyspark%20action%20workflow.html",relativePath:"04.编程/09.其他/02.使用hue创建ozzie的pyspark action workflow.md",key:"v-8c516c3e",path:"/pages/aba491/",headersStr:null,content:'> hue是一个Apache Hadoop ui系统，本篇文章介绍如何使用hue创建一个ozzie的pyspark action的workflow, 该workflow仅包含一个spark action。注意，本文使用的是python语言的pyspark。\n\n 1. 编写一个python操作spark的程序。 demo.py\n\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession.builder.enableHiveSupport().appName(\n"demo").getOrCreate()\n\n# spark 的一些操作\n.......\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 2. 新建workflow\n\n\n\n> 传入需要运行的python脚本\n\n\n\n 3. 对该action 进行一些属性的配置。\n\n> 对spark进行设置，可以选择spark的运行模式。 默认使用的是spark1 的库去执行，如果使用的是spark2，则需要设置属性oozie.action.sharelib.for.spark=spark2 如图所示。\n\n\n\n> 进入2设置，进行一些变量的设置 oozie.libpath 需要使用到spark的一些jar包，填入路径jar包路径。\n\n\n\n 4. 该workflow已经设置成功，可以对其进行运行进行测试。',normalizedContent:'> hue是一个apache hadoop ui系统，本篇文章介绍如何使用hue创建一个ozzie的pyspark action的workflow, 该workflow仅包含一个spark action。注意，本文使用的是python语言的pyspark。\n\n 1. 编写一个python操作spark的程序。 demo.py\n\nfrom pyspark.sql import sparksession\n\nspark = sparksession.builder.enablehivesupport().appname(\n"demo").getorcreate()\n\n# spark 的一些操作\n.......\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n 2. 新建workflow\n\n\n\n> 传入需要运行的python脚本\n\n\n\n 3. 对该action 进行一些属性的配置。\n\n> 对spark进行设置，可以选择spark的运行模式。 默认使用的是spark1 的库去执行，如果使用的是spark2，则需要设置属性oozie.action.sharelib.for.spark=spark2 如图所示。\n\n\n\n> 进入2设置，进行一些变量的设置 oozie.libpath 需要使用到spark的一些jar包，填入路径jar包路径。\n\n\n\n 4. 该workflow已经设置成功，可以对其进行运行进行测试。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"关于",frontmatter:{title:"关于",date:"2019-12-25T14:27:01.000Z",permalink:"/about/",sidebar:!1,article:!1,author:{name:"lizhengyuan",link:"https://github.com/msqfx"},description:"工作年限: 5年\n职业: 软件开发工程师\n目前: 在某厂搬砖中~",comment:!0,meta:[{name:"twitter:title",content:"关于"},{name:"twitter:description",content:"工作年限: 5年\n职业: 软件开发工程师\n目前: 在某厂搬砖中~"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/08.%E5%85%B3%E4%BA%8E/01.%E5%85%B3%E4%BA%8E.html"},{property:"og:type",content:"article"},{property:"og:title",content:"关于"},{property:"og:description",content:"工作年限: 5年\n职业: 软件开发工程师\n目前: 在某厂搬砖中~"},{property:"og:url",content:"https://www.msqfx.cc/08.%E5%85%B3%E4%BA%8E/01.%E5%85%B3%E4%BA%8E.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2019-12-25T14:27:01.000Z"},{itemprop:"name",content:"关于"},{itemprop:"description",content:"工作年限: 5年\n职业: 软件开发工程师\n目前: 在某厂搬砖中~"}],readingShow:"top"},regularPath:"/08.%E5%85%B3%E4%BA%8E/01.%E5%85%B3%E4%BA%8E.html",relativePath:"08.关于/01.关于.md",key:"v-54f1c73c",path:"/about/",headers:[{level:2,title:"关于博主",slug:"关于博主",normalizedTitle:"关于博主",charIndex:2},{level:3,title:"技能清单",slug:"技能清单",normalizedTitle:"技能清单",charIndex:54},{level:3,title:"✉️ 联系",slug:"联系",normalizedTitle:"✉️ 联系",charIndex:182},{level:2,title:"关于本站",slug:"关于本站",normalizedTitle:"关于本站",charIndex:320},{level:3,title:"博客历程",slug:"博客历程",normalizedTitle:"博客历程",charIndex:349}],headersStr:"关于博主 技能清单 ✉️ 联系 关于本站 博客历程",content:"# 关于博主\n\n * 工作年限: 5年\n * 职业: 软件开发工程师\n * 目前: 在某厂搬砖中~\n\n\n# 技能清单\n\n * 编程语言: java/go\n * web框架: spring/springboot/springcloud/mybatis/gin\n * 数据库: mysql/redis/mongo/es\n * 容器技术: docker/k8s\n\n\n# ✉️ 联系\n\n * WeChat or QQ: {{ QQ }}\n * Email: lizy928@163.com\n * GitHub: https://github.com/msqfx\n * CSDN: https://blog.csdn.net/lizy928\n\n\n# 关于本站\n\n用来记录本人学习、思考及生活的的博客\n\n\n# 博客历程\n\n * 2023-01-15\n\n> 添加了waline的评论系统，方便讨论交流问题。\n\n * 2022-08-07\n\n> 决定选用vuepress作为个人博客的技术框架，并开始学习搭建。",normalizedContent:"# 关于博主\n\n * 工作年限: 5年\n * 职业: 软件开发工程师\n * 目前: 在某厂搬砖中~\n\n\n# 技能清单\n\n * 编程语言: java/go\n * web框架: spring/springboot/springcloud/mybatis/gin\n * 数据库: mysql/redis/mongo/es\n * 容器技术: docker/k8s\n\n\n# ✉️ 联系\n\n * wechat or qq: {{ qq }}\n * email: lizy928@163.com\n * github: https://github.com/msqfx\n * csdn: https://blog.csdn.net/lizy928\n\n\n# 关于本站\n\n用来记录本人学习、思考及生活的的博客\n\n\n# 博客历程\n\n * 2023-01-15\n\n> 添加了waline的评论系统，方便讨论交流问题。\n\n * 2022-08-07\n\n> 决定选用vuepress作为个人博客的技术框架，并开始学习搭建。",charsets:{cjk:!0},lastUpdated:"2023/12/16, 15:47:37",lastUpdatedTimestamp:1702712857e3},{title:"读书笔记:如何阅读一本书",frontmatter:{title:"读书笔记:如何阅读一本书",date:"2022-10-21T20:52:34.000Z",permalink:"/pages/8bdb8d/",categories:["读书破万卷"],tags:["读书"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多",feed:{enable:!0},comment:!0,meta:[{name:"twitter:title",content:"读书笔记:如何阅读一本书"},{name:"twitter:description",content:"本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/05.%E8%AF%BB%E4%B9%A6%E7%A0%B4%E4%B8%87%E5%8D%B7/01.%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"读书笔记:如何阅读一本书"},{property:"og:description",content:"本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多"},{property:"og:url",content:"https://www.msqfx.cc/05.%E8%AF%BB%E4%B9%A6%E7%A0%B4%E4%B8%87%E5%8D%B7/01.%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-10-21T20:52:34.000Z"},{property:"article:tag",content:"读书"},{itemprop:"name",content:"读书笔记:如何阅读一本书"},{itemprop:"description",content:"本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多"}],readingShow:"top"},regularPath:"/05.%E8%AF%BB%E4%B9%A6%E7%A0%B4%E4%B8%87%E5%8D%B7/01.%E5%A6%82%E4%BD%95%E9%98%85%E8%AF%BB%E4%B8%80%E6%9C%AC%E4%B9%A6.html",relativePath:"05.读书破万卷/01.如何阅读一本书.md",key:"v-567cb3a8",path:"/pages/8bdb8d/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"主动阅读",slug:"主动阅读",normalizedTitle:"主动阅读",charIndex:104},{level:2,title:"阅读的目标 ：为获得资讯而读，以及为求得理解而读",slug:"阅读的目标-为获得资讯而读-以及为求得理解而读",normalizedTitle:"阅读的目标 ：为获得资讯而读，以及为求得理解而读",charIndex:603},{level:2,title:"真正的阅读",slug:"真正的阅读",normalizedTitle:"真正的阅读",charIndex:705},{level:2,title:"指导型的学习，以及自我发现型的学习",slug:"指导型的学习-以及自我发现型的学习",normalizedTitle:"指导型的学习，以及自我发现型的学习",charIndex:750},{level:2,title:"阅读是跟着已为缺席的来势在学习",slug:"阅读是跟着已为缺席的来势在学习",normalizedTitle:"阅读是跟着已为缺席的来势在学习",charIndex:883},{level:2,title:"四个层次",slug:"四个层次",normalizedTitle:"四个层次",charIndex:38},{level:2,title:"略读",slug:"略读",normalizedTitle:"略读",charIndex:1149},{level:2,title:"阅读速度",slug:"阅读速度",normalizedTitle:"阅读速度",charIndex:1404},{level:2,title:"培养阅读的习惯",slug:"培养阅读的习惯",normalizedTitle:"培养阅读的习惯",charIndex:1551},{level:2,title:"分析阅读的规则",slug:"分析阅读的规则",normalizedTitle:"分析阅读的规则",charIndex:1977},{level:2,title:"辅助阅读",slug:"辅助阅读",normalizedTitle:"辅助阅读",charIndex:3312},{level:2,title:"阅读好书的重要性",slug:"阅读好书的重要性",normalizedTitle:"阅读好书的重要性",charIndex:3689}],headersStr:"前言 主动阅读 阅读的目标 ：为获得资讯而读，以及为求得理解而读 真正的阅读 指导型的学习，以及自我发现型的学习 阅读是跟着已为缺席的来势在学习 四个层次 略读 阅读速度 培养阅读的习惯 分析阅读的规则 辅助阅读 阅读好书的重要性",content:'# 前言\n\n本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多\n\n\n# 主动阅读\n\n作者提倡我们需要主动读书，这样我们才能对书中知识有更好的探索并收获到的会更多。\n\n像在我们阅读资讯信息的时候，不仅仅只需要知道了某件事的发生，还需要理解它发生的背后逻辑及原理进行联想，将自己以前的知识进行关联起来。这就是主动的阅读。\n\n并且我们再主动阅读时会保持大脑的思考并保持清醒的状态，那么平时昏昏欲睡的人都只是在被动的接收知识，所以注意力才无法集中起来。\n\n问题来了，我们该如何做到主动阅读呢？答案是带着问题去阅读：\n\n * 这本书在讲什么？\n * 作者仔细说了什么，如何说的，找出对应的想法、声明及论点\n * 这本书有道理嘛？是全部有道理？还是部分有道理？\n * 这本书跟自己有什么关系？自己可以学到什么？对自己有什么启示？\n\n在阅读的过程中提出除了上面几个基础的问题之外，还需要自己去提出问题，并不断的去从书寻找并回答问题。只有这样经过思考才能做到主动阅读。\n\n作者还提到了做笔记的必要性，这也是主动阅读的一个方式：\n\n * 能让自己的保持清醒\n * 是一个主动思考的过程并用言语给表达出来。\n * 将自己的感想写出来，让自己更好的理解作者的思想，并展开自己的联想。\n\n\n# 阅读的目标 ：为获得资讯而读，以及为求得理解而读\n\n我们是为了获取到作者输出的知识而读书，而不是为了读书而读书，如果读完这本书，没有理解到作者想要表达的东西，自身没有改变，那么则纯粹的浪费时间。\n\n\n# 真正的阅读\n\n不借助外力，通过自己不断的思考去阅读，从模糊的理解到更清楚的理解。\n\n\n# 指导型的学习，以及自我发现型的学习\n\n无论是指导型学习还是自我发现型学习都可以是主动的，不论是哪一种 方式，只有真正学习到的人才是主动的学习者。\n\n在指导型的学习过程中，虽然我们是被动的接收知识，看起来毫不费力，但是一样还是需要经过自己的思考才能有所获得。\n\n\n# 阅读是跟着已为缺席的来势在学习\n\n有老师时，可以回答你的问题，节省自己思考的时间，而阅读书本时，必须经过自己的思考与分析才可能有答案。\n\n\n# 四个层次\n\n作者将阅读分为四个层次：\n\n * 基础阅读，就是最基础的阅读，能认字就行，经历了九年义务教育基本就能做到。\n * 检视阅读，就是在一定的时间之内，抓住一本书的重点。\n * 分析阅读，是全盘的阅读、完整的阅读。\n * 主题阅读，阅读者通过读很多的书，然后列举这些书之间的相关之处。这种方式是最主动、也是最花力气的阅读。\n\n作者整本书主要是围绕这四个层次进行讲解分析的。\n\n\n# 略读\n\n> 你脑中的目标是要发现这本书值不值得多花时间仔细阅读。其次，就算你决定了不再多花时间仔细阅读这本书，略读也能告诉你许多跟这本书有关的事。\n\n这是略读的目标，我们通过略读可以节省时间，排除一些垃圾书。\n\n那么我们改如何进行略读呢？有以下几个方法：\n\n * 先看书名页，然后如果有序就先看序。\n * 研究目录页。\n * 如果书中附有索引，也要检阅一下。\n * 如果那是本包着书衣的新书，不妨读一下出版者的介绍。\n * 从目录页中挑选几个跟主题相关的篇章查看。\n * 将全数翻一遍，随意看个几段。\n\n\n# 阅读速度\n\n我们在检视阅读时，是需要快速地阅读的，在不值得我们花时间的地方读快一点，这个时候我们时候需要知道我们在阅读中寻找什么，这样我们才能对不同的内容使用不同的速度来进行阅读。\n\n如何提升阅读速度：将手指指向文字往后移动下去，眼睛跟着手指看下去，强迫自己的眼睛跟着手部的动作移动。\n\n\n# 培养阅读的习惯\n\n> 我们谈到一个有技术的人时，并不是在说他知道该如何去做那件事，而是他已经养成去做那件事的习惯了。\n\n当我们养成习惯后，我就能够自然的按照规则去做那件事情，有技术的人也是通过不断的训练将规则养成了习惯。\n\n我们将阅读培养成习惯后，可以提高阅读的能力与速度，最后会像走路与吃饭一样的自然。\n\n> 你一定要学会忘掉那些分开的步骤，才能表现出整体的动作，而每一个单一的步骤都还要确实表现得很好。但是，为了要忘掉这些单一的动作，一开始你必须先分别学会每一个单一的动作。只有这样，你才能将所有的动作连结起来，变成一个优秀的滑雪高手。\n\n阅读是需要多个步骤结合起来的，我们需要不断的练习锻炼单个步骤，将这些步骤变成习惯后逐渐忘记，然后自然的将所有的连接起来，最终成为一个阅读高手。这让我想到了倚天屠龙记中的张三丰教张无忌太极时的场景，先是教张无忌每一个动作，熟练之后逐渐忘记，最终将太极融会贯通，当时不太懂，现在发现这里有异曲同工之妙。\n\n\n# 分析阅读的规则\n\n> 依照书本的种类与主题作分类。\n\n不同种类的书籍的目的是不同的，比如理论性的作品是教你这是什么，而实用性的作用在教你如何去做你想做的事情。\n\n将书籍的分类并不简单，我们可以通过书名、前言和书中主题内容来区分。\n\n不同种类的书籍也需要使用的是不同的方法阅读。\n\n> 用最简短的句子说出整本书在谈些什么。\n\n如果我们知道了这本书在谈什么，我们就能揣测出作者想要干什么，并能发现这本书的主题和重点。\n\n通过给自己或他人讲述这本书说的什么，可以验证自己是否对本书整体内容有一个详细的了解。\n\n> 按照顺序与关系，列出全书的重要部分。将全书的纲要拟出来之后，再将各个部分的纲要也一一列出。\n\n心中要对书中的整体架构有一个了解，才能从多个方面去看待这本书。\n\n> 找出作者在问的问题，或作者想要解决的问题。\n\n作者写书时，肯定是带着问题或者想要解决一个问题去写的。找出这些问题能够更好的为上面两条服务。\n\n> 诠释作者使用的关键字，与作者达成共识。\n\n相同的单字会呈现出不同的意义，比如我们在谈"阅读"时，可能是为娱乐而阅读，可能是为获得咨询而阅读，也可能是为追求理解力而阅读。我们需要和作者保持一致理解，才能有共同的思想。如果我们对字句毫不用心，自然无法跟作者达成共识，也就一无所获。\n\n我们可以通过上下文中已经理解的语句在帮助自己来推敲出我们不理解的那个字的意思。\n\n> 从最重要的句子中抓出作者的重要主旨。\n\n找出语句的主旨后，需要使用自己的话语来说来验证自己到底有没有理解透彻。也可以通过到某个例子或者事情来说明主旨来验证。\n\n> 找出作者的论述，重新架构这些论述的前因后果，以明白作者的主张。\n\n> 确定作者已经解决了哪些问题，还有哪些是未解决的。在未解决的问题中，定哪些是作者认为自己无法解决的问题。\n\n> 在你说出“我同意”，“我不同意”，或“我暂缓评论”之前，你一定要能肯定地说：“我了解了。”\n\n在我们评论之前，一定是在自己已经理解的基础之上，这是对对方的基本礼貌。在我们不清楚的时候便同意对方，是愚蠢的，如果不清楚还不同意对方的，则是无礼的。只有完全理解了，才有评头论足的资格。\n\n> 当你不同意作者的观点时，要理性地表达自己的意见，不要无理地辩驳或争论。\n\n我们需要把谈话当做学习，这是一个互相学习和头脑风暴的过程，从中获取到知识，这才是目的，而不是无意义的争吵。\n\n> 尊重知识与个人观点的不同，在作任何评断之前，都要找出理论基础\n\n作者提出满足和作者辩论资格的三个规则：\n\n * 读者一定要完整的了解这本书\n * 读者不要争强好胜或盲目反驳\n * 将知识上的不同意见看做是大体上可以解决的问题\n\n我们在阅读一本书时如果有不同的意见，可以有纪律的进行辩论：\n\n * 在争辩的过程中不要带有自己的情绪，否则就不是在说理了。\n * 在争辩时需要先将前提条件或者假设条件提出来，这个是你后面所有判断的基础，你也要接受对方的假设条件，即使你们的看法完全相反，但是也需要接受。\n * 在争辩时，需要站在对方的角度去思考，这样才能是意见的交流，而不是无意义的争吵。\n\n我们在反驳作者问题的时候，一定要拿出依据来证明自己的论点才对对方的尊重。\n\n\n# 辅助阅读\n\n对于辅助阅读，建议先尽自己所能的通过内在阅读去将一本书，如果还有不懂的则需要寻找外在的帮助。\n\n对于导读，建议是在读完一本书之后再去阅读，这是因为：\n\n * 导读不一定是对的，因为这个是别人读完书之后自己的思考\n * 即使是对的，也不是一定是全面的，可能导读这也会有遗漏\n * 看导读也会限制自己的理解，并且跟着导读者的角度去思考，但没有自己的思考。\n\n这么做的话，也是有好处的：\n\n * 帮助我们诠释语句，并找出共识与主旨。\n * 自我读书的一种补充，在阅读完之后产生的问答，可以帮助你解答与理解。\n\n对于摘要的作用：\n\n * 在阅读一本书之后，可以唤醒自己的记忆\n * 在主题阅读时，可以通过摘要相关联起来。\n\n对于工具书的使用，我们需要知道自己想要找什么，哪一种工具有我们想要找的内容，并如何使用他们快速查找到你想要找的资料。\n\n\n# 阅读好书的重要性\n\n> 如果你所读的书都在你的能力范围之内，你就没法提升自己的阅读能力。你必须能操纵超越你能力的书，或像我们所说的，阅读超越你头脑的书。只有那样的书能帮助你的思想增长，除非你能增长心智，否则你学不到东西。\n\n我们需要通过检视阅读来排除掉那些坏书，才能节省时间读更多的好书。',normalizedContent:'# 前言\n\n本文是我阅读完《如何阅读一本书》的读后感，作者主要是将阅读分为了四个层次：基础阅读、检视阅读、分析阅读和主题阅读，并讲解这几个层次该如何去做，能够更好的帮助我们阅读，让我们从中收获到更多\n\n\n# 主动阅读\n\n作者提倡我们需要主动读书，这样我们才能对书中知识有更好的探索并收获到的会更多。\n\n像在我们阅读资讯信息的时候，不仅仅只需要知道了某件事的发生，还需要理解它发生的背后逻辑及原理进行联想，将自己以前的知识进行关联起来。这就是主动的阅读。\n\n并且我们再主动阅读时会保持大脑的思考并保持清醒的状态，那么平时昏昏欲睡的人都只是在被动的接收知识，所以注意力才无法集中起来。\n\n问题来了，我们该如何做到主动阅读呢？答案是带着问题去阅读：\n\n * 这本书在讲什么？\n * 作者仔细说了什么，如何说的，找出对应的想法、声明及论点\n * 这本书有道理嘛？是全部有道理？还是部分有道理？\n * 这本书跟自己有什么关系？自己可以学到什么？对自己有什么启示？\n\n在阅读的过程中提出除了上面几个基础的问题之外，还需要自己去提出问题，并不断的去从书寻找并回答问题。只有这样经过思考才能做到主动阅读。\n\n作者还提到了做笔记的必要性，这也是主动阅读的一个方式：\n\n * 能让自己的保持清醒\n * 是一个主动思考的过程并用言语给表达出来。\n * 将自己的感想写出来，让自己更好的理解作者的思想，并展开自己的联想。\n\n\n# 阅读的目标 ：为获得资讯而读，以及为求得理解而读\n\n我们是为了获取到作者输出的知识而读书，而不是为了读书而读书，如果读完这本书，没有理解到作者想要表达的东西，自身没有改变，那么则纯粹的浪费时间。\n\n\n# 真正的阅读\n\n不借助外力，通过自己不断的思考去阅读，从模糊的理解到更清楚的理解。\n\n\n# 指导型的学习，以及自我发现型的学习\n\n无论是指导型学习还是自我发现型学习都可以是主动的，不论是哪一种 方式，只有真正学习到的人才是主动的学习者。\n\n在指导型的学习过程中，虽然我们是被动的接收知识，看起来毫不费力，但是一样还是需要经过自己的思考才能有所获得。\n\n\n# 阅读是跟着已为缺席的来势在学习\n\n有老师时，可以回答你的问题，节省自己思考的时间，而阅读书本时，必须经过自己的思考与分析才可能有答案。\n\n\n# 四个层次\n\n作者将阅读分为四个层次：\n\n * 基础阅读，就是最基础的阅读，能认字就行，经历了九年义务教育基本就能做到。\n * 检视阅读，就是在一定的时间之内，抓住一本书的重点。\n * 分析阅读，是全盘的阅读、完整的阅读。\n * 主题阅读，阅读者通过读很多的书，然后列举这些书之间的相关之处。这种方式是最主动、也是最花力气的阅读。\n\n作者整本书主要是围绕这四个层次进行讲解分析的。\n\n\n# 略读\n\n> 你脑中的目标是要发现这本书值不值得多花时间仔细阅读。其次，就算你决定了不再多花时间仔细阅读这本书，略读也能告诉你许多跟这本书有关的事。\n\n这是略读的目标，我们通过略读可以节省时间，排除一些垃圾书。\n\n那么我们改如何进行略读呢？有以下几个方法：\n\n * 先看书名页，然后如果有序就先看序。\n * 研究目录页。\n * 如果书中附有索引，也要检阅一下。\n * 如果那是本包着书衣的新书，不妨读一下出版者的介绍。\n * 从目录页中挑选几个跟主题相关的篇章查看。\n * 将全数翻一遍，随意看个几段。\n\n\n# 阅读速度\n\n我们在检视阅读时，是需要快速地阅读的，在不值得我们花时间的地方读快一点，这个时候我们时候需要知道我们在阅读中寻找什么，这样我们才能对不同的内容使用不同的速度来进行阅读。\n\n如何提升阅读速度：将手指指向文字往后移动下去，眼睛跟着手指看下去，强迫自己的眼睛跟着手部的动作移动。\n\n\n# 培养阅读的习惯\n\n> 我们谈到一个有技术的人时，并不是在说他知道该如何去做那件事，而是他已经养成去做那件事的习惯了。\n\n当我们养成习惯后，我就能够自然的按照规则去做那件事情，有技术的人也是通过不断的训练将规则养成了习惯。\n\n我们将阅读培养成习惯后，可以提高阅读的能力与速度，最后会像走路与吃饭一样的自然。\n\n> 你一定要学会忘掉那些分开的步骤，才能表现出整体的动作，而每一个单一的步骤都还要确实表现得很好。但是，为了要忘掉这些单一的动作，一开始你必须先分别学会每一个单一的动作。只有这样，你才能将所有的动作连结起来，变成一个优秀的滑雪高手。\n\n阅读是需要多个步骤结合起来的，我们需要不断的练习锻炼单个步骤，将这些步骤变成习惯后逐渐忘记，然后自然的将所有的连接起来，最终成为一个阅读高手。这让我想到了倚天屠龙记中的张三丰教张无忌太极时的场景，先是教张无忌每一个动作，熟练之后逐渐忘记，最终将太极融会贯通，当时不太懂，现在发现这里有异曲同工之妙。\n\n\n# 分析阅读的规则\n\n> 依照书本的种类与主题作分类。\n\n不同种类的书籍的目的是不同的，比如理论性的作品是教你这是什么，而实用性的作用在教你如何去做你想做的事情。\n\n将书籍的分类并不简单，我们可以通过书名、前言和书中主题内容来区分。\n\n不同种类的书籍也需要使用的是不同的方法阅读。\n\n> 用最简短的句子说出整本书在谈些什么。\n\n如果我们知道了这本书在谈什么，我们就能揣测出作者想要干什么，并能发现这本书的主题和重点。\n\n通过给自己或他人讲述这本书说的什么，可以验证自己是否对本书整体内容有一个详细的了解。\n\n> 按照顺序与关系，列出全书的重要部分。将全书的纲要拟出来之后，再将各个部分的纲要也一一列出。\n\n心中要对书中的整体架构有一个了解，才能从多个方面去看待这本书。\n\n> 找出作者在问的问题，或作者想要解决的问题。\n\n作者写书时，肯定是带着问题或者想要解决一个问题去写的。找出这些问题能够更好的为上面两条服务。\n\n> 诠释作者使用的关键字，与作者达成共识。\n\n相同的单字会呈现出不同的意义，比如我们在谈"阅读"时，可能是为娱乐而阅读，可能是为获得咨询而阅读，也可能是为追求理解力而阅读。我们需要和作者保持一致理解，才能有共同的思想。如果我们对字句毫不用心，自然无法跟作者达成共识，也就一无所获。\n\n我们可以通过上下文中已经理解的语句在帮助自己来推敲出我们不理解的那个字的意思。\n\n> 从最重要的句子中抓出作者的重要主旨。\n\n找出语句的主旨后，需要使用自己的话语来说来验证自己到底有没有理解透彻。也可以通过到某个例子或者事情来说明主旨来验证。\n\n> 找出作者的论述，重新架构这些论述的前因后果，以明白作者的主张。\n\n> 确定作者已经解决了哪些问题，还有哪些是未解决的。在未解决的问题中，定哪些是作者认为自己无法解决的问题。\n\n> 在你说出“我同意”，“我不同意”，或“我暂缓评论”之前，你一定要能肯定地说：“我了解了。”\n\n在我们评论之前，一定是在自己已经理解的基础之上，这是对对方的基本礼貌。在我们不清楚的时候便同意对方，是愚蠢的，如果不清楚还不同意对方的，则是无礼的。只有完全理解了，才有评头论足的资格。\n\n> 当你不同意作者的观点时，要理性地表达自己的意见，不要无理地辩驳或争论。\n\n我们需要把谈话当做学习，这是一个互相学习和头脑风暴的过程，从中获取到知识，这才是目的，而不是无意义的争吵。\n\n> 尊重知识与个人观点的不同，在作任何评断之前，都要找出理论基础\n\n作者提出满足和作者辩论资格的三个规则：\n\n * 读者一定要完整的了解这本书\n * 读者不要争强好胜或盲目反驳\n * 将知识上的不同意见看做是大体上可以解决的问题\n\n我们在阅读一本书时如果有不同的意见，可以有纪律的进行辩论：\n\n * 在争辩的过程中不要带有自己的情绪，否则就不是在说理了。\n * 在争辩时需要先将前提条件或者假设条件提出来，这个是你后面所有判断的基础，你也要接受对方的假设条件，即使你们的看法完全相反，但是也需要接受。\n * 在争辩时，需要站在对方的角度去思考，这样才能是意见的交流，而不是无意义的争吵。\n\n我们在反驳作者问题的时候，一定要拿出依据来证明自己的论点才对对方的尊重。\n\n\n# 辅助阅读\n\n对于辅助阅读，建议先尽自己所能的通过内在阅读去将一本书，如果还有不懂的则需要寻找外在的帮助。\n\n对于导读，建议是在读完一本书之后再去阅读，这是因为：\n\n * 导读不一定是对的，因为这个是别人读完书之后自己的思考\n * 即使是对的，也不是一定是全面的，可能导读这也会有遗漏\n * 看导读也会限制自己的理解，并且跟着导读者的角度去思考，但没有自己的思考。\n\n这么做的话，也是有好处的：\n\n * 帮助我们诠释语句，并找出共识与主旨。\n * 自我读书的一种补充，在阅读完之后产生的问答，可以帮助你解答与理解。\n\n对于摘要的作用：\n\n * 在阅读一本书之后，可以唤醒自己的记忆\n * 在主题阅读时，可以通过摘要相关联起来。\n\n对于工具书的使用，我们需要知道自己想要找什么，哪一种工具有我们想要找的内容，并如何使用他们快速查找到你想要找的资料。\n\n\n# 阅读好书的重要性\n\n> 如果你所读的书都在你的能力范围之内，你就没法提升自己的阅读能力。你必须能操纵超越你能力的书，或像我们所说的，阅读超越你头脑的书。只有那样的书能帮助你的思想增长，除非你能增长心智，否则你学不到东西。\n\n我们需要通过检视阅读来排除掉那些坏书，才能节省时间读更多的好书。',charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"友链",frontmatter:{title:"友链",date:"2022-10-30T20:28:03.000Z",permalink:"/friends",categories:["更多"],tags:[null],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"desc: 开发日常\n  avatar: https://www.lllomh.com/static/images/photos.jpg\n  link: https://www.lllomh.com/\n:::",article:!1,comment:!0,meta:[{name:"twitter:title",content:"友链"},{name:"twitter:description",content:"desc: 开发日常\n  avatar: https://www.lllomh.com/static/images/photos.jpg\n  link: https://www.lllomh.com/\n:::"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/09.%E6%9B%B4%E5%A4%9A/02.%E5%8F%8B%E9%93%BE.html"},{property:"og:type",content:"article"},{property:"og:title",content:"友链"},{property:"og:description",content:"desc: 开发日常\n  avatar: https://www.lllomh.com/static/images/photos.jpg\n  link: https://www.lllomh.com/\n:::"},{property:"og:url",content:"https://www.msqfx.cc/09.%E6%9B%B4%E5%A4%9A/02.%E5%8F%8B%E9%93%BE.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-10-30T20:28:03.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"友链"},{itemprop:"description",content:"desc: 开发日常\n  avatar: https://www.lllomh.com/static/images/photos.jpg\n  link: https://www.lllomh.com/\n:::"}],readingShow:"top"},regularPath:"/09.%E6%9B%B4%E5%A4%9A/02.%E5%8F%8B%E9%93%BE.html",relativePath:"09.更多/02.友链.md",key:"v-0485a99b",path:"/friends/",headers:[{level:2,title:"友链申请",slug:"友链申请",normalizedTitle:"友链申请",charIndex:1786}],headersStr:"友链申请",content:"陌上清风的博客\n\n朝闻道,夕死可矣\n\nEvan's blog\n\n积跬步以至千里，喜欢学习喜欢你。\n\n二丫讲梵\n\n💻学习📝记录🔗分享\n\n麋鹿鲁哟\n\n大道至简，知易行难。\n\nCrayonの博客\n\n程序猿 && 二次猿\n\nCase of Xeon\n\nWelcome inside\n\n肥猫博客\n\n技术改变生活\n\nmqray's blog\n\n明日复明日，明日何其多？\n\n九弦之屋\n\n欢迎旅行者，来到这个平凡但又记载了许多故事的小屋\n\n芈渡\n\n开发日常\n\n- name: 陌上清风的博客\n  desc: '朝闻道,夕死可矣'\n  avatar: https://www.zhengwenfeng.com/img/me.jpg\n  link: https://www.zhengwenfeng.com\n  bgColor: '#f8f9fa'\n- name: Evan's blog # 昵称\n  desc: 积跬步以至千里，喜欢学习喜欢你。 # 介绍\n  avatar: https://cdn.jsdelivr.net/gh/xugaoyi/image_store/blog/20200103123203.jpg # 头像\n  link: https://xugaoyi.com/  # 链接\n  bgColor: '#f8f9fa'\n- name: 二丫讲梵\n  desc: '💻学习📝记录🔗分享'\n  avatar: https://wiki.eryajf.net/img/logo.png\n  link: https://wiki.eryajf.net\n  bgColor: '#f8f9fa'\n- name: 麋鹿鲁哟\n  desc: '大道至简，知易行难。'\n  avatar: https://pic.cnblogs.com/avatar/1273193/20190806180831.png\n  link: https://www.cnblogs.com/miluluyo/\n  bgColor: '#f8f9fa'\n- name: Crayonの博客\n  desc: '程序猿 && 二次猿'\n  avatar: http://sucrayon.top/images/avatar.jpg\n  link: http://sucrayon.top/\n  bgColor: '#f8f9fa'\n- name: Case of Xeon\n  desc: 'Welcome inside'\n  avatar: https://hexo.chensmallx.top/img/avator.jpg\n  link: https://hexo.chensmallx.top/\n  bgColor: '#f8f9fa'\n- name: 肥猫博客\n  desc: 技术改变生活\n  avatar: http://blog.mryxh.cn/favicon.ico\n  link: http://blog.mryxh.cn/\n  bgColor: '#f8f9fa'\n- name: mqray's blog\n  desc: 明日复明日，明日何其多？\n  avatar: https://mqrayblog.cn/img/avatar.png\n  link: https://mqrayblog.cn/\n- name: 九弦之屋\n  desc: 欢迎旅行者，来到这个平凡但又记载了许多故事的小屋\n  avatar: https://blog.sinzmise.top/img/avatar.png\n  link: https://blog.sinzmise.top/\n- name: 芈渡\n  desc: 开发日常\n  avatar: https://www.lllomh.com/static/images/photos.jpg\n  link: https://www.lllomh.com/\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n\n\n\n# 友链申请\n\n申请前记得先添加本站哦~\n\n * 方法一\n\n与我 联系 或者 在本页面评论区留言您的友链信息，格式：(点击代码块右上角一键复制)\n\n- name: 陌上清风的博客 # 昵称\n  desc:  朝闻道,夕死可矣 # 介绍\n  avatar: https://www.zhengwenfeng.com/img/me.jpg # 头像\n  link: https://www.zhengwenfeng.com  # 链接\n\n\n1\n2\n3\n4\n\n * 方法二\n\nfork本项目,在docs/更多/友链.md文件中，新增自己的友链，然后提交PR即可。",normalizedContent:"陌上清风的博客\n\n朝闻道,夕死可矣\n\nevan's blog\n\n积跬步以至千里，喜欢学习喜欢你。\n\n二丫讲梵\n\n💻学习📝记录🔗分享\n\n麋鹿鲁哟\n\n大道至简，知易行难。\n\ncrayonの博客\n\n程序猿 && 二次猿\n\ncase of xeon\n\nwelcome inside\n\n肥猫博客\n\n技术改变生活\n\nmqray's blog\n\n明日复明日，明日何其多？\n\n九弦之屋\n\n欢迎旅行者，来到这个平凡但又记载了许多故事的小屋\n\n芈渡\n\n开发日常\n\n- name: 陌上清风的博客\n  desc: '朝闻道,夕死可矣'\n  avatar: https://www.zhengwenfeng.com/img/me.jpg\n  link: https://www.zhengwenfeng.com\n  bgcolor: '#f8f9fa'\n- name: evan's blog # 昵称\n  desc: 积跬步以至千里，喜欢学习喜欢你。 # 介绍\n  avatar: https://cdn.jsdelivr.net/gh/xugaoyi/image_store/blog/20200103123203.jpg # 头像\n  link: https://xugaoyi.com/  # 链接\n  bgcolor: '#f8f9fa'\n- name: 二丫讲梵\n  desc: '💻学习📝记录🔗分享'\n  avatar: https://wiki.eryajf.net/img/logo.png\n  link: https://wiki.eryajf.net\n  bgcolor: '#f8f9fa'\n- name: 麋鹿鲁哟\n  desc: '大道至简，知易行难。'\n  avatar: https://pic.cnblogs.com/avatar/1273193/20190806180831.png\n  link: https://www.cnblogs.com/miluluyo/\n  bgcolor: '#f8f9fa'\n- name: crayonの博客\n  desc: '程序猿 && 二次猿'\n  avatar: http://sucrayon.top/images/avatar.jpg\n  link: http://sucrayon.top/\n  bgcolor: '#f8f9fa'\n- name: case of xeon\n  desc: 'welcome inside'\n  avatar: https://hexo.chensmallx.top/img/avator.jpg\n  link: https://hexo.chensmallx.top/\n  bgcolor: '#f8f9fa'\n- name: 肥猫博客\n  desc: 技术改变生活\n  avatar: http://blog.mryxh.cn/favicon.ico\n  link: http://blog.mryxh.cn/\n  bgcolor: '#f8f9fa'\n- name: mqray's blog\n  desc: 明日复明日，明日何其多？\n  avatar: https://mqrayblog.cn/img/avatar.png\n  link: https://mqrayblog.cn/\n- name: 九弦之屋\n  desc: 欢迎旅行者，来到这个平凡但又记载了许多故事的小屋\n  avatar: https://blog.sinzmise.top/img/avatar.png\n  link: https://blog.sinzmise.top/\n- name: 芈渡\n  desc: 开发日常\n  avatar: https://www.lllomh.com/static/images/photos.jpg\n  link: https://www.lllomh.com/\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n\n\n\n# 友链申请\n\n申请前记得先添加本站哦~\n\n * 方法一\n\n与我 联系 或者 在本页面评论区留言您的友链信息，格式：(点击代码块右上角一键复制)\n\n- name: 陌上清风的博客 # 昵称\n  desc:  朝闻道,夕死可矣 # 介绍\n  avatar: https://www.zhengwenfeng.com/img/me.jpg # 头像\n  link: https://www.zhengwenfeng.com  # 链接\n\n\n1\n2\n3\n4\n\n * 方法二\n\nfork本项目,在docs/更多/友链.md文件中，新增自己的友链，然后提交pr即可。",charsets:{cjk:!0},lastUpdated:"2024/02/18, 14:37:23",lastUpdatedTimestamp:1708238243e3},{title:"Java内存管理总结",frontmatter:{title:"Java内存管理总结",date:"2023-08-27T20:50:06.000Z",permalink:"/pages/277c5b/",author:{name:"陌上清风",link:"https://msqfx.github.io"},categories:["java","并发篇"],tags:[null],description:"",comment:!0,meta:[{name:"twitter:title",content:"Java内存管理总结"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/10.Java%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%80%BB%E7%BB%93.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Java内存管理总结"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/10.Java%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%80%BB%E7%BB%93.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-08-27T20:50:06.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"Java内存管理总结"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/01.java/03.%E5%B9%B6%E5%8F%91%E7%AF%87/10.Java%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%80%BB%E7%BB%93.html",relativePath:"01.java/03.并发篇/10.Java内存管理总结.md",key:"v-e5fb5ede",path:"/pages/277c5b/",headers:[{level:2,title:"栈内存（Stack Memory）",slug:"栈内存-stack-memory",normalizedTitle:"栈内存（stack memory）",charIndex:16},{level:2,title:"堆内存（Heap Memory）：",slug:"堆内存-heap-memory",normalizedTitle:"堆内存（heap memory）：",charIndex:158},{level:2,title:"方法区（Method Area）",slug:"方法区-method-area",normalizedTitle:"方法区（method area）",charIndex:360},{level:2,title:"其他相关知识点",slug:"其他相关知识点",normalizedTitle:"其他相关知识点",charIndex:504}],headersStr:"栈内存（Stack Memory） 堆内存（Heap Memory）： 方法区（Method Area） 其他相关知识点",content:'# Java 内存管理\n\n\n# 栈内存（Stack Memory）\n\n * 栈是线程私有的，每个线程都有自己的栈。\n * 用于存储局部变量、方法参数、返回地址以及一些基本数据类型。\n * 具有快速的分配和释放，因为采用"后进先出"（LIFO）的数据结构。\n * 栈内存的大小是有限的，一般由虚拟机预先定义。\n\n\n# 堆内存（Heap Memory）：\n\n * 用于存储对象实例和数组等动态分配的对象。\n * Java 中的垃圾回收（Garbage Collection）发生在堆内存，回收不再使用的对象。\n * 可以通过设置参数调整堆的大小，如 -Xmx（最大堆大小）和 -Xms（初始堆大小）。\n * 堆内存分为新生代（Eden、Survivor）和老年代，不同的对象生成和生命周期影响对象在不同代中的分配。\n\n\n# 方法区（Method Area）\n\n * 存储类信息、常量、静态变量、方法代码等。\n * 方法区也叫永久代（Permanent Generation），但在 Java 8 后被元空间（Metaspace）取代。\n * 元空间的大小可以根据需要动态扩展，并且可以释放未使用的内存。\n\n\n# 其他相关知识点\n\n * 值传递与引用传递：基本类型采用值传递，传递的是值的拷贝；引用类型采用引用传递，传递的是引用的地址。\n * 自动内存管理：Java 通过垃圾回收器自动管理内存，释放不再使用的对象，避免了手动释放内存的问题。\n * 内存泄漏：未释放不再使用的对象，导致内存占用不断增加，最终可能耗尽可用内存。\n * 内存溢出（Out of Memory）：申请的内存超过了虚拟机的限制，导致程序崩溃。\n * 弱引用、软引用和强引用：不同级别的引用可以影响垃圾回收时对象的生命周期。\n * 栈帧（Stack Frame）：方法在执行时会在栈上创建栈帧，用于存储局部变量、操作数栈、方法返回值等。',normalizedContent:'# java 内存管理\n\n\n# 栈内存（stack memory）\n\n * 栈是线程私有的，每个线程都有自己的栈。\n * 用于存储局部变量、方法参数、返回地址以及一些基本数据类型。\n * 具有快速的分配和释放，因为采用"后进先出"（lifo）的数据结构。\n * 栈内存的大小是有限的，一般由虚拟机预先定义。\n\n\n# 堆内存（heap memory）：\n\n * 用于存储对象实例和数组等动态分配的对象。\n * java 中的垃圾回收（garbage collection）发生在堆内存，回收不再使用的对象。\n * 可以通过设置参数调整堆的大小，如 -xmx（最大堆大小）和 -xms（初始堆大小）。\n * 堆内存分为新生代（eden、survivor）和老年代，不同的对象生成和生命周期影响对象在不同代中的分配。\n\n\n# 方法区（method area）\n\n * 存储类信息、常量、静态变量、方法代码等。\n * 方法区也叫永久代（permanent generation），但在 java 8 后被元空间（metaspace）取代。\n * 元空间的大小可以根据需要动态扩展，并且可以释放未使用的内存。\n\n\n# 其他相关知识点\n\n * 值传递与引用传递：基本类型采用值传递，传递的是值的拷贝；引用类型采用引用传递，传递的是引用的地址。\n * 自动内存管理：java 通过垃圾回收器自动管理内存，释放不再使用的对象，避免了手动释放内存的问题。\n * 内存泄漏：未释放不再使用的对象，导致内存占用不断增加，最终可能耗尽可用内存。\n * 内存溢出（out of memory）：申请的内存超过了虚拟机的限制，导致程序崩溃。\n * 弱引用、软引用和强引用：不同级别的引用可以影响垃圾回收时对象的生命周期。\n * 栈帧（stack frame）：方法在执行时会在栈上创建栈帧，用于存储局部变量、操作数栈、方法返回值等。',charsets:{cjk:!0}},{title:"理解Linux IPIP隧道",frontmatter:{title:"理解Linux IPIP隧道",date:"2023-05-26T13:11:26.000Z",permalink:"/pages/c128e7/",categories:["编程","linux"],tags:["linux","计算机网络","linux网络虚拟化"],author:{name:"msqfx",link:"https://github.com/msqfx"},description:"IPIP隧道的工作原理是将源主机的IP数据包封装在一个新的IP数据包中，新的IP数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始IP数据包，并将其传递到目标主机。IPIP隧道可以在不同的网络之间建立连接，例如在IPv4网络和IPv6网络之间建立连接。",comment:!0,feed:{enable:!0},meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_ipip-20230526095538-83tl82w.png"},{name:"twitter:title",content:"理解Linux IPIP隧道"},{name:"twitter:description",content:"IPIP隧道的工作原理是将源主机的IP数据包封装在一个新的IP数据包中，新的IP数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始IP数据包，并将其传递到目标主机。IPIP隧道可以在不同的网络之间建立连接，例如在IPv4网络和IPv6网络之间建立连接。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_ipip-20230526095538-83tl82w.png"},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/03.linux/04.%E7%90%86%E8%A7%A3Linux%20IPIP%E9%9A%A7%E9%81%93.html"},{property:"og:type",content:"article"},{property:"og:title",content:"理解Linux IPIP隧道"},{property:"og:description",content:"IPIP隧道的工作原理是将源主机的IP数据包封装在一个新的IP数据包中，新的IP数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始IP数据包，并将其传递到目标主机。IPIP隧道可以在不同的网络之间建立连接，例如在IPv4网络和IPv6网络之间建立连接。"},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_ipip-20230526095538-83tl82w.png"},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/03.linux/04.%E7%90%86%E8%A7%A3Linux%20IPIP%E9%9A%A7%E9%81%93.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2023-05-26T13:11:26.000Z"},{property:"article:tag",content:"linux"},{property:"article:tag",content:"计算机网络"},{property:"article:tag",content:"linux网络虚拟化"},{itemprop:"name",content:"理解Linux IPIP隧道"},{itemprop:"description",content:"IPIP隧道的工作原理是将源主机的IP数据包封装在一个新的IP数据包中，新的IP数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始IP数据包，并将其传递到目标主机。IPIP隧道可以在不同的网络之间建立连接，例如在IPv4网络和IPv6网络之间建立连接。"},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/c__Users_User_OneDrive_workspace_excalidraw_ipip-20230526095538-83tl82w.png"}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/03.linux/04.%E7%90%86%E8%A7%A3Linux%20IPIP%E9%9A%A7%E9%81%93.html",relativePath:"04.编程/03.linux/04.理解Linux IPIP隧道.md",key:"v-e627318a",path:"/pages/c128e7/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"使用IPIP隧道实现跨主机网络",slug:"使用ipip隧道实现跨主机网络",normalizedTitle:"使用ipip隧道实现跨主机网络",charIndex:190},{level:2,title:"巨人的肩膀",slug:"巨人的肩膀",normalizedTitle:"巨人的肩膀",charIndex:1895}],headersStr:"简介 使用IPIP隧道实现跨主机网络 巨人的肩膀",content:"# 简介\n\nIPIP隧道是一种点对点的隧道协议，用于在IPv4网络上传输IPv4或IPv6数据包。\n\nIPIP隧道的工作原理是将源主机的IP数据包封装在一个新的IP数据包中，新的IP数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始IP数据包，并将其传递到目标主机。IPIP隧道可以在不同的网络之间建立连接，例如在IPv4网络和IPv6网络之间建立连接。\n\n\n# 使用IPIP隧道实现跨主机网络\n\n\n\n首先在Node1创建tun设备并设置为ipip模式，local设置为本地IP地址10.65.132.187，remote设置为对端IP10.65.132.187，这两个是隧道外层IP，然后再设置隧道内层IP，10.10.100.10到10.10.200.10。\n\nip tunnel add tun1 mode ipip remote 10.65.132.188 local 10.65.132.187\nip link set tun1 up\nip a add 10.10.100.10 peer 10.10.200.10 dev tun1\n\n\n1\n2\n3\n\n\n可以看到添加了一条路由，发送到目的地址10.10.200.10的包都会转发到tun1设备中\n\n# ip r\n...\n10.10.200.10 dev tun1 proto kernel scope link src 10.10.100.10\n...\n\n\n1\n2\n3\n4\n\n\ntun设备会将进入的IP包封装到一个IP包中，源地址是之前设置的外层local IP，而目的地址是外层remote IP，然后再通过路由达到从ens18网卡出去到Node2中。\n\n在Node2上创建tun设备，配置和Node1一样\n\nip tunnel add tun2 mode ipip remote 10.65.132.187 local 10.65.132.188\nip link set tun2 up\nip a add 10.10.200.10 peer 10.10.100.10 dev tun2\n\n\n\n1\n2\n3\n4\n\n\n然后在Node1上ping Node2的tun设备\n\nping 10.10.200.10 -c 1\n\n\n1\n\n\n通过tcpdump在Node2抓包如下：\n\n20:16:40.011992 IP 10.65.132.187 > 10.65.132.188: IP 10.10.100.10 > 10.10.200.10: ICMP echo request, id 17609, seq 1, length 64 (ipip-proto-4)\n20:16:40.012099 IP 10.65.132.188 > 10.65.132.187: IP 10.10.200.10 > 10.10.100.10: ICMP echo reply, id 17609, seq 1, length 64 (ipip-proto-4)\n\n\n1\n2\n\n\n数据包达到Node2后，是一个两层IP数据包，从Node2的ens18网卡出来后，解封数据包，发现内层的目的IP是10.10.200.10也就是tun2的地址，然后将数据包发到tun2设备。\n\ntun2设备收到数据包后再根据上面相同步骤进行封装数据包回包给tun1，最终整个ping过程完成。\n\nIPIP隧道是通过IP地址来标识网络设备的，所以不需要使用MAC地址，直接通过IP地址即可。通过查看tun设备信息，可以看到其是不存在mac地址的。\n\n# ip -d link show tun1\n59: tun1@NONE: <POINTOPOINT,NOARP,UP,LOWER_UP> mtu 1480 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000\n    link/ipip 10.65.132.187 peer 10.65.132.188 promiscuity 0 minmtu 68 maxmtu 65515 \n    ipip ipip remote 10.65.132.188 local 10.65.132.187 ttl inherit pmtudisc addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n\n# 巨人的肩膀\n\n * 《Kubernetes网络权威指南》\n\n‍",normalizedContent:"# 简介\n\nipip隧道是一种点对点的隧道协议，用于在ipv4网络上传输ipv4或ipv6数据包。\n\nipip隧道的工作原理是将源主机的ip数据包封装在一个新的ip数据包中，新的ip数据包的目的地址是隧道的另一端。在隧道的另一端，接收方将解封装原始ip数据包，并将其传递到目标主机。ipip隧道可以在不同的网络之间建立连接，例如在ipv4网络和ipv6网络之间建立连接。\n\n\n# 使用ipip隧道实现跨主机网络\n\n\n\n首先在node1创建tun设备并设置为ipip模式，local设置为本地ip地址10.65.132.187，remote设置为对端ip10.65.132.187，这两个是隧道外层ip，然后再设置隧道内层ip，10.10.100.10到10.10.200.10。\n\nip tunnel add tun1 mode ipip remote 10.65.132.188 local 10.65.132.187\nip link set tun1 up\nip a add 10.10.100.10 peer 10.10.200.10 dev tun1\n\n\n1\n2\n3\n\n\n可以看到添加了一条路由，发送到目的地址10.10.200.10的包都会转发到tun1设备中\n\n# ip r\n...\n10.10.200.10 dev tun1 proto kernel scope link src 10.10.100.10\n...\n\n\n1\n2\n3\n4\n\n\ntun设备会将进入的ip包封装到一个ip包中，源地址是之前设置的外层local ip，而目的地址是外层remote ip，然后再通过路由达到从ens18网卡出去到node2中。\n\n在node2上创建tun设备，配置和node1一样\n\nip tunnel add tun2 mode ipip remote 10.65.132.187 local 10.65.132.188\nip link set tun2 up\nip a add 10.10.200.10 peer 10.10.100.10 dev tun2\n\n\n\n1\n2\n3\n4\n\n\n然后在node1上ping node2的tun设备\n\nping 10.10.200.10 -c 1\n\n\n1\n\n\n通过tcpdump在node2抓包如下：\n\n20:16:40.011992 ip 10.65.132.187 > 10.65.132.188: ip 10.10.100.10 > 10.10.200.10: icmp echo request, id 17609, seq 1, length 64 (ipip-proto-4)\n20:16:40.012099 ip 10.65.132.188 > 10.65.132.187: ip 10.10.200.10 > 10.10.100.10: icmp echo reply, id 17609, seq 1, length 64 (ipip-proto-4)\n\n\n1\n2\n\n\n数据包达到node2后，是一个两层ip数据包，从node2的ens18网卡出来后，解封数据包，发现内层的目的ip是10.10.200.10也就是tun2的地址，然后将数据包发到tun2设备。\n\ntun2设备收到数据包后再根据上面相同步骤进行封装数据包回包给tun1，最终整个ping过程完成。\n\nipip隧道是通过ip地址来标识网络设备的，所以不需要使用mac地址，直接通过ip地址即可。通过查看tun设备信息，可以看到其是不存在mac地址的。\n\n# ip -d link show tun1\n59: tun1@none: <pointopoint,noarp,up,lower_up> mtu 1480 qdisc noqueue state unknown mode default group default qlen 1000\n    link/ipip 10.65.132.187 peer 10.65.132.188 promiscuity 0 minmtu 68 maxmtu 65515 \n    ipip ipip remote 10.65.132.188 local 10.65.132.187 ttl inherit pmtudisc addrgenmode eui64 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n\n\n1\n2\n3\n4\n\n\n\n# 巨人的肩膀\n\n * 《kubernetes网络权威指南》\n\n‍",charsets:{cjk:!0},lastUpdated:"2023/05/26, 13:21:02",lastUpdatedTimestamp:1685078462e3},{title:"分类",frontmatter:{categoriesPage:!0,title:"分类",permalink:"/categories/",article:!1,description:"",meta:[{name:"twitter:title",content:"分类"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/@pages/categoriesPage.html"},{property:"og:type",content:"article"},{property:"og:title",content:"分类"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/@pages/categoriesPage.html"},{property:"og:site_name",content:"msqfx"},{itemprop:"name",content:"分类"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/@pages/categoriesPage.html",relativePath:"@pages/categoriesPage.md",key:"v-7ffecc44",path:"/categories/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/08/09, 07:53:30",lastUpdatedTimestamp:166000281e4},{title:"django rest_framework使用jwt",frontmatter:{tags:["python","django"],title:"django rest_framework使用jwt",date:"2022-08-10T00:00:00.000Z",permalink:"/pages/25eafd/",author:{name:"msqfx",link:"https://github.com/msqfx"},description:"本文介绍在 django rest_framework 使用jwt认证.",feed:{enable:!0},categories:["编程","python","django"],comment:!0,meta:[{name:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604218012751.jpg#alt="},{name:"twitter:title",content:"django rest_framework使用jwt"},{name:"twitter:description",content:"本文介绍在 django rest_framework 使用jwt认证."},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604218012751.jpg#alt="},{name:"twitter:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/02.django%20rest_framework%E4%BD%BF%E7%94%A8jwt.html"},{property:"og:type",content:"article"},{property:"og:title",content:"django rest_framework使用jwt"},{property:"og:description",content:"本文介绍在 django rest_framework 使用jwt认证."},{property:"og:image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604218012751.jpg#alt="},{property:"og:url",content:"https://www.msqfx.cc/04.%E7%BC%96%E7%A8%8B/01.python/06.django/02.django%20rest_framework%E4%BD%BF%E7%94%A8jwt.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2022-08-10T00:00:00.000Z"},{property:"article:tag",content:"python"},{property:"article:tag",content:"django"},{itemprop:"name",content:"django rest_framework使用jwt"},{itemprop:"description",content:"本文介绍在 django rest_framework 使用jwt认证."},{itemprop:"image",content:"https://gcore.jsdelivr.net/gh/msqfx/BLOG-CDN@main/1604218012751.jpg#alt="}],readingShow:"top"},regularPath:"/04.%E7%BC%96%E7%A8%8B/01.python/06.django/02.django%20rest_framework%E4%BD%BF%E7%94%A8jwt.html",relativePath:"04.编程/01.python/06.django/02.django rest_framework使用jwt.md",key:"v-25855433",path:"/pages/25eafd/",headers:[{level:2,title:"简介",slug:"简介",normalizedTitle:"简介",charIndex:2},{level:2,title:"相关链接",slug:"相关链接",normalizedTitle:"相关链接",charIndex:113},{level:2,title:"jwt 认证流程",slug:"jwt-认证流程",normalizedTitle:"jwt 认证流程",charIndex:126},{level:2,title:"使用",slug:"使用",normalizedTitle:"使用",charIndex:34}],headersStr:"简介 相关链接 jwt 认证流程 使用",content:"# 简介\n\n本文介绍在 django rest_framework 使用jwt认证.\n\njwt 不是 rest_framework自带的认证方式，需要通过第三方库djangorestframework-jwt结合使用\n\n\n# 相关链接\n\n官网\n\n\n# jwt 认证流程\n\n\n\n\n# 使用\n\n 0. 安装djangorestframework-jwt\n\n> pip install djangorestframework-jwt\n\n 1. 添加获取token的路由\n\nfrom rest_framework_jwt.views import obtain_jwt_token\n\nurlpatterns = [\n    re_path(r'^api-token-auth/', obtain_jwt_token),\n]\n\n\n1\n2\n3\n4\n5\n\n 2. 全局添加认证。将jwt authentication类注入到框架中\n\n访问任何的路由都会使用JSONWebTokenAuthentication.authenticate进行认证.\n\nsettings.py\n\nREST_FRAMEWORK = {\n    'DEFAULT_AUTHENTICATION_CLASSES': [\n        'rest_framework_jwt.authentication.JSONWebTokenAuthentication',\n    ]\n\n\n1\n2\n3\n4\n\n 3. 局部添加认证，在APIView中添加认证类.\n\n每次访问该视图时，都会调用JSONWebTokenAuthentication.authenticate 进行认证.\n\nclass TestView(APIView):\n    authentication_classes = (JSONWebTokenAuthentication,)\n\n    def get(self, *args, **kwargs):\n        return HttpResponse(self.request.user)\n\n\n1\n2\n3\n4\n5\n\n 4. 设置\n\nsettings.py\n\n\nJWT_AUTH = {\n    'JWT_EXPIRATION_DELTA': datetime.timedelta(minutes=30),   # 过期时间\n    'JWT_RESPONSE_PAYLOAD_HANDLER': 'user.utils.jwt_response_payload_handler'    # 默认返回的仅有`token`字段，可以由自己修改返回的数据，可以包含user.id和user.username   \n}\n\n\n1\n2\n3\n4\n5\n",normalizedContent:"# 简介\n\n本文介绍在 django rest_framework 使用jwt认证.\n\njwt 不是 rest_framework自带的认证方式，需要通过第三方库djangorestframework-jwt结合使用\n\n\n# 相关链接\n\n官网\n\n\n# jwt 认证流程\n\n\n\n\n# 使用\n\n 0. 安装djangorestframework-jwt\n\n> pip install djangorestframework-jwt\n\n 1. 添加获取token的路由\n\nfrom rest_framework_jwt.views import obtain_jwt_token\n\nurlpatterns = [\n    re_path(r'^api-token-auth/', obtain_jwt_token),\n]\n\n\n1\n2\n3\n4\n5\n\n 2. 全局添加认证。将jwt authentication类注入到框架中\n\n访问任何的路由都会使用jsonwebtokenauthentication.authenticate进行认证.\n\nsettings.py\n\nrest_framework = {\n    'default_authentication_classes': [\n        'rest_framework_jwt.authentication.jsonwebtokenauthentication',\n    ]\n\n\n1\n2\n3\n4\n\n 3. 局部添加认证，在apiview中添加认证类.\n\n每次访问该视图时，都会调用jsonwebtokenauthentication.authenticate 进行认证.\n\nclass testview(apiview):\n    authentication_classes = (jsonwebtokenauthentication,)\n\n    def get(self, *args, **kwargs):\n        return httpresponse(self.request.user)\n\n\n1\n2\n3\n4\n5\n\n 4. 设置\n\nsettings.py\n\n\njwt_auth = {\n    'jwt_expiration_delta': datetime.timedelta(minutes=30),   # 过期时间\n    'jwt_response_payload_handler': 'user.utils.jwt_response_payload_handler'    # 默认返回的仅有`token`字段，可以由自己修改返回的数据，可以包含user.id和user.username   \n}\n\n\n1\n2\n3\n4\n5\n",charsets:{cjk:!0},lastUpdated:"2023/05/01, 18:02:43",lastUpdatedTimestamp:1682935363e3},{title:"网站",frontmatter:{title:"网站",permalink:"/pages/beb6c0bd8a66cea6/",date:"2020-04-19T11:33:04.000Z",article:!1,author:{name:"xugaoyi",link:"https://github.com/xugaoyi"},description:"k8s k8s中文官网\nvuepress-theme-vdoing 一款优秀的博客主题\n技术文章摘录\n代码片段 快速查看某一门技术的代码片段",comment:!0,meta:[{name:"twitter:title",content:"网站"},{name:"twitter:description",content:"k8s k8s中文官网\nvuepress-theme-vdoing 一款优秀的博客主题\n技术文章摘录\n代码片段 快速查看某一门技术的代码片段"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/09.%E6%9B%B4%E5%A4%9A/01.%E6%94%B6%E8%97%8F.html"},{property:"og:type",content:"article"},{property:"og:title",content:"网站"},{property:"og:description",content:"k8s k8s中文官网\nvuepress-theme-vdoing 一款优秀的博客主题\n技术文章摘录\n代码片段 快速查看某一门技术的代码片段"},{property:"og:url",content:"https://www.msqfx.cc/09.%E6%9B%B4%E5%A4%9A/01.%E6%94%B6%E8%97%8F.html"},{property:"og:site_name",content:"msqfx"},{property:"article:published_time",content:"2020-04-19T11:33:04.000Z"},{itemprop:"name",content:"网站"},{itemprop:"description",content:"k8s k8s中文官网\nvuepress-theme-vdoing 一款优秀的博客主题\n技术文章摘录\n代码片段 快速查看某一门技术的代码片段"}],readingShow:"top"},regularPath:"/09.%E6%9B%B4%E5%A4%9A/01.%E6%94%B6%E8%97%8F.html",relativePath:"09.更多/01.收藏.md",key:"v-8d4bc20e",path:"/pages/beb6c0bd8a66cea6/",headers:[{level:2,title:"文档",slug:"文档",normalizedTitle:"文档",charIndex:12},{level:2,title:"golang",slug:"golang",normalizedTitle:"golang",charIndex:103},{level:2,title:"博客",slug:"博客",normalizedTitle:"博客",charIndex:61},{level:2,title:"社区",slug:"社区",normalizedTitle:"社区",charIndex:324},{level:2,title:"技巧",slug:"技巧",normalizedTitle:"技巧",charIndex:476},{level:2,title:"视频",slug:"视频",normalizedTitle:"视频",charIndex:564},{level:2,title:"算法",slug:"算法",normalizedTitle:"算法",charIndex:727},{level:2,title:"工具",slug:"工具",normalizedTitle:"工具",charIndex:747},{level:2,title:"娱乐",slug:"娱乐",normalizedTitle:"娱乐",charIndex:886}],headersStr:"文档 golang 博客 社区 技巧 视频 算法 工具 娱乐",content:"# 个人收藏夹\n\n\n# 文档\n\n * k8s k8s中文官网\n * vuepress-theme-vdoing 一款优秀的博客主题\n * 技术文章摘录\n * 代码片段 快速查看某一门技术的代码片段\n\n\n# golang\n\n * hotexamples golang代码示例网站\n\n\n# 博客\n\n * 阮一峰的网络日志\n * 韦世东的技术专栏\n * IT码农\n * 明哥\n * 崔庆才\n * 酷壳\n * 王登科-DK博客\n * 二丫讲梵\n * Crayonの博客\n * Tushar's Blog 一个国外python程序员的博客，感觉不错\n * 初探云原生\n * simpleprogrammer 《软技能-代码之外的生存指南》作者的博客\n\n\n# 社区\n\n * Github 程序员同性交友社区\n * 掘金 一个帮助开发者成长的社区\n * 简书 有很多频道的创作社区\n * 思否 解决技术问题的社区\n * stack overflow 同上，外网的\n * InfoQ 促进软件开发及相关领域知识与创新的传播\n * V2EX 创意工作者们的社区\n\n\n# 技巧\n\n * Google 趋势 查看某项技术或关键字的热度趋势，可用于分析某项技术的发展前景，或对比某两项技术的热度。\n * 百度指数 同上，但百度的数据仅限国内。\n\n\n# 视频\n\n * bilibili B站，上面很多免费教学视频\n * 慕课网 实战视频教程\n * 妙味课堂 比较系统的前端入门视频教程\n * 中国大学MOOC 涵盖计算机、外语、心理学等专业免费课程\n * 终身教育平台 涵盖生活、兴趣、职场、技能、老年、学历等免费课程\n * egghead 质量还不错的短视频教程，外网\n\n\n# 算法\n\n * leetcode\n\n\n# 工具\n\n * 微信markdown编辑器\n * ossinsight 可以看到github上用户或者仓库的数据指标\n * feeddd 微信公众号的RSS订阅源\n * ChatGPT 聊天智能AI服务，可以自动写代码。\n * corrector 一款免费的中文纠错服务\n\n\n# 娱乐\n\n * 中文播客榜\n * 异常教程 工具破解网站",normalizedContent:"# 个人收藏夹\n\n\n# 文档\n\n * k8s k8s中文官网\n * vuepress-theme-vdoing 一款优秀的博客主题\n * 技术文章摘录\n * 代码片段 快速查看某一门技术的代码片段\n\n\n# golang\n\n * hotexamples golang代码示例网站\n\n\n# 博客\n\n * 阮一峰的网络日志\n * 韦世东的技术专栏\n * it码农\n * 明哥\n * 崔庆才\n * 酷壳\n * 王登科-dk博客\n * 二丫讲梵\n * crayonの博客\n * tushar's blog 一个国外python程序员的博客，感觉不错\n * 初探云原生\n * simpleprogrammer 《软技能-代码之外的生存指南》作者的博客\n\n\n# 社区\n\n * github 程序员同性交友社区\n * 掘金 一个帮助开发者成长的社区\n * 简书 有很多频道的创作社区\n * 思否 解决技术问题的社区\n * stack overflow 同上，外网的\n * infoq 促进软件开发及相关领域知识与创新的传播\n * v2ex 创意工作者们的社区\n\n\n# 技巧\n\n * google 趋势 查看某项技术或关键字的热度趋势，可用于分析某项技术的发展前景，或对比某两项技术的热度。\n * 百度指数 同上，但百度的数据仅限国内。\n\n\n# 视频\n\n * bilibili b站，上面很多免费教学视频\n * 慕课网 实战视频教程\n * 妙味课堂 比较系统的前端入门视频教程\n * 中国大学mooc 涵盖计算机、外语、心理学等专业免费课程\n * 终身教育平台 涵盖生活、兴趣、职场、技能、老年、学历等免费课程\n * egghead 质量还不错的短视频教程，外网\n\n\n# 算法\n\n * leetcode\n\n\n# 工具\n\n * 微信markdown编辑器\n * ossinsight 可以看到github上用户或者仓库的数据指标\n * feeddd 微信公众号的rss订阅源\n * chatgpt 聊天智能ai服务，可以自动写代码。\n * corrector 一款免费的中文纠错服务\n\n\n# 娱乐\n\n * 中文播客榜\n * 异常教程 工具破解网站",charsets:{cjk:!0},lastUpdated:"2023/02/17, 11:48:27",lastUpdatedTimestamp:1676605707e3},{title:"归档",frontmatter:{archivesPage:!0,title:"归档",permalink:"/archives/",article:!1,description:"",meta:[{name:"twitter:title",content:"归档"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/@pages/archivesPage.html"},{property:"og:type",content:"article"},{property:"og:title",content:"归档"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/@pages/archivesPage.html"},{property:"og:site_name",content:"msqfx"},{itemprop:"name",content:"归档"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-6cd702fe",path:"/archives/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/08/09, 07:53:30",lastUpdatedTimestamp:166000281e4},{title:"标签",frontmatter:{tagsPage:!0,title:"标签",permalink:"/tags/",article:!1,description:"",meta:[{name:"twitter:title",content:"标签"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://www.msqfx.cc/@pages/tagsPage.html"},{property:"og:type",content:"article"},{property:"og:title",content:"标签"},{property:"og:description",content:""},{property:"og:url",content:"https://www.msqfx.cc/@pages/tagsPage.html"},{property:"og:site_name",content:"msqfx"},{itemprop:"name",content:"标签"},{itemprop:"description",content:""}],readingShow:"top"},regularPath:"/@pages/tagsPage.html",relativePath:"@pages/tagsPage.md",key:"v-16e3f17e",path:"/tags/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/08/09, 07:53:30",lastUpdatedTimestamp:166000281e4}],themeConfig:{nav:[{text:"首页",link:"/"},{text:"java",link:"/java/",items:[{text:"基础篇",link:"/pages/11aacc/"},{text:"集合篇",link:"/pages/2e780e/"},{text:"并发篇",link:"/pages/846d88/"},{text:"JVM",link:"/pages/562a37/"}]},{text:"编程",link:"/code/",items:[{text:"python之路",link:"/python/"},{text:"go之路",link:"/go/"},{text:"linux",link:"/linux/"},{text:"其他",link:"/pages/19cfb6/"}]},{text:"中间件",link:"/middleware/",items:[{text:"kafka",link:"/kafka/"},{text:"mysql",link:"/mysql/"},{text:"redis",link:"/redis/"}]},{text:"云原生",link:"/CloudNative/",items:[{text:"docker",link:"/docker/"},{text:"k8s",link:"/k8s/"}]},{text:"读书破万卷",link:"/readbook/"},{text:"关于",link:"/about/"},{text:"我的工具",items:[{text:"json格式化",link:"https://www.json.cn/"},{text:"代码片段",link:"https://ref.zhengwenfeng.com/"},{text:"ng配置格式化",link:"https://www.dute.org/nginx-config-formatter/"},{text:"corn表达式",link:"https://www.pppet.net/"}]},{text:"更多",link:"/more/",items:[{text:"收藏",link:"/pages/beb6c0bd8a66cea6/"},{text:"友链",link:"/friends/"},{text:"外部页面",items:[{text:"开往",link:"https://www.travellings.cn/go.html"}]},{text:"索引",link:"/archives/",items:[{text:"分类",link:"/categories/"},{text:"标签",link:"/tags/"},{text:"归档",link:"/archives/"}]}]}],sidebarDepth:2,logo:"/img/me.jpg",repo:"msqfx/msqfx.github.io",searchMaxSuggestions:10,lastUpdated:"上次更新",docsDir:"docs",editLinks:!1,searchPlaceholder:"按下 𝑺 搜索",sidebar:{"/00.目录/":[["01.python之路.md","python之路","/python/"],["02.go之路.md","go之路","/go/"],["03.编程.md","编程","/code/"],["04.k8s.md","k8s","/k8s/"],["05.redis.md","redis","/redis/"],["06.mysql.md","mysql","/mysql/"],["07.读书破万卷.md","读书破万卷","/readbook/"],["08.云原生.md","云原生","/CloudNative/"],["10.docker.md","docker","/docker/"],["12.kafka.md","kafka","/kafka/"],["13.中间件.md","中间件","/middleware/"],["14.linux.md","linux","/linux/"],["100.更多.md","更多","/more"]],catalogue:{java:"/","python之路":"/python/","go之路":"/go/","编程":"/code/",k8s:"/k8s/",redis:"/redis/",mysql:"/mysql/","读书破万卷":"/readbook/","云原生":"/CloudNative/",docker:"/docker/","更多":"/more",kafka:"/kafka/","中间件":"/middleware/",linux:"/linux/"},"/01.java/":[{title:"基础篇",collapsable:!0,children:[["01.基础篇/01.Java基础小结.md","Java基础小结","/pages/11aacc/"],["01.基础篇/02.Java基本数据类型.md","Java基本数据类型","/pages/b3eb48/"]]},{title:"集合篇",collapsable:!0,children:[["02.集合篇/01.Java集合概述.md","Java集合概述","/pages/2e780e/"],["02.集合篇/02.List接口.md","List接口","/pages/dcfa33/"],["02.集合篇/03.Set接口.md","Set接口","/pages/4d8b8b/"],["02.集合篇/04.Queue接口.md","Queue接口","/pages/887881/"],["02.集合篇/05.Map接口.md","Map接口","/pages/4c1680/"]]},{title:"并发篇",collapsable:!0,children:[["03.并发篇/01.Java并发基础小结.md","Java并发基础小结","/pages/846d88/"],["03.并发篇/02.锁详解.md","锁详解","/pages/5a6aca/"],["03.并发篇/03.Synchronized和Volatile的使用与区别.md","Synchronized和Volatile的使用与区别","/pages/e19c5d/"],["03.并发篇/04.线程池详解.md","线程池详解","/pages/040070/"],["03.并发篇/05.CompletableFuture学习.md","CompletableFuture学习","/pages/f6a447/"],["03.并发篇/10.Java内存管理总结.md","Java内存管理总结","/pages/277c5b/"]]},{title:"JVM",collapsable:!0,children:[["04.JVM/01.JVM基础入门.md","JVM基础入门","/pages/562a37/"],["04.JVM/02.JVM常问.md","JVM常问","/pages/ff3623/"]]}],"/01.云原生/":[{title:"docker",collapsable:!0,children:[["06.docker/01.容器的本质.md","容器的本质","/pages/f3cf17/"],["06.docker/02.docker容器.md","docker容器","/pages/39f36e/"],["06.docker/03.手动实现docker容器bridge网络模型.md","手动实现docker容器bridge网络模型","/pages/d3768c/"],["06.docker/04.docker容器单机网络.md","docker容器单机网络","/pages/0ddeb7/"]]},{title:"k8s",collapsable:!0,children:[["07.k8s/03.k8s之pod.md","k8s之Pod","/pages/2b547f/"],["07.k8s/04.k8s之deployment.md","k8s之Deployment","/pages/d73c88/"],["07.k8s/05.k8s之service.md","k8s之Service","/pages/1f860b/"],["07.k8s/06.k8s之ConfigMap和Secret.md","k8s之ConfigMap和Secret","/pages/ff8188/"],["07.k8s/07.k8s之Job和CronJob.md","k8s之Job和CronJob","/pages/c96905/"],["07.k8s/08.k8s之DaemonSet.md","k8s之DaemonSet","/pages/92bee4/"],["07.k8s/09.k8s之PV、PVC和StorageClass.md","k8s之PV、PVC和StorageClass","/pages/095c75/"],["07.k8s/10.k8s之StatefulSet.md","k8s之StatefulSet","/pages/d178a2/"],["07.k8s/11.使用kubeadm安装k8s.md","使用kubeadm安装k8s","/pages/9e17c8/"],["07.k8s/12.pod中将代码与运行环境分离.md","pod中将代码与运行环境分离","/pages/27987d/"],["07.k8s/13.django后端服务、logstash和flink接入VictoriaMetrics指标监控.md","django后端服务、logstash和flink接入VictoriaMetrics指标监控","/pages/b1b4a3/"],["07.k8s/14.理解flannel的三种容器网络方案原理.md","理解flannel的三种容器网络方案原理","/pages/d9d0ce/"],["07.k8s/15.理解calico容器网络通信方案原理.md","理解calico容器网络通信方案原理","/pages/f0f725/"],["07.k8s/16.kubernetes service如何通过iptables转发.md","kubernetes service如何通过iptables转发","/pages/b3955c/"],["07.k8s/17.kube-proxy源码分析.md","kube-proxy源码分析","/pages/6e0045/"]]}],"/03.中间件/":[{title:"kafka",collapsable:!0,children:[["01.kafka/01.listener和advertised.listeners的作用.md","kafka中listener和advertised.listeners的作用","/pages/fa114f/"]]},{title:"mysql",collapsable:!0,children:[["03.mysql/01.mysql之日志.md","mysql之日志","/pages/2d69c7/"],["03.mysql/02.mysql之MVCC原理.md","mysql之MVCC原理","/pages/0d8f4a/"]]},{title:"redis",collapsable:!0,children:[["05.redis/01.redis之五种基本数据类型.md","redis之五种基本数据类型","/pages/2bbeb3/"],["05.redis/02.redis之持久化.md","redis之持久化","/pages/4c6b13/"],["05.redis/03. redis之主从库同步.md","redis之主从库同步","/pages/8072eb/"],["05.redis/04. redis之哨兵机制.md","redis之哨兵机制","/pages/ffee9e/"],["05.redis/05. redis之分片集群.md","redis之分片集群","/pages/1c2914/"],["05.redis/06. redis之缓存.md","redis之缓存","/pages/0d7b25/"]]}],"/04.编程/":[{title:"python",collapsable:!0,children:[{title:"基础",collapsable:!0,children:[["01.python/01.基础/01.python迭代器与生成器.md","python迭代器与生成器","/pages/e31b06/"],["01.python/01.基础/02.python元编程.md","python元编程","/pages/5fa368/"],["01.python/01.基础/03.python垃圾回收机制.md","python垃圾回收机制","/pages/78c648/"],["01.python/01.基础/04.python上下文管理器.md","python上下文管理器","/pages/a6b804/"],["01.python/01.基础/05.python装饰器的使用方法.md","python装饰器的使用方法","/pages/7434f1/"],["01.python/01.基础/06.使用python实现单例模式的三种方式.md","使用python实现单例模式的三种方式","/pages/33b8d0/"],["01.python/01.基础/07.python中import原理.md","python中import原理","/pages/d8fd49/"]]},{title:"第三方库",collapsable:!0,children:[["01.python/02.第三方库/01.使用ddt实现unittest的参数化测试.md","使用ddt实现unittest的参数化测试","/pages/8d9ab9/"],["01.python/02.第三方库/02.ddt源码分析.md","ddt源码分析","/pages/069c65/"],["01.python/02.第三方库/03.django-apschedule定时任务异常停止.md","django-apschedule定时任务异常停止","/pages/ec5110/"]]},{title:"django",collapsable:!0,children:[["01.python/06.django/01.django celery 结合使用.md","django celery 结合使用","/pages/853501/"],["01.python/06.django/02.django rest_framework使用jwt.md","django rest_framework使用jwt","/pages/25eafd/"],["01.python/06.django/03.django rest_framework Authentication.md","django rest_framework Authentication","/pages/626675/"],["01.python/06.django/04.django rest_framework异常处理.md","django rest_framework异常处理","/pages/070fec/"],["01.python/06.django/05.django rest_framework 自定义文档.md","django rest_framework 自定义文档","/pages/c3af6a/"],["01.python/06.django/06.django压缩文件下载.md","django压缩文件下载","/pages/f2738b/"],["01.python/06.django/07.django rest_framework使用pytest单元测试.md","django rest_framework使用pytest单元测试","/pages/c28126/"],["01.python/06.django/08.django restframework choice 自定义输出数据.md","django restframework choice 自定义输出数据","/pages/b90015/"],["01.python/06.django/09.django Filtering 使用.md","django Filtering 使用","/pages/cfdb5f/"],["01.python/06.django/10.django viewset 和 Router 配合使用时报的错.md","django viewset 和 Router 配合使用时报的错","/pages/e75ceb/"],["01.python/06.django/11.django model的序列化.md","django model的序列化","/pages/acdd50/"],["01.python/06.django/12.django中使用AbStractUser.md","django中使用AbStractUser","/pages/382755/"],["01.python/06.django/13.django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users.md","django.core.exceptions.ImproperlyConfigured Application labels aren't unique, duplicates users","/pages/060c51/"],["01.python/06.django/14.django 中 media配置.md","django 中 media配置","/pages/de01e2/"],["01.python/06.django/15.django 外键引用自身和on_delete参数.md","django 外键引用自身和on_delete参数","/pages/b422bd/"],["01.python/06.django/16.django 警告 while time zone support is active.md","django 警告 while time zone support is active","/pages/f0d816/"],["01.python/06.django/17.django rest_framework 分页.md","django rest_framework 分页","/pages/cb262f/"]]},{title:"flask",collapsable:!0,children:[["01.python/07.flask/01.Flask使用flask_socketio实现websocket.md","Flask使用flask_socketio实现websocket","/pages/b71dc2/"],["01.python/07.flask/02.flask结合mongo.md","flask结合mongo","/pages/c59edf/"]]},{title:"tornado",collapsable:!0,children:[["01.python/08.tornado/01.tornado 文件上传.md","tornado 文件上传","/pages/4c38f5/"],["01.python/08.tornado/02.tornado 使用jwt完成用户异步认证.md","tornado 使用jwt完成用户异步认证","/pages/c24905/"],["01.python/08.tornado/03.tornado 用户密码 bcrypt加密.md","tornado 用户密码 bcrypt加密","/pages/22f35b/"],["01.python/08.tornado/04.tornado 结合wtforms使用表单操作.md","tornado 结合wtforms使用表单操作","/pages/7ac01f/"],["01.python/08.tornado/05.tornado finish和write区别.md","tornado finish和write区别","/pages/d18657/"],["01.python/08.tornado/06.tornado 使用peewee-async 完成异步orm数据库操作.md","tornado 使用peewee-async 完成异步orm数据库操作","/pages/113ab1/"]]},{title:"其他",collapsable:!0,children:[["01.python/09.其他/01.python简单使用grpc.md","python简单使用grpc","/pages/f9d78c/"],["01.python/09.其他/02.pyspark streaming简介 和 消费 kafka示例.md","pyspark streaming简介 和 消费 kafka示例","/pages/72664a/"]]}]},{title:"go",collapsable:!0,children:[["02.go/01.go简单使用grpc.md","go简单使用grpc","/pages/87014e/"],["02.go/02. gin中validator模块的源码分析.md","gin中validator模块的源码分析","/pages/c41003/"],["02.go/03.优化gin表单的错误提示信息.md","优化gin表单的错误提示信息","/pages/cf9a4d/"],["02.go/04.go中如何处理error.md","go中如何处理error","/pages/d93df5/"],["02.go/05.tcp缓存引起的日志丢失.md","tcp缓存引起的日志丢失","/pages/36b0b2/"]]},{title:"linux",collapsable:!0,children:[["03.linux/01.快速了解iptables.md","快速了解iptables","/pages/72ba9a/"],["03.linux/02.理解Linux TunTap设备.md","理解Linux TunTap设备","/pages/143447/"],["03.linux/03.理解VXLAN网络.md","理解VXLAN网络","/pages/8a4b28/"],["03.linux/04.理解Linux IPIP隧道.md","理解Linux IPIP隧道","/pages/c128e7/"]]},{title:"其他",collapsable:!0,children:[["09.其他/01.分布式锁.md","分布式锁","/pages/d91dfb/"],["09.其他/02.使用hue创建ozzie的pyspark action workflow.md","使用hue创建ozzie的pyspark action workflow","/pages/aba491/"],["09.其他/03.使用java开发logstash的filter插件.md","使用java开发logstash的filter插件","/pages/7f16f6/"],["09.其他/20.count的性能优化.md","count的性能优化","/pages/19cfb6/"]]}],"/05.读书破万卷/":[["01.如何阅读一本书.md","读书笔记:如何阅读一本书","/pages/8bdb8d/"]],"/08.关于/":[["01.关于.md","关于","/about/"]],"/09.更多/":[["01.收藏.md","网站","/pages/beb6c0bd8a66cea6/"],["02.友链.md","友链","/friends"]]},author:{name:"zhengwenfeng",link:"https://github.com/msqfx"},blogger:{avatar:"/img/me.jpg",name:"zhengwenfeng",slogan:"穷则变，变则通，通则久"},social:{icons:[{iconClass:"icon-youjian",title:"发邮件",link:"mailto:lizy928@163.com"},{iconClass:"icon-github",title:"GitHub",link:"https://github.com/msqfx"},{iconClass:"icon-rss",title:"RSS订阅",link:"https://www.msqfx.cc/rss.xml"}]},footer:{createYear:2022,copyrightInfo:'msqfx | <a href="https://github.com/msqfx/msqfx.github.io/master/LICENSE" target="_blank">MIT License</a>'},extendFrontmatter:{author:{name:"msqfx",link:"https://github.com/msqfx"},description:"",comment:!0},htmlModules:{homeSidebarB:'<div style="padding: 0.95rem">\n    <p style="\n      color: var(--textColor);\n      opacity: 0.9;\n      font-size: 20px;\n      font-weight: bold;\n      margin: 0 0 8px 0;\n    ">csdn</p>\n    <img src="/img/csdn.png"  style="width:100%;" />\n    技术博客，扫码或者搜索关注\n    </p>\n    </div>'}}};var wl=t(96),xl=t(97),El=t(11);var jl={computed:{$filterPosts(){return this.$site.pages.filter(n=>{const{frontmatter:{pageComponent:e,article:t,home:r}}=n;return!(e||!1===t||!0===r)})},$sortPosts(){return(n=this.$filterPosts).sort((n,e)=>{const t=n.frontmatter.sticky,r=e.frontmatter.sticky;return t&&r?t==r?Object(El.a)(n,e):t-r:t&&!r?-1:!t&&r?1:Object(El.a)(n,e)}),n;var n},$sortPostsByDate(){return(n=this.$filterPosts).sort((n,e)=>Object(El.a)(n,e)),n;var n},$groupPosts(){return function(n){const e={},t={};for(let r=0,a=n.length;r<a;r++){const{frontmatter:{categories:a,tags:o}}=n[r];"array"===Object(El.n)(a)&&a.forEach(t=>{t&&(e[t]||(e[t]=[]),e[t].push(n[r]))}),"array"===Object(El.n)(o)&&o.forEach(e=>{e&&(t[e]||(t[e]=[]),t[e].push(n[r]))})}return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(n){const e=[],t=[];for(let t in n.categories)e.push({key:t,length:n.categories[t].length});for(let e in n.tags)t.push({key:e,length:n.tags[e].length});return{categories:e,tags:t}}(this.$groupPosts)}}};$t.component(wl.default),$t.component(xl.default);function Al(n){return n.toString().padStart(2,"0")}t(246);$t.component("Badge",()=>Promise.all([t.e(0),t.e(3)]).then(t.bind(null,445))),$t.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,96))),$t.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,97)));t(247);var Tl=t(95),Sl=t.n(Tl),Cl=t(25);let Bl,zl,Pl;var Il;"valine"===(Il="waline")?t.e(122).then(t.t.bind(null,325,7)).then(n=>zl=n.default):"gitalk"===Il?Promise.all([t.e(0),t.e(121)]).then(t.t.bind(null,326,7)).then(()=>t.e(120).then(t.t.bind(null,327,7))).then(n=>Bl=n.default):"waline"===Il&&t.e(5).then(t.t.bind(null,328,7)).then(n=>Pl=n.default);function ql(n,e){const t={};return Reflect.ownKeys(n).forEach(r=>{if("string"==typeof n[r])try{t[r]=Sl.a.render(n[r],e)}catch(e){console.warn(`Comment config option error at key named "${r}"`),console.warn("More info: "+e.message),t[r]=n[r]}else t[r]=n[r]}),t}console.log(`How to use "waline" in ${Cl.name}@v${Cl.version}:`,Cl.homepage);const Nl={gitalk:{render(n,e){const t=document.createElement("div");t.id=e;document.querySelector("main.page").appendChild(t);new Bl(ql({serverURL:"https://comment.msqfx.cc/"},{frontmatter:n})).render(e)},clear(n){const e=document.querySelector("#"+n);return e&&e.remove(),!0}},valine:{render(n,e){const t=document.createElement("div");t.id=e;document.querySelector("main.page").appendChild(t),new zl({...ql({serverURL:"https://comment.msqfx.cc/"},{frontmatter:n}),el:"#"+e})},clear(n){const e=document.querySelector("#"+n);return e&&e.remove(),!0}},waline:{render(n,e){const t=document.createElement("div");t.id=e;document.querySelector("main.page").appendChild(t),new Pl({...ql({serverURL:"https://comment.msqfx.cc/"},{frontmatter:n}),el:"#"+e})},clear(n){const e=document.querySelector("#"+n);return e&&e.remove(),!0}}},Dl="vuepress-plugin-comment";let Fl=null;function Ol(n){let e={serverURL:"https://comment.msqfx.cc/"}.el||Dl;return e.startsWith("#")&&(e=e.slice(1)),console.log(e),Nl.waline.clear(e)}function Ll(n){return!1!==n.comment&&!1!==n.comments}function Rl(n){clearTimeout(Fl);if(!document.querySelector("main.page"))return void(Fl=setTimeout(()=>Rl(n),200));let e={serverURL:"https://comment.msqfx.cc/"}.el||Dl;return e.startsWith("#")&&(e=e.slice(1)),Nl.waline.render(n,e)}var Ml={mounted(){Fl=setTimeout(()=>{const n={to:{},from:{},...this.$frontmatter};Ol()&&Ll(n)&&Rl(n)},1e3),this.$router.afterEach((n,e)=>{if(n&&e&&n.path===e.path)return;const t={to:n,from:e,...this.$frontmatter};Ol()&&Ll(t)&&Rl(t)})}},Ul=Object(bl.a)(Ml,(function(){var n=this.$createElement;return(this._self._c||n)("div")}),[],!1,null,null,null).exports,Vl={name:"ReadingProgress",data:()=>({readingTop:0,readingHeight:1,progressStyle:null,transform:void 0,running:!1}),watch:{$readingShow(){this.progressStyle=this.getProgressStyle(),this.$readingShow&&window.addEventListener("scroll",this.base)}},mounted(){this.transform=this.getTransform(),this.progressStyle=this.getProgressStyle(),this.$readingShow&&window.addEventListener("scroll",this.base)},beforeDestroy(){this.$readingShow&&window.removeEventListener("scroll",this.base)},methods:{base(){this.running||(this.running=!0,requestAnimationFrame(this.getReadingBase))},getReadingBase(){this.readingHeight=this.getReadingHeight()-this.getScreenHeight(),this.readingTop=this.getReadingTop(),this.progressStyle=this.getProgressStyle(),this.running=!1},getReadingHeight:()=>Math.max(document.body.scrollHeight,document.body.offsetHeight,0),getScreenHeight:()=>Math.max(window.innerHeight,document.documentElement.clientHeight,0),getReadingTop:()=>Math.max(window.pageYOffset,document.documentElement.scrollTop,0),getTransform(){const n=document.createElement("div");return["transform","-webkit-transform","-moz-transform","-o-transform","-ms-transform"].find(e=>e in n.style)||void 0},getProgressStyle(){const n=this.readingTop/this.readingHeight;switch(this.$readingShow){case"top":case"bottom":return this.transform?`${this.transform}: scaleX(${n})`:`width: ${100*n}%`;case"left":case"right":return this.transform?`${this.transform}: scaleY(${n})`:`height: ${100*n}%`;default:return null}}}},Jl=(t(252),Object(bl.a)(Vl,(function(){var n=this.$createElement,e=this._self._c||n;return e("ClientOnly",[this.$readingShow?e("div",{staticClass:"reading-progress",class:this.$readingShow},[e("div",{staticClass:"progress",style:this.progressStyle})]):this._e()])}),[],!1,null,"566fc75b",null).exports),Hl=[({Vue:n,options:e,router:t,siteData:r})=>{},({Vue:n,options:e,router:t,siteData:r})=>{r.pages.map(n=>{const{frontmatter:{date:e,author:t}}=n;"string"==typeof e&&"Z"===e.charAt(e.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return`${n.getUTCFullYear()}-${Al(n.getUTCMonth()+1)}-${Al(n.getUTCDate())} ${Al(n.getUTCHours())}:${Al(n.getUTCMinutes())}:${Al(n.getUTCSeconds())}`}(e)),t?n.author=t:r.themeConfig.author&&(n.author=r.themeConfig.author)}),n.mixin(jl)},{},({Vue:n})=>{n.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},({Vue:n})=>{n.component("Comment",Ul)},({router:n})=>{"undefined"!=typeof window&&function(){var n=document.createElement("script"),e=window.location.protocol.split(":")[0];n.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(n,t)}()},({router:n})=>{"undefined"!=typeof window&&(window._hmt=window._hmt||[],function(){var n=document.createElement("script");n.src="https://hm.baidu.com/hm.js?7c28cc47ffa100de44e976f816b0b294";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(n,e)}(),n.afterEach((function(n){_hmt.push(["_trackPageview",n.fullPath])})))},({Vue:n})=>{n.component(Jl.name,Jl),n.mixin({computed:{$readingShow(){return this.$page.frontmatter.readingShow}}})}],Gl=["Comment","ReadingProgress"];class $l extends class{constructor(){this.store=new $t({data:{state:{}}})}$get(n){return this.store.state[n]}$set(n,e){$t.set(this.store.state,n,e)}$emit(...n){this.store.$emit(...n)}$on(...n){this.store.$on(...n)}}{}Object.assign($l.prototype,{getPageAsyncComponent:ii,getLayoutAsyncComponent:li,getAsyncComponent:ci,getVueComponent:pi});var Kl={install(n){const e=new $l;n.$vuepress=e,n.prototype.$vuepress=e}};function Zl(n,e){const t=e.toLowerCase();return n.options.routes.some(n=>n.path.toLowerCase()===t)}var Wl={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(n){const e=this.pageKey||this.$parent.$page.key;return ui("pageKey",e),$t.component(e)||$t.component(e,ii(e)),$t.component(e)?n(e):n("")}},Xl={functional:!0,props:{slotKey:String,required:!0},render:(n,{props:e,slots:t})=>n("div",{class:["content__"+e.slotKey]},t()[e.slotKey])},Ql={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Yl=(t(253),t(254),Object(bl.a)(Ql,(function(){var n=this.$createElement,e=this._self._c||n;return e("span",[e("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[e("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),e("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),e("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),nc={functional:!0,render(n,{parent:e,children:t}){if(e._isMounted)return t;e.$once("hook:mounted",()=>{e.$forceUpdate()})}};$t.config.productionTip=!1,$t.use(Hs),$t.use(Kl),$t.mixin(function(n,e,t=$t){!function(n){n.locales&&Object.keys(n.locales).forEach(e=>{n.locales[e].path=e});Object.freeze(n)}(e),t.$vuepress.$set("siteData",e);const r=new(n(t.$vuepress.$get("siteData"))),a=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(r)),o={};return Object.keys(a).reduce((n,e)=>(e.startsWith("$")&&(n[e]=a[e].get),n),o),{computed:o}}(n=>class{setPage(n){this.__page=n}get $site(){return n}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:n={}}=this.$site;let e,t;for(const r in n)"/"===r?t=n[r]:0===this.$page.path.indexOf(r)&&(e=n[r]);return e||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:n}=this.$page.frontmatter;return"string"==typeof n&&n}get $title(){const n=this.$page,{metaTitle:e}=this.$page.frontmatter;if("string"==typeof e)return e;const t=this.$siteTitle,r=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?r?r+" | "+t:t:r||"VuePress"}get $description(){const n=function(n){if(n){const e=n.filter(n=>"description"===n.name)[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(n,e){for(let t=0;t<n.length;t++){const r=n[t];if(r.path.toLowerCase()===e.toLowerCase())return r}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},kl)),$t.component("Content",Wl),$t.component("ContentSlotsDistributor",Xl),$t.component("OutboundLink",Yl),$t.component("ClientOnly",nc),$t.component("Layout",li("Layout")),$t.component("NotFound",li("NotFound")),$t.prototype.$withBase=function(n){const e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.5",hash:"a23c0e0"},async function(n){const e="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:kl.routerBase||kl.base,t=new Hs({base:e,mode:"history",fallback:!1,routes:_l,scrollBehavior:(n,e,t)=>t||(n.hash?!$t.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})});!function(n){n.beforeEach((e,t,r)=>{if(Zl(n,e.path))r();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){const t=e.path.replace(/\/$/,"")+".html";Zl(n,t)?r(t):r()}else r();else{const t=e.path+"/",a=e.path+".html";Zl(n,a)?r(a):Zl(n,t)?r(t):r()}})}(t);const r={};try{await Promise.all(Hl.filter(n=>"function"==typeof n).map(e=>e({Vue:$t,options:r,router:t,siteData:kl,isServer:n})))}catch(n){console.error(n)}return{app:new $t(Object.assign(r,{router:t,render:n=>n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},Gl.map(e=>n(e)))])})),router:t}}(!1).then(({app:n,router:e})=>{e.onReady(()=>{n.$mount("#app")})})}]);