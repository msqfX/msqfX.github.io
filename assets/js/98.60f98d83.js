(window.webpackJsonp=window.webpackJsonp||[]).push([[98],{423:function(t,s,a){"use strict";a.r(s);var n=a(0),r=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"简介"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#简介"}},[t._v("#")]),t._v(" 简介")]),t._v(" "),a("blockquote",[a("p",[t._v("并不是真正的实时处理框架，只是按照时间进行微批处理进行，时间可以设置的尽可能的小。")])]),t._v(" "),a("blockquote",[a("p",[t._v("将不同的额数据源的数据经过SparkStreaming 处理之后将结果输出到外部文件系统")])]),t._v(" "),a("ul",[a("li",[t._v("特点")])]),t._v(" "),a("blockquote",[a("p",[t._v("低延时\n能从错误中搞笑的恢复: fault-tolerant\n能够运行在成百上千的节点\n能够将批处理、机器学习、图计算等自框架和Spark Streaming 综合起来使用")])]),t._v(" "),a("ul",[a("li",[t._v("粗粒度")])]),t._v(" "),a("blockquote",[a("p",[t._v("Spark Streaming接收到实时数据流，把数据按照指定的时间段切成一片片小的数据块，然后把小的数据块传给Spark Engine处理。")])]),t._v(" "),a("ul",[a("li",[a("p",[t._v("细粒度\n"),a("img",{attrs:{src:"https://img-blog.csdnimg.cn/20190416164155495.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIyOTE4MjQz,size_16,color_FFFFFF,t_70",alt:"在这里插入图片描述"}})])]),t._v(" "),a("li",[a("p",[t._v("数据源\nkafka提供了两种数据源。")])])]),t._v(" "),a("ol",[a("li",[t._v("基础数据源，可以直接通过streamingContext API实现。如"),a("code",[t._v("文件系统")]),t._v("和"),a("code",[t._v("socket连接")])]),t._v(" "),a("li",[t._v("高级的数据源，如Kafka, Flume, Kinesis等等. 可以通过额外的类库去实现。")])]),t._v(" "),a("h2",{attrs:{id:"基础数据源"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基础数据源"}},[t._v("#")]),t._v(" 基础数据源")]),t._v(" "),a("ol",[a("li",[t._v("使用官方的案例")])]),t._v(" "),a("p",[t._v("/spark/examples/src/main/python/streaming")]),t._v(" "),a("p",[t._v("nc -lk 6789")]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[t._v("处理socket数据\n"),a("img",{attrs:{src:"https://img-blog.csdnimg.cn/20190416164215686.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzIyOTE4MjQz,size_16,color_FFFFFF,t_70",alt:"在这里插入图片描述"}})])]),t._v(" "),a("p",[t._v("示例代码如下: 读取socket中的数据进行流处理")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pyspark "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SparkContext\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pyspark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" StreamingContext\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# local 必须设为2")]),t._v("\nsc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SparkContext"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"NetworkWordCount"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nssc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" StreamingContext"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nlines "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("socketTextStream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"localhost"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("9999")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nwords "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" lines"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" line"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" line"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\npairs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" words"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" word"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nwordCounts "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pairs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nwordCounts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nssc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nssc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br")])]),a("p",[t._v("测试")]),t._v(" "),a("blockquote",[a("p",[t._v("nc -lk 9999")])]),t._v(" "),a("ol",{attrs:{start:"3"}},[a("li",[t._v("处理文件系统数据")])]),t._v(" "),a("blockquote",[a("p",[t._v("文件系统(fileStream(that is, HDFSM S3, NFS))暂不支持python，python仅支持文本文件(textFileStream)")])]),t._v(" "),a("p",[t._v("示例如下，但未成功，找不到该文件。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("\nlines "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ssc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFileStream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hdfs://txz-data0:9820/user/jim/workflow/crash/python/crash_2_hdfs.py"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br")])]),a("ul",[a("li",[a("p",[t._v("streaming context")])]),t._v(" "),a("li",[a("p",[t._v("DStreams")])])]),t._v(" "),a("blockquote",[a("p",[t._v("持续化的数据流\n对DStream操作算子， 比如map/flatMap,其实底层会被翻译为对DStream中的每个RDD都做相同的操作，因为一个DStream是由不同批次的RDD所")])]),t._v(" "),a("ul",[a("li",[t._v("Input DStreams and Receivers")])]),t._v(" "),a("h2",{attrs:{id:"高级数据源"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#高级数据源"}},[t._v("#")]),t._v(" 高级数据源")]),t._v(" "),a("h3",{attrs:{id:"spark-streaming-和-kafka-整合"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#spark-streaming-和-kafka-整合"}},[t._v("#")]),t._v(" Spark Streaming 和 kafka 整合")]),t._v(" "),a("p",[t._v("两种模式")]),t._v(" "),a("ul",[a("li",[t._v("receiver 模式")])]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pyspark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("kafka "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" KafkaUtils\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pyspark "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" SparkContext\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" pyspark"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("streaming "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" StreamingContext\n\nsc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" SparkContext"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"local[2]"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"NetworkWordCount"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("setLogLevel"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"OFF"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nssc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" StreamingContext"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("sc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 创建Kafka streaming")]),t._v("\nline "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" KafkaUtils"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createStream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ssc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"192.168.0.208:2181"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'test'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jim_test"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分词")]),t._v("\nwords "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" line"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" line"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" line"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npairs "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" words"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("map")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" word"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nwordCounts "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pairs"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("lambda")]),t._v(" x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" x "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nwordCounts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("pprint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nssc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("start"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nssc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("awaitTermination"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br")])]),a("ul",[a("li",[t._v("no receiver")])]),t._v(" "),a("p",[t._v("根据上面的代码替换掉createStream即可。")]),t._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("line "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" KafkaUtils"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createDirectStream"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ssc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"jim_test"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"metadata.broker.list"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"192.168.0.208:9092"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br")])]),a("p",[t._v("运行:")]),t._v(" "),a("blockquote",[a("p",[t._v("spark-submit --jars spark-streaming-kafka-0-8-assembly_2.11-2.4.0.jar  test_spark_stream.py")])]),t._v(" "),a("p",[t._v("需要下载相应的jar包.下载地址如下，搜索。\nhttps://search.maven.org")]),t._v(" "),a("p",[t._v("jar版本会在运行程序时报错提醒。")])])}),[],!1,null,null,null);s.default=r.exports}}]);